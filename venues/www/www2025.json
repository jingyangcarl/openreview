[
    {
        "id": "0TydpJriuR",
        "title": "Towards Safe Machine Unlearning: a Paradigm that Mitigates Performance Degradation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the machine unlearning problem which aims to remove specific training data from a pre-trained machine learning model to allow users to exercise their \u2018right to be forgotten\u2019 to protect user privacy. Conventional machine unlearning methods would degrade the model performance after the unlearning procedure. To mitigate the issue, they typically rely on the access to the remaining training data to fine-tune the unlearned model to mitigate the influence of unlearning. However, accessing the remaining training data may not always be practical for different reasons (e.g., data expiration policies, storage limitations, or additional privacy constraints). Machine unlearning without access to the remaining training data poses significant challenges to retaining model performance. In this paper, we study how to unlearn specific training data from a pre-trained model without accessing the remaining training data and protect model performance without dramatically changing the model's parameters. We propose a practical method called Targeted Label Noise Injection. Intuitively, our method assigns incorrect yet controllable labels to the examples that need to be forgotten and fine-tunes the pre-trained model to learn these new labels. This strategy effectively moves the to-be-forgotten examples across the decision boundary with a small impact on the model's overall performance. We theoretically prove the effectiveness of the proposed method and empirically show that it achieves state-of-the-art unlearning performance across various datasets.",
        "keywords": "Privacy protection;machine unlearning;trustworthy machine learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shanshan Ye;Jie Lu;Guangquan Zhang",
        "authorids": "~Shanshan_Ye1;~Jie_Lu4;~Guangquan_Zhang2",
        "gender": "F;;",
        "homepage": "https://cassie133ye.github.io/;;",
        "dblp": "362/6685;;",
        "google_scholar": ";;_1RMrhsAAAAJ",
        "orcid": "0009-0003-6961-7455;;",
        "linkedin": ";;",
        "or_profile": "~Shanshan_Ye1;~Jie_Lu4;~Guangquan_Zhang2",
        "aff": "University of Technology Sydney;;University of Technology Sydney (UTS)",
        "aff_domain": "uts.edu.au;;uts.eud.au",
        "position": "PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\nye2025towards,\ntitle={Towards Safe Machine Unlearning: a Paradigm that Mitigates Performance Degradation},\nauthor={Shanshan Ye and Jie Lu and Guangquan Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=0TydpJriuR}\n}",
        "github": "",
        "project": "",
        "reviewers": "fcH6;bTwy;hrwF;P2de",
        "site": "https://openreview.net/forum?id=0TydpJriuR",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;5;4;3",
        "scope": "3;3;3;3",
        "confidence": "4;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.816496580927726
    },
    {
        "id": "0kfANA2Aa6",
        "title": "NoTeNet: Normalized Mutual Information-Driven Tuning-free Dynamic Dependence Network Inference Method for Multimodal Data",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Dynamic Dependence Network (DDN) inference is crucial for understanding evolving relationships in multimodal time series web data, with broad applications in fields like medical and financial network analysis. \nThe inherent dynamic nature, temporal continuity, and heterogeneous data sources in multimodal time series data pose three fundamental challenges: computational efficiency, prediction stability and robustness, and modality quality disparity.\nPrevious methods, generally lacking utilization of multiple modalities, either struggle with computational efficiency due to the time-intensive manual hyperparameter tuning, or compromise prediction stability and robustness by neglecting temporal coherence.\nTo address these challenges, we propose a Normalized mutual information-driven Tuning-free Dynamic Dependence Network inference method for multimodal data, namely NoTeNet. \nNoTeNet provides a promising paradigm that can integrate two different data modalities to enhance prediction accuracy. It uses normalized mutual information transforms noisy auxiliary data into relationship matrices and employs a kernel function for smooth temporal estimation. Additionally, NoTeNet significantly reduces the need for manual hyperparameter adjustments, offering a tuning-free approach with theoretical guarantees.\nOn various synthetic datasets and real-world data, NoTeNet demonstrates superior prediction accuracy and efficiency without the need for hyperparameter tuning, making it potential for a wide range of web data applications.",
        "keywords": "Dynamic Dependence Network;Multimodal Fusion;Web Time Series Data",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiao Tan;Yangyang Shen;Yan Zhang;Jingwen Shao;Dian Shen;Meng Wang;Beilun Wang",
        "authorids": "~Xiao_Tan5;~Yangyang_Shen1;~Yan_Zhang40;~Jingwen_Shao1;~Dian_Shen1;~Meng_Wang11;~Beilun_Wang1",
        "gender": "F;M;F;F;M;;M",
        "homepage": "https://github.com/MahjongGod-Saki;https://github.com/SYYatSEU;https://github.com/YanZhang1014;https://github.com/Dayflyyy;https://dianshenseu.github.io/en/;;https://cse.seu.edu.cn/2019/0105/c23024a257533/pagem.htm",
        "dblp": "116/7143-5;;;;139/4309;;180/5592",
        "google_scholar": ";;;;;;",
        "orcid": "0000-0002-3874-9557;;;;;;0000-0002-2646-1492",
        "linkedin": ";;;;;;",
        "or_profile": "~Xiao_Tan5;~Yangyang_Shen1;~Yan_Zhang40;~Jingwen_Shao1;~Dian_Shen1;~Meng_Wang11;~Beilun_Wang1",
        "aff": "Southeast University;Southeast University;Southeast University;Southeast University;Southeast University;;Southeast University",
        "aff_domain": "seu.edu.cn;seu.edu.cn;seu.edu.cn;seu.edu.cn;seu.edu.cn;;seu.edu.cn",
        "position": "PhD student;MS student;PhD student;Undergrad student;Associate Professor;;Associate Professor",
        "bibtex": "@inproceedings{\ntan2025notenet,\ntitle={NoTeNet: Normalized Mutual Information-Driven Tuning-free Dynamic Dependence Network Inference Method for Multimodal Data},\nauthor={Xiao Tan and Yangyang Shen and Yan Zhang and Jingwen Shao and Dian Shen and Meng Wang and Beilun Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=0kfANA2Aa6}\n}",
        "github": "",
        "project": "",
        "reviewers": "MyH5;oMvU;RdCH;wnv1;gAsR",
        "site": "https://openreview.net/forum?id=0kfANA2Aa6",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "5;5;4;5;5",
        "scope": "3;3;3;3;3",
        "confidence": "1;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.8,
            0.39999999999999997
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9185586535436918
    },
    {
        "id": "13lFc9v7f0",
        "title": "SmoothGNN: Smoothing-aware GNN for Unsupervised Node Anomaly Detection",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The smoothing issue in graph learning leads to indistinguishable node representations, posing significant challenges for graph-related tasks. However, our experiments reveal that this problem can uncover underlying properties of node anomaly detection (NAD) that previous research has missed. We introduce Individual Smoothing Patterns (ISP) and Neighborhood Smoothing Patterns (NSP), which indicate that the representations of anomalous nodes are harder to smooth than those of normal ones. In addition, we explore the theoretical implications of these patterns, demonstrating the potential benefits of ISP and NSP for NAD tasks.\nMotivated by these findings, we propose SmoothGNN, a novel unsupervised NAD framework. First, we design a learning component to explicitly capture ISP for detecting node anomalies. Second, we design a spectral graph neural network to implicitly learn ISP to enhance detection. Third, we design an effective coefficient based on our findings that NSP can serve as coefficients for node representations, aiding in the identification of anomalous nodes. Furthermore, we devise a novel anomaly measure to calculate loss functions and anomalous scores for nodes, reflecting the properties of NAD using ISP and NSP. Extensive experiments on 9 real datasets show that SmoothGNN outperforms the best rival by an average of 14.66% in AUC and 7.28% in Average Precision, with 75x running time speedup, validating the effectiveness and efficiency of our framework.",
        "keywords": "Unsupervised Node Anomaly Detection;Spectral GNN;Smoothing Patterns",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiangyu Dong;Xingyi Zhang;Yanni Sun;Lei Chen;Mingxuan Yuan;Sibo Wang",
        "authorids": "~Xiangyu_Dong2;~Xingyi_Zhang1;~Yanni_Sun3;~Lei_Chen26;~Mingxuan_Yuan1;~Sibo_Wang3",
        "gender": ";M;F;;M;M",
        "homepage": "https://xydong127.github.io/;http://josiah96zhang.github.io/;https://yannisun.github.io/;https://scholar.google.com/citations?user=73rBLl4AAAAJ&hl=en;;https://www1.se.cuhk.edu.hk/~swang/",
        "dblp": "84/3152-2.html;93/1107-3;;;74/2356;131/6529-1",
        "google_scholar": ";j_o_XDkAAAAJ;;73rBLl4AAAAJ;https://scholar.google.com/citations?hl=en;b2gLqsgAAAAJ",
        "orcid": "0009-0009-6312-8160;0000-0001-5203-5916;;;0000-0002-2236-8784;0000-0003-1892-6971",
        "linkedin": ";xingyi-zhang-769338204/;;;;sibo-wang-b6a60941/?originalSubdomain=hk",
        "or_profile": "~Xiangyu_Dong2;~Xingyi_Zhang1;~Yanni_Sun3;~Lei_Chen26;~Mingxuan_Yuan1;~Sibo_Wang3",
        "aff": "Chinese University of Hong Kong;Mohamed bin Zayed University of Artificial Intelligence;City University of Hong Kong;Huawei Technologies Ltd.;Huawei Technologies Ltd.;The Chinese University of Hong Kong",
        "aff_domain": "cuhk.hk;mbzuai.ac.ae;cityu.edu.hk;huawei.com;huawei.com;cuhk.edu.hk",
        "position": "PhD student;Postdoc;Full Professor;Researcher;Researcher;Associate Professor",
        "bibtex": "@inproceedings{\ndong2025smoothgnn,\ntitle={Smooth{GNN}: Smoothing-aware {GNN} for Unsupervised Node Anomaly Detection},\nauthor={Xiangyu Dong and Xingyi Zhang and Yanni Sun and Lei Chen and Mingxuan Yuan and Sibo Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=13lFc9v7f0}\n}",
        "github": "",
        "project": "",
        "reviewers": "CgwL;W9sy;WH6K;7hVn;MD9z;QiMS",
        "site": "https://openreview.net/forum?id=13lFc9v7f0",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6;6",
        "technical_quality": "3;6;4;5;6;6",
        "scope": "4;4;4;4;4;4",
        "confidence": "3;3;3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.166666666666667,
            0.6871842709362768
        ],
        "technical_quality_avg": [
            5.0,
            1.1547005383792515
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.5773502691896257
        ],
        "replies_avg": [
            6,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.42008402520840293
    },
    {
        "id": "14cNPqydxL",
        "title": "MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The vision of Web3 is to improve user control over data and assets, but one challenge that complicates this vision is the prevalence of non-transparent, scam-prone applications and vulnerable smart contracts that put web3 users at risk. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code. MAD empowers developers to understand and audit contracts easily and independently.\n\nOur evaluation shows that MAD produces logically correct code that successfully passes original unit tests and achieves a 66.7\\% recompilation success rate on real-world smart contracts. Additionally, in a user study involving 12 developers, MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD\u2019s outputs comparable to the original source code, simplifying the process of smart contract logic comprehension and auditing. Despite some limitations, such as occasional hallucinations and compile errors, MAD still provides significant improvements over traditional decompilers.\n\nMAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to review and audit non-open-source smart contracts, fostering trust and accountability. Additionally, MAD's approach could potentially extend to other smart contract languages, like Solidity, promoting transparency across various blockchains.",
        "keywords": "Web3;Smart Contract;Auditing Tools;Large Language Models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eason Chen;Xinyi Tang;Zimo Xiao;Chuangji Li;Shizhuo Li;Wu Tingguan;Siyun Wang;Kostas Kryptos Chalkias",
        "authorids": "~Eason_Chen1;~Xinyi_Tang2;~Zimo_Xiao1;~Chuangji_Li1;~Shizhuo_Li1;~Wu_Tingguan1;~Siyun_Wang2;~Kostas_Kryptos_Chalkias1",
        "gender": ";F;M;M;M;M;F;M",
        "homepage": "https://eason.best;https://tessietang.com;https://www.researchgate.net/profile/Zimo_Xiao;https://www.georgeli.top/;https://shizhuo-profile.com/;;;",
        "dblp": ";;;;;;;",
        "google_scholar": "https://scholar.google.com.tw/citations?user=SMOPejMAAAAJ;;;;;;;https://scholar.google.ca/citations?hl=en",
        "orcid": "0000-0003-1486-8559;;;;;;;",
        "linkedin": "easonc13;;;chuangji-li-8526a527a/;shizhuo-li-206109223/;tingguan-wu/;siyun-wang-b5604321b;",
        "or_profile": "~Eason_Chen1;~Xinyi_Tang2;~Zimo_Xiao1;~Chuangji_Li1;~Shizhuo_Li1;~Wu_Tingguan1;~Siyun_Wang2;~Kostas_Kryptos_Chalkias1",
        "aff": "Carnegie Mellon University, School of Computer Science, Human-Computer Interaction Institute;;;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Carnegie Mellon University;Mysten Labs",
        "aff_domain": "hcii.cmu.edu;;;cmu.edu;andrew.cmu.edu;cmu.edu;cmu.edu;mystenlabs.com",
        "position": "PhD student;;;Undergrad student;Undergrad student;Undergrad student;Undergrad student;Chief Cryptographer",
        "bibtex": "@inproceedings{\nchen2025mad,\ntitle={{MAD}: Move {AI} Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract},\nauthor={Eason Chen and Xinyi Tang and Zimo Xiao and Chuangji Li and Shizhuo Li and Wu Tingguan and Siyun Wang and Kostas Kryptos Chalkias},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=14cNPqydxL}\n}",
        "github": "",
        "project": "",
        "reviewers": "iucK;n2hA;3Lwx",
        "site": "https://openreview.net/forum?id=14cNPqydxL",
        "pdf_size": 0,
        "novelty": "4;5;6",
        "technical_quality": "4;6;4",
        "scope": "3;4;4",
        "confidence": "3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.816496580927726
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.9428090415820634
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "1Hfhp9BhI5",
        "title": "Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Fairness and relevance are two important aspects of recommender systems (RSs). Typically, they are evaluated either (i) separately by individual measures of fairness and relevance, or (ii) jointly using a single measure that accounts for fairness with respect to relevance. However, approach (i) often does not provide a reliable joint estimate of the goodness of the models, as it has two different best models: one for fairness and another for relevance. Approach (ii) is also problematic because these measures tend to be ad-hoc and do not relate well to traditional relevance measures, like NDCG. Motivated by this, we present a new approach for jointly evaluating fairness and relevance in RSs: distance from pareto frontier (DPFR). Given a user-item interaction dataset, we compute their Pareto frontier for a pair of existing relevance and fairness measures, and then use the distance from the frontier as a measure of the jointly achievable fairness and relevance. Our approach is modular and intuitive as it can be computed with existing measures. Experiments with 4 RS models, 3 re-ranking strategies, and 6 datasets show that the existing metrics have inconsistent associations with our Pareto-optimal solution, making DPFR a more robust and theoretically well-founded joint measure for assessing both fairness and relevance.",
        "keywords": "evaluation;relevance;fairness;pareto frontier;recommendation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Theresia Veronika Rampisela;Tuukka Ruotsalo;Maria Maistro;Christina Lioma",
        "authorids": "~Theresia_Veronika_Rampisela1;~Tuukka_Ruotsalo2;~Maria_Maistro1;~Christina_Lioma1",
        "gender": ";M;F;F",
        "homepage": ";https://www.cs.helsinki.fi/group/intercom/#home;;",
        "dblp": ";06/4486;147/9095;http://dblp.uni-trier.de/pers/hd/l/Lioma:Christina",
        "google_scholar": ";https://scholar.google.com/citations?hl=fi;QV3v_8kAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";;0000-0002-7001-4817;",
        "linkedin": ";;;",
        "or_profile": "~Theresia_Veronika_Rampisela1;~Tuukka_Ruotsalo2;~Maria_Maistro1;~Christina_Lioma1",
        "aff": ";Lappeenranta University of Technology+University of Copenhagen+University of Helsinki;University of Copenhagen;University of Copenhagen",
        "aff_domain": ";lut.fi+diku.dk+helsinki.fi;ku.dk;ku.dk",
        "position": ";Associate Professor+Associate Professor+Research Fellow;Assistant Professor;Professor",
        "bibtex": "@inproceedings{\nrampisela2025joint,\ntitle={Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier},\nauthor={Theresia Veronika Rampisela and Tuukka Ruotsalo and Maria Maistro and Christina Lioma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=1Hfhp9BhI5}\n}",
        "github": "",
        "project": "",
        "reviewers": "yVJj;fk2C;XYkR;SMTi",
        "site": "https://openreview.net/forum?id=1Hfhp9BhI5",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "4;4;6;6",
        "scope": "3;4;3;4",
        "confidence": "2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            5.0,
            1.0
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7745966692414834
    },
    {
        "id": "1MrGgYF5YF",
        "title": "FG-CIBGC: A Unified Framework for Fine-Grained and Class-Incremental Behavior Graph Classification",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Learning-based Behavior Graph Classification (BGC) has been widely adopted in Internet infrastructure for partitioning and identifying similar behavior graphs. However, the research communities realize significant limitations when deploying existing proposals in real-world scenarios.  The challenges are mainly concerned with (i) fine-grained emerging behavior graphs, and (ii) incremental model adaptations. To tackle these problems, we propose to (i) mine semantics in multi-source logs using Large Language Models (LLMs) under In-Context Learning (ICL), and (ii) bridge the gap between Out-Of-Distribution (OOD) detection and class-incremental graph learning. Based on the above core ideas, we develop the first unified framework termed as $\\textbf{F}$ine-$\\textbf{G}$rained and $\\textbf{C}$lass-$\\textbf{I}$ncremental $\\textbf{B}$ehavior $\\textbf{G}$raph $\\textbf{C}$lassification ($\\textbf{FG-CIBGC}$). It consists of two novel modules, i.e., gPartition and gAdapt, that are used for partitioning fine-grained graphs and performing unknown class detection and adaptation, respectively. To validate the efficacy of FG-CIBGC, we introduce a new benchmark, comprising a new 4,992-graph, 32-class dataset generated from 8 attack scenarios, as well as a novel Edge Intersection over Union (EIoU) metric for evaluation. Extensive experiments demonstrate FG-CIBGC's superior performance on fine-grained and class-incremental BGC tasks, as well as its ability to generate fine-grained behavior graphs that facilitate downstream tasks. The code and dataset are available at: https://anonymous.4open.science/r/FG-CIBGC-70BC/README.md.",
        "keywords": "Fine-grained Behavior Graph Classification;Class-Incremental Graph Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhibin Ni;Pan Fan;Shengzhuo Dai;Bo Zhang;Hai Wan;Xibin Zhao",
        "authorids": "~Zhibin_Ni1;~Pan_Fan1;~Shengzhuo_Dai1;~Bo_Zhang36;~Hai_Wan1;~Xibin_Zhao1",
        "gender": "M;;;M;M;M",
        "homepage": "https://thss-sec.github.io/posts/;;;https://thss-sec.github.io/posts;https://www.thss.tsinghua.edu.cn/en/faculty/haiwan.htm;http://www.thss.tsinghua.edu.cn/publish/soften/3131/2010/20101219192857877627039/20101219192857877627039_.html",
        "dblp": "396/8118;;;36/2259-10;54/977;62/5754",
        "google_scholar": ";;;;Qg0Xq9wAAAAJ;",
        "orcid": ";;;0009-0002-0123-6632;0000-0002-9608-5808;",
        "linkedin": ";;;;;",
        "or_profile": "~Zhibin_Ni1;~Pan_Fan1;~Shengzhuo_Dai1;~Bo_Zhang36;~Hai_Wan1;~Xibin_Zhao1",
        "aff": "Tsinghua University;;;Tsinghua University;Tsinghua University;Tsinghua University",
        "aff_domain": "mail.tsinghua.edu.cn;;;tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn",
        "position": "PhD student;;;MS student;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nni2025fgcibgc,\ntitle={{FG}-{CIBGC}: A Unified Framework for Fine-Grained and Class-Incremental Behavior Graph Classification},\nauthor={Zhibin Ni and Pan Fan and Shengzhuo Dai and Bo Zhang and Hai Wan and Xibin Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=1MrGgYF5YF}\n}",
        "github": "",
        "project": "",
        "reviewers": "hAEB;pXbA;Wd8n;H17m;hDZD;NtLm;PvpX",
        "site": "https://openreview.net/forum?id=1MrGgYF5YF",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6;6;7",
        "technical_quality": "2;4;3;5;7;6;5",
        "scope": "3;3;4;3;4;4;3",
        "confidence": "4;3;4;4;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.3093073414159542
        ],
        "technical_quality_avg": [
            4.571428571428571,
            1.5907898179514348
        ],
        "scope_avg": [
            3.4285714285714284,
            0.4948716593053935
        ],
        "confidence_avg": [
            3.7142857142857144,
            0.45175395145262565
        ],
        "replies_avg": [
            7,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "2QWP4qWVym",
        "title": "Fairness Evaluation with Item Response Theory",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Item Response Theory (IRT) has been widely used in educational psychometrics to assess student ability, as well as the difficulty and discrimination of test questions. In this context, discrimination specifically refers to how effectively a question distinguishes between students of different ability levels, and it does not carry any connotation related to fairness. In recent years, IRT has been successfully used to evaluate the predictive performance of Machine Learning (ML) models, but this paper marks its first application in fairness evaluation. In this paper, we propose a novel Fair-IRT framework to evaluate a set of predictive models on a set of individuals, while simultaneously eliciting specific parameters, namely, the ability to make fair predictions (a feature of predictive models), as well as the discrimination and difficulty of individuals that affect the prediction results. Furthermore, we conduct a series of experiments to comprehensively understand the implications of these parameters for fairness evaluation. Detailed explanations for item characteristic curves (ICCs) are provided for particular individuals. We propose the flatness of ICCs to disentangle the unfairness between individuals and predictive models. The experiments demonstrate the effectiveness of this framework as a fairness evaluation tool. Two real-world case studies illustrate its potential application in evaluating fairness in both classification and regression tasks. Our paper aligns well with the Responsible Web track by proposing a Fair-IRT framework to evaluate fairness in ML models, which directly contributes to the development of a more inclusive, equitable, and trustworthy AI.",
        "keywords": "Fairness Evaluation;Item Response Theory",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ziqi Xu;Sevvandi Kandanaarachchi;Cheng Soon Ong;Eirini Ntoutsi",
        "authorids": "~Ziqi_Xu1;~Sevvandi_Kandanaarachchi1;~Cheng_Soon_Ong1;~Eirini_Ntoutsi1",
        "gender": "M;;M;F",
        "homepage": "https://iron13.github.io/;https://people.csiro.au/K/S/sevvandi-kandanaarachchi;https://ong-home.my;https://aiml-research.github.io/",
        "dblp": "255/6518-1;172/8080;58/2283;n/IreneNtoutsi",
        "google_scholar": "znODztEAAAAJ;XIC1yhMAAAAJ;ofMZr0IAAAAJ;RdA9uxYAAAAJ",
        "orcid": "0000-0003-1748-5801;0000-0002-0337-0395;0000-0002-2302-9733;0000-0001-5729-1003",
        "linkedin": "ziqi-xu-846510113/;;cheng-soon-ong-38bbb524/;https://de.linkedin.com/in/eirinintoutsi",
        "or_profile": "~Ziqi_Xu1;~Sevvandi_Kandanaarachchi1;~Cheng_Soon_Ong1;~Eirini_Ntoutsi1",
        "aff": "Royal Melbourne Institute of Technology;CSIRO;Australian National University+CSIRO;University of the Bundeswehr Munich",
        "aff_domain": "rmit.edu.au;data61.csiro.au;anu.edu.au+csiro.au;unibw.de",
        "position": "Assistant Professor;Researcher;Associate Professor+Principal Researcher;Full Professor",
        "bibtex": "@inproceedings{\nxu2025fairness,\ntitle={Fairness Evaluation with Item Response Theory},\nauthor={Ziqi Xu and Sevvandi Kandanaarachchi and Cheng Soon Ong and Eirini Ntoutsi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=2QWP4qWVym}\n}",
        "github": "",
        "project": "",
        "reviewers": "HVTu;qMH2;XGSX;cstd",
        "site": "https://openreview.net/forum?id=2QWP4qWVym",
        "pdf_size": 0,
        "novelty": "4;5;5;7",
        "technical_quality": "4;4;5;7",
        "scope": "3;3;3;3",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            5.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.13245323570650439
    },
    {
        "id": "2ZaqnRIUCV",
        "title": "Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Retrieval-augmented generation (RAG) has demonstrated effectiveness in mitigating the hallucination problem of large language models (LLMs). However, the difficulty of aligning the retriever with the diverse LLMs' knowledge preferences inevitably poses an inevitable challenge in developing a reliable RAG system. To address this issue, we propose DPA-RAG, a universal framework designed to align diverse knowledge preferences within RAG systems. Specifically, we initially introduce a preference knowledge construction pipline and incorporate five novel query augmentation strategies to alleviate preference data scarcity. Based on preference data, DPA-RAG accomplishes both external and internal preference alignment: 1) It jointly integrate pair-wise, point-wise, and contrastive preference alignment abilities into the reranker, achieving external preference alignment among RAG components. 2) It further introduces a pre-aligned stage before vanilla Supervised Fine-tuning (SFT), enabling LLMs to implicitly capture knowledge aligned with their reasoning preferences, achieving LLMs' internal alignment. Experimental results across four knowledge-intensive QA datasets demonstrate that DPA-RAG outperforms all baselines and seamlessly integrates both black-box and open-sourced LLM readers. Further qualitative analysis and discussions also provide empirical guidance for achieving reliable RAG systems.",
        "keywords": "Retrieval-Augmented Generation;Large Language Models;Preference Alignment",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Guanting Dong;Yutao Zhu;Chenghao Zhang;Zechen Wang;Ji-Rong Wen;Zhicheng Dou",
        "authorids": "~Guanting_Dong1;~Yutao_Zhu1;~Chenghao_Zhang3;~Zechen_Wang1;~Ji-Rong_Wen1;~Zhicheng_Dou1",
        "gender": "M;M;M;M;M;",
        "homepage": "https://dongguanting.github.io/;https://daod.github.io;https://SnowNation101.github.io/;https://github.com/Zechen-W;https://gsai.ruc.edu.cn/english/jrwen;https://playbigdata.ruc.edu.cn/dou",
        "dblp": ";71/9704-1;;;w/JRWen;18/5740",
        "google_scholar": "amozZDkAAAAJ;tBqVOWsAAAAJ;q4CnV3oAAAAJ;;tbxCHJgAAAAJ;ChCjAAwAAAAJ",
        "orcid": "0000-0002-2318-0281;0000-0002-9432-3251;0009-0008-8399-2258;;0000-0002-9777-9676;0000-0002-9781-948X",
        "linkedin": ";;;;;",
        "or_profile": "~Guanting_Dong1;~Yutao_Zhu1;~Chenghao_Zhang3;~Zechen_Wang1;~Ji-Rong_Wen1;~Zhicheng_Dou1",
        "aff": "Renmin University of China;Renmin University of China;Renmin University of China;;Renmin University of China;Renmin University of China",
        "aff_domain": "ruc.edu.cn;ruc.edu.cn;ruc.edu.cn;;ruc.edu.cn;ruc.edu.cn",
        "position": "PhD student;Postdoc;PhD student;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ndong2025understand,\ntitle={Understand What {LLM} Needs: Dual Preference Alignment for Retrieval-Augmented Generation},\nauthor={Guanting Dong and Yutao Zhu and Chenghao Zhang and Zechen Wang and Ji-Rong Wen and Zhicheng Dou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=2ZaqnRIUCV}\n}",
        "github": "",
        "project": "",
        "reviewers": "fGTa;hkAH;U8a3;beCQ;QQsJ",
        "site": "https://openreview.net/forum?id=2ZaqnRIUCV",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "5;6;5;5;4",
        "scope": "4;4;4;3;4",
        "confidence": "3;4;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.408248290463863
    },
    {
        "id": "2c2ec6VlgK",
        "title": "Unlearning Incentivizes Learning under Privacy Risk",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "While machine learning empowers intelligent services and offers users customized experiences, privacy concerns emerge from regulatory requirements and the privacy-conscious demands of users.  Machine unlearning presents a potential solution to these concerns. Despite the growing demand for practical deployment due to \\textit{the right to be forgotten} privacy regulations, the economic impact of machine unlearning on user behavior and platform profitability remains largely unexplored and may limit its implementation. In this paper, we formulate a set of contract design problems under both unlearning-disabled and unlearning-enabled scenarios. Challenges arise when the unlearning-enabled platform jointly designs compensation for both learning and unlearning to incentivize users\u2019 sequential decisions to balance the expected revenue and unlearning cost. We first conduct a questionnaire survey that reveals that machine unlearning increases users\u2019 willingness to participate in federated learning. We then provide a necessary condition for maximizing the surplus of an unlearning-enabled platform, enabling the point-wise decomposition for the optimal contract design problem, based on which we minimize the incentive cost and maximize the surplus for the platform. Our further analysis reveals that i) the incentive effects of unlearning grow quadratically with users\u2019 privacy sensitivity, and ii)  enabling unlearning may even profit more than disabling it, under higher cost elasticity of risk distribution. Our numerical results show that the platform\u2019s profitability is primarily influenced by users\u2019 privacy sensitivity. When users are relatively highly privacy-sensitive, enabling unlearning can significantly improve profitability.",
        "keywords": "Machine Unlearning;Contract Design;Risk Aversion",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qiyuan Wang;Ruiling Xu;Shibo He;Randall Berry;Meng Zhang",
        "authorids": "~Qiyuan_Wang1;~Ruiling_Xu1;~Shibo_He1;~Randall_Berry1;~Meng_Zhang16",
        "gender": ";F;M;M;M",
        "homepage": ";https://github.com/carol-xrl;https://person.zju.edu.cn/en/shibohe;http://www.ece.northwestern.edu/~rberry/;https://zjui.intl.zju.edu.cn/node/1651",
        "dblp": ";;07/7178;b/RandallBerry;",
        "google_scholar": ";;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.tw/citations?user=iWq6Tn4AAAAJ;CEKASm8AAAAJ",
        "orcid": "0000-0002-5919-0465;0009-0005-9710-2496;;0000-0002-1861-6722;",
        "linkedin": ";;;randall-berry-2293b56/;",
        "or_profile": "~Qiyuan_Wang1;~Ruiling_Xu1;~Shibo_He1;~Randall_Berry1;~Meng_Zhang16",
        "aff": "Zhejiang University;Zhejiang University+University of Illinois, Urbana Champaign;Zhejiang University;Northwestern University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn+illinois.edu;zju.edu.cn;u.northwestern.edu;zju.edu.cn",
        "position": "PhD student;Undergrad student+Undergrad student;Full Professor;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025unlearning,\ntitle={Unlearning Incentivizes Learning under Privacy Risk},\nauthor={Qiyuan Wang and Ruiling Xu and Shibo He and Randall Berry and Meng Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=2c2ec6VlgK}\n}",
        "github": "",
        "project": "",
        "reviewers": "eELk;qit8;KEXL;oQ2w;uwEa",
        "site": "https://openreview.net/forum?id=2c2ec6VlgK",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "3;5;4;4;5",
        "scope": "3;3;3;3;3",
        "confidence": "3;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.40824829046386296
    },
    {
        "id": "2dA7IPkRIP",
        "title": "SANS: Efficient Densest Subgraph Discovery over Relational Graphs without Materialization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "How can we efficiently identify the densest subgraph over relational graphs? Existing dense subgraph discovery (DSD) approaches assume that a relational graph $H$ is already derived from a heterogeneous data source and they focus on efficient discovery of the densest subgraph on the materialized $H$. Unfortunately, materializing relational graphs can be resource-intensive, which thus limits the practical usefulness of existing algorithms over large datasets. To mitigate this, we propose a novel Summary-bAsed deNsest Subgraph discovery (SANS) system. Our unique summary-based peeling algorithm forms the core of SANS. Following the peeling paradigm, it utilizes summaries of each node's neighborhood to efficiently estimate peeling coefficients and subgraph densities at each peeling iteration and thus avoids materializing the relational graph completely.\nThrough extensive experiments, we demonstrate the efficacy and efficiency of SANS, reaching orders of magnitude speedups compared to the conventional baselines with materialization, while consistently achieving at least 95% accuracy compared to peeling algorithms based on materialization.",
        "keywords": "densest subgraph discovery;relational graph;neighborhood-summary;materialization-free",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yudong Niu;Yuchen Li;Jiaxin Jiang;Laks V. S. Lakshmanan",
        "authorids": "~Yudong_Niu1;~Yuchen_Li6;~Jiaxin_Jiang1;~Laks_V._S._Lakshmanan1",
        "gender": "M;M;M;",
        "homepage": "https://sites.google.com/view/niuyudong/home;http://yuchenli.net/;https://csjxjiang.github.io/;https://www.cs.ubc.ca/~laks",
        "dblp": "243/0807.html;143/0258-1;90/8494;l/LVSLakshmanan",
        "google_scholar": ";M4DWiJUAAAAJ;IJxaU-4AAAAJ;https://scholar.google.ca/citations?user=_RCsaOsAAAAJ",
        "orcid": "0000-0002-5434-8577;0000-0002-3145-350X;;0000-0002-9775-4241",
        "linkedin": ";;;laksvslakshmanan/",
        "or_profile": "~Yudong_Niu1;~Yuchen_Li6;~Jiaxin_Jiang1;~Laks_V._S._Lakshmanan1",
        "aff": "Singapore Management University;;National University of Singapore;University of British Columbia",
        "aff_domain": "smu.edu.sg;;nus.edu;ubc.ca",
        "position": "Postdoc;;Postdoc;Professor",
        "bibtex": "@inproceedings{\nniu2025sans,\ntitle={{SANS}: Efficient Densest Subgraph Discovery over Relational Graphs without Materialization},\nauthor={Yudong Niu and Yuchen Li and Jiaxin Jiang and Laks V. S. Lakshmanan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=2dA7IPkRIP}\n}",
        "github": "",
        "project": "",
        "reviewers": "b6QV;egQe;Um29;UWnm;gnBb",
        "site": "https://openreview.net/forum?id=2dA7IPkRIP",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "3;5;4;5;6",
        "scope": "3;3;4;4;2",
        "confidence": "3;3;2;4;1",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.6,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.19611613513818407
    },
    {
        "id": "2sQgjUKXnb",
        "title": "STGAN: Detecting Host Threats via Fusion of Spatial-Temporal Features in Host Provenance Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "As the complexity and frequency of cyberattacks, such as Advanced Persistent Threats (APTs) and ransomware, continue to escalate, traditional anomaly detection methods have proven inadequate in addressing these sophisticated, multi-faceted threats. Recently, Host Provenance Graphs (HPGs) have played a crucial role in analyzing system-level interactions, detecting anomalous behaviors, and tracing attack chains. However, existing provenance-based detection methods primarily rely on single-dimensional feature analysis, which fails to capture the dynamic and multi-dimensional patterns of modern APT attacks, resulting in insufficient detection performance. To overcome this limitation, we introduce STGAN, a model that integrates spatial-temporal graphs into host provenance graph modeling. STGAN applies temporal and spatial encoding to dynamic provenance graphs to extract temporal, spatial, and semantic features, constructing a comprehensive feature representation. This representation is further fused and enhanced using a multi-head self-attention mechanism, followed by anomaly detection. Through extensive evaluations on three widely-used provenance graph datasets, we demonstrate that our approach consistently outperforms current state-of-the-art techniques in terms of detection performance. Additionally, we contribute to the research community by releasing our datasets and code, facilitating further exploration and validation.",
        "keywords": "Network Security;Host Provenance Graph;Graph Anomaly Detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Anyuan Sang;Xuezheng Fan;Li Yang;Yuchen Wang;Lu Zhou;Junbo Jia;Huipeng YANG",
        "authorids": "~Anyuan_Sang1;~Xuezheng_Fan1;~Li_Yang27;~Yuchen_Wang10;~Lu_Zhou4;~Junbo_Jia1;~Huipeng_YANG1",
        "gender": "M;M;M;M;;;",
        "homepage": ";;;;;;",
        "dblp": ";;;;;;",
        "google_scholar": ";;https://scholar.google.com/citations?hl=en;;;;",
        "orcid": "0009-0006-3265-4078;0009-0003-1023-1902;;0000-0002-9685-6107;;0009-0009-4286-4003;0009-0004-1975-8062",
        "linkedin": ";;;;;;",
        "or_profile": "~Anyuan_Sang1;~Xuezheng_Fan1;~Li_Yang27;~Yuchen_Wang10;~Lu_Zhou4;~Junbo_Jia1;~Huipeng_YANG1",
        "aff": "Xidian University;Xidian University;Xidian University;Xidian University;;Xidian University ;Xidian university",
        "aff_domain": "stu.xidian.edu.cn;stu.xidian.edu.cn;xidian.edu.cn;xidian.edu.cn;;xidian.edu.cn;xidian.edu.cn",
        "position": "PhD student;MS student;Full Professor;PhD student;;PhD student;PhD student",
        "bibtex": "@inproceedings{\nsang2025stgan,\ntitle={{STGAN}: Detecting Host Threats via Fusion of Spatial-Temporal Features in Host Provenance Graphs},\nauthor={Anyuan Sang and Xuezheng Fan and Li Yang and Yuchen Wang and Lu Zhou and Junbo Jia and Huipeng YANG},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=2sQgjUKXnb}\n}",
        "github": "",
        "project": "",
        "reviewers": "xRyi;c5kg;hgbA;AAfk",
        "site": "https://openreview.net/forum?id=2sQgjUKXnb",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "3;5;5;5",
        "scope": "4;3;3;3",
        "confidence": "3;4;1;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.5,
            0.8660254037844386
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            1.0897247358851685
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.13245323570650439
    },
    {
        "id": "31fB9TR7Ku",
        "title": "Enhancing Cross-domain Link Prediction via Evolution Process Modeling",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "This paper proposes CrossLink, a novel framework for cross-domain link prediction. \nCrossLink learns the evolution pattern of a specific downstream graph and subsequently makes pattern-specific link predictions. \nIt employs a technique called \\textit{conditioned link generation}, which integrates both evolution and structure modeling to perform evolution-specific link prediction. \nThis conditioned link generation is carried out by a transformer-decoder architecture, enabling efficient parallel training and inference.\nCrossLink is trained on extensive dynamic graphs across diverse domains, encompassing 6 million dynamic edges. \nExtensive experiments on eight untrained graphs demonstrate that CrossLink achieves state-of-the-art performance in cross-domain link prediction. \nCompared to advanced baselines under the same settings, CrossLink shows an average improvement of 11.40% in Average Precision across eight graphs. Impressively, it surpasses the fully supervised performance of 8 advanced baselines on 6 untrained graphs.",
        "keywords": "Dynamic Graph;Link prerdiction",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xuanwen Huang;Wei Chow;Yize Zhu;YANG WANG;Ziwei Chai;Chunping Wang;Lei CHEN;Yang Yang",
        "authorids": "~Xuanwen_Huang1;~Wei_Chow1;~Yize_Zhu2;~YANG_WANG44;~Ziwei_Chai1;~Chunping_Wang1;~Lei_CHEN23;~Yang_Yang35",
        "gender": "M;M;;F;Not Specified;F;M;M",
        "homepage": ";http://none.com;;https://dgraph.xinye.com/team;https://zwchai.github.io;;https://www.linkedin.cn/incareer/in/ACoAAAPh8noB_KF0tgucaqFyKbDGOv9wkJkM0sY;http://yangy.org",
        "dblp": "256/9418;;;;325/1758;54/2715-1;09/3666a.html;",
        "google_scholar": "JFLCWNQAAAAJ;;;;;Rmy5RogAAAAJ;https://scholar.google.com.hk/citations?user=wDG2dMYAAAAJ;",
        "orcid": ";;;;0000-0003-1376-5101;0000-0003-1854-8667;0000-0002-4912-3293;0000-0002-5058-4417",
        "linkedin": ";;;;;https://linkedin.com/in/chunping-wang-7b94a15/;;",
        "or_profile": "~Xuanwen_Huang1;~Wei_Chow1;~Yize_Zhu2;~YANG_WANG44;~Ziwei_Chai1;~Chunping_Wang1;~Lei_CHEN23;~Yang_Yang35",
        "aff": "Zhejiang University;Zhejiang University;;;Zhejiang University;Finvolution Group;Peking University+Finvolution Group;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;;;zju.edu.cn;xinye.com;pku.edu.cn+xinye.com;zju.edu.cn",
        "position": "PhD student;Undergrad student;;;PhD student;Principal Scientist;PhD student+VP;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025enhancing,\ntitle={Enhancing Cross-domain Link Prediction via Evolution Process Modeling},\nauthor={Xuanwen Huang and Wei Chow and Yize Zhu and YANG WANG and Ziwei Chai and Chunping Wang and Lei CHEN and Yang Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=31fB9TR7Ku}\n}",
        "github": "",
        "project": "",
        "reviewers": "VTKS;dJJz;88GF;hUbD;ySED",
        "site": "https://openreview.net/forum?id=31fB9TR7Ku",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "4;4;4;5;3",
        "scope": "4;3;3;3;4",
        "confidence": "3;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.25000000000000006
    },
    {
        "id": "36Qk76s74U",
        "title": "Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Empathetic Response Generation (ERG) is one of the key tasks of the affective computing area, which aims to produce emotionally nuanced and compassionate responses to user's queries. However, existing ERG research is predominantly confined to the singleton text modality, limiting its effectiveness since human emotions are inherently conveyed through multiple modalities. To combat this, we introduce an avatar-based Multimodal ERG (MERG) task, entailing rich text, speech, and facial vision information. We first present a large-scale high-quality benchmark dataset, \\textbf{AvaMERG}, which extends traditional text ERG by incorporating authentic human speech audio and dynamic talking-face avatar videos, encompassing a diverse range of avatar profiles and broadly covering various topics of real-world scenarios. Further, we deliberately tailor a system, named \\textbf{Empatheia}, for MERG. Built upon a Multimodal Large Language Model (MLLM) with multimodal encoder, speech and avatar generators, Empatheia performs end-to-end MERG, with Chain-of-Empathetic reasoning mechanism integrated for enhanced empathy understanding and reasoning. Finally, we devise a list of empathetic-enhanced tuning strategies, strengthening the capabilities of emotional accuracy and content, avatar-profile consistency across modalities. Experimental results on AvaMERG data demonstrate that Empatheia consistently shows superior performance than baseline methods on both textual ERG and MERG. Overall, this work is expected to pioneer the MERG research by introducing a novel benchmark and an end-to-end model, laying a solid foundation for future advancements in multimodal empathetic response generation.",
        "keywords": "Empathetic Response Generation;Multimodal Large Language Model;Avatar Generation;Affective Computing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Han Zhang;Zixiang Meng;Meng Luo;Hong Han;Lizi Liao;Erik Cambria;Hao Fei",
        "authorids": "~Han_Zhang31;~Zixiang_Meng1;~Meng_Luo2;~Hong_Han1;~Lizi_Liao1;~Erik_Cambria1;~Hao_Fei1",
        "gender": "M;M;M;F;F;M;M",
        "homepage": "https://github.com/zhanghanXD?tab=repositories;;https://eurekaleo.github.io/;https://web.xidian.edu.cn/hanhong/;https://liziliao.github.io/;https://sentic.net/erikcambria/;https://haofei.vip/",
        "dblp": ";375/0079;16/3121-2;;149/1249;80/7421;81/3569-1",
        "google_scholar": ";;https://scholar.google.com.sg/citations?user=REbZPKUAAAAJ;;https://scholar.google.com.sg/citations?user=W2b08EUAAAAJ;ilSYpW0AAAAJ;YGDX46AAAAAJ",
        "orcid": "0009-0009-1204-9614;;0000-0003-2274-5719;;;0000-0002-3030-1280;0000-0003-3026-6347",
        "linkedin": ";\u5b50\u7fd4-\u5b5f-95024527b;;;;erikcambria/;",
        "or_profile": "~Han_Zhang31;~Zixiang_Meng1;~Meng_Luo2;~Hong_Han1;~Lizi_Liao1;~Erik_Cambria1;~Hao_Fei1",
        "aff": "Xidian University;Wuhan University;National University of Singapore;Xidian University ;Singapore Management University;Nanyang Technological University;National University of Singapore",
        "aff_domain": "stu.xidian.edu.cn;whu.edu.cn;u.nus.edu;xidian.edu.cn;smu.edu.sg;ntu.edu.sg;nus.edu.sg",
        "position": "PhD student;MS student;PhD student;Full Professor;Assistant Professor;Full Professor;Postdoc",
        "bibtex": "@inproceedings{\nzhang2025towards,\ntitle={Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark},\nauthor={Han Zhang and Zixiang Meng and Meng Luo and Hong Han and Lizi Liao and Erik Cambria and Hao Fei},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=36Qk76s74U}\n}",
        "github": "",
        "project": "",
        "reviewers": "rhh2;GUdZ;tx2X;Ca1Y;4gmP",
        "site": "https://openreview.net/forum?id=36Qk76s74U",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "5;5;6;6;6",
        "scope": "4;3;4;4;4",
        "confidence": "3;3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 1.0
    },
    {
        "id": "395kTBrUZi",
        "title": "Nature Makes No Leaps: Building Continuous Location Embeddings with Satellite Imagery from the Web",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Building location embedding from web-sourced satellite imagery has emerged as an enduring research focus in web mining. However, most existing methods are inherently constrained by their reliance on discrete, sparse sampling strategies, failing to capture\nthe essential spatial continuity of geographic spaces. Moreover, the presence of confounding factors in satellite images can distort the perception of actual objects, leading to semantic discontinuity in the embeddings. In this work, we propose **SatCLE**, a novel framework for Continuous Location Embeddings leveraging Satellite imagery. Specifically, to address the out-of-distribution query challenge of spatial continuity, we propose a geospatial refinement strategy comprising stochastic perturbation continuity expansion and graph propagation fusion, which transforms discrete geospatial coordinates into a continuous space. To mitigate the effects of confounders on semantic continuity, we introduce causal refinement, integrating causal theory to localize and eliminate spurious correlations arising from the environmental context. Through extensive experiments, **SatCLE** shows state-of-the-art performance, exhibiting superior spatial coherence and semantic fidelity across diverse geospatial tasks.",
        "keywords": "urban computing;multimodal learning;location embedding;satellite imagery;web mining;contrastive learning;geospatial learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xixuan Hao;Wei Chen;Xingchen Zou;Yuxuan Liang",
        "authorids": "~Xixuan_Hao2;~Wei_Chen50;~Xingchen_Zou1;~Yuxuan_Liang1",
        "gender": "M;M;M;M",
        "homepage": "https://skyerhxx.github.io/xxhao.github.io/;https://onedean.github.io/;https://xczou.top;https://yuxuanliang.com",
        "dblp": "354/0596.html;;371/4560;183/0977",
        "google_scholar": ";RCfQIcQAAAAJ;xh6SdPAAAAAJ;n9cODgcAAAAJ",
        "orcid": "0000-0003-0728-1944;;0009-0004-4362-6617;0000-0003-2817-7337",
        "linkedin": ";;;yoshall/",
        "or_profile": "~Xixuan_Hao2;~Wei_Chen50;~Xingchen_Zou1;~Yuxuan_Liang1",
        "aff": "The Hong Kong University of Science and Technology (Guangzhou);Hong Kong University of Science and Technology, Guangzhou+Huawei 2012 Research;The Hong Kong University of Science and Technology (Guangzhou)+PCITECH+Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "hkust-gz.edu.cn;hkust-gz.edu.cn+huawei.com;hkust-gz.edu.cn+pcitech.com+hkust-gz.edu.cn;hkust-gz.edu.cn",
        "position": "PhD student;PhD student+Researcher;PhD student+Intern+MS student;Assistant Professor",
        "bibtex": "@inproceedings{\nhao2025nature,\ntitle={Nature Makes No Leaps: Building Continuous Location Embeddings with Satellite Imagery from the Web},\nauthor={Xixuan Hao and Wei Chen and Xingchen Zou and Yuxuan Liang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=395kTBrUZi}\n}",
        "github": "",
        "project": "",
        "reviewers": "WBar;V9YC;yEcB",
        "site": "https://openreview.net/forum?id=395kTBrUZi",
        "pdf_size": 0,
        "novelty": "4;6;6",
        "technical_quality": "2;6;5",
        "scope": "3;4;4",
        "confidence": "3;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            0.9428090415820634
        ],
        "technical_quality_avg": [
            4.333333333333333,
            1.699673171197595
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            0.816496580927726
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "3D69Lb8vu8",
        "title": "ACME++: Secure ACME Client Verification for Web-PKI",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The Automatic Certificate Management Environment (ACME) protocol automates the SSL certificate issuance and renewal process, streamlining large-scale certificate management. Its caching mechanism allows Certificate Authorities (CAs) to store domain validation results for up to 30 days. While this mechanism reduces the burden of re-validation on the CA server, it also introduces a vulnerability where attackers can bypass domain validation using stolen ACME account credentials.\n\nIn this paper, we introduce the ACME $Authz$ Cache Attack, a method that enables attackers to request fraudulent certificates without domain control. We demonstrate that even Let's Encrypt, the world\u2019s largest CA, is susceptible to this vulnerability. To address this issue, we propose ACME++, an enhanced version of the protocol that binds the ACME account to the client\u2019s IP address and a unique ID, ensuring re-validation for each certificate request from a new client. Our implementation of ACME++ shows that it effectively mitigates this attack with minimal impact on server performance.",
        "keywords": "Web-PKI Security;Certificates;ACME Protocol",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tianyu Zhang;zhang Han;Yunze Wei;Yahui Li;Xingang Shi;Jilong Wang;Xia Yin",
        "authorids": "~Tianyu_Zhang16;~zhang_Han1;~Yunze_Wei1;~Yahui_Li2;~Xingang_Shi1;~Jilong_Wang4;~Xia_Yin1",
        "gender": "M;M;M;F;M;M;F",
        "homepage": ";https://netsyscode.github.io/netsyslab/index.html;;;;https://www.cs.tsinghua.edu.cn/csen/info/1184/4030.htm;http://www.tsinghua.edu.cn/publish/csen/4623/2010/20101226110908587907841/20101226110908587907841_.html",
        "dblp": ";;;;;;",
        "google_scholar": ";;;;BAo_KhMAAAAJ;;https://scholar.google.com.tw/citations?user=SKxhz04AAAAJ",
        "orcid": ";;0009-0004-8126-7248;0000-0002-0148-5965;;;",
        "linkedin": "tianyu-zhang-b54542323;;;;;;",
        "or_profile": "~Tianyu_Zhang16;~zhang_Han1;~Yunze_Wei1;~Yahui_Li2;~Xingang_Shi1;~Jilong_Wang4;~Xia_Yin1",
        "aff": "Tsinghua University;Tsinghua University+Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University;;, Tsinghua University",
        "aff_domain": "tsinghua.edu.cn;mail.tsinghua.edu.cn+tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn;;cs.tsinghua.edu.cn",
        "position": "PhD student;Associate Professor+Assistant Professor;PhD student;Assistant Professor;Associate Professor;;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025acme,\ntitle={{ACME}++: Secure {ACME} Client Verification for Web-{PKI}},\nauthor={Tianyu Zhang and zhang Han and Yunze Wei and Yahui Li and Xingang Shi and Jilong Wang and Xia Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3D69Lb8vu8}\n}",
        "github": "",
        "project": "",
        "reviewers": "SW7j;9qzQ;Gzyq;rWzs;ZNdz",
        "site": "https://openreview.net/forum?id=3D69Lb8vu8",
        "pdf_size": 0,
        "novelty": "5;5;5;5;6",
        "technical_quality": "5;4;7;4;6",
        "scope": "4;3;4;4;4",
        "confidence": "3;3;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7905694150420948
    },
    {
        "id": "3Nq5DEKXF6",
        "title": "Coreness Maximization through Budget-Limited Edge Insertion",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The Budget Limited Coreness Maximization (BLCM) problem aims to enhance average user engagement by activating a limited number of connections, i.e., inserting up to b edges to maximize the coreness gain of all vertices in a graph. Due to the cascading feature, we prove the BLCM is NP-hard, APX-hard, and not submodular, meaning greedy sequential edge insertion fails to deliver satisfactory results. As a result, solving BLCM requires combinatorial edge insertion and must face the combinatorial exploration difficulty. This paper proposes the first effective and polynomial-time approach to BLCM. It embeds local combinatorial optimization into global greedy search to boost the benefits of combinatorial optimization while restricting its complexity. Specifically,  we propose efficient methods to evaluate the cascaded coreness improvements of two local combinatorial strategies, i.e., when a leader or a group of nodes increase their coreness values via local edge insertion. Note that the key difficulty lies in evaluating the cascading effects. Based on these, we propose three efficient combinatorial edge insertion strategies: (1) Leader-Centric Greedy Insertion (LCGI), (2) Group-Centric Greedy Insertion (GCGI), and (3) a Leader-Group Balance (LGB) insertion. LCGI greedily finds the most influential leader that can produce the highest coreness gain together with its followers. GCGI finds the most influential group that can promote the most coreness gain. LGB combines the two strategies to select edge combinations adaptively.  We prove the low complexity of LCGI, GCGI and LGB. Experiments conducted on 13 real-world datasets highlight their practical utility and superiority over existing approaches.",
        "keywords": "k-core;Coreness;Budget Limited Coreness Maximization;User Engagement",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaowei Lv;Xiaojia Xu;Yongcai Wang;Haoyu Liu;Deying Li",
        "authorids": "~Xiaowei_Lv1;~Xiaojia_Xu1;~Yongcai_Wang1;~Haoyu_Liu4;~Deying_Li1",
        "gender": ";F;M;M;F",
        "homepage": ";;https://yongcaiwang.github.io;https://github.com/Elssky/Elssky.github.io;http://info.ruc.edu.cn/jsky/szdw/ajxjgcx/jsjkxyjsx1/js2/c2523870862c49758d02a6705c1e1556.htm",
        "dblp": ";;04/2124;;63/1296",
        "google_scholar": ";;ZOHWbl8AAAAJ;;",
        "orcid": ";0000-0001-9949-9451;;;",
        "linkedin": ";;;;",
        "or_profile": "~Xiaowei_Lv1;~Xiaojia_Xu1;~Yongcai_Wang1;~Haoyu_Liu4;~Deying_Li1",
        "aff": ";Renmin University of China;Renmin University of China;Renmin University of China;Renmin University of China",
        "aff_domain": ";ruc.edu.cn;ruc.edu.cn;ruc.edu.cn;ruc.edu.cn",
        "position": ";PhD student;Associate Professor;MS student;Full Professor",
        "bibtex": "@inproceedings{\nlv2025coreness,\ntitle={Coreness Maximization through Budget-Limited Edge Insertion},\nauthor={Xiaowei Lv and Xiaojia Xu and Yongcai Wang and Haoyu Liu and Deying Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3Nq5DEKXF6}\n}",
        "github": "",
        "project": "",
        "reviewers": "eyiC;6WWA;7FXz;1G2e;2pF9",
        "site": "https://openreview.net/forum?id=3Nq5DEKXF6",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;4;6;6;6",
        "scope": "4;2;4;3;3",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.2,
            0.9797958971132712
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6454972243679027
    },
    {
        "id": "3UeAN1zicJ",
        "title": "Scenario-independent Uncertainty Estimation for LLM-based Question Answering via Factor Analysis",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs) demonstrate significant potential in various applications; however, they are susceptible to generating hallucinations, which can lead to the spread of misinformation online. Existing studies address hallucination detection by (1) employing reference-based methods that consult external resources for verification or (2) utilizing reference-free methods that mainly estimate answer uncertainty based on LLM's internal states. However, reference-based methods incur significant costs and can be infeasible for obtaining reliable external references. Besides, existing uncertainty estimation (UE) methods often overlook the impact of scenario backgrounds inherited from the query's lexical resources, leading to noise in UE. In almost all real-world applications, users care about the uncertainty concerning semantics or facts instead of the query's scenario information. Therefore, we argue that mitigating scenario-related noise and focusing on semantic information can yield a more desirable UE. In this paper, we introduce a plug-and-play scenario-independent framework to enhance unsupervised UE in LLMs by removing scenario-related noise and focusing on semantic information. This framework is compatible with most existing UE methods, as it leverages only the existing UE methods' outputs. Specifically, we design a scenario-specific sampling to paraphrase queries, maintaining their common semantics while diversifying the scenario distribution. Subsequently, to estimate the contribution of the common semantics, we design a factor analysis (FA) model to disentangle the UE score obtained from the given UE method into a combination of multiple latent factors, which represent the contribution of the common semantics and scenario-related noise. By solving the FA model, we decompose the impact of the most significant factor to approximate the uncertainty caused by the common semantics, thus achieving scenario-independent UE. Extensive experiments and analysis across multiple models and datasets demonstrate the effectiveness of our approach.",
        "keywords": "large language models;hallucination;uncertainty estimation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhihua Wen;Zhizhao Liu;Zhiliang Tian;Shilong Pan;Zhen Huang;Dongsheng Li;Minlie Huang",
        "authorids": "~Zhihua_Wen2;~Zhizhao_Liu1;~Zhiliang_Tian2;~Shilong_Pan1;~Zhen_Huang3;~Dongsheng_Li3;~Minlie_Huang1",
        "gender": ";M;M;M;M;;M",
        "homepage": ";https://lzz335.github.io/profile/;https://scholar.google.com.hk/citations?hl=en&user=ClvGvccAAAAJ#;https://github.com/PANsir-hub;;;http://coai.cs.tsinghua.edu.cn/hml",
        "dblp": ";140/4591;203/9265;47/8705;22/3870-6;;47/6668.html",
        "google_scholar": ";;https://scholar.google.com.hk/citations?hl=en;;;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": ";0009-0006-1242-0661;;0009-0004-2165-8247;0000-0003-4819-373X;;0000-0001-7111-1849",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhihua_Wen2;~Zhizhao_Liu1;~Zhiliang_Tian2;~Shilong_Pan1;~Zhen_Huang3;~Dongsheng_Li3;~Minlie_Huang1",
        "aff": ";National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;;Tsinghua University",
        "aff_domain": ";nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;;tsinghua.edu.cn",
        "position": ";PhD student;Associate Professor;PhD student;Full Professor;;Full Professor",
        "bibtex": "@inproceedings{\nwen2025scenarioindependent,\ntitle={Scenario-independent Uncertainty Estimation for {LLM}-based Question Answering via Factor Analysis},\nauthor={Zhihua Wen and Zhizhao Liu and Zhiliang Tian and Shilong Pan and Zhen Huang and Dongsheng Li and Minlie Huang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3UeAN1zicJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "3tts;a8dp;FNhT;Gstq",
        "site": "https://openreview.net/forum?id=3UeAN1zicJ",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "4;5;4;6",
        "scope": "2;1;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            2.75,
            1.299038105676658
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "3V5QAkfY1k",
        "title": "Spherical Embeddings for Atomic Relation Projection Reaching Complex Logical Query Answering",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Projecting knowledge graph queries into an embedding space using geometric models (points, boxes and spheres) can help to answer queries for large incomplete knowledge graphs. In this work, we propose a symbolic learning-free approach using fuzzy logic to address the shape-closure problem that restricted geometric-based embedding models to only a few shapes (e.g. ConE) for answering complex logical queries. The use of symbolic approach facilitates non-closure geometric models (e.g. point, box) to handle logical operators (including negation). This enabled our newly proposed spherical embeddings (SpherE) in this work to use a polar coordinate system to effectively represent hierarchical relation. Results show that the SpherE model can answer existential positive first-order logic and negation queries. We show that SpherE significantly outperforms the point and box embeddings approaches while generating semantically meaningful hierarchy-aware embeddings.",
        "keywords": "Query Embeddings;Complex Logical Query Answering;Knowledge Graphs",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chau Nguyen;Tim French;Michael Stewart;Melinda Hodkiewicz;Wei Liu",
        "authorids": "~Chau_Nguyen2;~Tim_French1;~Michael_Stewart2;~Melinda_Hodkiewicz1;~Wei_Liu9",
        "gender": ";M;M;;F",
        "homepage": ";https://research-repository.uwa.edu.au/en/persons/tim-french;https://research-repository.uwa.edu.au/en/persons/michael-stewart;;https://research-repository.uwa.edu.au/en/persons/wei-liu",
        "dblp": ";29/1679;;;49/3283-6",
        "google_scholar": ";https://scholar.google.com.au/citations?user=zcqX-AgAAAAJ;https://scholar.google.com.au/citations?user=T0sFgOwAAAAJ;https://scholar.google.com.au/citations?user=1JGboosAAAAJ;https://scholar.google.com.au/citations?user=o_u17HMAAAAJ",
        "orcid": ";0000-0002-0748-8040;0000-0001-6494-7015;0000-0002-7336-3932;0000-0002-7409-0948",
        "linkedin": ";;;;",
        "or_profile": "~Chau_Nguyen2;~Tim_French1;~Michael_Stewart2;~Melinda_Hodkiewicz1;~Wei_Liu9",
        "aff": ";;University of Western Australia;University of Western Australia;University of Western Australia",
        "aff_domain": ";;uwa.edu.au;uwa.edu.au;uwa.edu.au",
        "position": ";;Postdoc;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nnguyen2025spherical,\ntitle={Spherical Embeddings for Atomic Relation Projection Reaching Complex Logical Query Answering},\nauthor={Chau Nguyen and Tim French and Michael Stewart and Melinda Hodkiewicz and Wei Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3V5QAkfY1k}\n}",
        "github": "",
        "project": "",
        "reviewers": "asVB;jfTC;2Gc5;aDMZ;8DEA",
        "site": "https://openreview.net/forum?id=3V5QAkfY1k",
        "pdf_size": 0,
        "novelty": "4;5;5;5;7",
        "technical_quality": "5;4;6;5;6",
        "scope": "3;4;3;3;4",
        "confidence": "3;2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.10206207261596577
    },
    {
        "id": "3r0SkwfJS9",
        "title": "IllusionCAPTCHA: A CAPTCHA based on visual illusion",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "CAPTCHAs have long been essential tools for protecting applications from automated bots. Initially designed as simple questions to distinguish humans from bots, they have become increasingly complex to keep pace with the proliferation of CAPTCHA-cracking techniques employed by malicious actors. However, with the advent of advanced large language models (LLMs), the effectiveness of existing CAPTCHAs is now being undermined.\n\nTo address this issue, we have conducted an empirical study to evaluate the performance of multimodal LLMs in solving CAPTCHAs and to assess how many attempts human users typically need to pass them. Our findings reveal that while LLMs can solve most CAPTCHAs, they struggle with those requiring complex reasoning\u2014a type of CAPTCHA that also presents significant challenges for human users. Interestingly, our user study showed that the majority of human participants required a second attempt to pass these reasoning CAPTCHAs, a finding not previously reported in existing research.\n\nBased on the findings of our empirical study, we introduce IllusionCAPTCHA, an innovative approach designed to be \"Human-Easy but AI-Hard\". This new CAPTCHA employs visual illusions to create tasks that are intuitive for humans but highly confusing for AI models. Furthermore, we developed a structured, step-by-step method that guides LLMs toward making specific incorrect choices, thereby reducing their ability to bypass CAPTCHA systems successfully. Our evaluation shows that IllusionCAPTCHA can effectively deceive LLMs 100\\% of the time. Moreover, our structured design significantly increases the likelihood of AI errors when attempting to solve these challenges. Results from our user study indicate that 86.95\\% of participants successfully passed the CAPTCHA on their first attempt, outperforming other CAPTCHA systems.",
        "keywords": "CAPTCHA;Visual Illusion;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ziqi Ding;Gelei Deng;Yi Liu;Junchen Ding;Jieshan Chen;Yulei Sui;Yuekang Li",
        "authorids": "~Ziqi_Ding2;~Gelei_Deng1;~Yi_Liu42;~Junchen_Ding1;~Jieshan_Chen1;~Yulei_Sui1;~Yuekang_Li1",
        "gender": "M;M;M;M;Not Specified;M;M",
        "homepage": ";https://geleideng.github.io/;;;https://chenjshnn.github.io/;;https://thepatrickstar.github.io/",
        "dblp": ";;;385/8573;;;204/3729",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;NuzUkMEAAAAJ;DcFodKsAAAAJ;;slrzj8kAAAAJ;https://scholar.google.com.au/citations?user=wGHqq1cAAAAJ;tuJEDb4AAAAJ",
        "orcid": ";;0000-0002-4978-127X;0009-0007-6531-8190;;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Ziqi_Ding2;~Gelei_Deng1;~Yi_Liu42;~Junchen_Ding1;~Jieshan_Chen1;~Yulei_Sui1;~Yuekang_Li1",
        "aff": "University of New South Wales;;Quantstamp;University of New South Wales;Commonwealth Scientific and Industrial Research Organisation, CSIRO;University of New South Wales;University of New South Wales",
        "aff_domain": "unsw.edu.au;;quantstamp.com;unsw.edu.au;data61.csiro.au;unsw.edu.au;unsw.edu.au",
        "position": "MS student;;Researcher;MS student;Researcher;Associate Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nding2025illusioncaptcha,\ntitle={Illusion{CAPTCHA}: A {CAPTCHA} based on visual illusion},\nauthor={Ziqi Ding and Gelei Deng and Yi Liu and Junchen Ding and Jieshan Chen and Yulei Sui and Yuekang Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3r0SkwfJS9}\n}",
        "github": "",
        "project": "",
        "reviewers": "CMVF;HsSP;tgzX;AahE;K3v2",
        "site": "https://openreview.net/forum?id=3r0SkwfJS9",
        "pdf_size": 0,
        "novelty": "2;3;4;5;6",
        "technical_quality": "1;4;3;4;3",
        "scope": "3;3;4;3;4",
        "confidence": "4;3;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.4142135623730951
        ],
        "technical_quality_avg": [
            3.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2886751345948129
    },
    {
        "id": "3roesJsPcd",
        "title": "Ask, Acquire, Understand: A Multimodal Agent-based Framework for Social Abuse Detection in Memes",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Memes serve as a powerful medium of expression in the digital age, shaping cultural discourse and conveying ideas succinctly and engagingly. However, their potential for social abuse highlights the importance of developing effective methods to detect harmful content within memes. Recent studies on memes have focused on transforming images into textual captions using large language models (LLMs). However, these approaches often result in non-informative captions. Furthermore, previous methods have only been tested on limited datasets, providing insufficient evidence of their robustness. To address these limitations, we present a multimodal, agent-based framework designed to generate informative visual descriptions of memes by asking insightful questions to improve visual descriptions in zero-shot visual question-answering settings. Specifically, we leverage an LLM as agents with distinct roles and a large multimodal model (LMM) as a vision expert. These agents first analyze the images and then ask informative questions related to potential social abuse in memes to obtain high-quality answers about the images. Through continuous discussion guided by instructional prompts, the agents gather high-quality information while repeatedly acquiring image data from the LMM, which helps detect social abuse in memes. Finally, the discussion history and basic information are classified using the LLM to obtain the final prediction results in a zero-shot setting. Experimental results on a meme benchmark dataset sourced from 5 diverse meme datasets, comprising 6,626 memes spanning 5 tasks of varying complexity related to social abuse, demonstrate that our framework outperforms state-of-the-art methods, with detailed comparative analysis and ablation studies, further validating its generalizability and ability to retrieve more relevant information for detecting social abuse in memes.",
        "keywords": "online harassment;Multimodal;Language and Vision;Social Media;online trust and safety",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xuanrui Lin;Chao Jia;Junhui Ji;Hui Han;Usman Naseem",
        "authorids": "~Xuanrui_Lin1;~Chao_Jia3;~Junhui_Ji1;~Hui_Han3;~Usman_Naseem1",
        "gender": "M;M;M;F;",
        "homepage": ";;;https://github.com/abigcatcat;https://usmaann.github.io/",
        "dblp": "375/0476;;;;253/6972.html",
        "google_scholar": ";;;;https://scholar.google.com.au/citations?hl=en",
        "orcid": "0009-0006-2096-0270;0009-0002-2152-0569;0009-0009-2811-1865;;0000-0003-0191-7171",
        "linkedin": ";;;;usman-naseem-a1568a139/",
        "or_profile": "~Xuanrui_Lin1;~Chao_Jia3;~Junhui_Ji1;~Hui_Han3;~Usman_Naseem1",
        "aff": "Alibaba Group+Alibaba Group+Shanghai Jiaotong University;Alibaba Group+Shanghai Jiaotong University;Zhipu.AI;Shanghai Jiaotong University;Macquarie University",
        "aff_domain": "alibaba-inc.com+alibaba-inc.com+sjtu.edu.cn;alibaba-inc.com+sjtu.edu.cn;zhipuai.cn;sjtu.edu.cn;mq.edu.au",
        "position": "Researcher+Intern+MS student;Researcher+MS student;Researcher;MS student;Assistant Professor",
        "bibtex": "@inproceedings{\nlin2025ask,\ntitle={Ask, Acquire, Understand: A Multimodal Agent-based Framework for Social Abuse Detection in Memes},\nauthor={Xuanrui Lin and Chao Jia and Junhui Ji and Hui Han and Usman Naseem},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3roesJsPcd}\n}",
        "github": "",
        "project": "",
        "reviewers": "jRrB;LimB;WDyK;nqum",
        "site": "https://openreview.net/forum?id=3roesJsPcd",
        "pdf_size": 0,
        "novelty": "4;4;4;6",
        "technical_quality": "5;4;4;6",
        "scope": "4;3;3;4",
        "confidence": "4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "3x3XhZ9AqX",
        "title": "TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Hierarchical text classification aims to categorize each document into a set of classes in a label taxonomy, which is a fundamental web text mining task with broad applications such as web content analysis and semantic indexing. Most earlier works focus on fully or semi-supervised methods that require a large amount of human annotated data which is costly and time-consuming to acquire. To alleviate human efforts, in this paper, we work on hierarchical text classification with a minimal amount of supervision: using the sole class name of each node as the only supervision. Recently, large language models (LLM) show competitive performance on various tasks through zero-shot prompting, but this method performs poorly in the hierarchical setting because it is ineffective to include the large and structured label space in a prompt. On the other hand, previous weakly-supervised hierarchical text classification methods only utilize the raw taxonomy skeleton and ignore the rich information hidden in the text corpus that can serve as additional class-indicative features. To tackle the above challenges, we propose TELEClass, **T**axonomy **E**nrichment and **L**LM-**E**nhanced weakly-supervised hierarchical text **Class**ification, which combines the general knowledge of LLMs and task-specific features mined from an unlabeled corpus. TELEClass automatically enriches the raw taxonomy with class-indicative features for better label space understanding and utilizes novel LLM-based data annotation and generation methods specifically tailored for the hierarchical setting. Experiments show that TELEClass can significantly outperform previous strong baselines while also achieving comparable performance to zero-shot prompting of LLMs with drastically less inference cost.",
        "keywords": "Weakly-Supervised Text Classification;Hierarchical Text Classification;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yunyi Zhang;Ruozhen Yang;Xueqiang Xu;Rui Li;Jinfeng Xiao;Jiaming Shen;Jiawei Han",
        "authorids": "~Yunyi_Zhang1;~Ruozhen_Yang1;~Xueqiang_Xu1;~Rui_Li26;~Jinfeng_Xiao1;~Jiaming_Shen1;~Jiawei_Han1",
        "gender": "M;F;M;M;M;;M",
        "homepage": "https://yzhan238.github.io/;;;https://ruili33.github.io;http://jxiao13.web.engr.illinois.edu/;https://mickeysjm.github.io;http://hanj.cs.illinois.edu/",
        "dblp": "384/0161;;371/8950.html;;188/6240;178/3627;h/JiaweiHan.html",
        "google_scholar": "5VMnkl0AAAAJ;;YPYIX9EAAAAJ;oPWoXicAAAAJ;aRqS7jcAAAAJ;-ZJ0sCoAAAAJ;https://scholar.google.com.tw/citations?user=Kv9AbjMAAAAJ",
        "orcid": "0000-0001-9790-4855;;0009-0006-3716-9979;;0000-0002-1215-8038;0000-0002-0467-4956;0000-0002-3629-2696",
        "linkedin": "yunyi-zhang-198982149;ruozhen-yang/;https://linkedin.com/in/xueqiang-xu;;;jiaming-shen-08186710a/;",
        "or_profile": "~Yunyi_Zhang1;~Ruozhen_Yang1;~Xueqiang_Xu1;~Rui_Li26;~Jinfeng_Xiao1;~Jiaming_Shen1;~Jiawei_Han1",
        "aff": "Amazon+University of Illinois Urbana-Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;Stanford University+University of Science and Technology of China;Amazon+University of Illinois, Urbana Champaign;Google DeepMind;University of Illinois at Urbana-Champaign (UIUC)",
        "aff_domain": "amazon.com+illinois.edu;illinois.edu;illinois.edu;stanford.edu+ustc.edu.cn;amazon.com+illinois.edu;google.com;illinois.edu",
        "position": "Researcher+PhD student;MS student;MS student;PhD student+Undergrad student;Researcher+PhD student;Research Scientist;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025teleclass,\ntitle={{TELEC}lass: Taxonomy Enrichment and {LLM}-Enhanced Hierarchical Text Classification with Minimal Supervision},\nauthor={Yunyi Zhang and Ruozhen Yang and Xueqiang Xu and Rui Li and Jinfeng Xiao and Jiaming Shen and Jiawei Han},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=3x3XhZ9AqX}\n}",
        "github": "",
        "project": "",
        "reviewers": "YanF;vfiH;5tYP;WMJy;Q7GY",
        "site": "https://openreview.net/forum?id=3x3XhZ9AqX",
        "pdf_size": 0,
        "novelty": "2;3;3;5;6",
        "technical_quality": "3;4;3;5;6",
        "scope": "4;3;3;4;3",
        "confidence": "3;2;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            1.469693845669907
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.4303314829119351
    },
    {
        "id": "46gY0iX4Jz",
        "title": "Towards Collaborative Anti-Money Laundering Among Financial Institutions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Money laundering is the process that intends to legalize the income derived from illicit activities, thus facilitating their entry into the monetary flow of the economy without jeopardizing their source. It is crucial to identify such activities accurately and reliably in order to enforce anti-money laundering (AML).\n\nDespite considerable efforts to AML, a large number of such activities still go undetected. Rule-based methods were first widely used in the early days and still be widely used in existing detection systems. With the rise of machine learning, graph-based learning methods have gained prominence in detecting illicit accounts by analyzing money transfer graphs between accounts. However, existing approaches work based on the prerequisite that the transaction graph is centralized, while in practice, money laundering activities usually span multiple financial institutions. Due to regulatory, legal, commercial, and customer privacy concerns, institutions tend not to share data, limiting their utility in practical usage. In this paper, we propose the first algorithm that supports performing AML over multiple institutions while protecting the security and privacy of local data.\n\nTo evaluate, we construct Alipay-ECB, a real-world dataset comprising digital transactions from Alipay, the world\u2019s largest mobile payment platform, alongside transactions from E-Commerce Bank (ECB). The dataset includes over 200 million accounts and 300 million transactions, covering both intra-institution transactions and those between Alipay and ECB. This makes it the largest real-world transaction graph available for analysis. The experimental results demonstrate that our methods can effectively identify cross-institution money laundering subgroups. Additionally, experiments on synthetic datasets also demonstrate that our method is efficient, requiring only a few minutes on datasets with millions of transactions.",
        "keywords": "Anti-money laundering;Collaborative anti-money laundering;Graph mining",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhihua Tian;Yuan Ding;Jian Liu;XIANG YU;Enchao Gong;Kui Ren",
        "authorids": "~Zhihua_Tian1;~Yuan_Ding2;~Jian_Liu6;~XIANG_YU9;~Enchao_Gong1;~Kui_Ren4",
        "gender": ";M;M;M;M;M",
        "homepage": ";https://github.com/Dy1anT;https://person.zju.edu.cn/en/jianliu;http://www.fishincloud.com;https://blog.csdn.net/jkjk1986?type=blog;",
        "dblp": "278/0000.html;94/489;35/295-12.html;;;20/6179-1.html",
        "google_scholar": ";;https://scholar.google.com/citations?hl=en;;;https://scholar.google.com/citations?view_op=list_works",
        "orcid": ";;;;;0000-0003-3441-6277",
        "linkedin": ";;;;;",
        "or_profile": "~Zhihua_Tian1;~Yuan_Ding2;~Jian_Liu6;~XIANG_YU9;~Enchao_Gong1;~Kui_Ren4",
        "aff": "Zhejiang University;;Zhejiang University;;;Zhejiang University",
        "aff_domain": "zju.edu.cn;;zju.edu.cn;;;zju.edu.cn",
        "position": "PhD student;;Assistant Professor;;;Full Professor",
        "bibtex": "@inproceedings{\ntian2025towards,\ntitle={Towards Collaborative Anti-Money Laundering Among Financial Institutions},\nauthor={Zhihua Tian and Yuan Ding and Jian Liu and XIANG YU and Enchao Gong and Kui Ren},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=46gY0iX4Jz}\n}",
        "github": "",
        "project": "",
        "reviewers": "TKfu;YG13;PP32;1wQK",
        "site": "https://openreview.net/forum?id=46gY0iX4Jz",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "3;4;6;5",
        "scope": "3;4;4;3",
        "confidence": "4;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9733285267845754
    },
    {
        "id": "49IQ5pP0PU",
        "title": "Logic-Aware Knowledge Graph Reasoning for Structural Sparsity under Large Language Model Supervision",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Knowledge Graph (KG) reasoning aims to predict missing entities in incomplete triples, which requires adequate structural information to derive accurate embeddings. However, KGs in the real world are not as dense as the idealized benchmarks, where sparse graph structures restrict the comprehensive structural information for superior performance. Although the logical semantics in KGs shows its potential in alleviating the impact of structural sparsity, there still exist some challenges. The deficient supervision and the semantic gap of logic make it difficult to introduce logical semantics in sparse KG reasoning. To this end, we propose a novel KG reasoning approach LoLLM injecting logic with the supervised information supplied by the Large Language Model (LLM), which is proved to be effective in evaluating and scoring. Firstly, LoLLM derives structural embeddings employing a graph convolutional network (GCN) with relation-aware and triple-aware attention. LoLLM secondly constructs reasoning paths instantiated from the first-order logics extracted from sparse KGs, and injects the logical semantics by a designed LLM-enhanced tuning strategy. We propose a textual loss (TL) and a logical loss (LL) in the optimization and obtain logical tuning embeddings of KG in this process. Finally, LoLLM fuses structural embeddings from the GCN and logical tuning embeddings from the LLM-enhanced tuning for scoring and incomplete triple prediction. Extensive experiments on two sparse KGs and a benchmark show that LoLLM outperforms state-of-the-art structure-based and Language Model (LM)-augmented baselines. Moreover, the logics with corresponding confidences provide explicit explanations as an interpretable paradigm.",
        "keywords": "Sparse Knowledge Graph Reasoning;Knowledge Graph;First-order Logic;LLM-enhanced Tuning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yudai Pan;Jiajie Hong;Tianzhe Zhao;Lingyun Song;Jun Liu;Xuequn Shang",
        "authorids": "~Yudai_Pan1;~Jiajie_Hong1;~Tianzhe_Zhao1;~Lingyun_Song1;~Jun_Liu10;~Xuequn_Shang1",
        "gender": "F;M;M;M;M;F",
        "homepage": ";https://hjj-designed.github.io/Hjj.github.io/;;http://jszy.nwpu.edu.cn/en/songlingyun;http://liukeen.gr.xjtu.edu.cn;",
        "dblp": "254/9696;402/7177;304/3457;152/7478;95/3736-2;21/6081",
        "google_scholar": "https://scholar.google.com.hk/citations?user=nQFK26sAAAAJ;;https://scholar.google.com/citations?hl=en;https://scholar.google.com/citations?hl=zh-CN;7OjnHZMAAAAJ;",
        "orcid": ";;0000-0002-2879-2703;0000-0002-7892-2617;0000-0002-6004-0675;0000-0002-7249-8210",
        "linkedin": ";;;;;",
        "or_profile": "~Yudai_Pan1;~Jiajie_Hong1;~Tianzhe_Zhao1;~Lingyun_Song1;~Jun_Liu10;~Xuequn_Shang1",
        "aff": "Northwestern Polytechnical University;Northwest Polytechnical University Xi'an;Xi'an Jiaotong University;Northwestern Polytechnical University;Xi'an Jiaotong University;Northwest Polytechnical University ",
        "aff_domain": "nwpu.edu.cn;nwpu.edu.cn;xjtu.edu.cn;nwpu.edu.cn;xjtu.edu.cn;nwpu.edu.cn",
        "position": "Postdoc;MS student;PhD student;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\npan2025logicaware,\ntitle={Logic-Aware Knowledge Graph Reasoning for Structural Sparsity under Large Language Model Supervision},\nauthor={Yudai Pan and Jiajie Hong and Tianzhe Zhao and Lingyun Song and Jun Liu and Xuequn Shang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=49IQ5pP0PU}\n}",
        "github": "",
        "project": "",
        "reviewers": "HRJz;kJuB;pZ2x;C7Zh;GtfF",
        "site": "https://openreview.net/forum?id=49IQ5pP0PU",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;6;4;4;4",
        "scope": "4;4;3;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "4AumMJKets",
        "title": "D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "A vast amount of user behavior data is constantly accumulating on today's large recommendation platforms, recording users' various interests and tastes. Preserving knowledge from the old data while new data continually arrives is a vital problem for recommender systems. Existing approaches generally seek to save the knowledge implicitly in the model parameters. However, such a parameter-centric approach lacks scalability and flexibility---the capacity is hard to scale, and the knowledge is inflexible to utilize. Hence, in this work, we propose a framework that turns massive user behavior data to retrievable knowledge (D2K). It is a data-centric approach that is model-agnostic and easy to scale up. Different from only storing unary knowledge such as the user-side or item-side information, D2K propose to store ternary knowledge for recommendation, which is determined by the complete recommendation factors---user, item, and context. The knowledge retrieved by target samples can be directly used to enhance the performance of any recommendation algorithms. Specifically, we introduce a Transformer-based knowledge encoder to transform the old data into knowledge with the user-item-context cross features. A personalized knowledge adaptation unit is devised to effectively exploit the information from the knowledge base by adapting the retrieved knowledge to the target samples. Extensive experiments on two public datasets show that D2K significantly outperforms existing baselines and is compatible with a major collection of recommendation algorithms.",
        "keywords": "retrieval-enhanced recommendation;recommender systems;knowledge discovery",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiarui Qin;Weiwen Liu;Weinan Zhang;Yong Yu",
        "authorids": "~Jiarui_Qin1;~Weiwen_Liu1;~Weinan_Zhang1;~Yong_Yu1",
        "gender": "M;F;M;",
        "homepage": "https://jiaruiqin.me;https://wwliu555.github.io/;http://wnzhang.net;https://apex.sjtu.edu.cn/members/yyu",
        "dblp": "227/2898;75/2746;28/10261-1;43/5685.html",
        "google_scholar": "https://scholar.google.com.hk/citations?user=JPBGjOYAAAAJ;https://scholar.google.com.hk/citations?user=C7UzRGgAAAAJ;Qzss0GEAAAAJ;",
        "orcid": "0000-0002-9064-885X;0000-0002-9148-3997;0000-0002-0127-2425;0000-0003-4457-2820",
        "linkedin": ";;;",
        "or_profile": "~Jiarui_Qin1;~Weiwen_Liu1;~Weinan_Zhang1;~Yong_Yu1",
        "aff": "Tencent+Huawei Technologies Ltd.;Shanghai Jiaotong University+Huawei Technologies Ltd.;;Shanghai Jiaotong University",
        "aff_domain": "tencent.com+huawei.com;sjtu.edu.cn+huawei.com;;sjtu.edu.cn",
        "position": "Researcher+Researcher;Associate Professor+Researcher;;Full Professor",
        "bibtex": "@inproceedings{\nqin2025dk,\ntitle={D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems},\nauthor={Jiarui Qin and Weiwen Liu and Weinan Zhang and Yong Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=4AumMJKets}\n}",
        "github": "",
        "project": "",
        "reviewers": "8dRV;tCVE;bw68;xtp4",
        "site": "https://openreview.net/forum?id=4AumMJKets",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "6;4;5;6",
        "scope": "4;4;4;4",
        "confidence": "2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.25,
            0.82915619758885
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5222329678670935
    },
    {
        "id": "4ByDbWQ0GA",
        "title": "Triangle Matters! TopDyG: Topology-aware Transformer for Link Prediction on Dynamic Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Dynamic graph link prediction is widely utilized in the complex web of the real world, such as social networks, citation networks, recommendation systems, etc. Recent Transformer-based link prediction methods on dynamic graphs not only fail to model the fine-grained structures such as triangles with the vanilla Transformers in the graph serialization process, but also amplify the imbalanced distribution of graphs because of their over-estimation of high-degree nodes. To tackle these issues, we propose a Topology-aware Transformer on Dynamic Graph (TopDyG) for link prediction, consisting of a topology injected Transformer (Ti-Transformer) and a mutual information learning (Mi-Learning). % mainly consisting of two components, i.e., the topology-injected (Ti) Transformer and the mutual information (Mi) learning module. The Ti-Transformer explores the explicit structure of serialized graphs, capturing the topological features. The Mi-Learning  mines the relationship between nodes by modeling the mutual information with a prior knowledge,  alleviating the over-estimation of high-degree nodes when applying the Transformer-based models for the dynamic graph link prediction task. Extensive experiments on four public datasets containing both transductive and inductive settings present the superiority of our proposal. In particular, TopDyG presents an improvement of 43.27% and 28.75% against the state-of-the-art baselines in terms of NDCG and Jaccard, respectively. The advantages are especially obvious on the high-density graphs.",
        "keywords": "Dynamic graphs;Transformer;Link prediction;Topology",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xin Zhang;Fei Cai;Jianming Zheng;Zhiqiang Pan;Wanyu Chen;Honghui Chen;chonghao chen",
        "authorids": "~Xin_Zhang66;~Fei_Cai1;~Jianming_Zheng1;~Zhiqiang_Pan2;~Wanyu_Chen1;~Honghui_Chen2;~chonghao_chen1",
        "gender": "M;M;M;M;F;M;M",
        "homepage": ";;;https://nudtzpan.github.io/;;https://www.researchgate.net/scientific-contributions/Honghui-Chen-69552857;",
        "dblp": ";71/2935;132/5498;https://dblp.uni-trier.de/pid/178/6933;204/0075;;",
        "google_scholar": ";;;mOUou4sAAAAJ;;;",
        "orcid": "0000-0002-6070-1592;;;;;;0000-0003-3919-8598",
        "linkedin": ";;;;;;",
        "or_profile": "~Xin_Zhang66;~Fei_Cai1;~Jianming_Zheng1;~Zhiqiang_Pan2;~Wanyu_Chen1;~Honghui_Chen2;~chonghao_chen1",
        "aff": "National University of Defense Technology;;;National University of Defense Technology;National University of Defense Technology;;National University of Defense Technology",
        "aff_domain": "nudt.edu.cn;;;nudt.edu.cn;nudt.edu.cn;;nudt.edu.cn",
        "position": "PhD student;;;PhD student;Assistant Professor;;PhD student",
        "bibtex": "@inproceedings{\nzhang2025triangle,\ntitle={Triangle Matters! TopDyG: Topology-aware Transformer for Link Prediction on Dynamic Graphs},\nauthor={Xin Zhang and Fei Cai and Jianming Zheng and Zhiqiang Pan and Wanyu Chen and Honghui Chen and chonghao chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=4ByDbWQ0GA}\n}",
        "github": "",
        "project": "",
        "reviewers": "uwgS;miDj;ENxr;1qfe;MMAa",
        "site": "https://openreview.net/forum?id=4ByDbWQ0GA",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "5;4;5;6;5",
        "scope": "3;3;3;4;3",
        "confidence": "3;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "4MU3afGenY",
        "title": "Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of Function Slices Approach",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Spectral graph neural networks are proposed to harness spectral information inherent in graph-structured data through the application of polynomial-defined graph filters, recently achieving notable success in graph-based web applications. \nExisting studies reveal that various polynomial choices greatly impact spectral GNN performance, underscoring the importance of polynomial selection. \nHowever, this selection process remains a critical and unresolved challenge. \nAlthough prior work suggests a connection between the approximation capabilities of polynomials and the efficacy of spectral GNNs, there is a lack of theoretical insights into this relationship, rendering polynomial selection a largely heuristic process.\n\nTo address the issue, this paper examines polynomial selection from an error-sum of function slices perspective. \nInspired by the conventional signal decomposition, we represent graph filters as a sum of disjoint function slices. \nBuilding on this, we then bridge the polynomial capability and spectral GNN efficacy by proving that the construction error of graph convolution layer is bounded by the sum of polynomial approximation errors on function slices. \nThis result leads us to develop an advanced filter based on trigonometric polynomials, a widely adopted option for approximating narrow signal slices. \nThe proposed filter remains provable parameter efficiency, with a novel Taylor-based parameter decomposition that achieves streamlined, effective implementation. \nWith this foundation, we propose TFGNN, a scalable spectral GNN operating in a decoupled paradigm. \nWe validate the efficacy of TFGNN via benchmark node classification tasks, along with an example graph anomaly detection application to show its practical utility.",
        "keywords": "Spectral graph neural networks;Polynomial graph filters;Polynomial approximation;Node classification",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Guo-Ming Li;Jian Yang;Shangsong Liang;Dongsheng Luo",
        "authorids": "~Guo-Ming_Li1;~Jian_Yang15;~Shangsong_Liang1;~Dongsheng_Luo1",
        "gender": ";M;M;M",
        "homepage": ";https://github.com/jackyyang9;;https://users.cs.fiu.edu/~dluo/",
        "dblp": ";;57/7731;",
        "google_scholar": ";8jeXo28AAAAJ;4uggVcIAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";0009-0009-4916-8246;;0000-0003-4192-0826",
        "linkedin": ";;;",
        "or_profile": "~Guo-Ming_Li1;~Jian_Yang15;~Shangsong_Liang1;~Dongsheng_Luo1",
        "aff": ";Institute of Automation, Chinese Academy of Sciences;SUN YAT-SEN UNIVERSITY;Florida International University",
        "aff_domain": ";ia.ac.cn;sysu.edu.cn;fiu.edu",
        "position": ";MS student;Associate Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nli2025polynomial,\ntitle={Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of Function Slices Approach},\nauthor={Guo-Ming Li and Jian Yang and Shangsong Liang and Dongsheng Luo},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=4MU3afGenY}\n}",
        "github": "",
        "project": "",
        "reviewers": "x9qP;oaop;oTtN;m4k1;S5MB",
        "site": "https://openreview.net/forum?id=4MU3afGenY",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;3;6;5;5",
        "scope": "4;3;4;4;3",
        "confidence": "3;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.408248290463863
    },
    {
        "id": "4NipenMTmC",
        "title": "ArtistAuditor: Auditing Artist Style Pirate in Text-to-image Generation Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The text-to-image models based on diffusion processes, such as DALL-E, Stable Diffusion, and Midjourney, are capable of transforming texts into detailed images and have widespread applications in art and design. As such, amateur users can easily imitate professional-level paintings by collecting an artist\u2019s work and fine-tuning the model, leading to concerns about artworks\u2019 copyright infringement. To tackle these issues, previous studies either add visually imperceptible perturbation to the artwork to change its underlying styles (perturbation-based methods) or embed posttraining detectable watermarks in the artwork (watermark-based methods). However, when the artwork or the model has been published online, i.e., modification to the original artwork or model retraining is not feasible, these strategies might not be viable. \n\nTo this end, we propose a novel method for data-use auditing in the text-to-image generation model. The general idea of ArtistAuditor is to identify if a suspicious model has been fine-tuned using specific artists\u2019 artworks by analyzing style-related features. Concretely, ArtistAuditor employs a style extractor to obtain the multi-granularity style representations and treats artworks as samplings of an artist\u2019s style. Then, ArtistAuditor queries a trained discriminator to gain the auditing decisions. The experimental results on six combinations of models and datasets show that ArtistAuditor can achieve high AUC values (> 0.937). By studying ArtistAuditor\u2019s transferability and core modules, we provide valuable insights into the practical implementation. Finally, we demonstrate the effectiveness of ArtistAuditor in real-world cases by an online platform Scenario.1 ArtistAuditor is open-sourced at https://anonymous.4open.science/r/ArtistAuditor.",
        "keywords": "trustworthy machine learning;dataset copyright auditing;text-to-image model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Linkang Du;Zheng Zhu;Min Chen;su zhou;Shouling Ji;Peng Cheng;Jiming Chen;Zhikun Zhang",
        "authorids": "~Linkang_Du1;~Zheng_Zhu2;~Min_Chen9;~su_zhou1;~Shouling_Ji1;~Peng_Cheng9;~Jiming_Chen1;~Zhikun_Zhang2",
        "gender": "M;M;;M;M;M;M;M",
        "homepage": "https://www.linkangd.info/;https://jozenn.github.io/;;http://www.xjtu.edu.cn/;https://nesa.zju.edu.cn/;https://person.zju.edu.cn/cp;;http://zhangzhk.com/",
        "dblp": "246/4947.html;;;;07/8388;76/185-1;55/2484-1.html;90/545-1.html",
        "google_scholar": "r-neGREAAAAJ;;;;https://scholar.google.com.vn/citations?hl=en;https://scholar.google.com/citations?hl=zh-CN;zK9tvo8AAAAJ;-GFAhOEAAAAJ",
        "orcid": ";;;;0000-0003-4268-372X;;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Linkang_Du1;~Zheng_Zhu2;~Min_Chen9;~su_zhou1;~Shouling_Ji1;~Peng_Cheng9;~Jiming_Chen1;~Zhikun_Zhang2",
        "aff": "Xi'an Jiaotong University;The Chinese University of Hong Kong;;Xi'an Jiaotong University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University",
        "aff_domain": "xjtu.edu.cn;link.cuhk.edu.hk;;xjtu.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "Assistant Professor;PhD student;;Full Professor;Full Professor;Full Professor;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\ndu2025artistauditor,\ntitle={ArtistAuditor: Auditing Artist Style Pirate in Text-to-image Generation Models},\nauthor={Linkang Du and Zheng Zhu and Min Chen and su zhou and Shouling Ji and Peng Cheng and Jiming Chen and Zhikun Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=4NipenMTmC}\n}",
        "github": "",
        "project": "",
        "reviewers": "va58;34yU;bDYW;gtAx",
        "site": "https://openreview.net/forum?id=4NipenMTmC",
        "pdf_size": 0,
        "novelty": "2;5;5;5",
        "technical_quality": "4;4;5;5",
        "scope": "3;4;4;3",
        "confidence": "4;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.299038105676658
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8703882797784892
    },
    {
        "id": "51IyhOAptb",
        "title": "Query Design for Crowdsourced Clustering: Effect of Cognitive Overload and Contextual Bias",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Crowdsourced clustering leverages human input to group items into clusters. The design of tasks for crowdworkers, specifically the number of items presented per query, impacts answer quality and cognitive load. This work investigates the trade-off between query size and answer accuracy, revealing diminishing returns beyond 4-5 items per query. Crucially, we identify contextual bias in crowdworker responses \u2013 the likelihood of grouping items depends not only on their similarity but also on the other items present in the query. This structured noise contradicts assumptions made in existing noise models. Our findings underscore the need for more nuanced noise models that account for the complex interplay between items and query context in crowdsourced clustering tasks.",
        "keywords": "crowdsourcing;crowd clustering;cognitive overload;contextual bias",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yi Chen;Ramya Korlakai Vinayak",
        "authorids": "~Yi_Chen19;~Ramya_Korlakai_Vinayak1",
        "gender": "M;",
        "homepage": "https://www.deepneural.network/;https://ramyakv.github.io/",
        "dblp": ";148/9626",
        "google_scholar": "QoO6pMEAAAAJ;",
        "orcid": "0000-0002-7936-1575;",
        "linkedin": "reid-chen-1601a3185/;",
        "or_profile": "~Yi_Chen19;~Ramya_Korlakai_Vinayak1",
        "aff": "University of Wisconsin - Madison;University of Wisconsin - Madison",
        "aff_domain": "wisc.edu;wisc.edu",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nchen2025query,\ntitle={Query Design for Crowdsourced Clustering: Effect of Cognitive Overload and Contextual Bias},\nauthor={Yi Chen and Ramya Korlakai Vinayak},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=51IyhOAptb}\n}",
        "github": "",
        "project": "",
        "reviewers": "7BSi;HSUA;tzg5;qctG",
        "site": "https://openreview.net/forum?id=51IyhOAptb",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;5;5;6",
        "scope": "2;4;3;1",
        "confidence": "2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            2.5,
            1.118033988749895
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "5AHO1syvXl",
        "title": "ABXI: Invariant Interest Adaptation for Task-Guided Cross-Domain Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Cross-Domain Sequential Recommendation (CDSR) has recently gained attention for countering data sparsity by transferring knowledge across domains. A common approach merges domain-specific sequences into cross-domain sequences, serving as bridges that enable mutual enhancement between domains. One key challenge is to correctly extract the effective shared knowledge among these sequences and appropriately transfer it. Most existing works directly transfer unfiltered cross-domain knowledge rather than extracting domain-invariant components and adaptively integrating them into domain-specific modelings. Another challenge lies in aligning the domain-specific and cross-domain sequences. Existing methods align these sequences based on timestamps, but this approach can cause prediction mismatches when the current tokens and their targets belong to different domains. In such cases, the domain-specific knowledge carried by the current tokens may degrade performance. To address these challenges, we propose the A-B-Cross-to-Invariant Learning Recommender (\\textbf{ABXI}). Specifically, leveraging LoRA's effectiveness for efficient adaptation as supported by numerous studies, our model incorporates two types of LoRAs to facilitate the adaptation process. First, all sequences are processed through a shared encoder that employs a domain LoRA for each sequence, thereby preserving unique domain characteristics. Next, we introduce an invariant projector that extracts domain-invariant interests from cross-domain representations, utilizing an invariant LoRA as well to adapt these interests into recommendations in each specific domain. Besides, to avoid prediction mismatches, all domain-specific sequences are re-aligned to match the domains of the cross-domain ground truths. Experimental results on three datasets demonstrate that our approach achieves better results than other CDSR counterparts, with an average improvement of 17.30\\% in HR@10 and 18.65\\% in NDCG@10.",
        "keywords": "Invariant Learning;Cross-Domain Sequential Recommendation;Sequential Recommendation;Low-Rank Adaptation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qingtian Bian;Marcus Vinicius De Carvalho;Tieying Li;Jiaxing Xu;Hui Fang;Yiping Ke",
        "authorids": "~Qingtian_Bian1;~Marcus_Vinicius_De_Carvalho1;~Tieying_Li1;~Jiaxing_Xu2;~Hui_Fang7;~Yiping_Ke1",
        "gender": "M;M;M;;F;F",
        "homepage": ";;;;https://fangh.org/;https://keyiping.wixsite.com/index",
        "dblp": "348/5974;250/3110;00/7664;;03/2511-2;07/3111",
        "google_scholar": "https://scholar.google.com.sg/citations?hl=en;s0bJxcEAAAAJ;https://scholar.google.com/citations?hl=zh-CN;;784G0hYAAAAJ;https://scholar.google.com.tw/citations?user=30Fp0YYAAAAJ",
        "orcid": "0000-0002-6864-8992;0000-0003-2050-5260;0009-0002-0194-0590;;0000-0001-9788-6634;0000-0001-9473-3202",
        "linkedin": "dimarzio-qingtian-bian-952a69176/;ivsucram/;;;;",
        "or_profile": "~Qingtian_Bian1;~Marcus_Vinicius_De_Carvalho1;~Tieying_Li1;~Jiaxing_Xu2;~Hui_Fang7;~Yiping_Ke1",
        "aff": "Nanyang Technological University;Nanyang Technological University;Northeastern University;;Shanghai University of Finance and Economics;Nanyang Technological University",
        "aff_domain": "ntu.edu.sg;ntu.edu.sg;neu.edu.cn;;shufe.edu.cn;ntu.edu.sg",
        "position": "PhD student;Postdoc;PhD student;;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nbian2025abxi,\ntitle={{ABXI}: Invariant Interest Adaptation for Task-Guided Cross-Domain Sequential Recommendation},\nauthor={Qingtian Bian and Marcus Vinicius De Carvalho and Tieying Li and Jiaxing Xu and Hui Fang and Yiping Ke},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=5AHO1syvXl}\n}",
        "github": "",
        "project": "",
        "reviewers": "A3dB;uq4X;WMgL;fvhY;ZPtB",
        "site": "https://openreview.net/forum?id=5AHO1syvXl",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "4;5;4;6;4",
        "scope": "4;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "5I66GoEqnS",
        "title": "AURO: Reinforcement Learning for Adaptive User Retention Optimization in Recommender Systems",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The field of Reinforcement Learning (RL) has garnered increasing attention for its ability of optimizing  user retention in recommender systems. A primary obstacle in this optimization process is the environment non-stationarity stemming from the continual and complex evolution of user behavior patterns over time, such as variations in interaction rates and retention propensities. These changes pose significant challenges to existing RL algorithms for recommendations, leading to issues with dynamics and reward distribution shifts. This paper introduces a novel approach called Adaptive User Retention Optimization (AURO) to address this challenge. To navigate the recommendation policy in non-stationary environments, AURO introduces an state abstraction module in the policy network. The module is trained with a new value-based loss function, aligning its output with the estimated performance of the current policy. As the policy performance of RL is sensitive to environment drifts, the loss function enables the state abstraction to be reflective of environment changes and notify the recommendation policy to adapt accordingly. \nAdditionally, the non-stationarity of the environment introduces the problem of implicit cold start, where the recommendation policy continuously interacts with users displaying novel behavior patterns. AURO encourages exploration guarded by performance-based rejection sampling to maintain a stable recommendation quality in the cost-sensitive online environment.\nExtensive empirical analysis are conducted in a user retention simulator, the MovieLens dataset, and a live short-video recommendation platform, demonstrating AURO's superior performance against all evaluated baseline algorithms.",
        "keywords": "reinforcement learning;recommendation systems;user retention;non-stationary environment",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhenghai Xue;Qingpeng Cai;Bin Yang;Lantao Hu;Peng Jiang;Kun Gai;Bo An",
        "authorids": "~Zhenghai_Xue1;~Qingpeng_Cai2;~Bin_Yang13;~Lantao_Hu1;~Peng_Jiang6;~Kun_Gai1;~Bo_An2",
        "gender": ";M;M;M;M;M;M",
        "homepage": ";https://qingpengcai.github.io/;https://www.zhihu.com/people/hui-yuan-jia-gei-liao-ke-nan;;;;https://personal.ntu.edu.sg/boan/",
        "dblp": ";183/0940-1;;;;59/2902;42/6178-1.html",
        "google_scholar": ";uU6s1tYAAAAJ;;P0EK1y8AAAAJ;https://scholar.google.com/citations?hl=en;PXO4ygEAAAAJ;PEEpuNwAAAAJ",
        "orcid": ";0000-0001-6451-9299;;;0000-0002-9266-0780;;0000-0002-7064-7438",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhenghai_Xue1;~Qingpeng_Cai2;~Bin_Yang13;~Lantao_Hu1;~Peng_Jiang6;~Kun_Gai1;~Bo_An2",
        "aff": ";Kuaishou Technology;;;Kuaishou Technology;Kuaishou- \u5feb\u624b\u79d1\u6280;Nanyang Technological University",
        "aff_domain": ";kuaishou.com;;;kuaishou.com;kuaishou.com;ntu.edu.sg",
        "position": ";Senior Staff Research Scientist;;;Vice President;Instructor;Full Professor",
        "bibtex": "@inproceedings{\nxue2025auro,\ntitle={{AURO}: Reinforcement Learning for Adaptive User Retention Optimization in Recommender Systems},\nauthor={Zhenghai Xue and Qingpeng Cai and Bin Yang and Lantao Hu and Peng Jiang and Kun Gai and Bo An},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=5I66GoEqnS}\n}",
        "github": "",
        "project": "",
        "reviewers": "8oau;quX7;tE89;aBMP;pzN4",
        "site": "https://openreview.net/forum?id=5I66GoEqnS",
        "pdf_size": 0,
        "novelty": "3;3;3;4;7",
        "technical_quality": "5;5;4;5;7",
        "scope": "4;4;3;4;4",
        "confidence": "2;2;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.5491933384829668
        ],
        "technical_quality_avg": [
            5.2,
            0.9797958971132712
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "5T5lHzF8FM",
        "title": "Fairness-aware Prompt Tuning for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph prompt tuning has achieved significant success for its ability to effectively adapt pre-trained graph neural networks to various downstream tasks. However, the pre-trained models may learn discriminatory representation due to the inherent prejudice in graph-structured data. Existing graph prompt tuning overlooks such unfairness, leading to biased outputs towards certain demographic groups determined by sensitive attributes such as gender, age, and political ideology. To overcome this limitation, we propose a fairness-aware graph prompt tuning method to promote fairness while enhancing the generality of any pre-trained GNNs (named FPrompt). FPrompt introduces hybrid graph prompts to augment counterfactual data while aligning the pre-training and downstream tasks. It also applies edge modification to increase sensitivity heterophily. We provide a two-fold theoretical analysis: first, we demonstrate that FPrompt possesses universal capabilities in handling pre-trained GNN models across various pre-training strategies, ensuring its adaptability in different scenarios. Second, we show that FPrompt effectively reduces the upper bound of generalized statistical parity, thereby mitigating the bias of pre-trained models. Extensive experiments demonstrate that FPrompt outperforms baseline models in both accuracy and fairness (~$33$\\%) on benchmark datasets. Additionally, we introduce a new benchmark for transferable evaluation, showing that FPrompt achieves state-of-the-art generalization performance.",
        "keywords": "fairness;prompt tuning;graph neural networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhengpin Li;Minhua Lin;Jian Wang;Suhang Wang",
        "authorids": "~Zhengpin_Li1;~Minhua_Lin1;~Jian_Wang14;~Suhang_Wang1",
        "gender": "M;M;M;M",
        "homepage": ";https://ventr1c.github.io/;http://homepage.fudan.edu.cn/jianwang/;https://faculty.ist.psu.edu/szw494/",
        "dblp": ";274/1711;;136/9440",
        "google_scholar": ";qLjk9gIAAAAJ;5i7YIEgAAAAJ;cdT_WMMAAAAJ",
        "orcid": "0000-0003-0897-980X;0000-0003-1591-7172;;0000-0003-3448-4878",
        "linkedin": ";;;",
        "or_profile": "~Zhengpin_Li1;~Minhua_Lin1;~Jian_Wang14;~Suhang_Wang1",
        "aff": "Fudan University;Pennsylvania State University;;Pennsylvania State University",
        "aff_domain": "fdu.edu;psu.edu;;psu.edu",
        "position": "PhD student;PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\nli2025fairnessaware,\ntitle={Fairness-aware Prompt Tuning for Graph Neural Networks},\nauthor={Zhengpin Li and Minhua Lin and Jian Wang and Suhang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=5T5lHzF8FM}\n}",
        "github": "",
        "project": "",
        "reviewers": "wzRj;cM7x;LxQP;izW9;gLWV",
        "site": "https://openreview.net/forum?id=5T5lHzF8FM",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;3;5;5;4",
        "scope": "3;3;3;4;3",
        "confidence": "3;2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3952847075210474
    },
    {
        "id": "5Uhp3W5504",
        "title": "Price Stability and Improved Buyer Utility with Presentation Design: A Theoretical Study of The Amazon Buy Box",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Platforms design the forms of presentation by which sellers are shown to the buyers.  This design not only shapes the buyers' experience but also leads to different market equilibria or dynamics.  One component in this design is through the platform's mediation of the search frictions experienced by the buyers for different sellers.  We take a model of monopolistic competition and show that, on one hand, when all sellers have the same inspection costs, the market sees no stable price as the sellers always have incentive to undercut each other, and, on the other hand, the platform may stabilize the price by giving prominence to one seller chosen by a carefully designed mechanism.  This calls to mind Amazon's Buy Box design.  We study natural mechanisms for choosing the prominent seller, characterize the range of equilibrium prices implementable by them, and find, somewhat counterintuitively, that in certain scenarios the buyers' surplus improves as the search friction increases.",
        "keywords": "search friction;platforms;mechanism design;market equilibrium",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ophir Friedler;Hu Fu;Anna Karlin;Ariana Tang",
        "authorids": "~Ophir_Friedler1;~Hu_Fu2;~Anna_Karlin1;~Ariana_Tang1",
        "gender": "M;M;F;F",
        "homepage": ";http://www.fuhuthu.com;https://homes.cs.washington.edu/~karlin/;https://aritang.github.io/about/",
        "dblp": "144/4634.html;74/16-1;;",
        "google_scholar": "https://scholar.google.co.il/citations?user=avRZjLsAAAAJ;fcqBMQgAAAAJ;;",
        "orcid": ";0009-0005-4217-4329;;",
        "linkedin": "ophir-friedler-12146a10/;;;",
        "or_profile": "~Ophir_Friedler1;~Hu_Fu2;~Anna_Karlin1;~Ariana_Tang1",
        "aff": "Outbrain;Shanghai University of Finance and Economics;University of Washington;Shanghai University of Finance and Economics",
        "aff_domain": "outbrain.com;shufe.edu.cn;u.washington.edu;shufe.edu.cn",
        "position": "Researcher;Associate Professor;Full Professor;Undergrad student",
        "bibtex": "@inproceedings{\nfriedler2025price,\ntitle={Price Stability and Improved Buyer Utility with Presentation Design: A Theoretical Study of The Amazon Buy Box},\nauthor={Ophir Friedler and Hu Fu and Anna Karlin and Ariana Tang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=5Uhp3W5504}\n}",
        "github": "",
        "project": "",
        "reviewers": "rVCC;eEnY;6AEg;S2gk;wVM2",
        "site": "https://openreview.net/forum?id=5Uhp3W5504",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;5;6;6;6",
        "scope": "3;3;3;3;4",
        "confidence": "4;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7905694150420949
    },
    {
        "id": "5qxBSIA0l3",
        "title": "Explainable Multi-Modality Alignment for Transferable Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the development of multi-modality data modeling techniques, recent recommender systems use not only textual data and user-item interactions but also multi-modality data such as images to improve their performances. Existing methods typically adopt cross-modal pairwise alignment strategies to alleviate the gap between modalities. Nevertheless, this alignment paradigm has limitations on explainability, consistency, and expansibility, which may only achieve suboptimal performances. In this paper, we propose a novel Explainable generative multi-modality Alignment method for transferable Recommender systems, i.e., EARec. Specifically, we design a two-stage pipeline to achieve unified multi-modality alignment of items and the sequential recommendation task, respectively. In the first phase, we present a generation task that parallel aligns each modality from multiple source domains to an anchor with explainable meaning. Three modality features share the same anchor to achieve a consistent alignment direction. Additionally, we incorporate behavior-related information as an independent modality into the alignment framework, establishing a bridge that promotes the alignment between multi-modalities and behavior. In the second stage, we composite the aligned modality encoders into a unified one and then transfer it to the target domain to enhance sequential recommendation. The pipeline that adopts parallel multi-modal alignment and composition shows flexibility and scalability for incorporating new modalities. Experimental results on multiple public datasets demonstrate the superiority of EARec over multi-modality recommendation baselines and further analysis indicates the explainability of generative alignment.",
        "keywords": "Transferable recommendation;Multi-modality alignment;Explainable alignment",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shenghao Yang;Weizhi Ma;Zhiqiang Guo;Min Zhang;Haiyang Wu;Junjie Zhai;Chunhui Zhang;Yuekui Yang",
        "authorids": "~Shenghao_Yang3;~Weizhi_Ma1;~Zhiqiang_Guo2;~Min_Zhang15;~Haiyang_Wu2;~Junjie_Zhai2;~Chunhui_Zhang4;~Yuekui_Yang2",
        "gender": "M;M;;F;;M;F;M",
        "homepage": "https://ysh-1998.github.io/;http://mawz12.github.io;;http://www.thuir.cn/group/~mzhang;;;;",
        "dblp": "41/4482-4;169/1390;;83/5342-6;;;;79/2690",
        "google_scholar": "hZEGb7wAAAAJ;FO3lHi4AAAAJ;;0HtCYQEAAAAJ;;https://scholar.google.com/citations?hl=en;https://scholar.google.com.hk/citations?view_op=list_works;wHTMZjAAAAAJ",
        "orcid": "0009-0004-6896-4268;0000-0001-5604-7527;;0000-0003-3158-1920;;;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Shenghao_Yang3;~Weizhi_Ma1;~Zhiqiang_Guo2;~Min_Zhang15;~Haiyang_Wu2;~Junjie_Zhai2;~Chunhui_Zhang4;~Yuekui_Yang2",
        "aff": "Tsinghua University+Tsinghua University;Tsinghua University;;Tsinghua University;;;Tencent AMS;Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn+mail.tsinghua.edu.cn;tsinghua.edu.cn;;tsinghua.edu.cn;;;tencent.com;tsinghua.edu.cn",
        "position": "PhD student+Intern;Assistant Professor;;Full Professor;;;Researcher;PhD student",
        "bibtex": "@inproceedings{\nyang2025explainable,\ntitle={Explainable Multi-Modality Alignment for Transferable Recommendation},\nauthor={Shenghao Yang and Weizhi Ma and Zhiqiang Guo and Min Zhang and Haiyang Wu and Junjie Zhai and Chunhui Zhang and Yuekui Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=5qxBSIA0l3}\n}",
        "github": "",
        "project": "",
        "reviewers": "iTfr;bgTJ;tfFK;4ew1",
        "site": "https://openreview.net/forum?id=5qxBSIA0l3",
        "pdf_size": 0,
        "novelty": "3;4;4;6",
        "technical_quality": "4;3;4;6",
        "scope": "3;4;4;4",
        "confidence": "3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.25,
            1.0897247358851685
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.13245323570650439
    },
    {
        "id": "6B6AmBaWfv",
        "title": "Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based Code Selection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph self-supervised learning has gained significant attention recently. However, many existing approaches heavily depend on perturbations, and inappropriate perturbations may corrupt the graph\u2019s inherent information. The Vector Quantized Variational Autoencoder (VQ-VAE) is a powerful autoencoder extensively used in fields such as computer vision; however, its application to graph data remains underexplored. In this paper, we provide an empirical analysis of vector quantization in the context of graph autoencoders, demonstrating its significant enhancement of the model's capacity to capture graph topology. Furthermore, we identify two key challenges associated with vector quantization when applying in graph data: codebook underutilization and codebook space sparsity. For the first challenge, we propose an annealing-based encoding strategy that promotes broad code utilization in the early stages of training, gradually shifting focus toward the most effective codes as training progresses. For the second challenge, we introduce a hierarchical two-layer codebook that captures relationships between embeddings through clustering. The second layer codebook links similar codes, encouraging the model to learn closer embeddings for nodes with similar features and structural topology in the graph. Our proposed model outperforms 16 representative baseline methods in self-supervised link prediction and node classification tasks across multiple datasets. Our implementation is available at https://anonymous.4open.science/r/hqa-gae-D2F4.",
        "keywords": "Graph neural networks;Graph self-supervised learning;Vector quantized variational autoencoders",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Long Zeng;Jianxiang Yu;Jiapeng Zhu;Qingsong Zhong;Xiang Li",
        "authorids": "~Long_Zeng3;~Jianxiang_Yu1;~Jiapeng_Zhu2;~Qingsong_Zhong1;~Xiang_Li24",
        "gender": "M;M;M;M;M",
        "homepage": "https://vitaminzl.com/;https://jianxiangyu.github.io/;https://jasonzhujp.github.io/;;https://lixiang3776.github.io",
        "dblp": "08/10533-4;72/6230-1;169/7704-2;;40/1491-67.html",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.hk/citations?user=EH6ntM0AAAAJ;piCIfLwAAAAJ;https://scholar.google.com.hk/citations?user=EldZ-B8AAAAJ;JnxxNtsAAAAJ",
        "orcid": "0009-0008-9066-8165;0009-0006-9900-9815;0009-0009-5957-1661;;0009-0003-0142-2483",
        "linkedin": ";;;;",
        "or_profile": "~Long_Zeng3;~Jianxiang_Yu1;~Jiapeng_Zhu2;~Qingsong_Zhong1;~Xiang_Li24",
        "aff": "East China Normal University;East China Normal University;East China Normal University;East China Normal University;East China Normal University",
        "aff_domain": "stu.ecnu.edu.cn;ecnu.edu.cn;stu.ecnu.edu.cn;stu.ecnu.edu.cn;ecnu.edu.cn",
        "position": "MS student;PhD student;PhD student;MS student;Full Professor",
        "bibtex": "@inproceedings{\nzeng2025hierarchical,\ntitle={Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based Code Selection},\nauthor={Long Zeng and Jianxiang Yu and Jiapeng Zhu and Qingsong Zhong and Xiang Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=6B6AmBaWfv}\n}",
        "github": "",
        "project": "",
        "reviewers": "2Qbi;z8bS;a3PQ;aCrT;15fS",
        "site": "https://openreview.net/forum?id=6B6AmBaWfv",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "4;4;6;6;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;2;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.18333969940564226
    },
    {
        "id": "6LdQbh1dg0",
        "title": "Fair Personalized Learner Modeling Without Sensitive Attributes",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Personalized learner modeling uses learners' historical behavior data to diagnose their cognitive abilities, a process known as Cognitive Diagnosis (CD) in the literature.\nThis is a fundamental yet crucial task in web-based learning services, such as learning resource recommendation and adaptive testing. \nPreviously, researchers discovered that models improperly correlate learners' abilities with their sensitive attributes, resulting in unfair diagnoses for learners from different sensitive groups (e.g., gender, region).\nGiven the input of sensitive attributes, researchers proposed decorrelating these attributes from the modeling process, demonstrating improved fairness results. \nHowever, privacy concerns make collecting sensitive attributes impractical. This challenge is compounded by the presence of multiple sensitive attributes, making fairness improvement under any of them difficult.\nIn this paper, we explore how to achieve fair personalized learner modeling without relying on any sensitive attribute input. Specifically, we first introduce a novel fairness objective tailored for personalized learner modeling. We then propose a max-min strategy that facilitates both potential sensitive information inference and fair CD modeling. In the max step, we propose a pseudo-label inference method based on maximizing the designed fairness objective. Given these pseudo-labels, the min step involves retraining a fair CD model by minimizing the designed objective. \nAdditionally, we provide a theoretical guarantee that implementing our proposed framework reduces the upper bound of fairness generalization error.\nExtensive experiments demonstrate that\nthe proposed framework significantly outperforms existing methods in terms of fairness and accuracy. Our code is available at\nhttps://anonymous.4open.science/r/FairWISA-40C6/.",
        "keywords": "Fairness;User Modeling;Cognitive Diagnosis",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hefei Xu;Min Hou;Le Wu;Fei Liu;Yonghui Yang;Haoyue Bai;Richang Hong;Meng Wang",
        "authorids": "~Hefei_Xu1;~Min_Hou1;~Le_Wu1;~Fei_Liu12;~Yonghui_Yang1;~Haoyue_Bai2;~Richang_Hong1;~Meng_Wang2",
        "gender": "M;F;F;F;M;;M;",
        "homepage": ";https://scholar.google.com/citations?user=ENdvgjYAAAAJ&hl=zh-CN;http://le-wu.com/;http://faculty.hfut.edu.cn/feiliu/zh_CN/index.htm;https://yimutianyang.github.io/;;https://sites.google.com/site/homeofrichanghong/;",
        "dblp": "317/5460.html;15/6301-1;121/4234;64/1350-38.html;42/10465-1;;59/1501;",
        "google_scholar": "https://scholar.google.com.hk/citations?hl=zh-CN;ENdvgjYAAAAJ;4EzlnxwAAAAJ;RieYF9oAAAAJ;https://scholar.google.co.jp/citations?user=B8LCMuIAAAAJ;;https://scholar.google.com/scholar?hl=en;",
        "orcid": "0000-0001-7975-6844;0000-0002-0524-6806;0000-0003-4556-0581;0000-0003-0022-4103;0000-0002-7601-6004;;0000-0001-5461-3986;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Hefei_Xu1;~Min_Hou1;~Le_Wu1;~Fei_Liu12;~Yonghui_Yang1;~Haoyue_Bai2;~Richang_Hong1;~Meng_Wang2",
        "aff": "Hefei University of Technology;Hefei University of Technology;Hefei University of Technology;Hefei University of Technology;National University of Singapore;;Hefei University of Technology;",
        "aff_domain": "hfut.edu;hfut.edu.cn;hfut.edu;hfut.edu.cn;nus.edu.sg;;hfut.edu;",
        "position": "PhD student;Lecturer;Full Professor;Postdoc;Postdoc;;Full Professor;",
        "bibtex": "@inproceedings{\nxu2025fair,\ntitle={Fair Personalized Learner Modeling Without Sensitive Attributes},\nauthor={Hefei Xu and Min Hou and Le Wu and Fei Liu and Yonghui Yang and Haoyue Bai and Richang Hong and Meng Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=6LdQbh1dg0}\n}",
        "github": "",
        "project": "",
        "reviewers": "zXvD;cL4b;errU;Yeqq",
        "site": "https://openreview.net/forum?id=6LdQbh1dg0",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "3;3;5;5",
        "scope": "4;4;4;4",
        "confidence": "4;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.0,
            1.0
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9045340337332909
    },
    {
        "id": "6Mgc1ZLDZt",
        "title": "Frequency-Augmented Mixture-of-Heterogeneous-Experts Framework for Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recently, many efforts have been devoted to building effective sequential recommenders. Despite their effectiveness, these methods typically develop a single model to serve all users. However, our empirical studies reveal that different sequential encoders have intrinsic architectural biases and tend to focus on specific behavioral patterns, \\ie particular frequency range of user behavior sequences. For example, the Self-Attention module is essentially a low-pass filter, focusing on low-frequency information while neglecting the high-frequency details. This evidently limits their ability to capture diverse user patterns, leading to suboptimal recommendations.\n\nTo tackle this problem, we present FamouSRec, a Frequency-Augmented mixture-of-Heterogeneous-Experts Framework for personalized recommendations. Our approach builds an MoE-based recommender system, integrating the strengths of various experts to achieve diversified user modeling. For developing the MoE framework, as the key to our approach, we instantiate experts with various model architectures, aiming to leverage their inherent architectural biases and capture diverse behavioral patterns. For selecting appropriate experts to serve individuals, we introduce a frequency-augmented router. It first identifies frequency components in user behavior sequences that are suited for expert encoding, and then conducts customized routing based on the informativeness of these components. Building on this framework, we further propose two novel contrastive tasks to enhance expert specialization and alignment, thus further improving modeling efficacy and enabling robust recommendations. Extensive experiments on five real-world datasets demonstrate the effectiveness of our approach.",
        "keywords": "Sequential Recommendation;Mixture-of-Heterogeneous-Experts",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Junjie Zhang;Ruobing Xie;Hongyu Lu;Wenqi Sun;Xin Zhao;yu chen;Zhanhui Kang",
        "authorids": "~Junjie_Zhang11;~Ruobing_Xie2;~Hongyu_Lu1;~Wenqi_Sun1;~Xin_Zhao10;~yu_chen30;~Zhanhui_Kang1",
        "gender": "M;M;M;M;M;M;M",
        "homepage": "https://scholar.google.com.sg/citations?user=T6s-QEkAAAAJ;http://nlp.csai.tsinghua.edu.cn/~xrb/;https://github.com/luhongyu;https://github.com/wenqisun;https://gsai.ruc.edu.cn/addons/teacher/index/info.html?user_id=5&ruccode=20140041&ln=cn;https://github.com/pp7284;https://llm.hunyuan.tencent.com/",
        "dblp": "99/6243-9;178/8590;44/4328;https://dblp.uni-trier.de/pid/151/6247.html;https://dblp.uni-trier.de/pid/52/8700.html;;157/6432",
        "google_scholar": "https://scholar.google.com.sg/citations?user=T6s-QEkAAAAJ;j3OX8KUAAAAJ;;;JNhNacoAAAAJ;;",
        "orcid": "0009-0008-8864-915X;0000-0003-3170-5647;0000-0002-0247-2496;;0000-0002-8333-6196;0009-0002-0726-2727;0009-0006-5151-4222",
        "linkedin": ";;;;;;kang-kego-628b1b28/",
        "or_profile": "~Junjie_Zhang11;~Ruobing_Xie2;~Hongyu_Lu1;~Wenqi_Sun1;~Xin_Zhao10;~yu_chen30;~Zhanhui_Kang1",
        "aff": "Renmin University of China;Tencent;;Renmin University of China;Renmin University of China;;Tencent",
        "aff_domain": "ruc.edu.cn;tencent.com;;ruc.edu.cn;ruc.edu.cn;;tencent.com",
        "position": "MS student;Senior researcher;;PhD student;Full Professor;;Researcher",
        "bibtex": "@inproceedings{\nzhang2025frequencyaugmented,\ntitle={Frequency-Augmented Mixture-of-Heterogeneous-Experts Framework for Sequential Recommendation},\nauthor={Junjie Zhang and Ruobing Xie and Hongyu Lu and Wenqi Sun and Xin Zhao and yu chen and Zhanhui Kang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=6Mgc1ZLDZt}\n}",
        "github": "",
        "project": "",
        "reviewers": "5ZPW;c5v5;ygAV;Axhz;XFVL",
        "site": "https://openreview.net/forum?id=6Mgc1ZLDZt",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "3;4;5;5;5",
        "scope": "4;3;3;4;3",
        "confidence": "4;3;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.10206207261596578
    },
    {
        "id": "6xhP8YW7pI",
        "title": "LP-DIXIT: Evaluating Explanations for Link Prediction on Knowledge Graphs using Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Link prediction methods predict missing facts in incomplete knowledge graphs, often using embeddings to enhance scalability. However, embeddings complicate explainability, which is crucial for users' understanding of inferences in many domains. Methods emerged to explain predictions by identifying supporting portions of knowledge. To evaluate explanations from a user perspective, they can be compared to those in benchmarks, though they are limited to simplistic graphs. In contrast, user studies on forward simulatability variation measure how explanations improve predictability, i.e., the user ability to predict the results of inferences, which is key to trust. However, user studies face scalability and reproducibility issues on large graphs. Recognizing these gaps, we propose LP-DIXIT to algorithmically evaluate explanations of link predictions by determining forward simulatability variation and adopting large language models to mimic users, as is done in other domains, e.g., in evaluating other approaches on language related tasks. We experimentally prove that LP-DIXIT evaluates as effective explanations those in benchmarks, and we adopt it to compare state-of-the-art explanation methods.",
        "keywords": "Knowledge Graphs;Large Language Models;Link Prediction;Explanation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Roberto Barile;Claudia d'Amato;Nicola Fanizzi",
        "authorids": "~Roberto_Barile1;~Claudia_d'Amato1;~Nicola_Fanizzi2",
        "gender": "M;F;M",
        "homepage": "https://rbarile17.github.io/robertobarile.github.io/;http://www.di.uniba.it/~cdamato/;http://www.di.uniba.it/~fanizzi",
        "dblp": "342/5973.html;56/6773;https://dblp.uni-trier.de/pers/f/Fanizzi:Nicola",
        "google_scholar": "kZt7gWUAAAAJ\\;https://scholar.google.it/citations?user=Ah9jLLwAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": "0009-0007-3058-8692;0000-0002-3385-987X;0000-0001-5319-7933",
        "linkedin": "roberto-barile-308b391b7/;claudia-d-amato-2148073/;",
        "or_profile": "~Roberto_Barile1;~Claudia_d'Amato1;~Nicola_Fanizzi2",
        "aff": "University of Bari;University of Bari;University of Bari",
        "aff_domain": "uniba.it;uniba.it;uniba.it",
        "position": "PhD student;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nbarile2025lpdixit,\ntitle={{LP}-{DIXIT}: Evaluating Explanations for Link Prediction on Knowledge Graphs using Large Language Models},\nauthor={Roberto Barile and Claudia d'Amato and Nicola Fanizzi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=6xhP8YW7pI}\n}",
        "github": "",
        "project": "",
        "reviewers": "MNfY;TGNy;ExB6;uSkB",
        "site": "https://openreview.net/forum?id=6xhP8YW7pI",
        "pdf_size": 0,
        "novelty": "2;4;6;6",
        "technical_quality": "3;4;4;4",
        "scope": "4;3;4;3",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.6583123951777
        ],
        "technical_quality_avg": [
            3.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5222329678670935
    },
    {
        "id": "6yBhoJn6qy",
        "title": "Causal Modeling of Climate Activism on Reddit",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Climate activism is crucial in stimulating collective societal and behavioral change towards sustainable practices through political pressure.\nAlthough multiple factors contribute to the participation in activism, their complex relationships and the scarcity of data on their interactions have restricted most prior research to studying them in isolation, thus preventing the development of a quantitative, causal understanding of why people approach activism.\nIn this work, we develop a comprehensive causal model of how and why Reddit users engage with activist communities driving mass climate protests (mainly the 2019 Earth Strike, Fridays for Future, and Extinction Rebellion).\nOur framework, based on Stochastic Variational Inference applied to Bayesian Networks, learns the causal pathways over multiple time periods.\nDistinct from previous studies, our approach uses large-scale and fine-grained longitudinal data (2016 to 2022) to jointly model the roles of sociodemographic makeup, experience of extreme weather events, exposure to climate-related news, and social influence through online interactions.\nWe find that among users interested in climate change, participation in online activist communities is indeed influenced by direct interactions with activists and largely by recent exposure to media coverage of climate protests.\nAmong people aware of climate change, left-leaning people from lower socioeconomic backgrounds are particularly represented in online activist groups.\nOur findings offer empirical validation for theories of media influence and critical mass, and lay the foundations to inform interventions and future studies to foster public participation in collective action.",
        "keywords": "Collective Action;Reddit;Probabilistic Modeling;Climate Activism",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jacopo Lenti;Luca Maria Aiello;Corrado Monti;Gianmarco De Francisci Morales",
        "authorids": "~Jacopo_Lenti1;~Luca_Maria_Aiello1;~Corrado_Monti1;~Gianmarco_De_Francisci_Morales2",
        "gender": ";M;M;",
        "homepage": "https://twitter.com/LentiJacopo;http://www.lajello.com;https://corradomonti.com/;",
        "dblp": ";61/5674;125/2323;",
        "google_scholar": ";FIX-7hcAAAAJ;FAzWs2oAAAAJ;",
        "orcid": ";0000-0002-0654-2527;0000-0001-6846-5718;",
        "linkedin": ";lucamariaaiello/;;",
        "or_profile": "~Jacopo_Lenti1;~Luca_Maria_Aiello1;~Corrado_Monti1;~Gianmarco_De_Francisci_Morales2",
        "aff": "University of Roma \"La Sapienza\";IT University of Copenhagen;CENTAI;",
        "aff_domain": "uniroma1.it;itu.dk;centai.eu;",
        "position": "PhD student;Associate Professor;Researcher;",
        "bibtex": "@inproceedings{\nlenti2025causal,\ntitle={Causal Modeling of Climate Activism on Reddit},\nauthor={Jacopo Lenti and Luca Maria Aiello and Corrado Monti and Gianmarco De Francisci Morales},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=6yBhoJn6qy}\n}",
        "github": "",
        "project": "",
        "reviewers": "Vmc1;ebAG;M7Cz;8bmk;Dsf7",
        "site": "https://openreview.net/forum?id=6yBhoJn6qy",
        "pdf_size": 0,
        "novelty": "3;5;6;6;6",
        "technical_quality": "3;4;6;6;6",
        "scope": "3;4;3;4;4",
        "confidence": "3;3;1;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            1.2649110640673518
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.140028008402801
    },
    {
        "id": "7C6cd95qvH",
        "title": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from our cooperating hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at https://github.com/username00-c/MedRAG.git.",
        "keywords": "Heathcare Copilot;Retrieval-augmented Generation;Knowledge Graph;Large Language Models;Decision Support",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xuejiao Zhao;Siyan Liu;Su-Yin Yang;Chunyan Miao",
        "authorids": "~Xuejiao_Zhao1;~Siyan_Liu2;~Su-Yin_Yang1;~Chunyan_Miao1",
        "gender": "F;;M;F",
        "homepage": "https://zxjwudi.github.io/xuejiaozhao/;;;http://www.ntulily.org/ascymiao/",
        "dblp": ";;;m/ChunyanMiao",
        "google_scholar": "gcXa1o8AAAAJ;;;https://scholar.google.com.tw/citations?user=fmXGRJgAAAAJ",
        "orcid": "0000-0002-0185-1558;;;0000-0002-0300-3448",
        "linkedin": ";;su-yin-yang-b4304355/;",
        "or_profile": "~Xuejiao_Zhao1;~Siyan_Liu2;~Su-Yin_Yang1;~Chunyan_Miao1",
        "aff": "Nanyang Technological University;;;School of Computer Science and  Engineering, Nanyang Technological University",
        "aff_domain": "ntu.edu.sg;;;scse.ntu.edu.sg",
        "position": "Presidential Postdoctoral Fellow;;;Full Professor",
        "bibtex": "@inproceedings{\nzhao2025medrag,\ntitle={Med{RAG}: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot},\nauthor={Xuejiao Zhao and Siyan Liu and Su-Yin Yang and Chunyan Miao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7C6cd95qvH}\n}",
        "github": "",
        "project": "",
        "reviewers": "K92D;8RwY;6BSR",
        "site": "https://openreview.net/forum?id=7C6cd95qvH",
        "pdf_size": 0,
        "novelty": "4;4;6",
        "technical_quality": "4;4;6",
        "scope": "4;3;3",
        "confidence": "3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            0.9428090415820634
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.9428090415820634
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "7D5Q2eDJBf",
        "title": "Brewing Vodka: Distilling Pure Knowledge for Lightweight Threat Detection in Audit Logs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Advanced Persistent Threats (APTs) are continuously evolving, leveraging their stealthiness and persistence to put increasing pressure on current provenance-based Intrusion Detection Systems (IDS). This evolution exposes several critical issues: (1) The dense interaction between malicious and benign nodes within provenance graphs introduces neighbor noise, hindering effective detection; (2) The complex prediction mechanisms of existing APTs detection models lead to the insufficient utilization of prior knowledge embedded in the data; (3) The high computational cost makes detection impractical. \n\nTo address these challenges, we propose Vodka, a lightweight threat detection system built on a knowledge distillation framework, capable of node-level detection within audit log provenance graphs. Specifically, Vodka applies graph Laplacian regularization to reduce neighbor noise, obtaining smoothed and denoised graph signals. Subsequently, Vodka employs a teacher model based on GNNs to extract knowledge, which is then distilled into a lightweight student model. The student model is designed as a trainable combination of a feature transformation module and a personalized PageRank random walk label propagation module, with the former capturing feature knowledge and the latter learning label and structural knowledge. After distillation, the student model benefits from the knowledge of the teacher model to perform precise threat detection. Finally, Vodka reconstructs attack paths from anomalous nodes, providing insight into the attackers' strategies. We evaluate Vodka through extensive experiments on three public datasets and compare its performance against several state-of-the-art IDS solutions. The results demonstrate that Vodka achieves outstanding detection accuracy across all scenarios and the detection time is 1.4 to 5.2 times faster than the current state-of-the-art methods.",
        "keywords": "Threat Detection;Host Provenance;Knowledge Distillation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weiheng Wu;Wei Qiao;Wenhao Yan;Bo Jiang;Yuling Liu;Baoxu Liu;Zhigang Lu;JunRong Liu",
        "authorids": "~Weiheng_Wu1;~Wei_Qiao3;~Wenhao_Yan2;~Bo_Jiang18;~Yuling_Liu2;~Baoxu_Liu1;~Zhigang_Lu2;~JunRong_Liu1",
        "gender": "M;M;M;M;M;M;M;F",
        "homepage": ";;;https://people.ucas.ac.cn/~bojiang;http://people.ucas.edu.cn/~yulingliu;https://people.ucas.edu.cn/~liubx;https://people.ucas.ac.cn/~luzhigang;https://people.ucas.ac.cn/~0063896",
        "dblp": ";;;34/2005-13;;10/8471;91/7802-2;69/10773-1",
        "google_scholar": ";https://scholar.google.com.hk/citations?user=_OFu_KEAAAAJ;;https://scholar.google.com.hk/citations?user=Pp0ON9kAAAAJ;https://scholar.google.com.hk/citations?user=phDkQ60AAAAJ;;;",
        "orcid": "0009-0001-3114-7422;0000-0003-1561-9466;0009-0001-0174-9326;0000-0002-7185-990X;0000-0002-2740-9362;0000-0002-7005-1183;0000-0002-2552-6231;0009-0003-3383-2292",
        "linkedin": ";;;;;;;",
        "or_profile": "~Weiheng_Wu1;~Wei_Qiao3;~Wenhao_Yan2;~Bo_Jiang18;~Yuling_Liu2;~Baoxu_Liu1;~Zhigang_Lu2;~JunRong_Liu1",
        "aff": "Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering\uff0cChinese Academy of Sciences;Institute of Information Engineering\uff0cCAS;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering\uff0cChinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_domain": "cas.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;cas.cn",
        "position": "MS student;MS student;PhD student;Associate Professor;Full Professor;Full Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nwu2025brewing,\ntitle={Brewing Vodka: Distilling Pure Knowledge for Lightweight Threat Detection in Audit Logs},\nauthor={Weiheng Wu and Wei Qiao and Wenhao Yan and Bo Jiang and Yuling Liu and Baoxu Liu and Zhigang Lu and JunRong Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7D5Q2eDJBf}\n}",
        "github": "",
        "project": "",
        "reviewers": "Gdjk;NNTd;28Uk;jumh",
        "site": "https://openreview.net/forum?id=7D5Q2eDJBf",
        "pdf_size": 0,
        "novelty": "4;4;4;6",
        "technical_quality": "4;4;5;5",
        "scope": "2;4;2;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.0,
            1.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 1.0
    },
    {
        "id": "7DrAIYuW9o",
        "title": "FUNU: Boosting machine unlearning efficiency by filtering unnecessary unlearning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Machine unlearning is an emerging field that selectively removes specific data samples from a trained model. This capability is crucial for addressing privacy concerns, complying with data protection regulations, and correcting errors or biases introduced by certain data. Unlike traditional machine learning, where models are typically static once trained, machine unlearning facilitates dynamic updates that enable the model to \"forget\" information without requiring complete retraining from scratch. There are various machine unlearning methods, some of which are more time-efficient when data removal requests are fewer.\n\nTo decrease the execution time of such machine unlearning methods, we aim to reduce the size of data removal requests based on the fundamental assumption that the removal of certain data would not result in a distinguishable retrained model. We first propose the concept of unnecessary unlearning, which indicates that the model would not alter noticeably after removing some data points. Subsequently, we review existing solutions that can be used to solve our problem. We highlight their limitations in adaptability to different unlearning scenarios and their reliance on manually selected parameters. We consequently put forward FUNU, a method to identify data points that lead to unnecessary unlearning. FUNU circumvents the limitations of existing solutions. The idea is to discover data points within the removal requests that have similar neighbors in the remaining dataset. We utilize a reference model to set parameters for finding neighbors, inspired from the area of model memorization. We provide a theoretical analysis of the privacy guarantee offered by FUNU and conduct extensive experiments to validate its efficacy.",
        "keywords": "Machine unlearning;Data selection;Data prototype",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zitong LI;Qingqing Ye;Haibo Hu",
        "authorids": "~Zitong_LI7;~Qingqing_Ye1;~Haibo_Hu2",
        "gender": "F;F;M",
        "homepage": ";https://www.qingqingye.net/;https://www.haibohu.org",
        "dblp": ";194/0001-1;90/5236-1",
        "google_scholar": "5YtceqAAAAAJ;u9xzOh4AAAAJ;N3DjoZYAAAAJ",
        "orcid": "0000-0003-3458-9098;0000-0003-1547-2847;0000-0002-9008-2112",
        "linkedin": ";;haibo-hu-33b09419/",
        "or_profile": "~Zitong_LI7;~Qingqing_Ye1;~Haibo_Hu2",
        "aff": "Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Hong Kong Polytechnic University",
        "aff_domain": "connect.polyu.hk;polyu.edu.hk;polyu.edu.hk",
        "position": "PhD student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nli2025funu,\ntitle={{FUNU}: Boosting machine unlearning efficiency by filtering unnecessary unlearning},\nauthor={Zitong LI and Qingqing Ye and Haibo Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7DrAIYuW9o}\n}",
        "github": "",
        "project": "",
        "reviewers": "xtCF;bFUa;F3pg",
        "site": "https://openreview.net/forum?id=7DrAIYuW9o",
        "pdf_size": 0,
        "novelty": "5;6;6",
        "technical_quality": "5;5;5",
        "scope": "3;3;2",
        "confidence": "2;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.666666666666667,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.0,
            0.0
        ],
        "scope_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5
    },
    {
        "id": "7VjR70sxti",
        "title": "LLGformer: Learnable Long-range Graph Transformer for Traffic Flow Prediction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Traffic prediction plays a pivotal role in intelligent transportation systems. Most existing studies only predict traffic flow for a specific time period based on traffic data from a  short period, such as an hour, overlooking the influence of periodicity present in traffic data. Moreover, most of the existing advanced methods rely on manually constructed spatio-temporal graphs for joint modeling, or use pure spatial and pure temporal modules to separately model spatial and temporal features, which limits the learning of complex spatio-temporal patterns in traffic data due to structural inadequacies in the model. To address these issues, we propose a novel approach by constructing a learnable long-range spatio-temporal graph, which can better capture complex patterns in traffic data. We introduce a new model, LLGformer, which improves upon traditional Transformer-style models, facilitating more efficient learning of traffic flow data by integrating long-range historical information. Leveraging attention mechanisms on a spatiotemporal graph enables direct interaction of information across different time slices and locations. Additionally, we propose two optimization strategies to further boost the speed of training and inference. Extensive experiments on four real-world datasets show that the new model significantly outperforms state-of-the-art methods.",
        "keywords": "Traffic flow prediction;Transformer;Predictive model;Spatio-temporal graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Di Jin;Cuiying Huo;\u5e08\u4f73\u6021;Dongxiao He;Jianguo Wei;Philip S. Yu",
        "authorids": "~Di_Jin4;~Cuiying_Huo1;~\u5e08\u4f73\u60211;~Dongxiao_He1;~Jianguo_Wei2;~Philip_S._Yu1",
        "gender": "M;F;F;F;M;M",
        "homepage": "http://cic.tju.edu.cn/faculty/jindi/index.htm;https://cuiying-huo.github.io/;;http://cic.tju.edu.cn/faculty/hedongxiao/index.htm;http://cic.tju.edu.cn/faculty/weijianguo/index.html;https://cs.uic.edu/profiles/philip-yu/",
        "dblp": "67/1861-1.html;294/0972.html;;48/8875;;y/PhilipSYu",
        "google_scholar": "Q8MRRecAAAAJ;2GDJavEAAAAJ;https://scholar.google.com/citations?hl=zh-CN;JyqwTr4AAAAJ;;D0lL1r0AAAAJ",
        "orcid": ";0000-0003-4914-4577;;;;0000-0002-3491-5968",
        "linkedin": ";;;;;",
        "or_profile": "~Di_Jin4;~Cuiying_Huo1;~\u5e08\u4f73\u60211;~Dongxiao_He1;~Jianguo_Wei2;~Philip_S._Yu1",
        "aff": ";Tianjin University+Tianjin University;;Tianjin University;Tianjin University;University of Illinois Chicago",
        "aff_domain": ";tju.edu+tju.edu;;tju.edu.cn;tju.edu.cn;uic.edu",
        "position": ";Assistant Professor+PhD student;;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\njin2025llgformer,\ntitle={{LLG}former: Learnable Long-range Graph Transformer for Traffic Flow Prediction},\nauthor={Di Jin and Cuiying Huo and \u5e08\u4f73\u6021 and Dongxiao He and Jianguo Wei and Philip S. Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7VjR70sxti}\n}",
        "github": "",
        "project": "",
        "reviewers": "SsUk;X77v;71aP;hVfH",
        "site": "https://openreview.net/forum?id=7VjR70sxti",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "6;4;6;4",
        "scope": "3;3;4;1",
        "confidence": "3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            5.0,
            1.0
        ],
        "scope_avg": [
            2.75,
            1.0897247358851685
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "7ashts34aa",
        "title": "Serial Scammers and Attack of the Clones: How Scammers Coordinate Multiple Rug Pulls on Decentralized Exchanges",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "We explored in this work the ubiquitous phenomenon of serial scammers, who deploy thousands of addresses to conduct a series\nof similar Rug Pulls on popular decentralized exchanges (DEXs). We first constructed a list of about 163,000 scammer addresses behind all 1-day Rug Pulls on the two most popular DEXs, Uniswap (Ethereum) and Pancakeswap (BSC), and identified many distinctive scam patterns including star-shaped, chain-shaped and majority-flow scam clusters. We then proposed an algorithm to build a complete scam network from given scammer addresses, which consists of not only scammer addresses but also supporting addresses including depositors, withdrawers, transferrers, coordinators, and most importantly, wash traders. We note that profit estimations in existing works on Rug Pulls failed to capture the cost of wash trading, leading to inflated figures. Knowing who the wash traders are, we established a more accurate estimate for the true profit of individual scam pools as well as of the entire (serial) scam network by taking into account the wash-trading expenses.",
        "keywords": "crypto scam;rug pull;honey pot;trapdoor;uniswap;pancakeswap;Ethereum;BNB",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Phuong Duy Huynh;Son Hoang Dau;Nicholas Huppert;Joshua Cervenjak;Hoonie Sun;Hong Yen Tran;Xiaodong Li;Emanuele Viterbo",
        "authorids": "~Phuong_Duy_Huynh1;~Son_Hoang_Dau1;~Nicholas_Huppert1;~Joshua_Cervenjak1;~Hoonie_Sun1;~Hong_Yen_Tran1;~Xiaodong_Li5;~Emanuele_Viterbo2",
        "gender": "M;M;M;M;M;F;M;M",
        "homepage": ";https://www.rmit.edu.au/contact/staff-contacts/academic-staff/d/dau-dr-son-hoang;;;;;https://titan.csit.rmit.edu.au/~e46507/;https://www.monash.edu/engineering/emanueleviterbo",
        "dblp": ";;;;;;;",
        "google_scholar": "8FocunQAAAAJ;https://scholar.google.com.sg/citations?user=dEdfBuwAAAAJ;;;;djbQ2X0AAAAJ;https://scholar.google.com.au/citations?user=AQewL04AAAAJ;https://scholar.google.com.au/citations?user=Hc79xA8AAAAJ",
        "orcid": "0000-0003-3854-3820;0000-0002-2276-017X;;;;0000-0003-3308-3378;;0000-0002-5861-2873",
        "linkedin": "hpduy/;son-hoang-dau-a3162935;nicholas-huppert/;joshua-cervenjak/;hoonie;;;",
        "or_profile": "~Phuong_Duy_Huynh1;~Son_Hoang_Dau1;~Nicholas_Huppert1;~Joshua_Cervenjak1;~Hoonie_Sun1;~Hong_Yen_Tran1;~Xiaodong_Li5;~Emanuele_Viterbo2",
        "aff": ";Royal Melbourne Institute of Technology;Royal Melbourne Institute of Technology;Royal Melbourne Institute of Technology;;University of New South Wales;Royal Melbourne Institute of Technology;Monash University",
        "aff_domain": ";rmit.edu.au;rmit.edu.au;rmit.edu.au;;unsw.edu.au;rmit.edu.au;monash.edu",
        "position": ";Assistant Professor;Instructor;Researcher;;Postdoc;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nhuynh2025serial,\ntitle={Serial Scammers and Attack of the Clones: How Scammers Coordinate Multiple Rug Pulls on Decentralized Exchanges},\nauthor={Phuong Duy Huynh and Son Hoang Dau and Nicholas Huppert and Joshua Cervenjak and Hoonie Sun and Hong Yen Tran and Xiaodong Li and Emanuele Viterbo},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7ashts34aa}\n}",
        "github": "",
        "project": "",
        "reviewers": "BCLV;gSpN;3hs8;nUvV;KCbW",
        "site": "https://openreview.net/forum?id=7ashts34aa",
        "pdf_size": 0,
        "novelty": "3;3;4;4;5",
        "technical_quality": "5;3;3;2;4",
        "scope": "3;3;4;3;1",
        "confidence": "3;3;3;4;1",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            3.4,
            1.019803902718557
        ],
        "scope_avg": [
            2.8,
            0.9797958971132712
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6000991981489792
    },
    {
        "id": "7cYDkGVYza",
        "title": "Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across $\\mathbb{X}$ (formerly Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspiciously similar sharing behaviors within and across platforms. Introducing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and $\\mathbb{X}$. \nOur analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. \nThese findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.",
        "keywords": "Social media;Coordination detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Federico Cinus;Marco Minici;Luca Luceri;Emilio Ferrara",
        "authorids": "~Federico_Cinus1;~Marco_Minici2;~Luca_Luceri1;~Emilio_Ferrara1",
        "gender": "M;;;",
        "homepage": ";;https://luceriluc.it/;",
        "dblp": "267/0092.html;;168/6289;38/8773",
        "google_scholar": "T9NxWbYAAAAJ;;https://scholar.google.it/citations?user=veoVwKwAAAAJ;",
        "orcid": "0000-0002-6696-9637;;0000-0001-5267-7484;",
        "linkedin": "federico-cinus/;;;",
        "or_profile": "~Federico_Cinus1;~Marco_Minici2;~Luca_Luceri1;~Emilio_Ferrara1",
        "aff": "CENTAI+University of Rome \"La Sapienza\";;University of Southern California;University of Southern California",
        "aff_domain": "centai.eu+uniroma1.it;;usc.edu;usc.edu",
        "position": "PhD student+PhD student;;Researcher;Full Professor",
        "bibtex": "@inproceedings{\ncinus2025exposing,\ntitle={Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election},\nauthor={Federico Cinus and Marco Minici and Luca Luceri and Emilio Ferrara},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7cYDkGVYza}\n}",
        "github": "",
        "project": "",
        "reviewers": "PAbk;VDPV;FeGS;Ue3Z",
        "site": "https://openreview.net/forum?id=7cYDkGVYza",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;5;6;6",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.25,
            0.82915619758885
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "7rvRPJ5v3s",
        "title": "Motivation-Aware Session Planning over Heterogeneous Social Platforms",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the explosive growth of online service platforms, an increasing number of people and enterprises are undertaking personal and professional tasks online. In real applications such as trip planning and online marketing, planning sessions for a sequence of activities or services will enable social users to receive the optimal services, improving their experience and reducing the cost of their activities. These online platforms are heterogeneous, including different types of services with different attributes. However, the problem of session planning over heterogeneous platforms has not been studied so far. In this paper, we propose a Motivation-Aware Session Planning (MASP) framework for session planning over heterogeneous social platforms. Specifically, we first propose a novel HeterBERT model to handle the heterogeneity of items at both type and attribute levels. Then, we propose to predict user preference using the motivations behind user activities. Finally, we propose an algorithm together with its optimisations for efficient session generation. The extensive tests prove the high effectiveness and efficiency of MASP.",
        "keywords": "Session planning;Heterogeneous social platform",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chengkun He;Xiangmin Zhou;Yurong Cheng;Jie Shao;Guoren Wang;Iqbal Gondal;Zahir Tari",
        "authorids": "~Chengkun_He1;~Xiangmin_Zhou1;~Yurong_Cheng1;~Jie_Shao4;~Guoren_Wang1;~Iqbal_Gondal1;~Zahir_Tari1",
        "gender": "M;F;F;M;M;;M",
        "homepage": ";https://sites.google.com/site/xiangminemilyzhou;https://dblp.org/pid/09/10704.html;http://cfm.uestc.edu.cn/~shaojie/;https://guorenwang.github.io/;;https://www.rmit.edu.au/contact/staff-contacts/academic-staff/t/tari-zahir",
        "dblp": ";29/4724;09/10704.html;;64/146;89/115;t/ZahirTari",
        "google_scholar": ";https://scholar.google.com.au/citations?user=tZ4NyYAAAAAJ;;ikbw5okAAAAJ;;;https://scholar.google.com.au/citations?user=Pz9Z7C0AAAAJ",
        "orcid": "0000-0003-3144-7166;0000-0002-1302-818X;0000-0002-8696-9685;0000-0003-2615-1555;0000-0002-0181-8379;;0000-0002-1235-9673",
        "linkedin": ";;;;;;",
        "or_profile": "~Chengkun_He1;~Xiangmin_Zhou1;~Yurong_Cheng1;~Jie_Shao4;~Guoren_Wang1;~Iqbal_Gondal1;~Zahir_Tari1",
        "aff": ";Royal Melbourne Institute of Technology;Beijing Institute of Technology;University of Electronic Science and Technology of China;Beijing Institute of Technology;;Royal Melbourne Institute of Technology",
        "aff_domain": ";rmit.edu.au;bit.edu.cn;uestc.edu.cn;bit.edu.cn;;rmit.edu.au",
        "position": ";Senior Lecturer;Associate Professor;Professor;Full Professor;;Full Professor",
        "bibtex": "@inproceedings{\nhe2025motivationaware,\ntitle={Motivation-Aware Session Planning over Heterogeneous Social Platforms},\nauthor={Chengkun He and Xiangmin Zhou and Yurong Cheng and Jie Shao and Guoren Wang and Iqbal Gondal and Zahir Tari},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7rvRPJ5v3s}\n}",
        "github": "",
        "project": "",
        "reviewers": "sVQ3;4d2q;kpdk;ufhV;NjFq",
        "site": "https://openreview.net/forum?id=7rvRPJ5v3s",
        "pdf_size": 0,
        "novelty": "3;3;5;5;5",
        "technical_quality": "3;3;5;5;5",
        "scope": "4;3;3;3;4",
        "confidence": "3;4;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.2,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5833333333333334
    },
    {
        "id": "7vXNIWMuxx",
        "title": "Beyond Neighbors: Distance-Generalized Graphlets for Enhanced Graph Characterization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graphs are widely used to model complex systems across various domains, including social networks and biological systems. A key\ntask in graph analysis is identifying recurring structural patterns, known as graphlets, which capture connectivity among a fixed-size\nsubset of nodes. While graphlets have been extensively applied in tasks such as measuring graph similarity and identifying communities, conventional graphlets focus only on direct connections between nodes. This limitation overlooks potential insights from more distant relationships within the graph structure.\n\nIn this paper, we introduce (\ud835\udc51, \ud835\udc60)-graphlets, a generalization of size-\ud835\udc60 graphlets that incorporates indirect connections between nodes up to distance \ud835\udc51. This new formulation provides a more fine-grained and comprehensive understanding of local graph structures. To efficiently count (\ud835\udc51, \ud835\udc60)-graphlets in a graph, we present EDGE, an exact counting algorithm that employs optimized combinatorial techniques to significantly reduce computational complexity compared to naive enumeration. Our empirical analysis across diverse real-world datasets demonstrates that (\ud835\udc51, \ud835\udc60)-graphlets provide superior graph characterization, outperforming conventional graphlets in the graph clustering task. Moreover, our case studies show that (\ud835\udc51, \ud835\udc60)-graphlets uncover non-trivial insights that would remain undiscovered when using conventional graphlets.",
        "keywords": "Graphlets;graph mining;characterization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yeongho Kim;Yuyeong Kim;Geon Lee;Kijung Shin",
        "authorids": "~Yeongho_Kim1;~Yuyeong_Kim2;~Geon_Lee1;~Kijung_Shin2",
        "gender": "M;F;;M",
        "homepage": ";;https://geonlee0325.github.io/;https://kijungs.github.io/",
        "dblp": ";;;153/2052",
        "google_scholar": ";;https://scholar.google.co.kr/citations?user=2g2psXcAAAAJ;https://scholar.google.co.kr/citations?user=Yp3Cz5AAAAAJ",
        "orcid": "0009-0006-1722-6817;0000-0003-2440-9874;0000-0001-6339-9758;0000-0002-2872-1526",
        "linkedin": ";;geon-lee-70322a161/;kijungshin/",
        "or_profile": "~Yeongho_Kim1;~Yuyeong_Kim2;~Geon_Lee1;~Kijung_Shin2",
        "aff": "Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science & Technology",
        "aff_domain": "kaist.ac.kr;kaist.ac.kr;kaist.ac.kr;kaist.ac.kr",
        "position": "MS student;MS student;PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nkim2025beyond,\ntitle={Beyond Neighbors: Distance-Generalized Graphlets for Enhanced Graph Characterization},\nauthor={Yeongho Kim and Yuyeong Kim and Geon Lee and Kijung Shin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=7vXNIWMuxx}\n}",
        "github": "",
        "project": "",
        "reviewers": "mjev;HK7u;NsPs",
        "site": "https://openreview.net/forum?id=7vXNIWMuxx",
        "pdf_size": 0,
        "novelty": "3;5;6",
        "technical_quality": "4;5;6",
        "scope": "3;4;4",
        "confidence": "2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            1.247219128924647
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.18898223650461365
    },
    {
        "id": "80BpkRq6xe",
        "title": "PSSD: Making Large Language Models Self-denial via Human Psyche Structure",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The enhance of accuracy in reasoning results of LLMs arouses the community\u2019s interests, wherein pioneering studies investigate post-hoc strategies to rectify potential mistakes. Despite extensive efforts, they are all stuck in a state of resource competition demanding significant time and computing expenses. The cause of the situation lies in failing to identify the fundamental feature of the solutions in this line, coined as the self-denial of LLMs. In other words, LLMs should confidently determine the potential mistakes and carefully execute the targeted correction. As the whole procedure conducts within LLMs, supporting and persuasive references are hard to acquire, while the absence of specific steps towards refining mistakes persists even when errors are acknowledged. In response to the challenges, we present PSSD, which refers to and implements the human psyche structure such that three distinct and interconnected roles contribute to human reasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is further enhanced with three innovatively conceived roles: (1) the intuition-based id role that provides initial attempts based on benign LLMs; (2) the rule-driven superego role that summarizes rules to regulate the above attempts, and returns specific key points as guidance; and (3) the script-centric ego role that absorbs all procedural information to generate executable script for the final answer prediction. Extensive experiments demonstrate that the proposed design not only better enhance reasoning capabilities, but also seamlessly integrate with current models, leading to superior performance.",
        "keywords": "Mistake correction;Multi-agent debate;Self-denial",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jinzhi Liao;Zenghua Liao;Xiang Zhao",
        "authorids": "~Jinzhi_Liao1;~Zenghua_Liao1;~Xiang_Zhao1",
        "gender": ";M;M",
        "homepage": ";https://github.com/2308559259;https://xiangz-nudt.github.io/",
        "dblp": "219/3212;;07/668-2",
        "google_scholar": ";;https://scholar.google.com/citations?hl=en",
        "orcid": ";;0000-0001-6339-0219",
        "linkedin": ";;",
        "or_profile": "~Jinzhi_Liao1;~Zenghua_Liao1;~Xiang_Zhao1",
        "aff": "National University of Defense Technology;National University of Defense Technology;National University of Defense Technology",
        "aff_domain": "nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "position": "Assistant Professor;PhD student;Professor",
        "bibtex": "@inproceedings{\nliao2025pssd,\ntitle={{PSSD}: Making Large Language Models Self-denial via Human Psyche Structure},\nauthor={Jinzhi Liao and Zenghua Liao and Xiang Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=80BpkRq6xe}\n}",
        "github": "",
        "project": "",
        "reviewers": "gevB;JHrp;JqMb;EbR2;SCV9",
        "site": "https://openreview.net/forum?id=80BpkRq6xe",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "4;4;4;6;6",
        "scope": "3;3;3;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "8Cggwrvkho",
        "title": "Memory Never Fades: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Processing long contexts presents a significant challenge for large language models (LLMs). While recent advancements allow LLMs to handle much longer contexts than before (e.g., 32K or 128K tokens), it is computationally expensive and can still be insufficient for many applications. Retrieval-Augmented Generation (RAG) is considered as a promising strategy to address this problem. However, conventional RAG methods face inherent limitations because of two underlying requirements: 1) explicitly-stated queries, and 2) well-structured knowledge. These conditions, however, do not hold in general long-context processing tasks. \nIn this work, we propose HawkRAG, a novel RAG framework empowered by global memory-augmented retrieval. HawkRAG features a dual-system architecture. The name HawkRAG is inspired by the way a hawk glides high in the sky to observe the land, allowing it to spot and target prey with precision from a broad vantage point. First, it employs a light but long-range system to create a global memory of the long context. Once a task is presented, it generates draft answers, providing useful clues for the retrieval tools to locate relevant information within the long context. Second, it leverages an expensive but expressive system, which generates the final answer based on the retrieved information. Building upon this fundamental framework, we realize the memory module in the form of KV compression, and reinforce its memorization and cluing capacity from the Generation quality's Feedback (a.k.a. RLGF). In our experiments, HawkRAG achieves superior performances across a variety of long-context evaluation tasks, not only complex scenarios where traditional RAG methods struggle, but also simpler ones where RAG is typically applied.",
        "keywords": "Retrieval-Augmented Generation;Long Context Processing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hongjin Qian;Zheng Liu;Peitian Zhang;Kelong Mao;Defu Lian;Zhicheng Dou;Tiejun Huang",
        "authorids": "~Hongjin_Qian1;~Zheng_Liu4;~Peitian_Zhang1;~Kelong_Mao1;~Defu_Lian1;~Zhicheng_Dou1;~Tiejun_Huang1",
        "gender": "M;;M;;M;;M",
        "homepage": "https://qhjqhj00.github.io;https://www.microsoft.com/en-us/research/people/zhengliu/;https://www.namespace-pt.com;https://kyriemao.github.io;https://faculty.ustc.edu.cn/liandefu/en/index.htm;https://playbigdata.ruc.edu.cn/dou;https://idm.pku.edu.cn/~tjhuang/",
        "dblp": "275/2898;06/3580-11;304/3403;270/6458;87/10734;18/5740;h/TiejunHuang",
        "google_scholar": "u9uPuxsAAAAJ;https://scholar.google.com.hk/citations?user=k2SF4M0AAAAJ;KyH5b58AAAAJ;SXAurKsAAAAJ;QW0ad4sAAAAJ;ChCjAAwAAAAJ;https://scholar.google.com.tw/citations?user=knvEK4AAAAAJ",
        "orcid": "0000-0003-4011-5673;0000-0001-7765-8466;0009-0007-1926-7433;0000-0002-5648-568X;0000-0002-3507-9607;0000-0002-9781-948X;0000-0002-4234-6099",
        "linkedin": ";;;;;;",
        "or_profile": "~Hongjin_Qian1;~Zheng_Liu4;~Peitian_Zhang1;~Kelong_Mao1;~Defu_Lian1;~Zhicheng_Dou1;~Tiejun_Huang1",
        "aff": "Beijing Academy of Artificial Intelligence+Peking University;Microsoft Research;Renmin University of China;Renmin University of China;University of Science and Technology of China;Renmin University of China;Peking University",
        "aff_domain": "baai.ac.cn+pku.edu.cn;research.microsoft.com;ruc.edu.cn;ruc.edu.cn;ustc.edu.cn;ruc.edu.cn;pku.edu.cn",
        "position": "Researcher+Postdoc;Researcher;MS student;PhD student;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nqian2025memory,\ntitle={Memory Never Fades: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation},\nauthor={Hongjin Qian and Zheng Liu and Peitian Zhang and Kelong Mao and Defu Lian and Zhicheng Dou and Tiejun Huang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8Cggwrvkho}\n}",
        "github": "",
        "project": "",
        "reviewers": "2GH3;GMKc;2yvR;USmj;k1fD",
        "site": "https://openreview.net/forum?id=8Cggwrvkho",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "3;4;5;4;7",
        "scope": "2;4;4;4;4",
        "confidence": "3;2;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            1.3564659966250536
        ],
        "scope_avg": [
            3.6,
            0.8000000000000002
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.42857142857142855
    },
    {
        "id": "8LuVZOMqF6",
        "title": "Plug and Play: Enabling Pluggable Attribute Unlearning in Recommender Systems",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the escalating privacy concerns in recommender systems, attribute unlearning has drawn widespread attention as an effective approach against attribute inference attacks. This approach focuses on unlearning users' privacy attributes to reduce the performance of attackers while preserving the overall effectiveness of recommendation. Current research attempts to achieve attribute unlearning through adversarial training and distribution alignment in the statistic setting. However, these methods often struggle in dynamic real-world environments, particularly when considering scenarios where unlearning requests are frequently updated. In this paper, we first identify three main challenges of current methods in dynamic environments, i.e., irreversible operation, low efficiency, and unsatisfied recommendation preservation. To overcome these challenges, we propose a Pluggable Attribute Unlearning framework, PAU. Upon receiving an unlearning request, PAU plugs an additional erasure module into the original model to achieve unlearning. This module can perform a reverse operation if the request is later withdrawn. To enhance the efficiency of unlearning, we introduce rate distortion theory and reduce the attack performance by maximizing the encoded bits required for users' embedding within the same class of the unlearned attribute and minimizing those for different classes. We further preserve recommendation performance by constraining the compactness of the user embedding space using an adjustable flooding parameter/around a reasonable flooding level. Extensive experiments conducted on four real-world datasets and three mainstream recommendation models demonstrate the effectiveness of our proposed framework.",
        "keywords": "Recommender Systems;Collaborative Filtering;Attribute Unlearning;Pluggable",
        "primary_area": "",
        "supplementary_material": "",
        "author": "XiaoHua Feng;Yuyuan Li;Fengyuan Yu;Li Zhang;Chaochao Chen;Xiaolin Zheng",
        "authorids": "~XiaoHua_Feng3;~Yuyuan_Li1;~Fengyuan_Yu1;~Li_Zhang41;~Chaochao_Chen3;~Xiaolin_Zheng1",
        "gender": "M;;M;M;;M",
        "homepage": ";;https://anonymifish.github.io;http://GitHub.io;https://sites.google.com/site/ccchomepage/;https://person.zju.edu.cn/xlzheng",
        "dblp": ";35/11288;;;26/1492-1;09/5763",
        "google_scholar": "https://scholar.google.com/citations?hl=en;v4e49qEAAAAJ;Lyh7nRQAAAAJ;;qZTMyzwAAAAJ;MY23M60AAAAJ",
        "orcid": "0009-0001-6829-7088;0000-0003-4896-2885;0009-0005-0491-1869;;0000-0003-1419-964X;0000-0001-5483-0366",
        "linkedin": ";;;;ccchomepage/;",
        "or_profile": "~XiaoHua_Feng3;~Yuyuan_Li1;~Fengyuan_Yu1;~Li_Zhang41;~Chaochao_Chen3;~Xiaolin_Zheng1",
        "aff": "Zhejiang University;Hangzhou Dianzi University;Zhejiang University;Zhejiang University+Zhejiang University;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;hdu.edu.cn;zju.edu.cn;zju.edu.cn+zju.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "PhD student;Associate Professor;PhD student;Intern+MS student;Distinguished Research Fellow;Full Professor",
        "bibtex": "@inproceedings{\nfeng2025plug,\ntitle={Plug and Play: Enabling Pluggable Attribute Unlearning in Recommender Systems},\nauthor={XiaoHua Feng and Yuyuan Li and Fengyuan Yu and Li Zhang and Chaochao Chen and Xiaolin Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8LuVZOMqF6}\n}",
        "github": "",
        "project": "",
        "reviewers": "Ve49;aRzg;fW3J;qj9B",
        "site": "https://openreview.net/forum?id=8LuVZOMqF6",
        "pdf_size": 0,
        "novelty": "3;5;6;6",
        "technical_quality": "2;5;6;6",
        "scope": "3;3;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.224744871391589
        ],
        "technical_quality_avg": [
            4.75,
            1.6393596310755
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "8O8eqpaCAI",
        "title": "Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs)-based recommendation algorithms typically assume that training and testing data\nare drawn from independent and identically distributed (IID) spaces. However, this assumption often fails in the presence of\nout-of-distribution (OOD) data, resulting in significant performance degradation. In this study, we construct a Structural\nCausal Model (SCM) to analyze interaction data, revealing that environmental confounders (e.g., the COVID-19 pandemic) lead\nto unstable correlations in GNN-based models, thus impairing their generalization to OOD data. To address this issue, we\npropose a novel approach, graph representation learning via causal diffusion (CausalDiffRec) for OOD recommendation. This\nmethod enhances the model\u2019s generalization on OOD data by eliminating environmental confounding factors and learning\ninvariant graph representations. Specifically, we use backdoor adjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This inferred distribution is then used as prior\nknowledge to guide the representation learning in the reverse phase of the diffusion process to learn the invariant representa-\ntion. In addition, we provide a theoretical derivation that proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby achieving excellent generalization performance in recom-\nmendations under distribution shifts. Our extensive experiments validate the effectiveness of CausalDiffRec in improving the\ngeneralization of OOD data, and the average improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018,\nand 11.65% on Douban datasets.",
        "keywords": "Graph Neural Networks;Out-of-distribution;Invariant Learning;Recommender Systems",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chu Zhao;Enneng Yang;Yuliang Liang;Pengxiang Lan;Yuting Liu;Jianzhe Zhao;Guibing Guo;Xingwei Wang",
        "authorids": "~Chu_Zhao2;~Enneng_Yang1;~Yuliang_Liang2;~Pengxiang_Lan1;~Yuting_Liu5;~Jianzhe_Zhao1;~Guibing_Guo2;~Xingwei_Wang3",
        "gender": "M;M;;M;M;F;M;M",
        "homepage": "https://anonymous.4open.science/;;;;https://vanillacreamer.github.io/;http://faculty.neu.edu.cn/zhaojz/zh_CN/index/110560/list/index.htm;https://guoguibing.github.io/cn/;https://www.neu.edu.cn/info/1012/3221.htm",
        "dblp": ";246/2889;;;20/7910-3;126/2196;84/10716;99/4694-1",
        "google_scholar": ";;;https://scholar.google.com.hk/citations?user=ULw0mF0AAAAJ;;;YMXJa2EAAAAJ;",
        "orcid": ";0000-0001-5419-5286;0000-0002-2946-7910;;;0000-0003-4492-5075;;0000-0003-2856-4716",
        "linkedin": ";;;;;;;",
        "or_profile": "~Chu_Zhao2;~Enneng_Yang1;~Yuliang_Liang2;~Pengxiang_Lan1;~Yuting_Liu5;~Jianzhe_Zhao1;~Guibing_Guo2;~Xingwei_Wang3",
        "aff": "Northeastern University ;SUN YAT-SEN UNIVERSITY+Nanyang Technological University+Northeastern University;Northeastern University;Northeastern University;Northeastern University;Northeastern University;Northeastern University;Northeastern University",
        "aff_domain": "northeastern.edu;sysu.edu.cn+ntu.edu.sg+neu.edu.cn;neu.edu.cn;neu.edu.cn;neu.edu;neu.edu;neu.edu.cn;neu.edu",
        "position": "PhD student;Postdoc+PhD student+PhD student;PhD student;PhD student;PhD student;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhao2025graph,\ntitle={Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation},\nauthor={Chu Zhao and Enneng Yang and Yuliang Liang and Pengxiang Lan and Yuting Liu and Jianzhe Zhao and Guibing Guo and Xingwei Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8O8eqpaCAI}\n}",
        "github": "",
        "project": "",
        "reviewers": "1rgP;Gm2P;TrdZ;8Mrh",
        "site": "https://openreview.net/forum?id=8O8eqpaCAI",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "4;5;5;6",
        "scope": "4;3;3;4",
        "confidence": "4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.42640143271122083
    },
    {
        "id": "8OIqXq455O",
        "title": "SigScope: Detecting and Understanding Off-Chain Message Signing-related Vulnerabilities in Decentralized Applications",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In Web 3.0, an emerging paradigm of building decentralized applications or DApps is off-chain message signing, which has advantages in performance, cost efficiency, and usability compared to conventional transaction-signing schemes. However, message signing burdens DApp developers with extra coding complexity and message designing, leading to new security risks.\nThis paper presents the first systematic study to uncover and characterize the security issues in off-chain message signing schemes and the DApps built atop them. We present a holistic static-analysis framework, SIGSCOPE, that uniquely combines the insights extracted from DApp frontend code (HTML and Javascript) off-chain and backend smart contracts on-chain.\nWe evaluate SIGSCOPE using the top 100 DApps to showcase its effectiveness and efficiency. Further, we leverage SIGSCOPE to study a large dataset of 4937 real-world DApps and show that 1579 DApps (including 73% of the top 100) rely on the off-chain message signing feature, and 1154 contain vulnerabilities. Finally, we use two real-world vulnerabilities in popular DApps to showcase our findings.",
        "keywords": "Blockchains Security;Smart Contract;Decentralized Applications;Off-Chain Message Signing;Signing-related Vulnerabilities",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sajad Meisami;Hugo Dabadie;Song Li;Yuzhe Tang;Yue Duan",
        "authorids": "~Sajad_Meisami1;~Hugo_Dabadie1;~Song_Li7;~Yuzhe_Tang1;~Yue_Duan3",
        "gender": "M;;M;;M",
        "homepage": ";;https://songli.io/;https://tristartom.github.io/;https://yueduan.github.io/",
        "dblp": ";;67/2580-6;;",
        "google_scholar": "https://scholar.google.com/citations?view_op=list_works;;BBPDISIAAAAJ;;q3rLf5kAAAAJ",
        "orcid": "0009-0008-8535-2975;0009-0008-3693-5314;0000-0002-7961-8502;;",
        "linkedin": "sajad-meisami-23739818b;;;;",
        "or_profile": "~Sajad_Meisami1;~Hugo_Dabadie1;~Song_Li7;~Yuzhe_Tang1;~Yue_Duan3",
        "aff": "Illinois Institute of Technology;;Hangzhou High-Tech Zone (Bin jiang) Institute of Blockchain and Data Security+Zhejiang University+Zhejiang University;;Singapore Management University",
        "aff_domain": "hawk.iit.edu;;hzbcds.zju.edu.cn+zju.edu.cn+zju.edu.cn;;smu.edu.sg",
        "position": "PhD student;;Assistant Professor+Assistant Professor+Assistant Professor;;Assistant Professor",
        "bibtex": "@inproceedings{\nmeisami2025sigscope,\ntitle={SigScope: Detecting and Understanding Off-Chain Message Signing-related Vulnerabilities in Decentralized Applications},\nauthor={Sajad Meisami and Hugo Dabadie and Song Li and Yuzhe Tang and Yue Duan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8OIqXq455O}\n}",
        "github": "",
        "project": "",
        "reviewers": "F6rr;hHDW;qZnf;gKc8;o5P4",
        "site": "https://openreview.net/forum?id=8OIqXq455O",
        "pdf_size": 0,
        "novelty": "1;2;3;5;7",
        "technical_quality": "1;2;6;5;6",
        "scope": "3;4;3;3;4",
        "confidence": "4;4;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            3.6,
            2.1540659228538015
        ],
        "technical_quality_avg": [
            4.0,
            2.0976176963403033
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.8944271909999159
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5190342490858748
    },
    {
        "id": "8OxDT9vnIU",
        "title": "C$^3$AI: Crafting and Evaluating Constitutions for Constitutional AI",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As large language models (LLMs) become more integrated into daily life, ensuring they align with human values is crucial for both safety and transparency. Constitutional AI (CAI) offers a novel approach to self-aligning LLMs by using sets of principles, referred to as constitutions. While this method is elegant in its ability to self-supervise without the need for costly human annotations, uncertainty remains about how to create effective constitutions and evaluate the models based on them. Specifically, it is unclear to what extent a CAI model adheres to specific principles within its constitution and how differences in these constitutions affect the model\u2019s overall behavior. To address this, we propose our C$^3$AI framework, which utilizes a pairwise preference evaluator to craft more effective constitutions. By incorporating insights from both AI and psychology, we evaluate a diverse set of principles using a network psychometric approach, constructing a constitutional principle graph to identify the most informative principles. Our findings reveal that the degree of principle-human agreement varies across different principles and conversational categories (such as harmless, helpful, and general conversations). For instance, principles that emphasize respecting human rights, unsurprisingly, show higher human agreement on harmlessness. We then apply our graph-based principle selection method in a safety alignment use case and compare it to previous CAI approaches without principle selection. We found that fine-tuned CAI models tend to perform well on negatively framed principles (e.g., minimizing aggression) but perform worse on positively framed principles (e.g., those focused on benefiting humanity). Compared to prior work, our principle-selection-based fine-tuned model performs better on safety measures while maintaining competitive performance in terms of general capabilities. Overall, C$^3$AI provides a systematic and transparent approach to developing constitutional AI models, laying a foundation for more reliable and ethical LLM alignment.",
        "keywords": "Constitutional AI;Human-AI Alignment;Responsible AI",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yara Kyrychenko;Ke Zhou;Edyta Bogucka;Daniele Quercia",
        "authorids": "~Yara_Kyrychenko1;~Ke_Zhou3;~Edyta_Bogucka1;~Daniele_Quercia2",
        "gender": ";;F;M",
        "homepage": "https://www.sdmlab.psychol.cam.ac.uk/staff/yara-kyrychenko;;;https://researchswinger.org",
        "dblp": ";;;04/1995",
        "google_scholar": ";;EdAme-MAAAAJ;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Yara_Kyrychenko1;~Ke_Zhou3;~Edyta_Bogucka1;~Daniele_Quercia2",
        "aff": "University of Cambridge;;;Nokia Bell Labs Cambridge",
        "aff_domain": "cam.ac.uk;;;nokia-bell-labs.com",
        "position": "PhD student;;;Full Professor",
        "bibtex": "@inproceedings{\nkyrychenko2025cai,\ntitle={C\\${\\textasciicircum}3\\${AI}: Crafting and Evaluating Constitutions for Constitutional {AI}},\nauthor={Yara Kyrychenko and Ke Zhou and Edyta Bogucka and Daniele Quercia},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8OxDT9vnIU}\n}",
        "github": "",
        "project": "",
        "reviewers": "sZDJ;YyG5;jG7Q;WTXd",
        "site": "https://openreview.net/forum?id=8OxDT9vnIU",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "6;3;5;5",
        "scope": "3;4;4;3",
        "confidence": "3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            4.75,
            1.0897247358851685
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7071067811865475
    },
    {
        "id": "8QJCZmycIS",
        "title": "Policy-Guided Causal State Representation for Offline Reinforcement Learning Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In offline reinforcement learning-based recommender systems (RLRS), learning effective state representations is crucial for capturing user preferences that directly impact long-term rewards. However, raw state representations often contain high-dimensional, noisy information and components that are not causally relevant to the reward. Additionally, missing transitions in offline data make it challenging to accurately identify features that are most relevant to user satisfaction. To address these challenges, we propose Policy-Guided Causal Representation (PGCR), a novel two-stage framework for causal feature selection and state representation learning in offline RLRS. In the first stage, we learn a causal feature selection policy that generates modified states by isolating and retaining only the causally relevant components (CRCs) while altering irrelevant components. This policy is guided by a reward function based on the Wasserstein distance, which measures the causal effect of state components on the reward and encourages the preservation of CRCs that directly influence user interests. In the second stage, we train an encoder to learn compact state representations by minimizing the mean squared error (MSE) loss between the latent representations of the original and modified states, ensuring that the representations focus on CRCs and filter out irrelevant variations. We provide a theoretical analysis proving the identifiability of causal effects from interventions, validating the ability of PGCR to isolate critical state components for decision-making. Extensive experiments demonstrate that PGCR significantly improves recommendation performance, confirming its effectiveness for offline RL-based recommender systems.",
        "keywords": "Offline Reinforcement Learning;Recommendation;Causal State Representation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Siyu Wang;Xiaocong Chen;Lina Yao",
        "authorids": "~Siyu_Wang4;~Xiaocong_Chen2;~Lina_Yao2",
        "gender": "F;;F",
        "homepage": "https://sylvia-siyuwang.github.io/home/;https://xiaocongchen.github.io/;https://www.linayao.com/",
        "dblp": "168/9309-1;245/9630.html;56/6651-1",
        "google_scholar": ";GE0iYnYAAAAJ;https://scholar.google.com.au/citations?user=EU3snBgAAAAJ",
        "orcid": "0009-0008-8726-5277;0000-0002-8849-4943;0000-0002-4149-839X",
        "linkedin": ";;linayao/",
        "or_profile": "~Siyu_Wang4;~Xiaocong_Chen2;~Lina_Yao2",
        "aff": "Macquarie University+University of New South Wales;Data 61, CSIRO;University of New South Wales+CSIRO's Data61",
        "aff_domain": "mq.edu.au+unsw.edu.au;data61.csiro.au;unsw.edu.au+data61.csiro.au",
        "position": "Postdoc+PhD student;Postdoc;Full Professor+Principal Researcher",
        "bibtex": "@inproceedings{\nwang2025policyguided,\ntitle={Policy-Guided Causal State Representation  for Offline Reinforcement Learning Recommendation},\nauthor={Siyu Wang and Xiaocong Chen and Lina Yao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=8QJCZmycIS}\n}",
        "github": "",
        "project": "",
        "reviewers": "YoFb;q1Yx;kUr2;Un9T",
        "site": "https://openreview.net/forum?id=8QJCZmycIS",
        "pdf_size": 0,
        "novelty": "4;4;5;7",
        "technical_quality": "4;6;5;7",
        "scope": "3;4;3;3",
        "confidence": "2;4;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.224744871391589
        ],
        "technical_quality_avg": [
            5.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "9S7TtvvGlI",
        "title": "Beyond tip of the Iceberg: Debiased Self-training for Long-tailed Semi-supervised Node Classification",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs) have achieved great success in dealing with non-Euclidean graph-structured data and have been widely deployed in many real-world applications. However, their effectiveness is often jeopardized under class-imbalanced training sets. Most existing studies have analyzed class-imbalanced node classification from a supervised learning perspective, they do not fully utilize the large number of unlabeled nodes in semi-supervised scenarios. We claim that the supervised signal is just the tip of the iceberg and a large number of unlabeled nodes have not yet been effectively utilized. In this work, we propose \\texttt{IceBerg}, a debiased self-training framework to address the class-imbalanced and few-shot challenges for GNNs at the same time. Specifically, to figure out the Matthew effect and label distribution shift in self-training, we propose \\texttt{Double Balancing}, which can largely improve the performance of existing baselines with just a few lines of code as a simple plug-and-play module. Secondly, to enhance the long-range propagation capability of GNNs, we disentangle the propagation and transformation operations of GNNs. Therefore, the weak supervision signals can propagate more effectively to address few shot issue. In summary, we find that leveraging unlabeled nodes can significantly enhance the performance of GNNs in class-imbalanced and few shot scenarios, and even small, surgical modifications can lead to substantial performance improvements. Systematic experiments on benchmark datasets show that our method can deliver considerable performance gain over existing class-imbalanced node classification baselines. Additionally, due to \\texttt{IceBerg}'s outstanding ability to leverage unsupervised signals, it also achieves state-of-the-art results in few shot node classification scenarios. The code of \\texttt{IceBerg} is available at: \\url{https://anonymous.4open.science/r/IceBerg-D865/}.",
        "keywords": "Graph Neural Networks;Self-training;Class-imbalanced",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhixun Li;Dingshuo Chen;Tong Zhao;Daixin Wang;Hongrui Liu;Zhiqiang Zhang;JUN ZHOU;Jeffrey Xu Yu",
        "authorids": "~Zhixun_Li1;~Dingshuo_Chen1;~Tong_Zhao7;~Daixin_Wang1;~Hongrui_Liu1;~Zhiqiang_Zhang4;~JUN_ZHOU6;~Jeffrey_Xu_Yu1",
        "gender": "M;M;M;M;M;M;M;M",
        "homepage": ";;;;https://github.com/TaurusTaurus-Rui;;https://scholar.google.com/citations?user=mCVvloEAAAAJ&hl=en;http://www.se.cuhk.edu.hk/people/yu.html",
        "dblp": ";289/7535;;165/2949;;67/2010-12;99/3847-11;y/JXuYu",
        "google_scholar": ";jvrhEfIAAAAJ;;ipYAetUAAAAJ;;TMx0g8kAAAAJ;mCVvloEAAAAJ;https://scholar.google.com.tw/citations?user=iHevumsAAAAJ",
        "orcid": "0000-0001-6750-9002;;0000-0002-5292-0541;0000-0001-9841-8605;;0000-0002-2321-7259;0000-0001-6033-6102;",
        "linkedin": ";;https://www.linkedin.cn/incareer/in/ACoAAAVCZKYBobhLmTT2sxiUH8m3jNaTp6lZ4Vo;;;;;",
        "or_profile": "~Zhixun_Li1;~Dingshuo_Chen1;~Tong_Zhao7;~Daixin_Wang1;~Hongrui_Liu1;~Zhiqiang_Zhang4;~JUN_ZHOU6;~Jeffrey_Xu_Yu1",
        "aff": "The Chinese University of Hong Kong;Institute of automation, Chinese Academy of Sciences;;Tsinghua University;Alibaba Group;Ant Group;Ant Group;The Chinese University of Hong Kong",
        "aff_domain": "se.cuhk.edu.hk;ia.ac.cn;;tsinghua.edu.cn;antgroup.com;antfin.com;antgroup.com;cuhk.edu.hk",
        "position": "PhD student;PhD student;;Researcher;Researcher;Researcher;Researcher;Full Professor",
        "bibtex": "@inproceedings{\nli2025beyond,\ntitle={Beyond tip of the Iceberg: Debiased Self-training for Long-tailed Semi-supervised Node Classification},\nauthor={Zhixun Li and Dingshuo Chen and Tong Zhao and Daixin Wang and Hongrui Liu and Zhiqiang Zhang and JUN ZHOU and Jeffrey Xu Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=9S7TtvvGlI}\n}",
        "github": "",
        "project": "",
        "reviewers": "1Miq;uY25;DnZM;EiqH;oYRm",
        "site": "https://openreview.net/forum?id=9S7TtvvGlI",
        "pdf_size": 0,
        "novelty": "3;3;4;4;5",
        "technical_quality": "4;6;4;4;6",
        "scope": "4;4;4;4;3",
        "confidence": "3;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8017837257372731
    },
    {
        "id": "9eRgajXN2w",
        "title": "BAT: Benchmark for Auto-bidding Task",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The optimization of bidding strategies for online advertising slot auctions presents a critical challenge across numerous digital marketplaces. A significant obstacle to the development, evaluation, and refinement of real-time autobidding algorithms is the scarcity of comprehensive datasets and standardized benchmarks.\n\nTo address this deficiency, we present an auction benchmark encompassing the two most prevalent auction formats. We implement a series of robust baselines on a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem domains: budget pacing uniformity and Cost Per Click (CPC) constraint optimization. This benchmark provides a user-friendly and intuitive framework for researchers and practitioners to develop and refine innovative autobidding algorithms, thereby facilitating advancements in the field of programmatic advertising.",
        "keywords": "Online auctions;advertising platforms;RTB;autobidding",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Khirianova Alexandra;Ekaterina Solodneva;Pudovikov Andrey;Sergei Osokin;Egor Samosvat;Yuriy Dorn;Alexander Ledovsky;Yana Zenkova",
        "authorids": "~Khirianova_Alexandra1;~Ekaterina_Solodneva1;~Pudovikov_Andrey1;~Sergei_Osokin1;~Egor_Samosvat1;~Yuriy_Dorn1;~Alexander_Ledovsky1;~Yana_Zenkova1",
        "gender": "F;F;M;M;M;M;;F",
        "homepage": ";https://istina.msu.ru/workers/552889406/;;https://orcid.org/0000-0002-4579-4583;;https://labmmo.ru/team/dorn.html;;",
        "dblp": ";;;;55/11467;347/3260;;",
        "google_scholar": ";;lai6_JAAAAAJ;;https://scholar.google.ru/citations?user=IbbDVcQAAAAJ;ByIc-l8AAAAJ;Ka8H1GIAAAAJ;",
        "orcid": "0000-0002-2142-3008;;0009-0008-0907-8396;0000-0002-4579-4583;;0000-0003-0533-3018;;0009-0000-8653-2777",
        "linkedin": ";;;;;https://ru.linkedin.com/in/yuriy-dorn-ph-d-167998a;;",
        "or_profile": "~Khirianova_Alexandra1;~Ekaterina_Solodneva1;~Pudovikov_Andrey1;~Sergei_Osokin1;~Egor_Samosvat1;~Yuriy_Dorn1;~Alexander_Ledovsky1;~Yana_Zenkova1",
        "aff": "AVITO+Lomonosov Moscow State University+LPI RAS;Avito+Moscow Institute of Physics and Technology+Moscow State University, Lomonosov Moscow State University;Avito+Lomonosov Moscow State University;;Avito;Lomonosov Moscow State University+Moscow Institute of Physics and Technology;Skolkovo Institute of Science and Technology;Avito",
        "aff_domain": "avito.ru+msu.ru+lebedev.ru;avito.ru+mipt.ru+cs.msu.ru;avito.ru+msu.ru;;avito.ru;msu.ru+mipt.ru;skoltech.ru;avito.ru",
        "position": "Researcher+Researcher+Researcher;Researcher+Intern+PhD student;Researcher+Researcher;;Researcher;Principal Researcher+Instructor;PhD student;Researcher",
        "bibtex": "@inproceedings{\nalexandra2025bat,\ntitle={{BAT}: Benchmark for Auto-bidding Task},\nauthor={Khirianova Alexandra and Ekaterina Solodneva and Pudovikov Andrey and Sergei Osokin and Egor Samosvat and Yuriy Dorn and Alexander Ledovsky and Yana Zenkova},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=9eRgajXN2w}\n}",
        "github": "",
        "project": "",
        "reviewers": "WGHS;fJpc;XMis;hsSq;EMox",
        "site": "https://openreview.net/forum?id=9eRgajXN2w",
        "pdf_size": 0,
        "novelty": "2;3;3;3;6",
        "technical_quality": "2;3;6;3;5",
        "scope": "3;4;4;3;4",
        "confidence": "2;2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            3.4,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            3.8,
            1.469693845669907
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2407717061715384
    },
    {
        "id": "AB22PNdfwP",
        "title": "Uncertainty-aware Graph Structure Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "*Graph Neural Networks* (GNNs) have become a prominent approach for learning from graph-structured data. However, their effectiveness can be significantly compromised when the graph structure is sub-optimal. To address this issue, *Graph Structure Learning* (GSL) has emerged as a promising technique that refines node connections adaptively. Nevertheless, we identify two key limitations in existing GSL methods: 1) Most methods primarily focus on node similarity to construct relationships, while overlooking the quality of node information. Blindly connecting low-quality nodes and aggregating their ambitious information can degrade the performance of other nodes. 2) The constructed graph structures are often constrained to be symmetric, which may limit the model's flexibility and effectiveness.\n\nTo overcome these limitations, we propose an **Uncertainty-aware Graph Structure Learning** (UnGSL) strategy. UnGSL estimates the uncertainty of node information and utilizes it to adjust the strength of directional connections, where the influence of nodes with high uncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-in module that can be seamlessly integrated into existing GSL methods with minimal additional computational cost. In our experiments, we implement UnGSL into six representative GSL methods, demonstrating consistent performance improvements.",
        "keywords": "Graph structure learning;Graph neural network;Uncertainty",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shen Han;Zhiyao Zhou;Jiawei Chen;Zhezheng Hao;Sheng Zhou;Gang Wang;Yan Feng;Chun Chen;Can Wang",
        "authorids": "~Shen_Han2;~Zhiyao_Zhou1;~Jiawei_Chen6;~Zhezheng_Hao1;~Sheng_Zhou1;~Gang_Wang32;~Yan_Feng3;~Chun_Chen1;~Can_Wang5",
        "gender": "M;;;M;M;M;F;M;M",
        "homepage": ";;;;https://zhoushengisnoob.github.io/;;https://person.zju.edu.cn/en/0085162;https://person.zju.edu.cn/en/0082004;https://person.zju.edu.cn/en/wangcan",
        "dblp": ";;;;34/4858-4.html;;;07/4182-0001.html;71/4716-1",
        "google_scholar": ";;;;https://scholar.google.co.jp/citations?user=Ss76nMwAAAAJ;;;;https://scholar.google.fr/citations?user=C63q3HoAAAAJ",
        "orcid": "0000-0001-6714-5237;;;0000-0001-9900-894X;0000-0003-3645-1041;0000-0001-6248-1426;;0000-0002-6198-7481;0000-0002-5890-4307",
        "linkedin": ";;;;;;;;",
        "or_profile": "~Shen_Han2;~Zhiyao_Zhou1;~Jiawei_Chen6;~Zhezheng_Hao1;~Sheng_Zhou1;~Gang_Wang32;~Yan_Feng3;~Chun_Chen1;~Can_Wang5",
        "aff": "College of Computer Science and Technology, Zhejiang University;;;Northwestern Polytechnical University, Northwest Polytechnical University Xi'an;Zhejiang University;;Zhejiang University;Zhejiang University;Zhejiang University",
        "aff_domain": "cs.zju.edu.cn;;;mai.nwpu.edu.cn;zju.edu.cn;;zju.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "MS student;;;MS student;Associate Professor;;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nhan2025uncertaintyaware,\ntitle={Uncertainty-aware Graph Structure Learning},\nauthor={Shen Han and Zhiyao Zhou and Jiawei Chen and Zhezheng Hao and Sheng Zhou and Gang Wang and Yan Feng and Chun Chen and Can Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=AB22PNdfwP}\n}",
        "github": "",
        "project": "",
        "reviewers": "s2DJ;oZcn;ubyQ;kadT;FXu8",
        "site": "https://openreview.net/forum?id=AB22PNdfwP",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "4;4;5;4;4",
        "scope": "4;3;3;4;4",
        "confidence": "4;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7637626158259733
    },
    {
        "id": "AKy9ryZwi3",
        "title": "SheetAgent: Towards a Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Spreadsheets are ubiquitous across the World Wide Web, playing a critical role in enhancing work efficiency across various domains. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce **SheetRM**, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose **SheetAgent**, a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules: *Planner*, *Informer*, and *Retriever*, achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection. Extensive experiments demonstrate that SheetAgent delivers 20-40\\% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities.  More details and visualizations are available at https://sheetagent.github.io. The datasets and source code are available at https://anonymous.4open.science/r/SheetAgent.",
        "keywords": "Agents;Large Language Models;Benchmark;Spreadsheet Reasoning and Manipulation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yibin Chen;Yifu Yuan;Zeyu Zhang;YAN ZHENG;Jinyi Liu;Fei Ni;Jianye HAO;Hangyu Mao;Fuzheng Zhang",
        "authorids": "~Yibin_Chen1;~Yifu_Yuan1;~Zeyu_Zhang16;~YAN_ZHENG1;~Jinyi_Liu1;~Fei_Ni1;~Jianye_HAO1;~Hangyu_Mao2;~Fuzheng_Zhang1",
        "gender": "M;M;M;M;;M;M;;M",
        "homepage": "https://github.com/cybisolated;https://yifu-yuan.github.io/;https://github.com/zzFestinaLente;https://yanzzzzz.github.io;;https://fei-ni.github.io/;http://www.icdai.org/jianye.html;;https://zhfzhmsra.github.io/",
        "dblp": ";261/3688;;10/2381-2;192/6688-2;11/579-1;21/7664.html;;",
        "google_scholar": ";83JhosMAAAAJ;;https://scholar.google.com.hk/citations?user=tJuhd1kAAAAJ;kaQS7NAAAAAJ;https://scholar.google.com.hk/citations?hl=zh-CN;;;8R0hla4AAAAJ",
        "orcid": ";0009-0009-2194-942X;;;;0009-0007-5623-2782;0000-0002-0422-8235;;",
        "linkedin": ";;;;\u91d1\u6bc5-\u5218-5b7447118;;;;",
        "or_profile": "~Yibin_Chen1;~Yifu_Yuan1;~Zeyu_Zhang16;~YAN_ZHENG1;~Jinyi_Liu1;~Fei_Ni1;~Jianye_HAO1;~Hangyu_Mao2;~Fuzheng_Zhang1",
        "aff": "Tianjin University;Tianjin University;, Institute of automation, Chinese academy of science+Tianjin University;Tianjin Unibersity, China;Tianjin University;Tianjin University;Tianjin University;;Kuaishou- \u5feb\u624b\u79d1\u6280",
        "aff_domain": "tju.edu.cn;tju.edu.cn;nlpr.ia.ac.cn+tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn;;kuaishou.com",
        "position": "MS student;PhD student;MS student+Undergrad student;Associate Professor;PhD student;PhD student;Full Professor;;Principal Researcher",
        "bibtex": "@inproceedings{\nchen2025sheetagent,\ntitle={SheetAgent: Towards a Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models},\nauthor={Yibin Chen and Yifu Yuan and Zeyu Zhang and YAN ZHENG and Jinyi Liu and Fei Ni and Jianye HAO and Hangyu Mao and Fuzheng Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=AKy9ryZwi3}\n}",
        "github": "",
        "project": "",
        "reviewers": "DKch;EMT1;KRWc;bhTk",
        "site": "https://openreview.net/forum?id=AKy9ryZwi3",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "5;6;7;5",
        "scope": "2;2;4;1",
        "confidence": "2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.75,
            0.82915619758885
        ],
        "scope_avg": [
            2.25,
            1.0897247358851685
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8703882797784891
    },
    {
        "id": "AN6WvJ24hw",
        "title": "WBSan: Webassembly Bug Detection for Sanitization and Binary-Only Fuzzing",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the advancement of WebAssembly, abbreviated as Wasm, various memory bugs and undefined behaviors have emerged, leading to security issues and discrepancies that affect usability and portability. Existing methods struggle to detect these problems in Wasm binaries due to challenges associated with binary instrumentation and the difficulty of defining legal memory bounds. While sanitizers combined with fuzzing are recognized as effective means for identifying memory bugs and undefined behaviors, current Wasm sanitizers necessitate compile-time instrumentation, rendering them unsuitable for practical scenarios where only binaries are accessible. In this paper, we propose WBSan, the first Wasm binary sanitizer by employing static analysis and Wasm binary instrumentation to detect memory bugs and undefined behaviors. We develop distinct instrumentation patterns tailored for each type of memory issue and introduce Wasm shadow memory to address complex memory bugs. Our results reveal that WBSan achieves a 16.8\\% false detection rate, outperforming current Wasm binary checkers and native sanitizers in detecting memory bugs and undefined behaviors. Furthermore, when compared with the binary-only fuzzer, WBSan uncovers more crashes (1,174 vs. 556) and achieves greater code coverage (162,385 vs. 22,237 unique search paths).",
        "keywords": "WebAssembly;Memory bug;Undefined behavior;Sanitizer;Binary-only fuzzing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiao Wu;Junzhou He;Liyan Huang;Cai Fu;Weihang Wang",
        "authorids": "~Xiao_Wu9;~Junzhou_He1;~Liyan_Huang1;~Cai_Fu1;~Weihang_Wang3",
        "gender": "M;Not Specified;M;M;",
        "homepage": "https://xiaowu417.github.io/;https://jz2000.de;https://github.com/hly2019;http://faculty.hust.edu.cn/fucai/zh_CN/index.htm;",
        "dblp": ";;;;",
        "google_scholar": ";;https://scholar.google.com/citations?hl=en;;",
        "orcid": ";;0009-0003-4929-1478;;",
        "linkedin": ";;liyan-huang-b9776328a/;;",
        "or_profile": "~Xiao_Wu9;~Junzhou_He1;~Liyan_Huang1;~Cai_Fu1;~Weihang_Wang3",
        "aff": "Huazhong University of Science and Technology;University of Southern California;University of Southern California+University of Southern California;Huazhong university of science and technology;",
        "aff_domain": "hust.edu;usc.edu;usc.edu+usc.edu;cse.hust.edu.cn;",
        "position": "MS student;MS student;PhD student+MS student;Full Professor;",
        "bibtex": "@inproceedings{\nwu2025wbsan,\ntitle={{WBS}an: Webassembly Bug Detection for Sanitization and Binary-Only Fuzzing},\nauthor={Xiao Wu and Junzhou He and Liyan Huang and Cai Fu and Weihang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=AN6WvJ24hw}\n}",
        "github": "",
        "project": "",
        "reviewers": "oqZn;tc9U;UWwK;Arik;ujEK",
        "site": "https://openreview.net/forum?id=AN6WvJ24hw",
        "pdf_size": 0,
        "novelty": "1;5;5;5;6",
        "technical_quality": "1;5;5;4;6",
        "scope": "3;4;4;3;4",
        "confidence": "4;3;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.7435595774162693
        ],
        "technical_quality_avg": [
            4.2,
            1.7204650534085255
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.36788360369097955
    },
    {
        "id": "AWu0bCMVgR",
        "title": "Dual Operation Aggregation Graph Neural Networks for Solving Flexible Job-Shop Scheduling Problem with Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the widespread adoption of Internet Protocol (IP) communication technology and Web-based platforms, cloud manufacturing has become a significant hallmark of Industry 4.0. Integrating graph algorithms into these web-enabled environments is crucial as they facilitate the representation and analysis of complex relationships in manufacturing processes, enabling efficient decision-making and adaptability in dynamic environments. As a key scheduling problem in cloud manufacturing, the flexible Job-shop Scheduling Problem (FJSP) finds extensive applications in real-world scenarios. However, traditional FJSP-solving methods struggle to meet the efficiency and adaptability demands of cloud manufacturing due to generalization issues and excessive computational time, while reinforcement learning-based methods fail to learn relationships between FJSP nodes, such as interactions between operations of different jobs, leading to limited interpretability and performance. To address these issues, we propose a dual operation aggregation graph neural network (GNN) for solving FJSP. Specifically, we decouple the disjunctive graph into two distinct graphs, reducing graph density and clarifying relationships between machines and operations, thus enabling more effective aggregation and understanding by neural networks. We develop two distinct graph aggregation methods to minimize the influence of non-critical machine and operation nodes on decision-making while enhancing the model's ability to account for long-term benefits. Additionally, to achieve more accurate multi-objective estimation and mitigate reward sparsity, we design a reward function that simultaneously considers machine efficiency, schedule balance, and makespan minimization. Extensive experimental results on well-known datasets demonstrate that our model outperforms state-of-the-art models and exhibits excellent generalization capabilities, effectively addressing the challenges of cloud manufacturing.",
        "keywords": "Flexible Job-Shop Scheduling Problem;Graph Neural Network;Reinforcement Learning;Combinatorial Optimization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Peng Zhao;You Zhou;Di Wang;Zhiguang Cao;Yubin Xiao;Xuan Wu;Yuanshu Li;Hongjia Liu;Wei Du;Yuan Jiang;Liupu Wang",
        "authorids": "~Peng_Zhao14;~You_Zhou5;~Di_Wang26;~Zhiguang_Cao1;~Yubin_Xiao1;~Xuan_Wu7;~Yuanshu_Li1;~Hongjia_Liu1;~Wei_Du12;~Yuan_Jiang7;~Liupu_Wang2",
        "gender": ";M;M;M;;;;;M;M;",
        "homepage": "https://scholar.google.com.tw/citations?view_op=list_works&hl=zh-TW&user=lmvN1rYAAAAJ;https://ccst.jlu.edu.cn/info/1026/17797.htm;https://www.diwang.org/;https://zhiguangcaosg.github.io/;;https://wuuu110.github.io/;https://scholar.google.com.hk/citations?view_op=list_works&hl=zh-CN&user=Tav1nXYAAAAJ;https://scholar.google.com.hk/citations?view_op=list_works&hl=zh-CN&user=0o_Q2P8AAAAJ;http://www.csbg-jlu.info/weidu/;https://scholar.google.com/citations?user=oFg-ifMAAAAJ&hl=en;",
        "dblp": ";20/2165-8;18/5410-4;178/8621;;54/2088-4.html;85/8999;;69/870-2;02/393-7;",
        "google_scholar": "https://scholar.google.com.tw/citations?view_op=list_works;;y7hN7F0AAAAJ;https://scholar.google.com.sg/citations?user=2R-cOkYAAAAJ;;https://scholar.google.com.hk/citations?user=euFhn8cAAAAJ;https://scholar.google.com.hk/citations?view_op=list_works;https://scholar.google.com.hk/citations?view_op=list_works;https://scholar.google.com.hk/citations?user=9RnYXQEAAAAJ;oFg-ifMAAAAJ;",
        "orcid": "0009-0005-8910-8847;0000-0003-0013-1281;0000-0002-3171-4001;0000-0002-4499-759X;;0000-0002-0989-6718;0009-0000-1014-6714;0009-0009-7983-4713;0000-0001-9872-4821;0000-0003-4629-9901;",
        "linkedin": ";;;;;;;;;;",
        "or_profile": "~Peng_Zhao14;~You_Zhou5;~Di_Wang26;~Zhiguang_Cao1;~Yubin_Xiao1;~Xuan_Wu7;~Yuanshu_Li1;~Hongjia_Liu1;~Wei_Du12;~Yuan_Jiang7;~Liupu_Wang2",
        "aff": "Jilin University;Jilin University;Nanyang Technological University;Singapore Management University;;Jilin University;Jilin University;;Jilin University;Nanyang Technological University;",
        "aff_domain": "jlu.edu.cn;jlu.edu.cn;ntu.edu.sg;smu.edu.sg;;mails.jlu.edu.cn;jlu.edu.cn;;jlu.edu.cn;scse.ntu.edu.sg;",
        "position": "PhD student;Full Professor;Principal Researcher;Assistant Professor;;PhD student;PhD student;;Full Professor;Researcher;",
        "bibtex": "@inproceedings{\nzhao2025dual,\ntitle={Dual Operation Aggregation Graph Neural Networks for Solving Flexible Job-Shop Scheduling Problem with Reinforcement Learning},\nauthor={Peng Zhao and You Zhou and Di Wang and Zhiguang Cao and Yubin Xiao and Xuan Wu and Yuanshu Li and Hongjia Liu and Wei Du and Yuan Jiang and Liupu Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=AWu0bCMVgR}\n}",
        "github": "",
        "project": "",
        "reviewers": "Cqmn;3Tw7;bn5C;7LA3;vibt",
        "site": "https://openreview.net/forum?id=AWu0bCMVgR",
        "pdf_size": 0,
        "novelty": "4;4;4;4;6",
        "technical_quality": "4;5;4;4;6",
        "scope": "4;3;4;3;4",
        "confidence": "2;3;3;1;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            11,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6864064729836441
    },
    {
        "id": "AegCFewVum",
        "title": "M$^2$-VLP: Enhancing Multilingual Vision-Language Pre-Training via Multi-Grained Alignment",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recently, multilingual Vision-Language Pre-training (mVLP) has shown remarkable progress in learning joint representations across different modalities and languages. However, most existing methods learn semantic alignment at a coarse-grained level and fail to capture fine-grained correlations between different languages and modalities. To address this, we propose a Multi-grained Multilingual Vision-Language Pre-training (M$^2$-VLP) model, which aims to learn cross-lingual cross-modal alignment at different semantic granular levels. In cross-lingual interaction, the model learns the global alignment of parallel sentence pairs and the word-level correlations. In cross-modal interaction, the model aligns images with captions and image regions with corresponding words. To integrate the cross-lingual and cross-modal alignment above, we propose a unified multi-grained contrastive learning paradigm. Under zero-shot cross-lingual and fine-tuned multilingual settings, extensive experiments on vision-language downstream tasks across twenty languages demonstrate the effectiveness of M$^2$-VLP over competitive contrastive models.",
        "keywords": "Multilingual vision-language pre-training;Multi-modal alignment;Cross-lingual Transfer",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ahtamjan Ahmat;Lei Wang;Yating Yang;Bo Ma;Rui Dong;Kaiwen Lu;Rong Ma;Xinyue Wang",
        "authorids": "~Ahtamjan_Ahmat1;~Lei_Wang32;~Yating_Yang2;~Bo_Ma5;~Rui_Dong2;~Kaiwen_Lu1;~Rong_Ma5;~Xinyue_Wang4",
        "gender": "M;M;F;M;M;M;M;F",
        "homepage": ";http://www.xjipc.cas.cn/sourcedb_xjipc_cas/zw/rck/yjy/200908/t20090812_2380374.html;http://people.ucas.edu.cn/~yangyating;https://people.ucas.edu.cn/~mabo;https://xjipc.cas.cn/sourcedb_xjipc_cas/zw/rck/fyjy/202104/t20210401_5988658.html;;;",
        "dblp": "360/9599;w/LeiWang65;;26/4179-4;127/0871-2;;;",
        "google_scholar": "CGKGwRsAAAAJ;;;https://scholar.google.com.hk/citations?user=Aq2XJuIAAAAJ;;;;",
        "orcid": "0000-0002-6660-8989;;;;;0000-0002-6327-9171;0000-0002-2974-0569;0009-0006-3735-6475",
        "linkedin": ";;;;;;;",
        "or_profile": "~Ahtamjan_Ahmat1;~Lei_Wang32;~Yating_Yang2;~Bo_Ma5;~Rui_Dong2;~Kaiwen_Lu1;~Rong_Ma5;~Xinyue_Wang4",
        "aff": "University of Chinese Academy of Sciences;Xinjiang Institute of physical and chemical technology, Chinese Academy of Sciences;The Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Chinese Academy of Sciences;Hohai University",
        "aff_domain": "ucas.ac.cn;xjipc.cas.cn;ms.xjb.ac.cn;ucas.ac.cn;ms.xjb.ac.cn;ucas.edu.cn;ucas.edu.cn;hhu.edu.cn",
        "position": "PhD student;Full Professor;Full Professor;Full Professor;Full Professor;PhD student;PhD student;Undergrad student",
        "bibtex": "@inproceedings{\nahmat2025mvlp,\ntitle={M\\${\\textasciicircum}2\\$-{VLP}: Enhancing Multilingual Vision-Language Pre-Training via Multi-Grained Alignment},\nauthor={Ahtamjan Ahmat and Lei Wang and Yating Yang and Bo Ma and Rui Dong and Kaiwen Lu and Rong Ma and Xinyue Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=AegCFewVum}\n}",
        "github": "",
        "project": "",
        "reviewers": "7mCJ;EBrg;Mn88;QdAx;h18i",
        "site": "https://openreview.net/forum?id=AegCFewVum",
        "pdf_size": 0,
        "novelty": "3;3;4;5;6",
        "technical_quality": "4;4;6;5;7",
        "scope": "3;2;2;3;4",
        "confidence": "3;4;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            2.8,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2100420126042015
    },
    {
        "id": "Ay5XucNRSR",
        "title": "Multimodal Taylor Series Network For Misinformation Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the rapid development of the Internet and the widespread use of social media, the proliferation of multimodal misinformation combining images and text poses serious risks to societal trust, individual well-being, and the integrity of AI models trained on such data. Recently, the automatic detection multimodal misinformation has become an essential area of research. However, traditional methods often rely on hierarchical neural networks that compress and fuse modalities, potentially overlooking deeper interactions between modalities and reducing model interpretability. In this paper, we present a novel Multimodal Taylor Series (MTS) network for detecting multimodal misinformation. The MTS network leverages Taylor series expansion to explicitly capture both low-order and high-order interactions between modalities, which also enhances interpretability by decomposing the model\u2019s processing into distinct terms. Additionally, the proposed MTS network avoids exponential parameter growth and maintains linear scalability, allowing the model to effectively capture complex cross-modal correlations. Extensive experiments on three benchmark datasets demonstrate that the MTS network significantly outperforms state-of-the-art models. We will release our code after the final publication of the paper.",
        "keywords": "Multimodal;Misinformation Detection;Taylor Series Network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiahao Sun;Chen Chen;Chunyan Hou;Yike Wu;Xiaojie Yuan",
        "authorids": "~Jiahao_Sun6;~Chen_Chen47;~Chunyan_Hou1;~Yike_Wu2;~Xiaojie_Yuan1",
        "gender": "M;;;;",
        "homepage": "https://github.com/OneForAllSama;;;https://yikewu.tech/;https://dbis.nankai.edu.cn/2023/0322/c12139a506919/page.htm",
        "dblp": ";65/4423-12;66/3541;246/5764;79/2280",
        "google_scholar": ";;;JOPICP0AAAAJ;",
        "orcid": "0009-0007-2604-8255;;;0000-0001-7384-8836;0000-0002-5876-6856",
        "linkedin": ";;;;",
        "or_profile": "~Jiahao_Sun6;~Chen_Chen47;~Chunyan_Hou1;~Yike_Wu2;~Xiaojie_Yuan1",
        "aff": "Nankai University;Nankai University;Tianjin University of Technology;Nankai University;Nankai University",
        "aff_domain": "nankai.edu.cn;nankai.edu.cn;tjut.edu.cn;nankai.edu.cn;nankai.edu.cn",
        "position": "MS student;Associate Professor;Associate Professor;Lecturer;Full Professor",
        "bibtex": "@inproceedings{\nsun2025multimodal,\ntitle={Multimodal Taylor Series Network For Misinformation Detection},\nauthor={Jiahao Sun and Chen Chen and Chunyan Hou and Yike Wu and Xiaojie Yuan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Ay5XucNRSR}\n}",
        "github": "",
        "project": "",
        "reviewers": "Zc6L;yz9q;wA1c",
        "site": "https://openreview.net/forum?id=Ay5XucNRSR",
        "pdf_size": 0,
        "novelty": "4;5;6",
        "technical_quality": "4;5;6",
        "scope": "4;4;3",
        "confidence": "3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.816496580927726
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "BK15humBF1",
        "title": "Safeguarding Blockchain Ecosystem: Understanding and Detecting Attack Transactions on Cross-chain Bridges",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Cross-chain bridges are essential decentralized applications (DApps) to facilitate interoperability between different blockchain networks. Unlike regular DApps, the functionality of cross-chain bridges relies on the collaboration of information both on and off the chain, which exposes them to a wider risk of attacks. According to our statistics, attacks on cross-chain bridges have resulted in losses of nearly 4.3 billion dollars since 2021. Therefore, it is particularly necessary to understand and detect attacks on cross-chain bridges.\nIn this paper, we collect the largest number of cross-chain bridge attack incidents to date, including 49 attacks that occurred between June 2021 and September 2024.\nOur analysis reveal that attacks against cross-chain business logic cause significantly more damage than those that do not. These cross-chain attacks exhibit different patterns compared to normal transactions in terms of call structure, which effectively indicates potential attack behaviors. Given the significant losses in these cases and the scarcity of related research, this paper aims to detect attacks against cross-chain business logic, and propose the BridgeGuard tool. \nSpecifically, BridgeGuard models cross-chain transactions from a graph perspective, and\nemploys a two-stage detection framework comprising global and local graph mining to identify attack patterns in cross-chain transactions.\nWe conduct multiple experiments on the datasets with 203 attack transactions and 40,000 normal cross-chain transactions. The results show that BridgeGuard's reported recall score is 36.32\\% higher than that of state-of-the-art tools and can detect unknown attack transactions.",
        "keywords": "Blockchain;Cross-Chain;Transaction Analysis;Graph mining",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiajing Wu;Kaixin Lin;Dan Lin;Bozhao Zhang;Zhiying Wu;Jianzhong Su",
        "authorids": "~Jiajing_Wu1;~Kaixin_Lin1;~Dan_Lin3;~Bozhao_Zhang1;~Zhiying_Wu1;~Jianzhong_Su3",
        "gender": "F;F;;M;M;M",
        "homepage": "http://xplanet.site/;;;;;https://demonhero0.github.io/",
        "dblp": ";;;;;",
        "google_scholar": "EaqeskUAAAAJ;https://scholar.google.jp/citations?user=Alh4X50AAAAJ;iTGMohsAAAAJ;;;-wdUfC8AAAAJ",
        "orcid": "0000-0001-5155-8547;;0000-0001-7067-2396;;0000-0003-4633-0008;",
        "linkedin": ";;;%E5%8D%9A%E6%98%AD-%E5%BC%A0-247871331/;;",
        "or_profile": "~Jiajing_Wu1;~Kaixin_Lin1;~Dan_Lin3;~Bozhao_Zhang1;~Zhiying_Wu1;~Jianzhong_Su3",
        "aff": ";SUN YAT-SEN UNIVERSITY;;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY",
        "aff_domain": ";sysu.edu.cn;;mail2.sysu.edu.cn;sysu.edu.cn;mail2.sysu.edu.cn",
        "position": ";MS student;;Undergrad student;PhD student;PhD student",
        "bibtex": "@inproceedings{\nwu2025safeguarding,\ntitle={Safeguarding Blockchain Ecosystem: Understanding and Detecting Attack Transactions on Cross-chain Bridges},\nauthor={Jiajing Wu and Kaixin Lin and Dan Lin and Bozhao Zhang and Zhiying Wu and Jianzhong Su},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=BK15humBF1}\n}",
        "github": "",
        "project": "",
        "reviewers": "dSMe;WFBW;mm9o;4pyj;Y3fg",
        "site": "https://openreview.net/forum?id=BK15humBF1",
        "pdf_size": 0,
        "novelty": "5;6;6;6;6",
        "technical_quality": "4;7;5;6;3",
        "scope": "3;4;4;3;3",
        "confidence": "4;4;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            5.0,
            1.4142135623730951
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4082482904638631
    },
    {
        "id": "BP2XTfkx94",
        "title": "Covering K-Cliques in Billion-Scale Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The k-clique structure in graphs has been investigated in various real-world applications, such as community detection in complex networks, functional module discovery in biological networks, and link spam detection in web graphs. Despite extensive research on $k$-clique enumeration, the large number of k-cliques in many graphs poses a challenge for practical application and computation. To address this, we explore the $k$-clique $\\tau$-cover problem, a generalization of the vertex cover problem. The problem aims to find a small set of vertices that can effectively represent all k-cliques in the graph. We prove the NP-hardness of finding the minimum k-clique cover. We propose a hierarchical solution that computes a small cover without enumerating k-cliques. Extensive experiments on real-world graphs verify the efficiency and effectiveness of our solution.",
        "keywords": "clique;k-clique;clique cover;vertex cover;set cover",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kaiyu Chen;Dong Wen;Hanchen Wang;Zhengyi Yang;Wenjie Zhang;Xuemin Lin",
        "authorids": "~Kaiyu_Chen3;~Dong_Wen2;~Hanchen_Wang2;~Zhengyi_Yang2;~Wenjie_Zhang3;~Xuemin_Lin2",
        "gender": ";;M;M;F;M",
        "homepage": ";;https://hanchen-wang.com/;http://www.cse.unsw.edu.au/~zyang/;http://www.cse.unsw.edu.au/~zhangw/;https://www.acem.sjtu.edu.cn/en/faculty/linxuemin.html",
        "dblp": "08/2232;;242/5152;73/908-1;98/5684-1;l/LinXuemin",
        "google_scholar": ";;8jHgBdsAAAAJ;https://scholar.google.com.au/citations?hl=en;https://scholar.google.com.au/citations?user=yHTJo1kAAAAJ;j6rglkYAAAAJ",
        "orcid": ";;;0000-0003-1772-6863;0000-0001-6572-2600;0000-0003-2396-7225",
        "linkedin": "kaiyu-chen/;;;y-zhengyi/;;",
        "or_profile": "~Kaiyu_Chen3;~Dong_Wen2;~Hanchen_Wang2;~Zhengyi_Yang2;~Wenjie_Zhang3;~Xuemin_Lin2",
        "aff": "University of New South Wales;;University of Technology Sydney+University of New South Wales;University of New South Wales;the university of new south wales;Shanghai Jiaotong University",
        "aff_domain": "unsw.edu.au;;uts.edu.au+unsw.edu.au;unsw.edu.au;cse.unsw.edu.au;sjtu.edu.cn",
        "position": "PhD student;;Lecturer+Postdoc;Researcher;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nchen2025covering,\ntitle={Covering K-Cliques in Billion-Scale Graphs},\nauthor={Kaiyu Chen and Dong Wen and Hanchen Wang and Zhengyi Yang and Wenjie Zhang and Xuemin Lin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=BP2XTfkx94}\n}",
        "github": "",
        "project": "",
        "reviewers": "qEwj;8yt7;dtdd;fLvT;QUsM",
        "site": "https://openreview.net/forum?id=BP2XTfkx94",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;4;5;4;5",
        "scope": "3;3;4;4;4",
        "confidence": "2;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.4,
            0.4898979485566356
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.16666666666666663
    },
    {
        "id": "BgSrNpCMqO",
        "title": "MSDZip: Universal Lossless Compression for Multi-source Data via Stepwise-parallel and Learning-based Prediction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the rapid development of the Internet, the huge amount of multi-source data (MSD) brings challenges in data sharing and storing. Lossless data compression is the major way to solve those problems. Nowadays, neural-network technologies bring significant advantages in data modeling, making learning-based lossless compressors (LLCs) for multi-source data have emerged continuously. \nCompared with traditional compressors, the LLCs are more useful to catch complex redundancy patterns in MSD, and thus have great potential in enhancing compression ratio. However, existing LLCs still suffer from unsatisfactory compression ratios and lower throughput. To solve those problems, we propose a novel universal MSD lossless compressor called MSDZip via Stepwise-parallel and learning-based prediction technologies, it introduces two major designs:  1) We propose a Local-Global-Deep Mixing block in the learning-based prediction module to establish dependencies for MSD symbols, where designed Deep Mixing block solves the problem of unstable weights in the perceptual layers caused by cold-start problem to enhance the compression ratio significantly.  2) We design a Stepwise-parallel multi-GPU-accelerated compression strategy to address the compression speed and graphics memory constraints of single GPU in the face of large-scale data. The Stepwise-parallel module passes the source MSD to learning-based prediction model through the data chunking strategy, where the model of the previous chunk is used to guide the compression of the next chunk in parallel. We compare MSDZip with 5 classical learning-based and 6 traditional compressors on 12 well-studied real-world datasets. The experimental results demonstrate that MSDZip optimizes 3.418%-69.874% in terms of compression ratio and 31.171%-495.649% in terms of throughput compared to advanced LLCs. The source code of MSDZip and the linkages of the experimental datasets are available at https://anonymous.4open.science/r/MSDZip-0E4E/.",
        "keywords": "multi-source data;lossless data compression;neural networks;deep learning;parallel computing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Huidong Ma;Sun Hui;Liping Yi;Ding Yanfeng;xiaoguang Liu;Gang Wang",
        "authorids": "~Huidong_Ma2;~Sun_Hui2;~Liping_Yi1;~Ding_Yanfeng1;~xiaoguang_Liu3;~Gang_Wang8",
        "gender": ";M;;;;M",
        "homepage": ";https://fahaihi.github.io/;https://lipingyi.github.io/;https://github.com/dingyanfeng;;https://cc.nankai.edu.cn/2021/0323/c13619a490377/page.htm",
        "dblp": ";31/3925-2;249/7727;;;71/4292-1",
        "google_scholar": ";;https://scholar.google.com.hk/citations?user=7DqiAM8AAAAJ;;;",
        "orcid": ";0000-0003-0290-142X;0000-0001-6236-3673;0009-0000-4736-8134;;0000-0003-0387-2501",
        "linkedin": ";;;;;",
        "or_profile": "~Huidong_Ma2;~Sun_Hui2;~Liping_Yi1;~Ding_Yanfeng1;~xiaoguang_Liu3;~Gang_Wang8",
        "aff": ";Nankai University+Nanyang Technological University;Tianjin University+Nankai University;Nankai University;;Nankai University",
        "aff_domain": ";nankai.edu.cn+ntu.edu.sg;tju.edu.cn+nankai.edu.cn;nankai.edu.cn;;nankai.edu.cn",
        "position": ";PhD student+PhD student;Associate Professor+PhD student;MS student;;Full Professor",
        "bibtex": "@inproceedings{\nma2025msdzip,\ntitle={{MSDZ}ip: Universal Lossless Compression for Multi-source Data via Stepwise-parallel and Learning-based Prediction},\nauthor={Huidong Ma and Sun Hui and Liping Yi and Ding Yanfeng and xiaoguang Liu and Gang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=BgSrNpCMqO}\n}",
        "github": "",
        "project": "",
        "reviewers": "y5T7;Dtdp;RvAg;xB1Q;jTnh",
        "site": "https://openreview.net/forum?id=BgSrNpCMqO",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;3;6;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.25000000000000006
    },
    {
        "id": "Bgr4RHYONd",
        "title": "Large Language Models as Narrative-Driven Recommenders",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Narrative-driven recommenders aim to provide personalized suggestions for user requests expressed in free-form text such as \"I want to watch a thriller with a mind-bending story, like Shutter Island.\" Although large language models (LLMs) have been shown to excel in processing general natural language queries, their effectiveness for handling such recommendation requests remains relatively unexplored. To close this gap, we compare the performance of 38 open- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in a movie recommendation setting. For this, we utilize a gold-standard, crowdworker-annotated dataset of posts from reddit's movie suggestion community and employ various prompting strategies, including zero-shot, identity, and few-shot prompting. Our findings demonstrate the ability of LLMs to generate contextually relevant movie recommendations, significantly outperforming other state-of-the-art approaches, such as doc2vec. While we find that closed-source and large-parameterized models generally perform best, medium-sized open-source models remain competitive, being only slightly outperformed by their more computationally expensive counterparts. Furthermore, we observe no significant differences across prompting strategies for most models, underscoring the effectiveness of simple approaches such as zero-shot prompting for narrative-driven recommendations. Overall, this work offers valuable insights for recommender system researchers as well as practitioners aiming to integrate LLMs into real-world recommendation tools.",
        "keywords": "Recommender systems;Large language models;Narrative-driven recommendations;Movie recommendations;Prompting strategies",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Lukas Eberhard;Thorsten Ruprechter;Denis Helic",
        "authorids": "~Lukas_Eberhard2;~Thorsten_Ruprechter1;~Denis_Helic1",
        "gender": ";;M",
        "homepage": ";;https://courses.isds.tugraz.at/dhelic/",
        "dblp": ";;11/6129",
        "google_scholar": ";;https://scholar.google.at/citations?user=7tAilWQAAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Lukas_Eberhard2;~Thorsten_Ruprechter1;~Denis_Helic1",
        "aff": ";;Modul University Vienna",
        "aff_domain": ";;modul.ac.at",
        "position": ";;Full Professor",
        "bibtex": "@inproceedings{\neberhard2025large,\ntitle={Large Language Models as Narrative-Driven Recommenders},\nauthor={Lukas Eberhard and Thorsten Ruprechter and Denis Helic},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Bgr4RHYONd}\n}",
        "github": "",
        "project": "",
        "reviewers": "z6zk;4Y4a;Xy5E;vsna;sssJ",
        "site": "https://openreview.net/forum?id=Bgr4RHYONd",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "3;5;6;5;4",
        "scope": "4;3;4;3;3",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6454972243679028
    },
    {
        "id": "BqqAe7JRTM",
        "title": "Dynamic Security Analysis of JavaScript: Are We There Yet?",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In this paper, we systematically evaluate the effectiveness of existing tools for the dynamic security analysis of client-side JavaScript, focusing in particular on information flow control. Each tool is evaluated in terms of: $(i)$ compatibility, i.e., the ability to process and analyze existing scripts without breaking; $(ii)$ transparency, i.e., the ability to preserve the original script semantics when security enforcement is not necessary; $(iii)$ coverage, i.e., the effectiveness in terms of number of detected information flows; $(iv)$ performance, i.e., the computational overhead introduced by the analysis. Our investigation shows that most of the existing analysis tools are incompatible with the modern Web and the compatibility issues affecting them are not easily fixed. Moreover, transparency issues abound and make us question analysis correctness. This is also confirmed by our coverage evaluation, showing that some tools are unable to detect any information flow on real-world websites, while the remaining tools report significantly different outputs. Finally, we observe that the computational overhead of analysis tools may be significant and can exceed 30x. In the end, out of all the evaluated tools, just one of them (Project Foxhound) is effective enough for practical adoption at scale.",
        "keywords": "JavaScript;Information flow control;Web measurements",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Stefano Calzavara;Samuele Casarin;Riccardo Focardi",
        "authorids": "~Stefano_Calzavara1;~Samuele_Casarin1;~Riccardo_Focardi2",
        "gender": "M;M;M",
        "homepage": "https://www.dais.unive.it/~calzavara;;https://www.unive.it/data/people/5590470",
        "dblp": "89/9526;;f/RiccardoFocardi",
        "google_scholar": "hje68Y4AAAAJ;;5AX8Pb8AAAAJ",
        "orcid": ";0009-0009-1938-7237;0000-0003-0101-0692",
        "linkedin": ";;https://it.linkedin.com/in/riccardo-focardi-21b080aa",
        "or_profile": "~Stefano_Calzavara1;~Samuele_Casarin1;~Riccardo_Focardi2",
        "aff": "University of Venice;Institute for Advanced Studies Lucca;University of Venice",
        "aff_domain": "unive.it;imtlucca.it;unive.it",
        "position": "Associate Professor;PhD student;Full Professor",
        "bibtex": "@inproceedings{\ncalzavara2025dynamic,\ntitle={Dynamic Security Analysis of JavaScript: Are We There Yet?},\nauthor={Stefano Calzavara and Samuele Casarin and Riccardo Focardi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=BqqAe7JRTM}\n}",
        "github": "",
        "project": "",
        "reviewers": "5Hic;Ex4V;hGhA;5ccJ;jyoQ",
        "site": "https://openreview.net/forum?id=BqqAe7JRTM",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6",
        "technical_quality": "3;6;3;4;5",
        "scope": "3;4;4;4;4",
        "confidence": "3;2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.19611613513818402
    },
    {
        "id": "C3MvOQULs3",
        "title": "Strong Equilibria in Bayesian Games with Bounded Group Size",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the group strategic behaviors in Bayesian games. Equilibria in previous work do not consider group strategic behaviors with bounded sizes and are too ``strong'' to exist in many scenarios. \nWe propose the ex-ante Bayesian $k$-strong equilibrium and the Bayesian $k$-strong equilibrium, where no group of at most $k$ agents can benefit from deviation. The two solution concepts differ in how agents calculate their utilities when contemplating whether a deviation is beneficial. Intuitively, agents are more risk-averse in the Bayesian $k$-strong equilibrium than in the ex-ante Bayesian $k$-strong equilibrium. With our solution concepts, we study collusion in the peer prediction mechanisms, as a representative of the Bayesian games with group strategic behaviors. We characterize the thresholds of the group size $k$ so that truthful reporting in the peer prediction mechanism is an equilibrium for each solution concept, respectively. Our solution concepts can serve as criteria to evaluate the robustness of a peer prediction mechanism against collusion. Besides the peer prediction problem, we also discuss two other potential applications of our new solution concepts, voting and Blotto games, where introducing bounded group sizes provides more fine-grained insights into the behavior of strategic agents.",
        "keywords": "Algorithmic game theory;information elicitation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qishen Han;Grant Schoenebeck;Biaoshuai Tao;Lirong Xia",
        "authorids": "~Qishen_Han1;~Grant_Schoenebeck1;~Biaoshuai_Tao1;~Lirong_Xia2",
        "gender": "M;;M;",
        "homepage": "https://hnick2021.github.io/;http://schoeneb.people.si.umich.edu/;https://jhc.sjtu.edu.cn/~bstao/;",
        "dblp": "298/1253;21/1633;117/4948;",
        "google_scholar": "fRSEYW0AAAAJ;m4zCAPoAAAAJ;F65i6zcAAAAJ;",
        "orcid": "0000-0003-0268-6918;;;",
        "linkedin": "qishen-han-a893a8292/;;;",
        "or_profile": "~Qishen_Han1;~Grant_Schoenebeck1;~Biaoshuai_Tao1;~Lirong_Xia2",
        "aff": "Rutgers University;;Shanghai Jiaotong University;",
        "aff_domain": "rutgers.edu;;sjtu.edu.cn;",
        "position": "PhD student;;Assistant Professor;",
        "bibtex": "@inproceedings{\nhan2025strong,\ntitle={Strong Equilibria in Bayesian Games with Bounded Group Size},\nauthor={Qishen Han and Grant Schoenebeck and Biaoshuai Tao and Lirong Xia},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=C3MvOQULs3}\n}",
        "github": "",
        "project": "",
        "reviewers": "2Fg3;oVPC;QLAw;FV5r",
        "site": "https://openreview.net/forum?id=C3MvOQULs3",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;3;5;6",
        "scope": "3;2;4;4",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "CKJXHFvm3v",
        "title": "Dual Graph Denoising Model for Social Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph-based social recommender systems utilize user-item interaction graphs and user-user social graphs to model user preferences. However, their performance can be limited by redundant and noisy information in these two graphs. Although several recommender studies on data denoising exist, most either rely on heuristic assumptions, which limit their adaptability, or use a single model that combines denoising and recommendation, potentially imposing substantial demands on the model capacity. To address these issues, we propose a dual Graph Denoising Social Recommender (GDSR), which consists of two steps: graph denoising and user preference prediction. \\textit{First}, we design a denoising module which exploits a dual denoising model to alleviate noises in the interaction and social graphs by performing multi-step noise removal. We develop three kinds of conditions to guide our dual graph denoising paradigm and propose a cross-domain graph optimization strategy to enhance the structure of denoised graphs. \\textit{Second}, we devise a recommender module that employs a dual graph learning structure on denoised graphs to generate recommendations. Moreover, we use additional supervision signals to introduce a graph contrastive learning task, enhancing the recommender module's representation quality and robustness. Experiment results show the effectiveness of our GDSR.",
        "keywords": "Recommender Systems",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Anchen Li;Bo Yang",
        "authorids": "~Anchen_Li1;~Bo_Yang6",
        "gender": "M;",
        "homepage": "https://www.linkedin.com/in/anchen-li-1720842b0/;http://ccst.jlu.edu.cn/info/1367/19045.htm",
        "dblp": "286/1408;46/999-2",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;",
        "orcid": "0000-0001-9828-6964;0000-0003-1927-8419",
        "linkedin": ";",
        "or_profile": "~Anchen_Li1;~Bo_Yang6",
        "aff": "Aalto University;Jilin University",
        "aff_domain": "aalto.fi;jlu.edu.cn",
        "position": "Postdoc;Full Professor",
        "bibtex": "@inproceedings{\nli2025dual,\ntitle={Dual Graph Denoising Model for Social Recommendation},\nauthor={Anchen Li and Bo Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CKJXHFvm3v}\n}",
        "github": "",
        "project": "",
        "reviewers": "J9Jj;pgVc;1sxi;KXFx;iKL2",
        "site": "https://openreview.net/forum?id=CKJXHFvm3v",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6",
        "technical_quality": "4;5;4;5;6",
        "scope": "4;3;4;4;4",
        "confidence": "3;3;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.08006407690254358
    },
    {
        "id": "CLGPmhD2Jh",
        "title": "Hyper-Relational Knowledge Representation Learning with Multi-Hypergraph Disentanglement",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Hyper-relational knowledge graphs (HKGs) extend the traditional triplet-based knowledge graph by adding qualifiers to the relationships, making HKGs particularly useful for tasks that require more profound understanding and inference from relationships between entities. However, existing hyper-relational knowledge representation learning methods (HKRL) focus on direct neighbourhood information of entities only by neglecting the relational similarity of the main triple in hyper-relational facts and the attribute details in the qualifiers. In addition, few works extract common and private information across multiple views to minimize noise and interference. This paper proposes a multi-hypergraph disentanglement method for HKRL to address the above issues. Specifically, we first construct four hypergraphs to mine and utilise the inherent structure information of HKGs, and then propose to extract common representations among hypergraphs and private representations within individual hypergraphs to mine the semantic information and the task-relevant information, respectively. Experiment results on four real datasets demonstrate the effectiveness of the proposed method compared to SOTA methods in link prediction tasks on HKGs. Source code is available at the URL: https://anonymous.4open.science/r/MHD.",
        "keywords": "Hyper-relational knowledge graph; Hypergraph; Multi-view; Information disentangled",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiecheng Li;Xudong Luo;Guangquan Lu;Shichao Zhang",
        "authorids": "~Jiecheng_Li1;~Xudong_Luo3;~Guangquan_Lu1;~Shichao_Zhang3",
        "gender": "M;M;M;M",
        "homepage": ";https://www.scholat.com/angeladad;;",
        "dblp": "325/2906;;132/8989.html;z/ShichaoZhang",
        "google_scholar": "8Emru3cAAAAJ;;_sJmB64AAAAJ;",
        "orcid": "0000-0001-6551-6292;;;",
        "linkedin": ";;;",
        "or_profile": "~Jiecheng_Li1;~Xudong_Luo3;~Guangquan_Lu1;~Shichao_Zhang3",
        "aff": "Guangxi Normal University;Guangxi Normal University;Guangxi Normal University;Central South University+Guangxi Normal University",
        "aff_domain": "gxnu.edu.cn;gxnu.edu.cn;gxnu.edu.cn;csu.edu.cn+gxnu.edu.cn",
        "position": "PhD student;Full Professor;Full Professor;Full Professor+Full Professor",
        "bibtex": "@inproceedings{\nli2025hyperrelational,\ntitle={Hyper-Relational Knowledge Representation Learning with Multi-Hypergraph Disentanglement},\nauthor={Jiecheng Li and Xudong Luo and Guangquan Lu and Shichao Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CLGPmhD2Jh}\n}",
        "github": "",
        "project": "",
        "reviewers": "advK;J2oH;gHPK;RxFS;dwr3",
        "site": "https://openreview.net/forum?id=CLGPmhD2Jh",
        "pdf_size": 0,
        "novelty": "3;3;5;6;7",
        "technical_quality": "4;3;5;5;6",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.6
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3572172541558802
    },
    {
        "id": "CPzQ7pAyW5",
        "title": "Learning against Non-credible Second-Price Auctions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The standard framework of online bidding algorithm design assumes that the seller commits himself to faithfully implementing the rules of the adopted auction. However, the seller may attempt to cheat in execution to increase his revenue if the auction belongs to the class of non-credible auctions. For example, in a second-price auction, the seller could create a fake bid between the highest bid and the second highest bid. This paper focuses on one such case of online bidding in repeated second-price auctions. At each time $t$, the winner with bid $b_t$ is charged not the highest competing bid $d_t$ but a manipulated price $p_t = \\alpha_0 d_t + (1-\\alpha_0) b_t$, where the parameter $\\alpha_0 \\in [0, 1]$ in essence measures the seller's credibility. Unlike classic repeated-auction settings where the bidder has access to samples $(d_s)\\_{s=1}^{t-1}$, \nshe can only receive mixed signals of $(b_s)\\_{s=1}^{t-1}$, $(d_s)\\_{s=1}^{t-1}$ and $\\alpha_0$ in this problem. The task for the bidder is to learn not only the bid distributions of her competitors but also the seller's credibility. We establish regret lower bounds in various information models and provide corresponding online bidding algorithms that can achieve near-optimal performance. Specifically, we consider three cases of prior information based on whether the credibility $\\alpha_0$ and the distribution of the highest competing bids are known. Our goal is to characterize the landscape of online bidding in non-credible second-price auctions and understand the impact of the seller's credibility on online bidding algorithm design under different information structures.",
        "keywords": "Non-credible Auctions;No-regret Learning;Bidding Algorithms",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qian Wang;Xuanzhi Xia;Zongjun Yang;Xiaotie Deng;Yuqing Kong;Zhilin Zhang;Liang Wang;Chuan Yu;Jian Xu;Bo Zheng",
        "authorids": "~Qian_Wang22;~Xuanzhi_Xia1;~Zongjun_Yang1;~Xiaotie_Deng1;~Yuqing_Kong1;~Zhilin_Zhang1;~Liang_Wang15;~Chuan_Yu1;~Jian_Xu8;~Bo_Zheng5",
        "gender": "M;M;M;M;F;M;M;M;M;M",
        "homepage": ";;https://pkuyzj.github.io/pkuyzj/;https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm;https://cfcs.pku.edu.cn/yuqkong/;https://scholar.google.com/citations?user=ehwxPtEAAAAJ&hl=zh-CN;;;https://www.linkedin.com/in/jianxu15/;",
        "dblp": "75/5723;;;d/XiaotieDeng;https://dblp.uni-trier.de/pers/k/Kong:Yuqing.html;95/1820-3;;;73/1149-15.html;33/1610-7",
        "google_scholar": "sM9xjLsAAAAJ;;ihgf9rsAAAAJ;https://scholar.google.com.tw/citations?user=OBUwP_oAAAAJ;;ehwxPtEAAAAJ;3hcLUEAAAAAJ;;30VZBsIAAAAJ;3gHhO9QAAAAJ",
        "orcid": ";0009-0005-2265-662X;;0000-0002-5282-6467;;0000-0001-6665-2288;0000-0001-5353-7803;0000-0001-8094-1545;0000-0003-3111-1005;0000-0002-4037-6315",
        "linkedin": ";;;;;;;;jianxu15/;bo-zheng-0315254/",
        "or_profile": "~Qian_Wang22;~Xuanzhi_Xia1;~Zongjun_Yang1;~Xiaotie_Deng1;~Yuqing_Kong1;~Zhilin_Zhang1;~Liang_Wang15;~Chuan_Yu1;~Jian_Xu8;~Bo_Zheng5",
        "aff": ";Tsinghua University;Columbia University;Peking University;Peking University;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group;Alibaba Group",
        "aff_domain": ";mails.tsinghua.edu.cn;columbia.edu;pku.edu.cn;pku.edu.cn;alibaba-inc.com;alibaba-inc.com;alibaba-inc.com;alibaba-inc.com;alibaba-inc.com",
        "position": ";PhD student;PhD student;Full Professor;Assistant Professor;Senior Algorithm Specialist;Senior Tech Expert;Researcher;Principal Researcher;Principal Researcher",
        "bibtex": "@inproceedings{\nwang2025learning,\ntitle={Learning against Non-credible Second-Price Auctions},\nauthor={Qian Wang and Xuanzhi Xia and Zongjun Yang and Xiaotie Deng and Yuqing Kong and Zhilin Zhang and Liang Wang and Chuan Yu and Jian Xu and Bo Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CPzQ7pAyW5}\n}",
        "github": "",
        "project": "",
        "reviewers": "GzBD;xD26;ZnLF;js58;C9TB",
        "site": "https://openreview.net/forum?id=CPzQ7pAyW5",
        "pdf_size": 0,
        "novelty": "4;5;5;6;6",
        "technical_quality": "4;4;6;5;5",
        "scope": "3;4;4;4;3",
        "confidence": "1;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5345224838248487
    },
    {
        "id": "CSwXx8DhYj",
        "title": "Communication Hierarchy-aware Graph Engine for Distributed Model Training",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Efficient processing of large-scale graphs with billions to trillions of edges is essential for training graph-based large language models\n(LLMs) in web-scale systems. The increasing complexity and size of these models create significant communication challenges due to\nthe extensive message exchanges required across distributed nodes. Current graph engines struggle to effectively scale across hundreds\nof computing nodes because they often overlook variations in communication costs within the interconnection hierarchy. To address\nthis challenge, we introduce TuComm, a communication hierarchy-aware engine specifically designed to optimize distributed training\nof graph-based LLMs. By leveraging hierarchical network topology, TuComm dynamically aggregates and transfers messages, fully\naccounting for the underlying communication domains, thereby enhancing the efficiency of distributed model training across large-scale systems. We implemented TuComm on top of the message passing interface (MPI), incorporating innovations such as dynamic\nbuffer expansion and active buffer switching to enhance scalability. Evaluations conducted on synthetic and real-world datasets,\nutilizing up to 79,024 nodes and over 1.2 million processor cores, demonstrate that TuComm surpasses leading graph-parallel systems and state-of-the-art counterparts in both throughput and scalability. Moreover, we have deployed TuComm on a production supercomputer, where it consistently outperforms top solutions on the Graph500 list. These results highlight TuComm\u2019s potential\nto significantly enhance the efficiency of distributed large-scale graph-based LLM training by optimizing communication among\ndistributed systems, making it an invaluable communication engine for web-scale model training.",
        "keywords": "Communication hierarchy;message aggregation;communication domain;graph processing;Graph500",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinbiao Gan;Tiejun Li;Liyang Wu;Qiang Zhang;Lingyun Song;Bo Yang;Jie Liu;KAI LU",
        "authorids": "~Xinbiao_Gan1;~Tiejun_Li1;~Liyang_Wu1;~Qiang_Zhang21;~Lingyun_Song1;~Bo_Yang26;~Jie_Liu41;~KAI_LU8",
        "gender": "M;M;F;M;M;M;M;M",
        "homepage": "http://www.tianhegraph.top/homepage;https://xueshu.baidu.com/scholarID/CN-BU74ZJ7J;;https://gitee.com/zhang-yuyuyuyu;http://jszy.nwpu.edu.cn/en/songlingyun;https://www.researchgate.net/profile/Bo-Yang-77;https://xueshu.baidu.com/scholarID/CN-BYG71YLK;https://www.ccf.org.cn/Chapters/Chapters/Changsha/zzjg/zxwy/2017-05-11/594599.shtml",
        "dblp": "36/4875;;;;152/7478;;;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;;;https://scholar.google.com/citations?hl=zh-CN;;;",
        "orcid": "0000-0003-3622-1772;;0009-0006-5727-7678;0009-0001-5234-1937;0000-0002-7892-2617;;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Xinbiao_Gan1;~Tiejun_Li1;~Liyang_Wu1;~Qiang_Zhang21;~Lingyun_Song1;~Bo_Yang26;~Jie_Liu41;~KAI_LU8",
        "aff": "National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;Northwestern Polytechnical University;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology",
        "aff_domain": "nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nwpu.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "position": "Associate Professor;Full Professor;MS student;MS student;Associate Professor;Assistant Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ngan2025communication,\ntitle={Communication Hierarchy-aware Graph Engine for Distributed Model Training},\nauthor={Xinbiao Gan and Tiejun Li and Liyang Wu and Qiang Zhang and Lingyun Song and Bo Yang and Jie Liu and KAI LU},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CSwXx8DhYj}\n}",
        "github": "",
        "project": "",
        "reviewers": "yyz6;T6Q5;Nj7U;MbCZ",
        "site": "https://openreview.net/forum?id=CSwXx8DhYj",
        "pdf_size": 0,
        "novelty": "4;5;6;7",
        "technical_quality": "4;6;7;7",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            6.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7745966692414834
    },
    {
        "id": "CV29IretPR",
        "title": "Unveiling Network Performance in the Wild: An Ad-Driven Analysis of Mobile Download Speeds",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Accurate measurement of mobile network performance is crucial for optimizing user experience and ensuring regulatory compliance. Traditional methods like crowdsourcing approaches, though effective, depend heavily on user participation and extensive infrastructure. In this paper, we introduce adNPM, a novel technique for measuring download speed by embedded measurement code in ads displayed across web browsers and mobile apps, without requiring user participation. Through controlled lab tests and real-world deployments in 15 countries, we show that adNPM produces results comparable to well-established tools such as Speedtest by Ookla and Opensignal while consuming significantly less data.\n\nOur solution leverages ad campaigns to collect extensive data from diverse demographics and geographic regions, providing deep insights into the performance of major Internet Service Providers (ISPs). Furthermore, adNPM can segment download speed analyses by demographic factors and operating systems, making it a versatile and scalable tool for network performance assessment.",
        "keywords": "d/l speed;network measurements;ad;adTag;bandwidth",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Miguel A Bermejo-Agueda;Patricia Callejo;RUBEN CUEVAS RUMIN;\u00c1ngel Cuevas;Ramakrishnan Durairajan;Reza Rejaie;\u00c1lvaro Mayol Garrido",
        "authorids": "~Miguel_A_Bermejo-Agueda1;~Patricia_Callejo1;~RUBEN_CUEVAS_RUMIN1;~\u00c1ngel_Cuevas1;~Ramakrishnan_Durairajan1;~Reza_Rejaie1;~\u00c1lvaro_Mayol_Garrido1",
        "gender": "M;F;M;M;;;M",
        "homepage": ";;https://www.it.uc3m.es/rcuevas;https://www.it.uc3m.es/acrumin/;https://ix.cs.uoregon.edu/~ram/;;",
        "dblp": ";190/1431;;76/4893;;;",
        "google_scholar": ";X0dAnL8AAAAJ;https://scholar.google.es/citations?user=lGuDTyAAAAAJ;tP-984YAAAAJ;;;",
        "orcid": ";0000-0001-6124-6213;0000-0002-1440-8360;0000-0002-5738-0820;;;",
        "linkedin": "mbermejoagueda/;;;;;;alvaromayolgarrido?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3B4r4B1uWAS4SP34rHlRjTXA%3D%3D",
        "or_profile": "~Miguel_A_Bermejo-Agueda1;~Patricia_Callejo1;~RUBEN_CUEVAS_RUMIN1;~\u00c1ngel_Cuevas1;~Ramakrishnan_Durairajan1;~Reza_Rejaie1;~\u00c1lvaro_Mayol_Garrido1",
        "aff": "Universidad Carlos III de Madrid;;Universidad Carlos III de Madrid;Universidad Carlos III de Madrid;University of Oregon;University of Oregon Eugene;",
        "aff_domain": "uc3m.es;;uc3m.es;uc3m.es;uoregon.edu;;",
        "position": "PhD student;;Associate Professor;Associate Professor;Associate Professor;;",
        "bibtex": "@inproceedings{\nbermejo-agueda2025unveiling,\ntitle={Unveiling Network Performance in the Wild: An Ad-Driven Analysis of Mobile Download Speeds},\nauthor={Miguel A Bermejo-Agueda and Patricia Callejo and RUBEN CUEVAS RUMIN and {\\'A}ngel Cuevas and Ramakrishnan Durairajan and Reza Rejaie and {\\'A}lvaro Mayol Garrido},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CV29IretPR}\n}",
        "github": "",
        "project": "",
        "reviewers": "Uixt;zshH;p69R;nCZH;sV3Z",
        "site": "https://openreview.net/forum?id=CV29IretPR",
        "pdf_size": 0,
        "novelty": "1;3;4;5;5",
        "technical_quality": "1;3;5;5;5",
        "scope": "4;2;3;4;4",
        "confidence": "1;4;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            3.6,
            1.4966629547095764
        ],
        "technical_quality_avg": [
            3.8,
            1.6
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            2.6,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.41931393468876726
    },
    {
        "id": "CvCn4UgeqW",
        "title": "Omni-SILA: Towards Omni-scene Driven Visual Sentiment Identifying, Locating and Attributing in Videos",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Prior studies on Visual Sentiment Understanding (VSU) primarily rely on the explicit scene information (e.g., facial expression) to judge visual sentiments, which largely ignore implicit scene information (e.g., human action, objection relation and visual background), while such information is critical for precisely discovering visual sentiments. Motivated by this, this paper proposes a new Omni-scene driven visual Sentiment Identifying, Locating and Attributing in videos (Omni-SILA) task, aiming to interactively and precisely identify, locate and attribute visual sentiments through both explicit and implicit scene information. Furthermore, this paper believes that this Omni-SILA task faces two key challenges: modeling scene and highlighting implicit scene beyond explicit. To this end, this paper proposes an Implicit-enhanced Causal MoE (ICM) approach for addressing the Omni-SILA task. Specifically, a Scene-Balanced MoE (SBM) and an Implicit-Enhanced Causal (IEC) blocks are tailored to model scene information and highlight the implicit scene information beyond explicit, respectively. Extensive experimental results on our constructed explicit and implicit Omni-SILA datasets demonstrate the great advantage of the proposed ICM approach over advanced Video-LLMs.",
        "keywords": "Omni-Scene Information;Implicit-enhanced Causal MoE Framework;Visual Sentiment Identifying;Locating and Attributing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiamin Luo;Jingjing Wang;Junxiao Ma;Yujie Jin;Shoushan Li;Guodong Zhou",
        "authorids": "~Jiamin_Luo1;~Jingjing_Wang4;~Junxiao_Ma1;~Yujie_Jin3;~Shoushan_Li2;~Guodong_Zhou1",
        "gender": "F;M;M;M;M;M",
        "homepage": "https://github.com/BonnieLuo;https://djingwang.github.io/;https://myaccount.google.com/u/1/?hl=zh-CN;https://github.com/haruka-025;;http://nlp.suda.edu.cn/~gdzhou/",
        "dblp": ";62/2638;;;83/4790.html;",
        "google_scholar": ";;;;;",
        "orcid": ";0009-0006-3619-1525;0009-0008-6437-2061;0009-0001-4832-6902;0000-0002-1000-3278;0000-0002-7887-5099",
        "linkedin": ";;;;;",
        "or_profile": "~Jiamin_Luo1;~Jingjing_Wang4;~Junxiao_Ma1;~Yujie_Jin3;~Shoushan_Li2;~Guodong_Zhou1",
        "aff": "Suzhou University;Soochow University+Microsoft (Asia);School of Computer Science and Technology;Suzhou University;Soochow University;Soochow University, China",
        "aff_domain": "suda.edu.cn;suda.edu.cn+microsoft.com;stu.suda.edu;suda.edu.cn;suda.edu.cn;suda.edu.cn",
        "position": "PhD student;Associate Professor+Senior Technical Consultant;MS student;MS student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nluo2025omnisila,\ntitle={Omni-{SILA}: Towards Omni-scene Driven Visual Sentiment Identifying, Locating and Attributing in Videos},\nauthor={Jiamin Luo and Jingjing Wang and Junxiao Ma and Yujie Jin and Shoushan Li and Guodong Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CvCn4UgeqW}\n}",
        "github": "",
        "project": "",
        "reviewers": "47ta;ZJJc;1oGm;jDtU",
        "site": "https://openreview.net/forum?id=CvCn4UgeqW",
        "pdf_size": 0,
        "novelty": "5;6;6;6",
        "technical_quality": "5;6;5;6",
        "scope": "3;4;3;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "Cw8PUNXPhn",
        "title": "Two-stage Auction Design in Online Advertising",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Modern online advertising systems usually involve a large amount of advertisers in each auction, causing scalability issues. To mitigate the problem, two-stage auctions are designed and deployed in practice, enabling efficient allocations of ad slots among numerous candidate advertisers within a short response time. Such a design uses a fast but coarse model to select a small subset of advertisers in the first stage, and a slow yet refined model to finally decide the winners. However, existing two-stage auction mechanisms primarily focus on optimizing welfare, ignoring other crucial objectives of the platform, such as revenue. \n\nIn this paper, we propose ad-wise selection metrics (namely Max-Wel and Max-Rev) that are based on an ad's contribution to the platform's objective (welfare or revenue). Then we provide theoretical guarantees for the proposed metrics. Our method is applicable to both welfare and revenue optimizations and can be easily implemented using neural networks. We conduct extensive experiments on both synthetic and industrial data to demonstrate the advantages of our proposed selection metrics over existing baselines.",
        "keywords": "Mechanism design;Online advertising;Neural networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhikang Fan;Lan Hu;Ruirui Wang;Zhongrui Ma;Yue Wang;YE QI;Weiran Shen",
        "authorids": "~Zhikang_Fan1;~Lan_Hu1;~Ruirui_Wang2;~Zhongrui_Ma1;~Yue_Wang39;~YE_QI2;~Weiran_Shen1",
        "gender": "M;;;M;M;M;M",
        "homepage": "https://fanzhikang.github.io/;;;;https://heydatatalks.github.io/;;https://www.weiran-shen.info/",
        "dblp": "319/0076-1;;;117/4308;;;159/2147",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;;OcKplr4AAAAJ;;XFOKNqkAAAAJ;-lXgERkAAAAJ",
        "orcid": "0000-0001-5026-2269;;;0009-0002-5907-1607;0009-0006-2710-8945;;0000-0003-4366-9276",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhikang_Fan1;~Lan_Hu1;~Ruirui_Wang2;~Zhongrui_Ma1;~Yue_Wang39;~YE_QI2;~Weiran_Shen1",
        "aff": "Renmin University of China;Huawei Technologies Ltd.;;Huawei Technologies Ltd.;Huawei Technologies Ltd.;;Renmin University of China",
        "aff_domain": "ruc.edu.cn;huawei.com;;huawei.com;huawei.com;;ruc.edu.cn",
        "position": "PhD student;Researcher;;Principal Researcher;Researcher;;Associate Professor",
        "bibtex": "@inproceedings{\nfan2025twostage,\ntitle={Two-stage Auction Design in Online Advertising},\nauthor={Zhikang Fan and Lan Hu and Ruirui Wang and Zhongrui Ma and Yue Wang and YE QI and Weiran Shen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Cw8PUNXPhn}\n}",
        "github": "",
        "project": "",
        "reviewers": "4Kqq;wW9G;CPBp;sJs2;psxR",
        "site": "https://openreview.net/forum?id=Cw8PUNXPhn",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "6;5;1;3;6",
        "scope": "4;4;4;3;3",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.2,
            1.9390719429665317
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9302605094190635
    },
    {
        "id": "CylwuCplKk",
        "title": "Robust Aggregation with Adversarial Experts",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We consider a robust aggregation problem in the presence of both truthful and adversarial experts. The truthful experts will report their private signals truthfully, while the adversarial experts can report arbitrarily. We assume experts are marginally symmetric in the sense that they share the same common prior and marginal posteriors. The rule maker needs to design an aggregator to predict the true world state from these experts' reports, without knowledge of the underlying information structures or adversarial strategies. We aim to find the optimal aggregator that outputs a forecast minimizing regret under the worst information structure and adversarial strategies. The regret is defined by the difference in expected loss between the aggregator and a benchmark who aggregates optimally given the information structure and reports of truthful experts. \n\nWe focus on binary states and reports. Under L1 loss, we show that the truncated mean aggregator is optimal. When there are at most k adversaries, this aggregator discards the k lowest and highest reported values and averages the remaining ones. For L2 loss, the optimal aggregators are piecewise linear functions. All the optimalities hold when the ratio of adversaries is bounded above by a value determined by the experts' priors and posteriors. The regret only depends on the ratio of adversaries, not on their total number. For hard aggregators that output a decision, we prove that a random version of the truncated mean is optimal for both L1 and L2. This aggregator randomly follows a remaining value after discarding the $k$ lowest and highest reported values. We evaluate our aggregators numerically in an ensemble learning task. We also obtain negative results for general adversarial aggregation problems under broader information structures and report spaces.",
        "keywords": "Robust Aggregation;Adversary;Ensemble Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongkang Guo;Yuqing Kong",
        "authorids": "~Yongkang_Guo1;~Yuqing_Kong1",
        "gender": "M;F",
        "homepage": ";https://cfcs.pku.edu.cn/yuqkong/",
        "dblp": ";https://dblp.uni-trier.de/pers/k/Kong:Yuqing.html",
        "google_scholar": "8E7FdhkAAAAJ;",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Yongkang_Guo1;~Yuqing_Kong1",
        "aff": "Peking University;Peking University",
        "aff_domain": "pku.edu.cn;pku.edu.cn",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nguo2025robust,\ntitle={Robust Aggregation with Adversarial Experts},\nauthor={Yongkang Guo and Yuqing Kong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=CylwuCplKk}\n}",
        "github": "",
        "project": "",
        "reviewers": "ND1x;Vb5W;CAxy;vqAV;mumW",
        "site": "https://openreview.net/forum?id=CylwuCplKk",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "4;4;4;6;6",
        "scope": "3;3;3;4;3",
        "confidence": "3;2;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6123724356957946
    },
    {
        "id": "DKoMOT7x70",
        "title": "STKOpt: Automated Spatio-Temporal Knowledge Optimization for Traffic Prediction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Ubiquitous sensors and mobile devices have spurred the growth of Web-of-Things (WoT) services in smart cities, making accurate spatio-temporal traffic predictions increasingly crucial. Leveraging advances in deep learning, recent Spatio-Temporal Graph Neural Networks (STGNNs) have achieved remarkable results. However, these methods address scenario-specific spatio-temporal heterogeneity by designing model architectures, often overlooking the importance of selecting optimal spatio-temporal knowledge (i.e., model inputs). In this paper, we propose an automated framework for spatio-temporal knowledge optimization to address this challenge. Our framework seamlessly integrates with downstream models, enhancing their performance across various prediction tasks. Specifically, we design a knowledge search space composed of parameters that represent scenario-specific spatio-temporal correlations within data. Additionally, we employ a bandit-based multi-fidelity algorithm for knowledge optimization to solve the constraint of limited resource. Furthermore, we adopt a meta-learner to extract transferable meta-knowledge about optimal knowledge, facilitating efficient exploration of the search space. Extensive experiments on five widely used real-world datasets demonstrate the effectiveness of our proposed framework. To the best of our knowledge, we are the first to automatically optimize spatio-temporal knowledge for spatio-temporal traffic prediction.",
        "keywords": "Traffic Prediction;Spatio-Temporal Modeling;Automated Machine Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yayao Hong;Liyue Chen;Leye Wang;Xiuhuai Xie;Guofeng Luo;Cheng Wang;Longbiao CHEN",
        "authorids": "~Yayao_Hong1;~Liyue_Chen1;~Leye_Wang1;~Xiuhuai_Xie1;~Guofeng_Luo2;~Cheng_Wang2;~Longbiao_CHEN1",
        "gender": "F;M;M;M;;M;M",
        "homepage": "https://www.researchgate.net/profile/Yayao-Hong;https://liyue-chen.github.io/;https://wangleye.github.io/;https://github.com/Mystic4l;;https://chwang.xmu.edu.cn/index_en.htm;https://longbiao.crowdsensing.cn/",
        "dblp": ";;07/8764;;;54/2062-3;",
        "google_scholar": ";;;;;https://scholar.google.com/citations?hl=en;",
        "orcid": ";;;;;0000-0001-6075-796X;",
        "linkedin": ";;;;;;",
        "or_profile": "~Yayao_Hong1;~Liyue_Chen1;~Leye_Wang1;~Xiuhuai_Xie1;~Guofeng_Luo2;~Cheng_Wang2;~Longbiao_CHEN1",
        "aff": "Xiamen University;Peking University;Peking University;Xiamen University;;Xiamen University;Xiamen University",
        "aff_domain": "xmu.edu.cn;pku.edu.cn;pku.edu.cn;xmu.edu.cn;;xmu.edu.cn;xmu.edu.cn",
        "position": "MS student;PhD student;Assistant Professor;MS student;;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nhong2025stkopt,\ntitle={{STKO}pt: Automated Spatio-Temporal Knowledge Optimization for Traffic Prediction},\nauthor={Yayao Hong and Liyue Chen and Leye Wang and Xiuhuai Xie and Guofeng Luo and Cheng Wang and Longbiao CHEN},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=DKoMOT7x70}\n}",
        "github": "",
        "project": "",
        "reviewers": "EVGS;5Vfd;FUhJ;wH5w;MCwn",
        "site": "https://openreview.net/forum?id=DKoMOT7x70",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;5;5;4;6",
        "scope": "3;3;3;3;4",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.13363062095621217
    },
    {
        "id": "DLYkSal8oC",
        "title": "BATON: Enhancing Batch-wise Inference Efficiency for Large Language Models via Dynamic Re-batching",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The advanced capabilities of Large Language Models (LLMs) have inspired the development of various interactive web services or applications, such as ChatGPT, which offer query inference services for users. Unlike traditional DNN model, the inference of LLM entails different iterations of forward computation for different queries, which result in efficiency challenges for existing run-to-completion batch-wise inference. Hence, some methods refine batch-wise inference to iteration-level by duplicating all nonlinear layers of LLM. However, this approach not only increases resource usage but also introduces idle computations to the batch due to the prefilling of newly added queries. \n\nTherefore, we propose BATON, an efficient batch-wise LLM inference scheme by dynamically adjusting processing batch, which can achieve near-zero idle computations without incurring additional resource consumption. To do so, BATON 1) shapes the vectors involved in the inference of the newly inserted query and processing batch to align dimensions and generates a new attention mask based on vector shaping to ensure inference correctness, which enables query inserting without consuming additional resource; 2) embeds prefilled \\textit{Keys} and \\textit{Values} of the new query into the \\textit{KV\\_Cache} of the processing batch by leveraging the prefilling and decoding separation mechanism, eliminating idle computations to the batch introduced by the prefilling process of the new query. Experimental results show that compared to the state-of-the-art solution Orca, \\name outperforms improves query processing by up to 1.75$\\times$.",
        "keywords": "LLM;inference serving;query scheduling",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Peizhuang Cong;Chen Qizhi;Haochen Zhao;Tong Yang",
        "authorids": "~Peizhuang_Cong1;~Chen_Qizhi1;~Haochen_Zhao1;~Tong_Yang6",
        "gender": ";M;;M",
        "homepage": ";;;https://yangtonghome.github.io/",
        "dblp": ";;;44/7710-2",
        "google_scholar": ";;;https://scholar.google.com.hk/citations?user=zYDaX-4AAAAJ",
        "orcid": ";0009-0004-4020-6772;;0000-0003-2402-5854",
        "linkedin": ";;;",
        "or_profile": "~Peizhuang_Cong1;~Chen_Qizhi1;~Haochen_Zhao1;~Tong_Yang6",
        "aff": ";Peking University;;",
        "aff_domain": ";pku.edu.cn;;",
        "position": ";PhD student;;",
        "bibtex": "@inproceedings{\ncong2025baton,\ntitle={{BATON}: Enhancing Batch-wise Inference Efficiency for Large Language Models via Dynamic Re-batching},\nauthor={Peizhuang Cong and Chen Qizhi and Haochen Zhao and Tong Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=DLYkSal8oC}\n}",
        "github": "",
        "project": "",
        "reviewers": "ZJJN;xBeH;o929;Fabn",
        "site": "https://openreview.net/forum?id=DLYkSal8oC",
        "pdf_size": 0,
        "novelty": "3;4;6;7",
        "technical_quality": "4;5;6;7",
        "scope": "3;4;4;4",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.5811388300841898
        ],
        "technical_quality_avg": [
            5.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.36514837167011077
    },
    {
        "id": "DcOivrmH8C",
        "title": "Mitigating Forgetting in Adapting Pre-trained Language Models to Text Processing Tasks via Consistency Alignment",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "There are a large number of text processing tasks in web applications, such as sentiment classification, summary extraction, and question answering. Recently, fine-tuning pre-trained language models (PLMs) to adapt to downstream text-processing tasks has attracted much attention. However, due to the differences in data, model, and tasks between the pre-training and fine-tuning processes, the fine-tuning process may suffer from catastrophic forgetting of pre-training knowledge, which may implicitly limit the model\u2019s performance and generalization ability. To address these challenges, we propose a novel dual-model framework, termed as \\emph{co}nsistency \\emph{a}l\\emph{i}gnment (CoAi). The insight of CoAi lies in building an auxiliary model that simulates the distribution of pre-training knowledge in real-time according to the current task, and co-training the task-specific model and the auxiliary model to balance the pre-training knowledge and task-specific knowledge during fine-tuning. Specifically, the auxiliary model is constructed on-the-fly to maintain the pre-training knowledge. Subsequently, CoAi simulates the pre-training process by performing distributional exploration in the parameter space, which is built upon our novel insight into the transformation between data and model parameter space. However, the objectives leveraged to construct the auxiliary model lead to the misalignment between the pre-training and task-specific knowledge. To alleviate the inconsistency, we employ an auxiliary variable to align the prediction distribution of the task-specific and the auxiliary models, inspired by constrastive clustering. We validate the effectiveness of CoAi on ten classic classification tasks and three generation tasks, showing consistent and significant improvements compared with state-of-the-art methods.",
        "keywords": "Catastrophic Forgetting;Consistency Alignment;Pre-training Knowledge;Task-specific Knowledge;Auxiliary Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jianqi Gao;Hao Wu;Yiu-ming Cheung;Jian Cao;Hang Yu;Yonggang Zhang",
        "authorids": "~Jianqi_Gao1;~Hao_Wu49;~Yiu-ming_Cheung1;~Jian_Cao1;~Hang_Yu9;~Yonggang_Zhang1",
        "gender": "M;M;;M;M;M",
        "homepage": ";https://blog.csdn.net/weixin_43734080?type=blog;;https://www.cs.sjtu.edu.cn/en/PeopleDetail.aspx?id=182;;https://yonggangzhangben.github.io/index.html",
        "dblp": "279/0646;;;50/2102;74/2568-6;27/6859-3",
        "google_scholar": "d7GoxiwAAAAJ;;;;https://scholar.google.com.au/citations?user=3BLeGSoAAAAJ;XSbEr98AAAAJ",
        "orcid": "0000-0002-9840-7866;;;;0000-0003-3444-9992;0000-0002-4080-7592",
        "linkedin": ";;;;;",
        "or_profile": "~Jianqi_Gao1;~Hao_Wu49;~Yiu-ming_Cheung1;~Jian_Cao1;~Hang_Yu9;~Yonggang_Zhang1",
        "aff": "Shanghai Jiaotong University;Shanghai University;;Shanghai Jiaotong University;Shanghai University;Hong Kong University of Science and Technology+Hong Kong Baptist University",
        "aff_domain": "sjtu.edu.cn;shu.edu.cn;;sjtu.edu.cn;shu.edu.cn;hkust.edu.hk+hkbu.edu.hk",
        "position": "Postdoc;PhD student;;Full Professor;Full Professor;Postdoc+Postdoc",
        "bibtex": "@inproceedings{\ngao2025mitigating,\ntitle={Mitigating Forgetting in Adapting Pre-trained Language Models to Text Processing Tasks via Consistency Alignment},\nauthor={Jianqi Gao and Hao Wu and Yiu-ming Cheung and Jian Cao and Hang Yu and Yonggang Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=DcOivrmH8C}\n}",
        "github": "",
        "project": "",
        "reviewers": "7chU;nf59;hc8e;Z9MN;N2Zp",
        "site": "https://openreview.net/forum?id=DcOivrmH8C",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "3;5;4;5;6",
        "scope": "3;4;2;3;3",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7905694150420948
    },
    {
        "id": "DfVIe2WLsT",
        "title": "2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding for Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Tables are ubiquitous across various domains for concisely representing structured information. Empowering large language models (LLMs) to reason over tabular data represents an actively explored direction. However, since typical LLMs only support one-dimensional (1D) inputs, existing methods often flatten the two-dimensional (2D) table structure into a sequence of tokens, which can severely disrupt the spatial relationships and result in an inevitable loss of vital contextual information. In this paper, we first empirically demonstrate the detrimental impact of such flattening operations on the performance of LLMs in capturing the spatial information of tables through two elaborate proxy tasks. Subsequently, we introduce a simple yet effective positional encoding method, termed ``2D-TPE'' (Two-Dimensional Table Positional Encoding), to address this challenge. 2D-TPE enables each attention head to dynamically select a permutation order of tokens within the context for attending to them, where each permutation represents a distinct traversal mode for the table, such as column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of losing essential spatial information while preserving computational efficiency, thus better preserving the table structure. Extensive experiments across five benchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring the importance of preserving the table structure for accurate table comprehension. Comprehensive analysis further reveals the substantially better scalability of 2D-TPE to large tables than baselines.",
        "keywords": "positional encoding;table understanding;large language models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jia-Nan Li;Jian Guan;Wei Wu;Zhengtao Yu;Rui Yan",
        "authorids": "~Jia-Nan_Li1;~Jian_Guan1;~Wei_Wu1;~Zhengtao_Yu2;~Rui_Yan2",
        "gender": ";M;M;M;M",
        "homepage": ";https://jianguanthu.github.io/;https://sites.google.com/view/wei-wu-homepage;http://rsc.kmust.edu.cn/info/1181/1081.htm;https://gsai.ruc.edu.cn/english/ruiyan",
        "dblp": "372/2705;58/2489-2;95/6985-14;03/6757;19/2405-1",
        "google_scholar": ";BWCDa8YAAAAJ;https://scholar.google.co.jp/citations?hl=en;;eLw6g-UAAAAJ",
        "orcid": "0009-0000-3529-7869;0000-0002-3597-0176;0000-0001-6079-7697;0000-0001-8952-8984;0000-0002-3356-6823",
        "linkedin": "li-jianan/;;;;",
        "or_profile": "~Jia-Nan_Li1;~Jian_Guan1;~Wei_Wu1;~Zhengtao_Yu2;~Rui_Yan2",
        "aff": "Renmin University of China;Alibaba Group;Ant Research;Kunming University of Science and Technology;Renmin University of China",
        "aff_domain": "ruc.edu.cn;antgroup.com;antgroup.com;kmust.edu.cn;ruc.edu.cn",
        "position": "PhD student;Researcher;Researcher;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nli2025dtpe,\ntitle={2D-{TPE}: Two-Dimensional Positional Encoding Enhances Table Understanding for Large Language Models},\nauthor={Jia-Nan Li and Jian Guan and Wei Wu and Zhengtao Yu and Rui Yan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=DfVIe2WLsT}\n}",
        "github": "",
        "project": "",
        "reviewers": "fxkQ;A7wP;K4VU;WgeU;PyNC",
        "site": "https://openreview.net/forum?id=DfVIe2WLsT",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "3;4;5;6;6",
        "scope": "4;3;3;4;4",
        "confidence": "4;3;1;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3273268353539886
    },
    {
        "id": "Dp4GnUZsDL",
        "title": "Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly in Ethereum\u2019s Block Building Market",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Ethereum, as a representative of Web3, adopts a novel framework called Proposer Builder Separation (PBS) to prevent the centralization of block profits in the hands of institutional Ethereum stakers. Introducing builders to generate blocks based on public transactions, PBS aims to ensure that block profits are distributed among all stakers. Through the auction among builders, only one will win the block in each slot. Ideally, the equilibrium strategy of builders under public information would lead them to bid all block profits. However, builders are now capable of extracting profits from private order flows. In this paper, we explore the effect of PBS with private order flows. Specifically, we propose the asymmetry auction model of MEV-Boost auction. Moreover, we conduct empirical study on Ethereum blocks from January 2023 to May 2024. Our analysis indicates that private order flows contribute to 54.59% of the block value, indicating that different builders will build blocks with different valuations. Interestingly, we find that builders with more private order flows (i.e., higher block valuations) are more likely to win the block, while retain larger proportion of profits. In return, such builders will further attract more private order flows, resulting in a monopolistic market gradually. Our findings reveal that PBS in current stage is unable to balance the profit distribution, which just transits the centralization of block profits from institutional stakers to the monopolistic builder.",
        "keywords": "Ethereum;Builder market;Private Order Flow;Centralization;Monopoly",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shuzheng Wang;Yue HUANG;Wenqin Zhang;Huang Yuming;Xuechao Wang;Jing Tang",
        "authorids": "~Shuzheng_Wang1;~Yue_HUANG15;~Wenqin_Zhang1;~Huang_Yuming2;~Xuechao_Wang2;~Jing_Tang5",
        "gender": "M;M;F;M;M;M",
        "homepage": ";https://hyue0768.github.io/;https://www.hkust-gz.edu/wenqinzhang;https://ymhuang.me;https://xuechao2.github.io/;https://sites.google.com/view/jtang",
        "dblp": ";;;;;83/663-4",
        "google_scholar": ";kDqzr3YAAAAJ;;;2NXOKQ8AAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";;;;0000-0001-6918-2699;0000-0002-0785-707X",
        "linkedin": "ShuzhengRunguine;;;;;",
        "or_profile": "~Shuzheng_Wang1;~Yue_HUANG15;~Wenqin_Zhang1;~Huang_Yuming2;~Xuechao_Wang2;~Jing_Tang5",
        "aff": "Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;;;Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology (Guangzhou)+Hong Kong University of Science and Technology",
        "aff_domain": "connect.hkust-gz.edu.cn;connect.hkust-gz.edu.cn;;;hkust-gz.edu.cn;hkust-gz.edu.cn+ust.hk",
        "position": "PhD student;MS student;;;Assistant Professor;Assistant Professor+Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025private,\ntitle={Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly in Ethereum{\\textquoteright}s Block Building Market},\nauthor={Shuzheng Wang and Yue HUANG and Wenqin Zhang and Huang Yuming and Xuechao Wang and Jing Tang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Dp4GnUZsDL}\n}",
        "github": "",
        "project": "",
        "reviewers": "e9xc;1LRe;kceh;c9LH;7Pxv",
        "site": "https://openreview.net/forum?id=Dp4GnUZsDL",
        "pdf_size": 0,
        "novelty": "2;4;5;6;6",
        "technical_quality": "2;3;5;6;6",
        "scope": "3;3;3;4;4",
        "confidence": "4;4;2;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.4966629547095764
        ],
        "technical_quality_avg": [
            4.4,
            1.624807680927192
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.49099025303098287
    },
    {
        "id": "Dr0T2XRSMO",
        "title": "Virtual Stars, Real Fans: Understanding the VTuber Ecosystem",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Livestreaming by VTubers -- animated 2D/3D avatars controlled by real individuals -- have recently garnered substantial global followings and achieved significant monetary success. Despite prior research highlighting the importance of realism in audience engagement, VTubers deliberately conceal their identities, cultivating dedicated fan communities through virtual personas. While previous studies underscore that building a core fan community is essential to a streamer's success, we lack an understanding of the characteristics and behaviors of viewers of this new type of streamer. Gaining a deeper insight into these viewers is critical for VTubers to enhance audience engagement, foster a more robust fan base, and attract a larger viewership. To address this gap, we conduct a comprehensive analysis of VTuber viewers on Bilibili, a leading livestreaming platform where nearly all VTubers in China stream. By compiling a first-of-its-kind dataset covering 2.7M livestreaming sessions, we investigate the characteristics, engagement patterns, and influence of VTuber viewers. Our research yields several valuable insights, which we then leverage to develop a tool to \"recommend\"  future subscribers to VTubers. By reversing the typical approach of recommending streams to viewers, this tool assists VTubers in pinpointing potential future fans to pay more attention to, and thereby effectively growing their fan community.",
        "keywords": "VTuber;Livestream;Empirical Investigation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yiluo Wei;Gareth Tyson",
        "authorids": "~Yiluo_Wei1;~Gareth_Tyson1",
        "gender": "Not Specified;",
        "homepage": ";https://www.eecs.qmul.ac.uk/~tysong/",
        "dblp": ";85/85",
        "google_scholar": "YqPG1HkAAAAJ;https://scholar.google.co.uk/citations?user=91hmRA0AAAAJ",
        "orcid": "0009-0000-0318-9249;",
        "linkedin": ";",
        "or_profile": "~Yiluo_Wei1;~Gareth_Tyson1",
        "aff": "Hong Kong University of Science and Technology (GZ);Queen Mary, University of London",
        "aff_domain": "hkust-gz.edu.cn;qmul.ac.uk",
        "position": "PhD student;Senior Lecturer",
        "bibtex": "@inproceedings{\nwei2025virtual,\ntitle={Virtual Stars, Real Fans: Understanding the {VT}uber Ecosystem},\nauthor={Yiluo Wei and Gareth Tyson},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Dr0T2XRSMO}\n}",
        "github": "",
        "project": "",
        "reviewers": "Xs4M;RLeJ;QQse;Qtzb",
        "site": "https://openreview.net/forum?id=Dr0T2XRSMO",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;4;5;4",
        "scope": "4;4;4;4",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.25,
            0.4330127018922193
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "E5kOggLraC",
        "title": "Generalization Performance of Hypergraph Neural Networks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Hypergraph neural networks have been promising tools for handling learning tasks involving higher-order data, with notable applications in web graphs, such as modeling multi-way hyperlink structures and complex user interactions. Yet, their generalization abilities in theory are less clear to us. In this paper, we seek to develop margin-based generalization bounds for four representative classes of hypergraph neural networks, including convolutional-based methods (UniGCN), set-based aggregation (AllDeepSets), invariant and equivariant transformations (M-IGN), and tensor-based approaches (T-MPHN). Through the PAC-Bayes framework, our results reveal the manner in which hypergraph structure and spectral norms of the learned weights can affect the generalization bounds, where the key technical challenge lies in developing new perturbation analysis for hypergraph neural networks, which offers a rigorous understanding of how variations in the model's weights and hypergraph structure impact its generalization behavior. Our empirical study examines the relationship between the practical performance and theoretical bounds of the models over synthetic and real-world datasets. One of our primary observations is the strong correlation between the theoretical bounds and empirical loss, with statistically significant consistency in most cases.",
        "keywords": "Graph Classification;Hypergraph Neural Network;Learning Theory",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yifan Wang;Gonzalo Arce;Guangmo Tong",
        "authorids": "~Yifan_Wang41;~Gonzalo_Arce1;~Guangmo_Tong1",
        "gender": "F;M;",
        "homepage": ";https://www.ece.udel.edu/people/faculty/arce/;",
        "dblp": ";;",
        "google_scholar": "-J4jwDoAAAAJ;;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Yifan_Wang41;~Gonzalo_Arce1;~Guangmo_Tong1",
        "aff": "University of Delaware;University of Delaware;",
        "aff_domain": "udel.edu;udel.edu;",
        "position": "PhD student;Full Professor;",
        "bibtex": "@inproceedings{\nwang2025generalization,\ntitle={Generalization Performance of Hypergraph Neural Networks},\nauthor={Yifan Wang and Gonzalo Arce and Guangmo Tong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=E5kOggLraC}\n}",
        "github": "",
        "project": "",
        "reviewers": "d4KL;axNx;KjzA;LQpF",
        "site": "https://openreview.net/forum?id=E5kOggLraC",
        "pdf_size": 0,
        "novelty": "5;6;6;7",
        "technical_quality": "4;6;6;6",
        "scope": "3;4;4;4",
        "confidence": "2;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            6.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.5,
            0.8660254037844386
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5
    },
    {
        "id": "E8bjWloEvU",
        "title": "When Large Vision Language Models Meet Multimodal Sequential Recommendation: An Empirical Study",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "As multimedia content continues to grow on the Web, the integration of visual and textual data has become a crucial challenge for Web applications, particularly in recommendation systems. Large Vision Language Models (LVLMs) have demonstrated considerable potential in addressing this challenge across various tasks that require such multimodal integration. However, their application in multimodal sequential recommendation (MSR) has not been extensively studied, despite their potential to significantly enhance the performance of web-based multimodal recommendations. To bridge this gap, we introduce MSRBench, the first comprehensive benchmark designed to systematically evaluate different LVLM integration strategies in web-based recommendation scenarios. We benchmark three state-of-the-art LVLMs, i.e., GPT-4 Vision, GPT4o, and Claude-3-Opus, on the next item prediction task using the constructed Amazon Review Plus dataset, which includes additional item descriptions generated by LVLMs. Our evaluation examines five integration strategies: using LVLMs as recommender, item enhancer, reranker, and various combinations of these roles. The benchmark results reveal that 1) using LVLMs as rerankers is the most effective strategy, significantly outperforming others that rely on LVLMs to directly generate recommendations or only enhance items; 2) GPT-4o consistently achieves the best performance across most scenarios, particularly when employed as a reranker; 3) the computational inefficiency of LVLMs presents a major barrier to their widespread adoption in real-time multimodal recommendation systems. Our codes and datasets will be made publicly available upon acceptance.",
        "keywords": "Multimodal Recommendation;Benchmark;Large Vision Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Peilin Zhou;Chao Liu;Jing Ren;Xinfeng Zhou;Yueqi XIE;Meng Cao;Zhongtao Rao;You-Liang Huang;Dading Chong;Junling Liu;Jae Boum KIM;Shoujin Wang;Raymond Chi-Wing Wong;Sunghun Kim",
        "authorids": "~Peilin_Zhou1;~Chao_Liu8;~Jing_Ren2;~Xinfeng_Zhou1;~Yueqi_XIE1;~Meng_Cao1;~Zhongtao_Rao1;~You-Liang_Huang1;~Dading_Chong1;~Junling_Liu1;~Jae_Boum_KIM1;~Shoujin_Wang1;~Raymond_Chi-Wing_Wong1;~Sunghun_Kim1",
        "gender": "M;M;M;M;F;M;M;M;M;M;;M;M;M",
        "homepage": "https://palin2018.github.io;;;https://github.com/zhouxinfeng2?tab=projects;https://xyq7.github.io/;https://mengcaopku.github.io/;;https://youliangh.github.io/;;;;https://shoujinwang1.github.io/;http://www.cse.ust.hk/~raywong/;https://www.cse.ust.hk/~hunkim/",
        "dblp": "164/9272;;;;239/5986;67/833;;360/4854;232/0256;16/870.html;;16/8492;w/RaymondChiWingWong;",
        "google_scholar": "3dx8O1AAAAAJ;;;;XB8oP_gAAAAJ;ZRbRQ0cAAAAJ;;7pDl1GsAAAAJ;tPSb8YoAAAAJ;https://scholar.google.com.hk/citations?user=rXS0vhsAAAAJ;;BQ0mBRIAAAAJ;https://scholar.google.com.tw/citations?user=IKgiD0AAAAAJ;https://scholar.google.com.tw/citations?user=dQM6NLgAAAAJ",
        "orcid": ";0000-0001-5323-2209;;;0000-0002-5169-3180;0000-0002-8946-4228;;0000-0003-0587-9571;;;;0000-0003-1133-9379;0000-0001-7045-6503;",
        "linkedin": ";;jing-ren-aba259196/;;;;zhongtao-rao-405879198?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app;;;https://www.linkedin.cn/incareer/in/ACoAADAu538BuKRWcX4dZ9EESgLTtH6p9BaroRc;;;;",
        "or_profile": "~Peilin_Zhou1;~Chao_Liu8;~Jing_Ren2;~Xinfeng_Zhou1;~Yueqi_XIE1;~Meng_Cao1;~Zhongtao_Rao1;~You-Liang_Huang1;~Dading_Chong1;~Junling_Liu1;~Jae_Boum_KIM1;~Shoujin_Wang1;~Raymond_Chi-Wing_Wong1;~Sunghun_Kim1",
        "aff": "Hong Kong University of Science and Technology (Guangzhou);Meituan;ByteDance Inc.;;Princeton University+Hong Kong University of Science and Technology;Mohamed bin Zayed University of Artificial Intelligence;The Hong Kong University of Science and Technology (Guangzhou);Boston University+Hong Kong University of Science and Technology;Zoom;Xiaohongshu;;University of Technology Sydney;Department of Computer Science and Engineering, Hong Kong University of Science and Technology;Hong Kong University of Science and Technology",
        "aff_domain": "hkust-gz.edu.cn;meituan.com;bytedance.com;;princeton.edu+hkust.edu;mbzuai.ac.ae;hkust-gz.edu.cn;bu.edu+connect.hkust-gz.edu.cn;zoom.com;xiaohongshu.com;;uts.edu.au;cse.ust.hk;ust.hk",
        "position": "PhD student;Researcher;Full Professor;;Postdoc+PhD student;Postdoc;MS student;PhD student+MS student;Undergrad student;Researcher;;Lecturer;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nzhou2025when,\ntitle={When Large Vision Language Models Meet Multimodal Sequential Recommendation: An Empirical Study},\nauthor={Peilin Zhou and Chao Liu and Jing Ren and Xinfeng Zhou and Yueqi XIE and Meng Cao and Zhongtao Rao and You-Liang Huang and Dading Chong and Junling Liu and Jae Boum KIM and Shoujin Wang and Raymond Chi-Wing Wong and Sunghun Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=E8bjWloEvU}\n}",
        "github": "",
        "project": "",
        "reviewers": "bhPt;qY6e;eJYb;hDat",
        "site": "https://openreview.net/forum?id=E8bjWloEvU",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "5;2;4;5",
        "scope": "2;3;3;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.0,
            0.7071067811865476
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            14,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8703882797784891
    },
    {
        "id": "E91gjsccP1",
        "title": "HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Retrieval-Augmented Generation (RAG) has been shown to improve knowledge capabilities and alleviate the hallucination problem of LLMs. The Web is a major source of external knowledge used in RAG systems, and many commercial systems such as ChatGPT and Perplexity have used Web search engines as their major retrieval systems. Typically, such RAG systems retrieve search results, download HTML sources of the results, and then extract plain texts from the HTML sources. Plain text documents or chunks are fed into the LLMs to augment the generation. However, much of the structural and semantic information inherent in HTML, such as headings and table structures, is lost during this plain-text-based RAG process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead of plain text as the format of retrieved knowledge in RAG. We believe HTML is better than plain text in modeling knowledge in external documents, and most LLMs possess robust capacities to understand HTML. However, utilizing HTML presents new challenges. HTML contains additional content such as tags, JavaScript, and CSS specifications, which bring extra input tokens and noise to the RAG system. To address this issue, we propose HTML cleaning, compression, and pruning strategies, to shorten the HTML while minimizing the loss of information. Specifically, we design a two-step block-tree-based pruning method that prunes useless HTML blocks and keeps only the relevant part of the HTML. Experiments on six QA datasets confirm the superiority of using HTML in RAG systems.",
        "keywords": "HTML;Retrieval-Augmented Generation;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiejun Tan;Zhicheng Dou;Wen Wang;Mang Wang;Weipeng Chen;Ji-Rong Wen",
        "authorids": "~Jiejun_Tan2;~Zhicheng_Dou1;~Wen_Wang20;~Mang_Wang3;~Weipeng_Chen3;~Ji-Rong_Wen1",
        "gender": "M;;M;;;M",
        "homepage": "http://www.plageon.cn;https://playbigdata.ruc.edu.cn/dou;;;;https://gsai.ruc.edu.cn/english/jrwen",
        "dblp": "355/5723;18/5740;;;;w/JRWen",
        "google_scholar": ";ChCjAAwAAAAJ;https://scholar.google.com/citations?hl=zh-CN;;;tbxCHJgAAAAJ",
        "orcid": "0009-0001-8106-4780;0000-0002-9781-948X;;;;0000-0002-9777-9676",
        "linkedin": ";;;;;",
        "or_profile": "~Jiejun_Tan2;~Zhicheng_Dou1;~Wen_Wang20;~Mang_Wang3;~Weipeng_Chen3;~Ji-Rong_Wen1",
        "aff": "Renmin University of China;Renmin University of China;Beijing Baichuan Intelligence Technology Co., Ltd.;;;Renmin University of China",
        "aff_domain": "ruc.edu.cn;ruc.edu.cn;baichuan-ai.com;;;ruc.edu.cn",
        "position": "PhD student;Full Professor;Independent Researcher;;;Full Professor",
        "bibtex": "@inproceedings{\ntan2025htmlrag,\ntitle={Html{RAG}: {HTML} is Better Than Plain Text for Modeling Retrieved Knowledge in {RAG} Systems},\nauthor={Jiejun Tan and Zhicheng Dou and Wen Wang and Mang Wang and Weipeng Chen and Ji-Rong Wen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=E91gjsccP1}\n}",
        "github": "",
        "project": "",
        "reviewers": "n7h6;zv2a;CW8s;sVZq;n5QX",
        "site": "https://openreview.net/forum?id=E91gjsccP1",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "5;5;4;5;6",
        "scope": "4;3;3;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "EAVs2PgwsD",
        "title": "Breaking the Shield: Analyzing and Attacking Canvas Fingerprinting Defenses in the Wild",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Canvas fingerprinting has become one of the most effective techniques for tracking users online, allowing websites to identify and track visitors without their consent. In this paper, we investigate four primary defense techniques designed to counter canvas fingerprinting, systematically analyzing their adoption across 18 browser extensions in Chrome and Firefox, as well as built-in protections from five major browsers: Chrome, Firefox, Brave, Tor, and Safari. Our analysis reveals significant disparities in the implementation and effectiveness of these defenses, with randomization-based techniques being the most widely adopted, particularly across nine extensions and in the privacy-focused browser, Brave. Despite their sophistication, we demonstrate successful attacks on all these randomization mechanisms, revealing that their supposed non-deterministic behavior can, in fact, be predicted and exploited. In summary, we demonstrate that, unfortunately, no fully deployable defense against canvas fingerprinting attacks exists currently. We conclude by proposing recommendations to strengthen existing defenses and enhance their resistance to future attacks.",
        "keywords": "Web security;Privacy;Online Tracking;Canvas Fingerprinting Attack",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hoang Dai Nguyen;Phani Vadrevu",
        "authorids": "~Hoang_Dai_Nguyen1;~Phani_Vadrevu1",
        "gender": "M;M",
        "homepage": "https://www.hoangdainguyen.com;https://www.phanivadrevu.com",
        "dblp": "331/5808;133/2036",
        "google_scholar": "yUbHSugAAAAJ;tjlBAEIAAAAJ",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Hoang_Dai_Nguyen1;~Phani_Vadrevu1",
        "aff": "Louisiana State University;Louisiana State University",
        "aff_domain": "lsu.edu;lsu.edu",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nnguyen2025breaking,\ntitle={Breaking the Shield: Analyzing and Attacking Canvas Fingerprinting Defenses in the Wild},\nauthor={Hoang Dai Nguyen and Phani Vadrevu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=EAVs2PgwsD}\n}",
        "github": "",
        "project": "",
        "reviewers": "xMts;qrUq;Xu89;WfMv;Sjrk",
        "site": "https://openreview.net/forum?id=EAVs2PgwsD",
        "pdf_size": 0,
        "novelty": "2;3;3;4;5",
        "technical_quality": "2;3;4;3;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;4;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            3.4,
            1.019803902718557
        ],
        "technical_quality_avg": [
            3.4,
            1.019803902718557
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.32025630761017426
    },
    {
        "id": "ETyLTCkvfT",
        "title": "You Can't Eat Your Cake and Have It Too: The Performance Degradation of LLMs with Jailbreak Defense",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the rise of generative large language models (LLMs) like LLaMA and ChatGPT, these models have significantly transformed daily life and work by providing advanced insights. However, as jailbreak attacks continue to circumvent built-in safety mechanisms, exploiting carefully crafted scenarios or tokens, the safety risks of LLMs have come into focus. While numerous defense strategies\u2014such as prompt detection, modification, and model fine-tuning\u2014have been proposed to counter these attacks, a critical question arises: do these defenses compromise the utility and usability of LLMs for legitimate users? Existing research predominantly focuses on the effectiveness of defense strategies without thoroughly examining their impact on performance, leaving a gap in understanding the trade-offs between LLM safety and performance.\n\nOur research addresses this gap by conducting a comprehensive study on the utility degradation, safety elevation, and exaggerated-safety escalation of LLMs with jailbreak defense strategies. We propose _**USEBench**_, a novel benchmark designed to evaluate these aspects, along with _**USEIndex**_, a comprehensive metric for assessing overall model performance. Through experiments on seven state-of-the-art LLMs, we found that mainstream jailbreak defenses fail to ensure both safety and performance simultaneously. Although model-finetuning performs the best overall, their effectiveness varies across LLMs. Furthermore, vertical comparisons reveal that developers commonly prioritize performance over safety when iterating or fine-tuning their LLMs.",
        "keywords": "LLM Jailbreak;Jailbreak Evaluation;LLM Performance Downgrade;LLM Benchmark",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wuyuao Mai;Geng Hong;Pei Chen;Xudong Pan;Baojun Liu;Yuan Zhang;Haixin Duan;Min Yang",
        "authorids": "~Wuyuao_Mai1;~Geng_Hong1;~Pei_Chen5;~Xudong_Pan1;~Baojun_Liu1;~Yuan_Zhang28;~Haixin_Duan2;~Min_Yang12",
        "gender": ";M;F;M;M;M;M;M",
        "homepage": "https://marphownio.github.io/;https://ghong.site/;;https://ravensanstete.github.io/pages/About%20Me/;https://liubaojun.org;https://yuanxzhang.github.io/;https://netsec.ccert.edu.cn/people/duanhx/;https://secsys.fudan.edu.cn/",
        "dblp": ";;;71/7816;89/10754.html;;;02/1640-2",
        "google_scholar": ";https://scholar.google.com/citations?hl=en;;Unl69CYAAAAJ;6Hme86QAAAAJ;;yGTOi34AAAAJ;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": ";0000-0003-1811-9432;0009-0001-8088-316X;;;;;0000-0001-9714-5545",
        "linkedin": ";;;;;;;",
        "or_profile": "~Wuyuao_Mai1;~Geng_Hong1;~Pei_Chen5;~Xudong_Pan1;~Baojun_Liu1;~Yuan_Zhang28;~Haixin_Duan2;~Min_Yang12",
        "aff": "Fudan University;Fudan University;Fudan University;;Tsinghua University;Fudan University;Tsinghua University;Fudan University",
        "aff_domain": "fudan.edu.cn;fudan.edu.cn;fudan.edu.cn;;tsinghua.edu.cn;fudan.edu.cn;tsinghua.edu.cn;fudan.edu.cn",
        "position": "MS student;Assistant Professor;PhD student;;Assistant Professor;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nmai2025you,\ntitle={You Can't Eat Your Cake and Have It Too: The Performance Degradation of {LLM}s  with Jailbreak Defense},\nauthor={Wuyuao Mai and Geng Hong and Pei Chen and Xudong Pan and Baojun Liu and Yuan Zhang and Haixin Duan and Min Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ETyLTCkvfT}\n}",
        "github": "",
        "project": "",
        "reviewers": "oY1L;AZJV;Szmj;6spx;xHP4",
        "site": "https://openreview.net/forum?id=ETyLTCkvfT",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;4;6;3;6",
        "scope": "2;3;4;4;3",
        "confidence": "2;2;4;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            1.2
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.6,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5624999999999999
    },
    {
        "id": "EVIREJsGEE",
        "title": "Decoupling Knowledge and Context: An Efficient and Effective Retrieval Augmented Generation Framework via Cross Attention",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Retrieval-Augmented Generation (RAG) systems have become acrucial tool to augment large language models (LLMs) with external knowledge for better task performance. However, existing traditional RAG methods inject knowledge directly in the context, resulting in several limitations. First, these methods highly rely on the in-context learning capability of LLMs, which often leads to excessively long contexts. This is inefficient due to the quadratic complexity of self-attention, leading to significant increases in inference time. Second, the extended context and the nature of self-attention can cause the LLMs to lose important information in the context, thereby degrading the original capabilities of LLMs. Furthermore, the effectiveness of knowledge injection is perturbed by the permutation of knowledge within the extended context, reducing the robustness of existing RAG methods. To tackle the above problems, we propose DecoupledRAG, a method that decouples external knowledge from the context within the RAG framework. Specifically, we introduce a cross-attention based method that injects retrieved knowledge directly to the inference process of LLM on the fly, without modifying its parameters or the input context. The external knowledge could be utilized robustly in a permutation-independent manner. To the best of our knowledge, this is the first work that explore how to utilize cross-attention to inject knowledge with low training cost in decoder-only LLM era. By leveraging cross-attention operation, DecoupledRAG enables seamless knowledge aggregation without creating extended context. Experimental results demonstrate that our method achieves high efficiency while maintaining strong performance, which indicates that RAG frameworks have the potential to benefit further from more knowledge.",
        "keywords": "Retrieval-augmented Generation;Large Language Model;Knowledge Injection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qian Dong;Qingyao Ai;Hongning Wang;Yiding Liu;Haitao Li;Weihang Su;Yiqun LIU;Tat-Seng Chua;Shaoping Ma",
        "authorids": "~Qian_Dong1;~Qingyao_Ai1;~Hongning_Wang1;~Yiding_Liu1;~Haitao_Li3;~Weihang_Su1;~Yiqun_LIU1;~Tat-Seng_Chua2;~Shaoping_Ma1",
        "gender": "M;Not Specified;M;M;M;M;M;;M",
        "homepage": "https://dq0408.github.io/;https://qingyaoai.github.io;http://www.cs.virginia.edu/~hw5x/;https://liuyiding.net;https://cshaitao.github.io;;http://www.thuir.cn/group/~YQLiu/;;http://www.thuir.cn/group/~msp/",
        "dblp": ";169/1808;05/6545;;29/5847-6.html;301/7966;49/1579;;40/1949",
        "google_scholar": "m88SZGgAAAAJ;UKqaI5IAAAAJ;qkdvKNoAAAAJ;c7oiMdIAAAAJ;https://scholar.google.com.hk/citations?user=jj5HjKUAAAAJ;xEJc8cgAAAAJ;NJOnxh4AAAAJ;;",
        "orcid": ";0000-0002-5030-709X;0000-0002-6524-9195;0000-0001-6857-261X;;;;;0000-0002-8762-8268",
        "linkedin": ";qingyao-ai-4ab8306a;;;;;;;",
        "or_profile": "~Qian_Dong1;~Qingyao_Ai1;~Hongning_Wang1;~Yiding_Liu1;~Haitao_Li3;~Weihang_Su1;~Yiqun_LIU1;~Tat-Seng_Chua2;~Shaoping_Ma1",
        "aff": "Tsinghua University;Tsinghua University;Tsinghua University;Baidu;Tsinghua University;, Tsinghua University;Tsinghua University;;Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn;baidu.com;tinghua.edu.cn;cs.tsinghua.edu.cn;tsinghua.edu.cn;;tsinghua.edu.cn",
        "position": "PhD student;Associate Professor;Associate Professor;Researcher;MS student;PhD student;Full Professor;;Full Professor",
        "bibtex": "@inproceedings{\ndong2025decoupling,\ntitle={Decoupling Knowledge and Context: An Efficient and Effective Retrieval Augmented Generation Framework via Cross Attention},\nauthor={Qian Dong and Qingyao Ai and Hongning Wang and Yiding Liu and Haitao Li and Weihang Su and Yiqun LIU and Tat-Seng Chua and Shaoping Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=EVIREJsGEE}\n}",
        "github": "",
        "project": "",
        "reviewers": "j7Mo;AfAr;GdYS;AWVe",
        "site": "https://openreview.net/forum?id=EVIREJsGEE",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "3;4;5;6",
        "scope": "2;4;4;4",
        "confidence": "3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.8660254037844386
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "EhEK5INtSP",
        "title": "Dual-level Mixup for Graph Few-shot Learning with Fewer Tasks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph neural networks have been demonstrated as a powerful paradigm for effectively learning graph-structured data for downstream task analysis. Current leading graph models require a large number of labeled samples for training, which unavoidably leads to overfitting in few-shot scenarios. Recent research has sought to alleviate this issue by simultaneously leveraging graph learning and meta-learning paradigms. However, these graph meta-learning models assume the availability of numerous meta-training tasks to learn transferable meta-knowledge. Such an assumption may not be feasible in the real world due to the difficulty of constructing tasks and the substantial costs involved. Therefore, we propose a SiMple yet effectIve approach for graph few-shot Learning with fEwer tasks, named SMILE. We introduce a dual-level mixup strategy, encompassing both within-task and across-task mixup, to simultaneously enrich the available nodes and tasks in meta-learning. Moreover, we explicitly leverage the prior information provided by the node degrees in the graph to encode expressive node representations. Theoretically, we demonstrate that SMILE can enhance the model generalization ability. Empirically, SMILE consistently outperforms other competitive models by a large margin across all evaluated datasets with in-domain and cross-domain settings. Our anonymous code can be found here.",
        "keywords": "few-shot learning;graph neural network;node classification",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yonghao Liu;Mengyu Li;Fausto Giunchiglia;Lan Huang;Ximing Li;Xiaoyue Feng;Renchu Guan",
        "authorids": "~Yonghao_Liu1;~Mengyu_Li2;~Fausto_Giunchiglia1;~Lan_Huang1;~Ximing_Li1;~Xiaoyue_Feng1;~Renchu_Guan1",
        "gender": ";;M;F;M;F;M",
        "homepage": "https://scholar.google.com.hk/citations?hl=zh-CN&view_op=list_works&gmla=AILGF5Udn-P7gWE0kdGS-fIdpbsdOUmuZhGmthSVvfT8983shU8IxPGs73r4_jfb6JKqeA8f4dBT3PE80HlV3DW5zv4&user=wCqFrjoAAAAJ;https://scholar.google.com/citations?user=ckQcqtwAAAAJ&hl=zh-CN;http://fausto.disi.unitn.it/;https://ccst.jlu.edu.cn/info/1367/19279.htm;https://ccst.jlu.edu.cn/info/1367/19282.htm;http://ccst.jlu.edu.cn/info/1312/17077.htm;https://ccst.jlu.edu.cn/info/1322/17817.htm",
        "dblp": "185/7866-1.html;47/1793;g/FaustoGiunchiglia;74/1260-2;130/1013-2;15/5229;84/8179",
        "google_scholar": "https://scholar.google.com.hk/citations?hl=zh-CN;ckQcqtwAAAAJ;https://scholar.google.it/citations?hl=it;;2WQ--c4AAAAJ;https://scholar.google.com.hk/citations?user=O-aznvsAAAAJ;U8Zhze4AAAAJ",
        "orcid": "0000-0001-8621-7144;0000-0001-9327-434X;0000-0002-5903-6150;0000-0003-3233-3777;0000-0001-8190-5087;0000-0003-3954-1333;0000-0002-7162-7826",
        "linkedin": ";;fausto-giunchiglia-662a8/;;;;",
        "or_profile": "~Yonghao_Liu1;~Mengyu_Li2;~Fausto_Giunchiglia1;~Lan_Huang1;~Ximing_Li1;~Xiaoyue_Feng1;~Renchu_Guan1",
        "aff": "Jilin University;;University of Trento;Jilin University;RIKEN+Jilin University;Jilin University;Jilin University",
        "aff_domain": "jlu.edu.cn;;unitn.it;jlu.edu.cn;riken.jp+jlu.edu.cn;jlu.edu.cn;jlu.edu.cn",
        "position": "PhD student;;Full Professor;Full Professor;Researcher+Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025duallevel,\ntitle={Dual-level Mixup for Graph Few-shot Learning with Fewer Tasks},\nauthor={Yonghao Liu and Mengyu Li and Fausto Giunchiglia and Lan Huang and Ximing Li and Xiaoyue Feng and Renchu Guan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=EhEK5INtSP}\n}",
        "github": "",
        "project": "",
        "reviewers": "SQza;b3kg;HxTv;Gr8k;5DJX",
        "site": "https://openreview.net/forum?id=EhEK5INtSP",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "3;5;5;5;5",
        "scope": "3;4;3;3;4",
        "confidence": "2;3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "F8RBFdKXWZ",
        "title": "InfoMAE: Pairing-Efficient Cross-Modal Alignment with Informational Masked Autoencoders for IoT Signals",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Standard multimodal self-supervised learning (SSL) algorithms regard cross-modal synchronization as implicit supervisory labels\nduring pretraining, thus posing high requirements on the scale\nand quality of multimodal samples. These constraints significantly\nlimit the performance of sensing intelligence in IoT applications,\nwhere the heterogeneity and the non-interpretability of time-series\nsignals result in abundant unimodal data but scarce high-quality\nmultimodal pairs. This paper proposes InfoMAE, a cross-modal\nalignment framework that tackles the challenge of multimodal\npair efficiency under the SSL setting by facilitating efficient cross-\nmodal alignment of pretrained unimodal representations. InfoMAE\nachieves efficient cross-modal alignment with limited data pairs\nthrough a novel information theory-inspired formulation that simultaneously addresses distribution-level and instance-level align-\nment. Extensive experiments on two real-world IoT applications\nare performed to evaluate InfoMAE\u2019s pairing efficiency to bridge\npretrained unimodal models into a cohesive joint multimodal model.\nInfoMAE enhances downstream multimodal tasks by over 60% with\nsignificantly improved multimodal pairing efficiency. It also improves unimodal task accuracy by an average of 22%",
        "keywords": "Internet of Things;Self-Supervised Learning;Multimodal Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tomoyoshi Kimura;Xinlin Li;Osama Hanna;Yatong Chen;Yizhuo Chen;Denizhan Kara;Tianshi Wang;Jinyang Li;Xiaomin OUYANG;Shengzhong Liu;Mani Srivastava;Suhas Diggavi;Tarek F. Abdelzaher",
        "authorids": "~Tomoyoshi_Kimura1;~Xinlin_Li3;~Osama_Hanna1;~Yatong_Chen2;~Yizhuo_Chen2;~Denizhan_Kara1;~Tianshi_Wang1;~Jinyang_Li2;~Xiaomin_OUYANG1;~Shengzhong_Liu1;~Mani_Srivastava1;~Suhas_Diggavi1;~Tarek_F._Abdelzaher1",
        "gender": "M;F;M;F;;M;M;;F;M;;;",
        "homepage": "https://www.tomoyoshikimura.com/;;https://www.arni.ee.ucla.edu/people/osama-hanna/;;https://yizhuochen99.github.io/;https://denizhankara.github.io/;https://leowangx2013.github.io/;;https://xmouyang.github.io/;https://liushengzhong1023.github.io/;;https://www.ee.ucla.edu/suhas-diggavi/;",
        "dblp": ";;;;;;;79/572-4;295/6332.html;166/5424;;d/SNDiggavi.html#j15;",
        "google_scholar": "8uuJfmoAAAAJ;tKcDMGoAAAAJ;;fFAiWTYAAAAJ;;;G5cJK7oAAAAJ;VbeL3UUAAAAJ;y7oUVucAAAAJ;REzrIucAAAAJ;;;",
        "orcid": "0009-0008-4297-5865;;;;;;0000-0002-3085-1434;0000-0001-9285-9872;0000-0003-0710-0963;;;;",
        "linkedin": "tomoyoshi-kimura/;;;;;;;;xiaomin-ouyang-059556179;;;;",
        "or_profile": "~Tomoyoshi_Kimura1;~Xinlin_Li3;~Osama_Hanna1;~Yatong_Chen2;~Yizhuo_Chen2;~Denizhan_Kara1;~Tianshi_Wang1;~Jinyang_Li2;~Xiaomin_OUYANG1;~Shengzhong_Liu1;~Mani_Srivastava1;~Suhas_Diggavi1;~Tarek_F._Abdelzaher1",
        "aff": "Department of Computer Science, University of Illinois at Urbana Champaign;University of California, Los Angeles;Meta Facebook;Shanghai Jiaotong University;University of Illinois;Department of Computer Science;Amazon;University of Illinois, Urbana Champaign;Department of Computer Science and Engineering, Hong Kong University of Science and Technology;Shanghai Jiaotong University;;University of California, Los Angeles;",
        "aff_domain": "cs.illinois.edu;ucla.edu;meta.com;sjtu.edu.cn;cs.illinois.edu;cs.illinois.edu;amazon.com;uiuc.edu;cse.ust.hk;sjtu.edu.cn;;ucla.edu;",
        "position": "PhD student;PhD student;Research Scientist;PhD student;PhD student;PhD student;Researcher;PhD student;Assistant Professor;Associate Professor;;Professor;",
        "bibtex": "@inproceedings{\nkimura2025infomae,\ntitle={Info{MAE}: Pairing-Efficient Cross-Modal Alignment with Informational Masked Autoencoders for IoT Signals},\nauthor={Tomoyoshi Kimura and Xinlin Li and Osama Hanna and Yatong Chen and Yizhuo Chen and Denizhan Kara and Tianshi Wang and Jinyang Li and Xiaomin OUYANG and Shengzhong Liu and Mani Srivastava and Suhas Diggavi and Tarek F. Abdelzaher},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=F8RBFdKXWZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "JQ9p;D3Lv;ebqq;uQgK",
        "site": "https://openreview.net/forum?id=F8RBFdKXWZ",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;5;5;5",
        "scope": "1;3;1;4",
        "confidence": "3;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.5,
            0.8660254037844386
        ],
        "scope_avg": [
            2.25,
            1.299038105676658
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            13,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3162277660168379
    },
    {
        "id": "FGlYLoXWSz",
        "title": "Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Browser fingerprinting is a pervasive online tracking technique increasingly used for profiling and targeted advertising.\nExisting research on fingerprinting prevalence relies heavily on automated web crawls, which inherently struggle to replicate the nuances of human-computer interaction.\nThis raises concerns about the accuracy of current understandings of real-world fingerprinting deployments.\nTo that end, this paper presents a user study involving 30 participants over a 10-week period, capturing telemetry data from real browsing sessions across 3,000 top-ranked websites.\n\nOur findings reveal that automated crawls miss nearly half (47.8%) of the fingerprinting websites encountered by real users.\nThis discrepancy mainly stems from crawlers' inability to access authentication-protected pages, circumvent bot detection mechanisms, and trigger fingerprinting scripts activated by specific user interactions.\nWe also identify potential new fingerprinting vectors present in real user data but absent from automated crawls.\nFinally, we evaluate the effectiveness of federated learning for training browser fingerprinting detection models on real user data, demonstrating superior performance to models trained solely on automated crawl data.",
        "keywords": "Browser Fingerprinting;Differential Privacy;Federated Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Meenatchi Sundaram Muthu Selva Annamalai;Emiliano De Cristofaro;Igor Bilogrevic",
        "authorids": "~Meenatchi_Sundaram_Muthu_Selva_Annamalai1;~Emiliano_De_Cristofaro1;~Igor_Bilogrevic1",
        "gender": ";;",
        "homepage": "https://msundarmsa.github.io;https://emilianodc.com;",
        "dblp": "303/3273;36/6225;",
        "google_scholar": "zYVEyL4AAAAJ;https://scholar.google.com/citations?hl=en;",
        "orcid": "0000-0002-6452-9865;;",
        "linkedin": ";;",
        "or_profile": "~Meenatchi_Sundaram_Muthu_Selva_Annamalai1;~Emiliano_De_Cristofaro1;~Igor_Bilogrevic1",
        "aff": "University College London, University of London;University of California, Riverside;",
        "aff_domain": "ucl.ac.uk;ucr.edu;",
        "position": "PhD student;Full Professor;",
        "bibtex": "@inproceedings{\nannamalai2025beyond,\ntitle={Beyond the Crawl: Unmasking Browser Fingerprinting in Real User Interactions},\nauthor={Meenatchi Sundaram Muthu Selva Annamalai and Emiliano De Cristofaro and Igor Bilogrevic},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=FGlYLoXWSz}\n}",
        "github": "",
        "project": "",
        "reviewers": "3SnG;i2Q7;AcHi;9ttL;ERLG",
        "site": "https://openreview.net/forum?id=FGlYLoXWSz",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "2;6;5;4;4",
        "scope": "4;4;4;4;4",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.2,
            1.32664991614216
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6123724356957948
    },
    {
        "id": "FVQfMb1ZcQ",
        "title": "HeatSnap: A Hot Page-Aware Continuous Snapshots System for Virtual Machines in Web Infrastructure",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Snapshot technology is crucial for data protection and system recovery in virtualized environments, particularly with the growing need for continuous snapshots to maintain the integrity of long-running web-based and distributed applications. However, traditional snapshot methods often suffer from performance bottlenecks, and inefficient storage usage. These challenges are closely tied to the way memory pages are accessed during VM execution, where memory access patterns show significant disparities between frequently accessed \"hot\" pages and less-used \"cold\" pages.In this paper, we introduce HeatSnap, a continuous snapshot system designed to address these issues by leveraging the uneven access frequencies of memory pages. HeatSnap distinguishes between intensive hot pages and dirty pages, applying specialized snapshotting and storage strategies to optimize the handling of both hot and cold memory regions. This approach aims to optimize snapshot efficiency, minimize performance impact on the VM, and decrease storage costs.Our implementation of HeatSnap on QEMU/KVM demonstrates significant improvements in VM performance loss, snapshot duration, and storage efficiency compared to existing methods, as evidenced by evaluations on common web and cloud-based workloads.",
        "keywords": "Virtualization;Snapshot;Web Infrastructure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kangyue Gao;Chuangyu Ouyang;Xinkui Zhao;Miao Ye;Chen Zhi;Guanjie Cheng;Yueshen Xu;Shuiguang Deng;Jianwei Yin",
        "authorids": "~Kangyue_Gao1;~Chuangyu_Ouyang1;~Xinkui_Zhao1;~Miao_Ye1;~Chen_Zhi1;~Guanjie_Cheng1;~Yueshen_Xu1;~Shuiguang_Deng1;~Jianwei_Yin1",
        "gender": ";M;M;;M;M;M;M;M",
        "homepage": ";http://yasyakarasu.tech/;https://person.zju.edu.cn/en/NB22088;;;;https://faculty.xidian.edu.cn/XYS1/zh_CN/index.htm;https://person.zju.edu.cn/shuiguang;https://person.zju.edu.cn/0001038",
        "dblp": ";;135/5118;;132/3563;282/4657;;d/ShuiguangDeng;74/3786",
        "google_scholar": ";;;;https://scholar.google.com/citations?hl=en;xTw0l8QAAAAJ;;https://scholar.google.com/citations?hl=zh-CN;0s1A5fwAAAAJ",
        "orcid": ";;0000-0002-1115-5652;0009-0001-9533-8922;0000-0002-1273-2992;0000-0003-2080-3903;;0000-0001-5015-6095;0000-0003-4703-7348",
        "linkedin": "kangyue-gao-29bba432b;;;;;;;;",
        "or_profile": "~Kangyue_Gao1;~Chuangyu_Ouyang1;~Xinkui_Zhao1;~Miao_Ye1;~Chen_Zhi1;~Guanjie_Cheng1;~Yueshen_Xu1;~Shuiguang_Deng1;~Jianwei_Yin1",
        "aff": "Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Xidian University;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;xidian.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "MS student;Undergrad student;Full Professor;MS student;Researcher;Assistant Professor;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ngao2025heatsnap,\ntitle={HeatSnap: A Hot Page-Aware Continuous Snapshots System for Virtual Machines in Web Infrastructure},\nauthor={Kangyue Gao and Chuangyu Ouyang and Xinkui Zhao and Miao Ye and Chen Zhi and Guanjie Cheng and Yueshen Xu and Shuiguang Deng and Jianwei Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=FVQfMb1ZcQ}\n}",
        "github": "",
        "project": "",
        "reviewers": "6wcH;XXFL;x9RY;U6uz;ZPkB",
        "site": "https://openreview.net/forum?id=FVQfMb1ZcQ",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "2;4;5;5;7",
        "scope": "3;3;2;3;4",
        "confidence": "3;2;2;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.6,
            1.624807680927192
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.6,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.29417420270727607
    },
    {
        "id": "FizmdvsE64",
        "title": "Navigating the Deployment Dilemma and Innovation Paradox: Open-Source v.s. Closed-source Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recent advances in Artificial Intelligence (AI) have introduced a new paradigm in Machine Learning (ML) model development: pre-training of foundation model and domain adaptation. Two groups lead in developing foundation model: closed-source developers and open-source community. As open-source community becomes increasingly engaged, the performance open-source models are catching up with closed-source models. However, this leaves domain deployers into a dilemma: use closed-source models via API access or host open-source models on proprietary hardware. Using closed-source models incurs recurring costs, while hosting open-source models incurs substantial hardware investments and potentially lagging advancements. This paper presents a game-theoretical model to examine the economic incentives behind the deployment choice and the impact of open-source engagement strategy on technology innovation. We find that the deployer consistently opts for closed-source APIs when the open-source community engages in the market reactively by maintaining a fixed performance ratio relative to closed-source advancements. However, open-source models can be favored when a proactive open-source community produces high-performance models independently. Also, we identify conditions under which engagement and competitiveness of the open-source community can foster or inhibit technological progress. These insights offer valuable implications for market regulation and the future of AI model innovation.",
        "keywords": "Deployment dilemma; open-source; close-source; foundation model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yanxuan WU;Haihan Duan;Xitong Li;Xiping Hu",
        "authorids": "~Yanxuan_WU1;~Haihan_Duan1;~Xitong_Li3;~Xiping_Hu1",
        "gender": ";M;M;",
        "homepage": ";https://seaxiaod.gitee.io/;https://ai.smbu.edu.cn/info/1261/1941.htm;https://scholar.google.com/citations?hl=en&user=Mc93YSEAAAAJ&view_op=list_works",
        "dblp": ";253/1007;;81/10098.html",
        "google_scholar": ";KnEtyrIAAAAJ;;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0001-6438-3790;0009-0001-1033-0711;0000-0002-4952-699X",
        "linkedin": ";;;",
        "or_profile": "~Yanxuan_WU1;~Haihan_Duan1;~Xitong_Li3;~Xiping_Hu1",
        "aff": ";Shenzhen MSU-BIT University;Guangdong Engineering Center for Social Computing and Mental Health+Shenzhen MSU-BIT University;Beijing Institute of Technology",
        "aff_domain": ";smbu.edu.cn;smbu.edu.cn+smbu.edu.cn;bit.edu.cn",
        "position": ";Associate Professor;Full Professor+Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nwu2025navigating,\ntitle={Navigating the Deployment Dilemma and Innovation Paradox: Open-Source v.s. Closed-source Models},\nauthor={Yanxuan WU and Haihan Duan and Xitong Li and Xiping Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=FizmdvsE64}\n}",
        "github": "",
        "project": "",
        "reviewers": "EG9x;mqSP;hqi7;SzLH;htuR",
        "site": "https://openreview.net/forum?id=FizmdvsE64",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "3;2;4;4;5",
        "scope": "3;3;3;3;4",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            3.6,
            1.019803902718557
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.4082482904638631
    },
    {
        "id": "FvKEZWQHlk",
        "title": "Spatial-temporal Analysis of Collective Emotional Resonance During Global Health Crisis",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The 21st century has already witnessed so many outbreaks with pandemic potential, including SARS (2002), H1N1 (2009), MERS (2012), Ebola (2014), Zika virus (2015), and the COVID-19 pandemic (2019). Using 60 million geotagged Sina Weibo tweets covering over 20 million active accounts, we investigate the collective emotional dynamics on social media in the most recent global pandemic, i.e., COVID-19. This research features two highlights: (1) It focuses on the Chinese population located in the initial epicenter of the pandemic. (2) It examines the initial year after the pandemic outbreak, a critical period where emotions were most intense due to the uncertainty and rapid developments related to the crisis. Using cross-disciplinary methods, we reveal a positive connection between online emotional resonance and geographic proximity, demonstrating a direct mapping between virtual network distances and physical spatial embedding. We propose a percolation-based index to measure the nationwide emotional resonance level with which we illustrate the significant economic impact of the global health issue. Finally, we identify a leader-follower pattern in emotional resonance fluctuations based on time-lag emotion correlations, revealing that less active regions play a crucial role in leading and responding to emotional changes. In the face of long COVID and emerging global health crises, our analysis elucidates how collective emotional resonance evolves, providing potential directions for online opinion interventions during global shocks.",
        "keywords": "Emotional resonance;Sentimental analysis;Social network;Percolation theory",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Limiao Zhang;Xinyang Qi;Haiping Ma;JieGao;Xingyi Zhang;Yanqing HU;Yaochu Jin",
        "authorids": "~Limiao_Zhang1;~Xinyang_Qi1;~Haiping_Ma1;~JieGao1;~Xingyi_Zhang2;~Yanqing_HU1;~Yaochu_Jin1",
        "gender": "F;M;F;M;M;M;M",
        "homepage": "http://bimk.ahu.edu.cn/2022/0805/c12971a290785/page.htm;https://github.com/qixy4;;https://isie.qd.sdu.edu.cn/info/1015/3040.htm;https://cs.ahu.edu.cn/2023/0815/c20806a313390/page.htm;http://www.sustech.edu.cn/zh/faculties/yanqinghu.html;https://en.westlake.edu.cn/faculty/yaochu-jin.html",
        "dblp": ";;83/8129.html;;93/1107;;j/YaochuJin",
        "google_scholar": ";;;;https://scholar.google.com/citations?hl=zh-CN;;B5WAkz4AAAAJ",
        "orcid": ";;0000-0002-3115-6855;;0000-0002-5052-000X;;0000-0003-1100-0631",
        "linkedin": ";;;;;;",
        "or_profile": "~Limiao_Zhang1;~Xinyang_Qi1;~Haiping_Ma1;~JieGao1;~Xingyi_Zhang2;~Yanqing_HU1;~Yaochu_Jin1",
        "aff": "Anhui University;Anhui University;Anhui University;Shandong University;Anhui University;Southern University of Science and Technology;Westlake University",
        "aff_domain": "ahu.edu.cn;ahu.edu.cn;ahu.edu.cn;sdu.edu.cn;ahu.edu.cn;sustech.edu.cn;westlake.edu.cn",
        "position": "Associate Professor;MS student;Assistant Professor;Associate Professor;Full Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025spatialtemporal,\ntitle={Spatial-temporal Analysis of Collective Emotional Resonance During Global Health Crisis},\nauthor={Limiao Zhang and Xinyang Qi and Haiping Ma and JieGao and Xingyi Zhang and Yanqing HU and Yaochu Jin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=FvKEZWQHlk}\n}",
        "github": "",
        "project": "",
        "reviewers": "aSov;WxNz;7ZPQ;ck4v;idzG",
        "site": "https://openreview.net/forum?id=FvKEZWQHlk",
        "pdf_size": 0,
        "novelty": "2;3;4;5;5",
        "technical_quality": "3;2;5;5;5",
        "scope": "3;3;3;3;4",
        "confidence": "3;2;4;3;2",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.0,
            1.2649110640673518
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.04583492485141057
    },
    {
        "id": "GE71TxvTH3",
        "title": "Unleash LLMs Potential for Sequential Recommendation by Coordinating Dual Dynamic Index Mechanism",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Owing to the unprecedented capability in semantic understanding and logical reasoning, the large language models (LLMs) have shown fantastic potential in developing the next-generation sequential recommender systems (RSs). However, on one hand, existing LLM-based sequential RSs mostly separate the index generation from the sequential recommendation, leading to insufficient integration between the semantic information and the collaborative information. On the other hand, the neglect of the user-related information hinders the LLM-based sequential RSs from exploiting the high-order user-item interaction patterns implicating in user behavior. In this paper, we propose the End-to-End Dual Dynamic (ED$^2$) recommender, the first LLM-based sequential recommender system which adopts the dual dynamic index mechanism, targeting at resolving the above limitations simultaneously. The dual dynamic index mechanism can not only assembly the index generation and the sequential recommendation into an unified LLM-backbone pipeline, but also make it practical for the LLM-based sequential recommender to take advantage of the user-related information. Specifically, to facilitate the LLMs comprehension ability to the dual dynamic index, we propose a multi-grained token regulator which constructs alignment supervision based on the LLMs semantic knowledge across multiple representation granularities. Moreover, the associated user collection data and a series of novel instruction tuning tasks are specially customized to exploit the user historical behavior in depth and  capture the high-order user-item interaction patterns. Extensive experiments on three public datasets demonstrate the superiority of ED$^2$, achieving an average improvement of 19.41\\% in Hit-Rate and 20.84\\% in NDCG metric.",
        "keywords": "Sequential Recommender Systems;Large Language Models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jun Yin;Zhengxin Zeng;Mingzheng Li;Hao Yan;Chaozhuo Li;Weihao Han;Jianjin Zhang;Ruochen Liu;Hao Sun;Weiwei Deng;Feng Sun;Qi Zhang;Shirui Pan;Senzhang Wang",
        "authorids": "~Jun_Yin11;~Zhengxin_Zeng1;~Mingzheng_Li2;~Hao_Yan6;~Chaozhuo_Li1;~Weihao_Han1;~Jianjin_Zhang2;~Ruochen_Liu5;~Hao_Sun6;~Weiwei_Deng2;~Feng_Sun1;~Qi_Zhang19;~Shirui_Pan1;~Senzhang_Wang2",
        "gender": "M;F;M;M;;M;;M;M;M;M;M;;M",
        "homepage": "https://esperanto-mega.github.io/;;;https://sktsherlock.github.io/;https://scss.bupt.edu.cn/info/1063/5534.htm;;;https://space.bilibili.com/15291300?spm_id_from=333.1007.0.0;;;;;;https://senzhangwangcsu.github.io/index.html",
        "dblp": "58/5423-5;;;;316/1269.html;234/8823;230/4168;03/6999-1;;311/3565.html;09/3224;;91/8171;118/5055",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com/citations?view_op=list_works;https://scholar.google.com/citations?hl=en;;https://scholar.google.com/citations?hl=zh-CN;;MW5n_WcAAAAJ;;OjWD_SsAAAAJ;;;;https://scholar.google.com.au/citations?user=frWRJN4AAAAJ;zdWyGRMAAAAJ",
        "orcid": ";;;;0000-0002-8179-7503;;;0009-0000-6597-2044;0009-0004-5027-7478;0009-0001-4793-9715;;;0000-0003-0794-527X;0000-0002-3615-4859",
        "linkedin": ";;;;;;;;;;feng-sun/;qizhang07/;;",
        "or_profile": "~Jun_Yin11;~Zhengxin_Zeng1;~Mingzheng_Li2;~Hao_Yan6;~Chaozhuo_Li1;~Weihao_Han1;~Jianjin_Zhang2;~Ruochen_Liu5;~Hao_Sun6;~Weiwei_Deng2;~Feng_Sun1;~Qi_Zhang19;~Shirui_Pan1;~Senzhang_Wang2",
        "aff": "Hong Kong Polytechnic University+Central South University;Microsoft;;Central South University;Beijing University of Posts and Telecommunications;Microsoft;Microsoft;Central South University;Microsoft;Microsoft;;Microsoft;Griffith University;Central South University",
        "aff_domain": "connect.polyu.hk+csu.edu.cn;microsoft.com;;csu.edu.cn;bupt.edu.cn;microsoft.com;microsoft.com;csu.edu.cn;microsoft.com;microsoft.com;;microsoft.com;griffith.edu.au;csu.edu.cn",
        "position": "PhD student+MS student;Researcher;;PhD student;Associate Professor;Researcher;Researcher;MS student;Researcher;Researcher;;Researcher;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nyin2025unleash,\ntitle={Unleash {LLM}s Potential for Sequential Recommendation by Coordinating Dual Dynamic Index Mechanism},\nauthor={Jun Yin and Zhengxin Zeng and Mingzheng Li and Hao Yan and Chaozhuo Li and Weihao Han and Jianjin Zhang and Ruochen Liu and Hao Sun and Weiwei Deng and Feng Sun and Qi Zhang and Shirui Pan and Senzhang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GE71TxvTH3}\n}",
        "github": "",
        "project": "",
        "reviewers": "oCpA;FgHA;rJTb;mgTF;yoLm",
        "site": "https://openreview.net/forum?id=GE71TxvTH3",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "5;5;5;6;6",
        "scope": "4;4;4;4;4",
        "confidence": "2;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            5.4,
            0.48989794855663565
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            14,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2988071523335984
    },
    {
        "id": "GLjvvBom8S",
        "title": "FP-Rainbow : Fingerprint-based Browser Configuration Identification",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Browser fingerprinting is a tracking technique that collects attributes and calls functions from the browser\u2019s APIs. Unlike cookies, browser fingerprints are difficult to evade or delete, raising significant privacy concerns for users as they can be used to re-identify individuals over browsing sessions without their consent. Yet, there has been limited research on the impact of browser configuration settings on these fingerprints. This paper introduces FP-Rainbow, a novel approach to systematically explore and map the configuration space of Chromium-based web browsers aiming to identify the impact of configuration parameters on browser fingerprints and their changes over time. We explore 1,748 configuration parameters (switches) and identify their impact on the browser\u2019s BOM (Browser Object Model). By collecting and analyzing over 61,000 fingerprints from 18 versions of Chromium, our study reveals that 32 to 56 of these configuration parameters (depending on versions), such as disable-3d-apis or disable-notifications, influence the fingerprint of a web browser. FP-Rainbow also proves efficient in identifying browser configuration parameters from unknown fingerprints, achieving an average successful identification rate of 84% when considering a single configuration parameter and 78% when multiple parameters are involved, across all evaluated browser versions. These findings emphasize the importance of measuring the impact of configuration parameters on browsers to develop safer and more ethical web browsers.",
        "keywords": "Browser Fingerprinting;Privacy;Web Security;Online Tracking;Configuration Parameters;BOM Exploration",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Maxime Huyghe;Walter Rudametkin;Cl\u00e9ment Quinton",
        "authorids": "~Maxime_Huyghe1;~Walter_Rudametkin1;~Cl\u00e9ment_Quinton1",
        "gender": "M;;M",
        "homepage": "https://mhuyghe.fr/;https://rudametw.github.io;https://clementquinton.github.io/",
        "dblp": ";;",
        "google_scholar": ";https://scholar.google.com/citations?hl=fr;",
        "orcid": ";;0000-0003-3203-6107",
        "linkedin": ";;",
        "or_profile": "~Maxime_Huyghe1;~Walter_Rudametkin1;~Cl\u00e9ment_Quinton1",
        "aff": "INRIA+University of Lille;IRISA / Univ Rennes;University of Lille",
        "aff_domain": "inria.fr+univ-lille.fr;irisa.fr;univ-lille.fr",
        "position": "PhD student+PhD student;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nhuyghe2025fprainbow,\ntitle={{FP}-Rainbow : Fingerprint-based Browser Configuration Identification},\nauthor={Maxime Huyghe and Walter Rudametkin and Cl{\\'e}ment Quinton},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GLjvvBom8S}\n}",
        "github": "",
        "project": "",
        "reviewers": "wEU1;1EG3;maYm;e43e",
        "site": "https://openreview.net/forum?id=GLjvvBom8S",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "4;5;5;4",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "GXxzv80i0O",
        "title": "Detecting and Understanding the Promotion of Illicit Goods and Services on Twitter",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In this study, we reveal, for the first time, popular online social networks (especially Twitter) are being extensively abused by miscreants to promote illicit goods and services of diverse categories. This study is made possible by multiple machine learning tools that are designed to detect and analyze Posts of Illicit Promotion (PIPs) as well as revealing their underlying promotion campaigns. Particularly, we observe that PIPs are prevalent on Twitter, along with extensive visibility on other three popular OSNs including YouTube, Facebook, and TikTok. For instance, applying our PIP hunter to the Twitter platform for 6 months has led to the discovery of 12 million distinct PIPs which are widely distributed in 5 major natural languages and 10 illicit categories, e.g., drugs, data leakage, gambling, and weapon sales. Along the discovery of PIPs are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging accounts that are embedded in PIPs and serve as next hops of communication with prospective customers. Also, an arms race between Twitter and illicit promotion operators is also observed. Especially, 90% PIPs can survice the first two months since getting published on Twitter, which is likely due to the diverse evasion tactics adopted by miscreants to masquerade PIPs.",
        "keywords": "Illicit Promotion;Online Abuse;Cybercrime;Twitter;Online Social Networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hongyu Wang;Ying Li;Ronghong Huang;xianghang mi",
        "authorids": "~Hongyu_Wang9;~Ying_Li28;~Ronghong_Huang1;~xianghang_mi1",
        "gender": "F;F;;M",
        "homepage": "https://github.com/WangHonyu;https://y1ngli.github.io/;https://github.com/HRH0517;https://xianghang.me",
        "dblp": ";;;192/2270.html",
        "google_scholar": ";rJO3CPUAAAAJ;;6duSrM8AAAAJ",
        "orcid": ";;;0000-0002-8747-5601",
        "linkedin": ";;;xianghang/",
        "or_profile": "~Hongyu_Wang9;~Ying_Li28;~Ronghong_Huang1;~xianghang_mi1",
        "aff": "University of Science and Technology of China;University of California, Los Angeles;University of Science and Technology of China;University of Science and Technology of China",
        "aff_domain": "ustc.edu;ucla.edu;ustc.edu.cn;ustc.edu.cn",
        "position": "MS student;PhD student;MS student;Full Professor",
        "bibtex": "@inproceedings{\nwang2025detecting,\ntitle={Detecting and Understanding the Promotion of Illicit Goods and Services on Twitter},\nauthor={Hongyu Wang and Ying Li and Ronghong Huang and xianghang mi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GXxzv80i0O}\n}",
        "github": "",
        "project": "",
        "reviewers": "5k4N;pam9;zPwN;JMem;3psN",
        "site": "https://openreview.net/forum?id=GXxzv80i0O",
        "pdf_size": 0,
        "novelty": "2;3;4;5;5",
        "technical_quality": "2;3;5;6;4",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.0,
            1.4142135623730951
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "GdzcwAWPq3",
        "title": "Multivariate Time Series Anomaly Detection by Capturing Coarse-Grained Intra- and Inter-Variate Dependencies",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Multivariate time series anomaly detection is essential for failure management in web application operations, as it directly influences the effectiveness and timeliness of implementing remedial or preventive measures. This task is often framed as a semi-supervised learning problem, where only normal data are available for model training, primarily due to the labor-intensive nature of data labeling and the scarcity of anomalous data. Existing semi-supervised methods often detect anomalies by capturing intra-variate temporal dependencies and/or inter-variate relationships to learn normal patterns, flagging timestamps that deviate from these patterns as anomalies. However, these approaches often fail to capture salient intra-variate temporal and inter-variate dependencies in time series due to their focus on excessively fine granularity, leading to suboptimal performance. In this study, we introduce MtsCID, a novel semi-supervised multivariate time series anomaly detection method. MtsCID employs a dual network architecture: one network operates on the attention maps of multi-scale intra-variate patches for coarse-grained temporal dependency learning, while the other works on variates to capture coarse-grained inter-variate relationships through convolution and interaction with sinusoidal prototypes. This design enhances the ability to capture the patterns from both intra-variate temporal dependencies and inter-variate relationships, resulting in improved performance. Extensive experiments across seven widely used datasets demonstrate that MtsCID achieves performance comparable or superior to state-of-the-art benchmark methods.",
        "keywords": "Time Series;Anomaly Detection;Deep Learning;AIOps",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongzheng Xie;Hongyu Zhang;Muhammad Ali Babar",
        "authorids": "~Yongzheng_Xie1;~Hongyu_Zhang1;~Muhammad_Ali_Babar1",
        "gender": "M;M;M",
        "homepage": "https://www.adelaide.edu.au/directory/yongzheng.xie;https://sites.google.com/site/hongyujohn;https://malibabar.wordpress.com",
        "dblp": ";29/2726-2;03/1909.html",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.au/citations?user=zsUN6PkAAAAJ;https://scholar.google.com.au/citations?user=oagBheUAAAAJ",
        "orcid": ";0000-0002-3063-9425;",
        "linkedin": ";;",
        "or_profile": "~Yongzheng_Xie1;~Hongyu_Zhang1;~Muhammad_Ali_Babar1",
        "aff": ";Chongqing University;University of Adelaide",
        "aff_domain": ";cqu.edu.cn;adelaide.edu.au",
        "position": ";Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nxie2025multivariate,\ntitle={Multivariate Time Series Anomaly Detection by Capturing Coarse-Grained Intra- and Inter-Variate Dependencies},\nauthor={Yongzheng Xie and Hongyu Zhang and Muhammad Ali Babar},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GdzcwAWPq3}\n}",
        "github": "",
        "project": "",
        "reviewers": "XNcv;dLLQ;Qyor;dbmn;BFtj",
        "site": "https://openreview.net/forum?id=GdzcwAWPq3",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "4;4;5;7;6",
        "scope": "4;3;4;3;3",
        "confidence": "4;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.21004201260420152
    },
    {
        "id": "Gf3aFnrE9Y",
        "title": "Scalable Algorithms for Forest-Based Centrality on Large Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Centrality measures are essential for identifying important nodes and edges within a network. In this paper, we focus on two forest-based centrality measures on undirected graphs: forest node centrality (FNC) and forest edge centrality (FEC), which capture the influence of nodes and edges through their participation in spanning forests. Both centrality measures can be represented using entries of the forest matrix. To address the challenge of computing the two measures on large networks,  we propose two scalable algorithms  from different perspectives. The first algorithm $\\textbf{IFGN}$ combines two variance reduction techniques to approximate the entries of the forest matrix, which is applicable to both FNC and FEC. The second  algorithm $\\textbf{FECE}$ incorporates a new physical interpretation of FEC, allowing for a better overall estimation. We provide error guarantees for both algorithms and   demonstrate their efficiency and effectiveness  through extensive experiments on various real-world networks.",
        "keywords": "Forest-based Centrality;Variance Reduction Technique;Approximation Algorithms.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yubo Sun;Haoxin Sun;Zhongzhi Zhang",
        "authorids": "~Yubo_Sun1;~Haoxin_Sun1;~Zhongzhi_Zhang1",
        "gender": "M;M;M",
        "homepage": ";https://scholar.google.com/citations?user=IPVq8H8AAAAJ&hl=zh-CN;https://scholar.google.com/citations?user=DrcEuSkAAAAJ&hl=zh-CN",
        "dblp": ";151/5585;47/7618",
        "google_scholar": ";IPVq8H8AAAAJ;DrcEuSkAAAAJ",
        "orcid": "0009-0008-8207-8122;0000-0002-4626-2079;0000-0003-1260-2079",
        "linkedin": ";;",
        "or_profile": "~Yubo_Sun1;~Haoxin_Sun1;~Zhongzhi_Zhang1",
        "aff": "Fudan University;Fudan University;Fudan University",
        "aff_domain": "fudan.edu.cn;fudan.edu.cn;fudan.edu.cn",
        "position": "MS student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nsun2025scalable,\ntitle={Scalable Algorithms for Forest-Based Centrality on Large Graphs},\nauthor={Yubo Sun and Haoxin Sun and Zhongzhi Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Gf3aFnrE9Y}\n}",
        "github": "",
        "project": "",
        "reviewers": "4D6b;DrPW;LYo8;ATLG",
        "site": "https://openreview.net/forum?id=Gf3aFnrE9Y",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "4;6;5;6",
        "scope": "3;4;4;3",
        "confidence": "2;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            5.25,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3333333333333333
    },
    {
        "id": "GjF3k6xfd1",
        "title": "Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The $q$-parameterized magnetic Laplacian serves as the foundation of directed graph (digraph) convolution from a spectral perspective, enabling this kind of digraph neural network (MagDG) to encode node features and structural insights by complex-domain message passing. As a generalization of undirected methods, MagDG shows superior capability in modeling intricate web-scale topology and offers greater application potential. Despite the great success achieved by existing MagDGs, limitations still exist: (1) {Hand-crafted $q$}: The performance of MagDGs depends on selecting an appropriate $q$-parameter to construct suitable graph propagation equations in the complex domain. This parameter tuning, driven by downstream tasks, limits model flexibility and significantly increases manual effort. (2) {Coarse Message Passing}: Most approaches treat all nodes with the same complex-domain propagation and aggregation rules, neglecting their unique digraph contexts. This oversight results in sub-optimal performance. To address the above issues, we propose two key techniques: (1) MAP is crafted to be a plug-and-play complex-domain propagation optimization strategy in the context of digraph learning, enabling seamless integration into any MagDG to improve predictions while enjoying high running efficiency. (2) MAP++ is a new digraph learning framework, further incorporating a learnable mechanism to achieve adaptively edge-wise propagation and node-wise aggregation in the complex domain for better performance. Extensive experiments on 12 datasets demonstrate that MAP enjoys flexibility for it can be incorporated with any MagDG, and scalability as it can deal with web-scale digraphs. MAP++ achieves SOTA predictive performance on 4 different downstream tasks.",
        "keywords": "Directed Graph Neural Network;Magnetic Laplacian",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xunkai Li;Daohan Su;Zhengyu Wu;Guang Zeng;Hongchao Qin;Rong-Hua Li;Guoren Wang",
        "authorids": "~Xunkai_Li1;~Daohan_Su1;~Zhengyu_Wu1;~Guang_Zeng2;~Hongchao_Qin1;~Rong-Hua_Li2;~Guoren_Wang2",
        "gender": "M;M;M;F;M;M;M",
        "homepage": "https://xkli-allen.github.io/;;;;https://qinhc.github.io/;https://ronghuali.github.io/;https://guorenwang.github.io/",
        "dblp": "275/2483;;83/6594;;185/7920;37/548.html;",
        "google_scholar": "VfEdG18AAAAJ;;;https://scholar.google.com.tw/citations?view_op=list_works;;fOKGw-EAAAAJ;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0000-0002-1230-7603;0009-0003-1627-9608;0009-0004-8791-3191;;;0000-0002-3105-5325;",
        "linkedin": ";;https://www.linkedin.cn/incareer/in/ACoAAC2Ee3kB7hGhoYm5S1nYBEErC5CRiJUqM64;;;;",
        "or_profile": "~Xunkai_Li1;~Daohan_Su1;~Zhengyu_Wu1;~Guang_Zeng2;~Hongchao_Qin1;~Rong-Hua_Li2;~Guoren_Wang2",
        "aff": "Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;Alibaba Group;Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology",
        "aff_domain": "bit.edu.cn;bit.edu.cn;bit.edu.cn;antfin.com;bit.edu.cn;bit.edu.cn;bit.edu.cn",
        "position": "PhD student;MS student;PhD student;Researcher;Assistant Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nli2025toward,\ntitle={Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach},\nauthor={Xunkai Li and Daohan Su and Zhengyu Wu and Guang Zeng and Hongchao Qin and Rong-Hua Li and Guoren Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GjF3k6xfd1}\n}",
        "github": "",
        "project": "",
        "reviewers": "p5qm;f4vd;dca8;RVxi",
        "site": "https://openreview.net/forum?id=GjF3k6xfd1",
        "pdf_size": 0,
        "novelty": "3;4;6;6",
        "technical_quality": "3;4;5;6",
        "scope": "4;4;4;4",
        "confidence": "3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.299038105676658
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.19245008972987526
    },
    {
        "id": "GrJYzmDzfW",
        "title": "Biting Off More Than You Can Detect: Retrieval-Augmented Multimodal Experts for Short Video Hate Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Short Video Hate Detection (SVHD) is increasingly vital as hateful content \u2014 such as racial and gender-based discrimination \u2014 spreads rapidly across platforms like TikTok, YouTube Shorts, and Instagram Reels. Existing approaches face significant challenges: hate expressions continuously evolve, hateful signals are dispersed across multiple modalities (audio, text, and vision), and the contribution of each modality varies across different hate content. To address these issues, we introduce MoRE (Mixture of Retrieval-augmented multimodal Experts), a novel framework designed to enhance SVHD. MoRE employs specialized multimodal experts for each modality, leveraging their unique strengths to identify hateful content effectively. To ensure model's adaptability to rapidly evolving hate content, MoRE leverages contextual knowledge extracted from relevant instances retrieved by a powerful joint multimodal video retriever for each target short video. Moreover, a dynamic sample-sensitive integration network adaptively adjusts the importance of each modality on a per-sample basis, optimizing the detection process by prioritizing the most informative modalities for each instance. Our MoRE adopts an end-to-end training strategy that jointly optimizes both expert networks and the overall framework, resulting in nearly a twofold improvement in training efficiency, which in turn enhances its applicability to real-world scenarios. Extensive experiments on three benchmarks demonstrate that MoRE surpasses state-of-the-art baselines, achieving an average improvement of 6.91% in macro-F1 score across all datasets.",
        "keywords": "Short video hate detection;retrieval augmentation;mixture of multimodal experts",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jian Lang;Rongpei Hong;Jin Xu;YILI LI;Xovee Xu;Fan Zhou",
        "authorids": "~Jian_Lang1;~Rongpei_Hong1;~Jin_Xu19;~YILI_LI2;~Xovee_Xu1;~Fan_Zhou11",
        "gender": "M;;M;F;M;M",
        "homepage": "https://jian-lang.github.io/;https://rongpei.org;https://www.maynoothuniversity.ie/people/jin-xu;;https://www.xoveexu.com;https://sise.uestc.edu.cn/info/1035/9375.htm",
        "dblp": "380/2006;358/7838.html;;;261/9309;63/3122-2",
        "google_scholar": "https://scholar.google.com.hk/citations?user=tEVL8eUAAAAJ;mS-iMV4AAAAJ;UKXjf5UAAAAJ;https://scholar.google.com/citations?hl=en;ra0qyRQAAAAJ;https://scholar.google.com.hk/citations?hl=zh-CN",
        "orcid": "0009-0009-0876-0497;0009-0007-4977-1657;0000-0002-6644-8217;0009-0006-9865-6930;0000-0001-6415-7558;0000-0002-8038-8150",
        "linkedin": ";;xu-jin-engineer/;;xovee/;",
        "or_profile": "~Jian_Lang1;~Rongpei_Hong1;~Jin_Xu19;~YILI_LI2;~Xovee_Xu1;~Fan_Zhou11",
        "aff": "University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Maynooth University;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;mu.ie;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "position": "MS student;MS student;Assistant Professor;PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nlang2025biting,\ntitle={Biting Off More Than You Can Detect: Retrieval-Augmented Multimodal Experts for Short Video Hate Detection},\nauthor={Jian Lang and Rongpei Hong and Jin Xu and YILI LI and Xovee Xu and Fan Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GrJYzmDzfW}\n}",
        "github": "",
        "project": "",
        "reviewers": "snR7;BNda;cq5F;wopR;Bj6n",
        "site": "https://openreview.net/forum?id=GrJYzmDzfW",
        "pdf_size": 0,
        "novelty": "4;5;5;6;6",
        "technical_quality": "5;5;4;6;6",
        "scope": "4;4;4;4;4",
        "confidence": "4;3;2;1;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.4,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8910421112136304
    },
    {
        "id": "GrvxqI3XL4",
        "title": "Fact-based Counter Narrative Generation to Combat Hate Speech",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Online hatred has become an increasingly pervasive issue, affecting individuals and communities across various digital platforms. To combat hate speech in such platforms, counter narratives (CNs) are regarded as an effective method. In recent years, there has been growing interest in using generative AI tools to construct CNs. However, most of the generative models produce generic responses to hate speech and can hallucinate, reducing their effectiveness. To address the above limitations, we propose a counter narrative generation method that enhances CNs by providing non-aggressive, fact-based narratives with relevant background knowledge from two distinct sources, including a web search module. Furthermore we conduct a comprehensive evaluation using multiple metrics, including LLM-based measures for persuasion, factuality, and informativeness, along with human and traditional NLP evaluations. Our method significantly outperforms baselines, achieving an average factuality score of 0.915, compared to 0.741 and 0.701 for competitive baselines, and performs well in human evaluations.",
        "keywords": "Hate Speech;Counter Narrative;Counter Speech;Fact-based narrative;LLMs",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Brian Wilk;Homaira Huda Shomee;Suman Maity;Sourav Medya",
        "authorids": "~Brian_Wilk1;~Homaira_Huda_Shomee1;~Suman_Maity1;~Sourav_Medya1",
        "gender": "Not Specified;F;M;M",
        "homepage": ";https://hhshomee.github.io/;;https://souravmedya.github.io/",
        "dblp": ";310/4183;65/11265;178/3021",
        "google_scholar": ";0vrRwsgAAAAJ;5YNCBU0AAAAJ;RCFhOM4AAAAJ",
        "orcid": ";;;0000-0003-0996-2807",
        "linkedin": "brianmaciejwilk/;homaira-huda-shomee/;;sourav-medya-35987a49/",
        "or_profile": "~Brian_Wilk1;~Homaira_Huda_Shomee1;~Suman_Maity1;~Sourav_Medya1",
        "aff": "University of Illinois at Chicago;University of Illinois at Chicago;Missouri University of Science and Technology;University of Illinois at Chicago",
        "aff_domain": "uic.edu;uic.edu;mst.edu;uic.edu",
        "position": "Undergrad student;PhD student;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwilk2025factbased,\ntitle={Fact-based Counter Narrative Generation to Combat Hate Speech},\nauthor={Brian Wilk and Homaira Huda Shomee and Suman Maity and Sourav Medya},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=GrvxqI3XL4}\n}",
        "github": "",
        "project": "",
        "reviewers": "PQmV;38Uc;j2Ja;gZHi;w3Co",
        "site": "https://openreview.net/forum?id=GrvxqI3XL4",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "3;5;5;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "4;2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.10482848367219184
    },
    {
        "id": "H9BYGURN9M",
        "title": "A LLM-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Conversational Recommender System (CRS) leverages real-time feedback from users to dynamically model their preferences, thereby enhancing the system's ability to provide personalized recommendations and improving the overall user experience. CRS has demonstrated significant promise, prompting researchers to concentrate their efforts on developing user simulators that are both more realistic and trustworthy. The emergence of Large Language Models (LLMs) has marked the onset of a new epoch in computational capabilities, exhibiting human-level intelligence in various tasks. Research efforts have been made to utilize LLMs for building user simulators to evaluate the performance of CRS. Although these efforts showcase innovation, they are accompanied by certain limitations. In this work, we introduce a Controllable, Scalable, and Human-Involved (CSHI) simulator framework that manages the behavior of user simulators across various stages via a plugin manager. CSHI customizes the simulation of user behavior and interactions to provide a more lifelike and convincing user interaction experience. Through experiments and case studies in two conversational recommendation scenarios, we show that our framework can adapt to a variety of conversational recommendation settings and effectively simulate users' personalized preferences. Consequently, our simulator is able to generate feedback that closely mirrors that of real users. This facilitates a reliable assessment of existing CRS studies and promotes the creation of high-quality conversational recommendation datasets.",
        "keywords": "User Simulator;Conversational Recommender Systems;Large language models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "lixi Zhu;Xiaowen Huang;Jitao Sang",
        "authorids": "~lixi_Zhu2;~Xiaowen_Huang1;~Jitao_Sang1",
        "gender": "M;F;",
        "homepage": "https://github.com/zlxxlz1026/;https://faculty.bjtu.edu.cn/9545/;",
        "dblp": ";166/0337;",
        "google_scholar": ";Is1Of9MAAAAJ;",
        "orcid": ";0000-0001-9590-3285;",
        "linkedin": ";;",
        "or_profile": "~lixi_Zhu2;~Xiaowen_Huang1;~Jitao_Sang1",
        "aff": ";Beijing Jiaotong University;",
        "aff_domain": ";bjtu.edu.cn;",
        "position": ";Associate Professor;",
        "bibtex": "@inproceedings{\nzhu2025a,\ntitle={A {LLM}-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems},\nauthor={lixi Zhu and Xiaowen Huang and Jitao Sang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=H9BYGURN9M}\n}",
        "github": "",
        "project": "",
        "reviewers": "fdaX;J44H;XJ3B;1Nro;13Jf",
        "site": "https://openreview.net/forum?id=H9BYGURN9M",
        "pdf_size": 0,
        "novelty": "2;4;5;5;5",
        "technical_quality": "2;4;5;5;4",
        "scope": "3;4;4;4;4",
        "confidence": "3;3;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "HEBVEmK22u",
        "title": "LLM4Rerank: LLM-based Auto-Reranking Framework for Recommendations",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Reranking is significant for recommender systems due to its pivotal role in refining recommendation results. To meet diverse reranking requirements in practical applications, numerous reranking models have emerged, which not only prioritize accuracy but also consider additional aspects such as diversity and fairness, etc. However, most of the existing models struggle to strike a harmonious balance between these diverse aspects at the model level. Additionally, the scalability and personalization of these models are often limited by their complexity and a lack of attention to the varying importance of different aspects in diverse reranking scenarios. \n  To address these issues, we propose LLM4Rerank, a comprehensive LLM-based reranking framework designed to bridge the gap between various reranking aspects while ensuring scalability and personalized performance. \n  Specifically, we abstract different aspects into distinct nodes and construct a fully connected graph for LLM to automatically consider aspects like accuracy, diversity, fairness, and more, all in a coherent Chain-of-Thought (CoT) process. To further enhance personalization during reranking, we facilitate a customizable input mechanism that allows fine-tuning of LLM's focus on different aspects according to specific reranking needs.\n  Experimental results on three widely used public datasets demonstrate that LLM4Rerank outperforms existing state-of-the-art reranking models across multiple aspects. The implementation code is available for reproducibility.",
        "keywords": "Reranking;Recommender System;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jingtong Gao;Bo Chen;Xiangyu Zhao;Weiwen Liu;Xiangyang Li;Yichao Wang;Wanyu Wang;Huifeng Guo;Ruiming Tang",
        "authorids": "~Jingtong_Gao1;~Bo_Chen17;~Xiangyu_Zhao1;~Weiwen_Liu1;~Xiangyang_Li7;~Yichao_Wang3;~Wanyu_Wang1;~Huifeng_Guo1;~Ruiming_Tang2",
        "gender": "M;M;M;F;;M;F;M;M",
        "homepage": "https://gaojingtong.github.io;https://scholar.google.com.hk/citations?user=RZU1wxsAAAAJ;https://zhaoxyai.github.io/;https://wwliu555.github.io/;;;https://scholars.cityu.edu.hk/en/persons/wanyu-wang(dbf75484-d33f-428d-9f63-58994e10a34c).html;;https://scholar.google.com/citations?user=fUtHww0AAAAJ&hl=en",
        "dblp": "329/6049;89/5615-23;08/890-1.html;75/2746;;79/10448-2;24/5140-1.html;152/3785;24/10003.html",
        "google_scholar": "https://scholar.google.com.hk/citations?user=tkis1Q0AAAAJ;https://scholar.google.com.hk/citations?user=RZU1wxsAAAAJ;;https://scholar.google.com.hk/citations?user=C7UzRGgAAAAJ;;W7vCGJAAAAAJ;;jlBcPn8AAAAJ;https://scholar.google.com.sg/citations?user=fUtHww0AAAAJ",
        "orcid": "0000-0002-4470-5972;0000-0003-3750-2533;0000-0003-2926-4416;0000-0002-9148-3997;;0000-0001-7053-8269;0000-0001-5976-0707;0000-0002-7393-8994;0000-0002-9224-2431",
        "linkedin": ";;;;;;;;",
        "or_profile": "~Jingtong_Gao1;~Bo_Chen17;~Xiangyu_Zhao1;~Weiwen_Liu1;~Xiangyang_Li7;~Yichao_Wang3;~Wanyu_Wang1;~Huifeng_Guo1;~Ruiming_Tang2",
        "aff": "City University of Hong Kong;Huawei Technologies Ltd.;City University of Hong Kong;Shanghai Jiaotong University+Huawei Technologies Ltd.;;Huawei Technologies Ltd.;City University of Hong Kong;Huawei Technologies Ltd.;Kuaishou- \u5feb\u624b\u79d1\u6280+Huawei Technologies Ltd.",
        "aff_domain": "cityu.edu.hk;huawei.com;cityu.edu.hk;sjtu.edu.cn+huawei.com;;huawei.com;cityu.edu.hk;huawei.com;kuaishou.com+huawei.com",
        "position": "PhD student;Researcher;Assistant Professor;Associate Professor+Researcher;;Researcher;PhD student;Researcher;Principal Researcher+Principal Researcher",
        "bibtex": "@inproceedings{\ngao2025llmrerank,\ntitle={{LLM}4Rerank: {LLM}-based Auto-Reranking Framework for Recommendations},\nauthor={Jingtong Gao and Bo Chen and Xiangyu Zhao and Weiwen Liu and Xiangyang Li and Yichao Wang and Wanyu Wang and Huifeng Guo and Ruiming Tang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HEBVEmK22u}\n}",
        "github": "",
        "project": "",
        "reviewers": "kif5;Ba34;jqhk;Lnnx;oX92",
        "site": "https://openreview.net/forum?id=HEBVEmK22u",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "4;4;4;4;4",
        "scope": "3;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.0,
            0.0
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "HRIRfbYTIF",
        "title": "Centralization in Decentralized Web: Challenges and Opportunities in IPFS\u2019s Data Management",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The InterPlanetary File System (IPFS) is a pioneering effort\nfor Web 3.0, well-known for its decentralized infrastructure.\nHowever, some recent studies have shown that IPFS exhibits\na high degree of centralization and has integrated centralized components for better performance. While this change\ncontradicts the core decentralized ethos of IPFS and introduces risks of hurting the data replication level and thus\navailability, it also opens some opportunities for better data\nmanagement and cost savings through deduplication.\nTo explore these challenges and opportunities, we start\nby collecting an extensive dataset of IPFS internal traffic\nspanning the last three years with 20+ billion messages. By\nanalyzing this long-term trace, we obtain a more complete\nand accurate view of how the status of centralization evolves\nover an extended period. In particular, (1) IPFS shows a low\nreplication level in general, with only about 2.71% of data\nfiles replicated more than 5 times. While increasing replication enhances lookup performance and data availability, it\nadversely affects downloading throughput due to the over-\nhead involved in managing peer connections, (2) there is\na clear growing trend in centralization within IPFS in the\nlast 3 years, with just 5% of peers now hosting over 80% of\nthe content, significantly decreasing from 21.38% 3 years\nago, which is largely driven by the increase of cloud nodes,\n(3) the IPFS default deduplication strategy using Fixed-Size\nChunking (FSC) is largely inefficient, especially with the\ncurrent 256KB chunk size, achieving nearly zero efficiency.\nAlthough Content-Defined Chunking (CDC) with smaller\nchunks could save significant storage (about 1.8 PB) and\ncost, it could impact user performance negatively. We thus\ndesign and evaluate a new metadata format that optimizes\ndeduplication without compromising performance.",
        "keywords": "decentralized web;replication;centralization;deduplication;web data management",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ruizhe Shi;Ruizhi Cheng;Yuqi Fu;Bo Han;Yue Cheng;Songqing Chen",
        "authorids": "~Ruizhe_Shi2;~Ruizhi_Cheng1;~Yuqi_Fu1;~Bo_Han5;~Yue_Cheng1;~Songqing_Chen1",
        "gender": "M;;M;;M;M",
        "homepage": ";https://felixshing.github.io/;https://fishercht1995.github.io/;;https://tddg.github.io;https://cs.gmu.edu/~sqchen/",
        "dblp": ";312/6541.html;;;20/777-1;47/3276",
        "google_scholar": ";u0ZFxFsAAAAJ;;;TMGwBH0AAAAJ;https://scholar.google.com.tw/citations?user=T7IRM8EAAAAJ",
        "orcid": ";;;;0000-0003-1695-4864;",
        "linkedin": "ruizhe-shi-556430294/;;;;;",
        "or_profile": "~Ruizhe_Shi2;~Ruizhi_Cheng1;~Yuqi_Fu1;~Bo_Han5;~Yue_Cheng1;~Songqing_Chen1",
        "aff": "George Mason University;George Mason University;University of Virginia, Charlottesville;;University of Virginia, Charlottesville;George Mason University",
        "aff_domain": "gmu.edu;gmu.edu;virginia.edu;;virginia.edu;gmu.edu",
        "position": "PhD student;PhD student;PhD student;;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nshi2025centralization,\ntitle={Centralization in Decentralized Web: Challenges and Opportunities in {IPFS}{\\textquoteright}s Data Management},\nauthor={Ruizhe Shi and Ruizhi Cheng and Yuqi Fu and Bo Han and Yue Cheng and Songqing Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HRIRfbYTIF}\n}",
        "github": "",
        "project": "",
        "reviewers": "3JrF;G7fd;erVR;EkDg",
        "site": "https://openreview.net/forum?id=HRIRfbYTIF",
        "pdf_size": 0,
        "novelty": "3;5;6;6",
        "technical_quality": "3;5;5;6",
        "scope": "3;3;4;3",
        "confidence": "3;3;1;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.224744871391589
        ],
        "technical_quality_avg": [
            4.75,
            1.0897247358851685
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4714045207910316
    },
    {
        "id": "HSbSATEKv7",
        "title": "Maverick: Personalized Edge-Assisted Federated Learning with Contrastive Training",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In an edge-assisted federated learning (FL) system, edge servers aggregate the local models from the clients within their coverage areas to produce intermediate models for the production of the global model. This significantly reduces the communication overhead incurred during the FL process. To accelerate model convergence, FedEdge, the state-of-the-art edge-assisted FL system, trains clients' models in local federations when they wait for the global model in each training round. However, our investigation reveals that it drives the global model towards clients with excessive local training, causing model drifts that undermine model performance for other clients. To tackle this problem, this paper presents Maverick, a new edge-assisted FL system that mitigates model drifts by training personalized local models for clients through contrastive local training. It introduces a model-contrastive loss to facilitate personalized local federated training by driving clients' local models away from the global model and close to their corresponding intermediate models. In addition, Maverick includes anomalous models in contrastive local training as negative samples to accelerate the convergence of clients' local models. Extensive experiments are conducted on three widely-used public datasets to comprehensively evaluate the performance of Maverick. Compared to state-of-the-art edge-assisted FL systems, Maverick accelerates model convergence by up to 16.2x and improves model accuracy by up to 12.7%.",
        "keywords": "Edge-assisted federated learning;model drift;contrastive learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "KAIBIN WANG;Qiang He;Zeqian Dong;rui chen;Chuan He;Caslon Chua;Feifei Chen;Yun Yang",
        "authorids": "~KAIBIN_WANG1;~Qiang_He2;~Zeqian_Dong1;~rui_chen28;~Chuan_He7;~Caslon_Chua1;~Feifei_Chen1;~Yun_Yang1",
        "gender": "M;;M;M;M;;F;M",
        "homepage": "https://abc123.com;;;https://github.com/Ruicrand;https://github.com/Interstellar-PHC;https://www.swinburne.edu.au/research/our-research/access-our-research/find-a-researcher-or-supervisor/researcher-profile/?id=cchua;https://sites.google.com/view/feifeichen/home;https://experts.swinburne.edu.au/368-yun-yang",
        "dblp": ";;;;;;;90/3406-1",
        "google_scholar": ";;https://scholar.google.com/citations?view_op=list_works;;;;https://scholar.google.com.au/citations?user=5Hyav0gAAAAJ;https://scholar.google.com.hk/citations?user=YTDQzfsAAAAJ",
        "orcid": ";;;;;;;0000-0002-7868-5471",
        "linkedin": ";;;;;;;",
        "or_profile": "~KAIBIN_WANG1;~Qiang_He2;~Zeqian_Dong1;~rui_chen28;~Chuan_He7;~Caslon_Chua1;~Feifei_Chen1;~Yun_Yang1",
        "aff": "Swinburne University of Technology;;Swinburne University of Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology;Swinburne University of Technology;Deakin University;Swinburne University of Technology",
        "aff_domain": "swin.edu.au;;swin.edu.au;hust.edu.cn;hust.edu.cn;swin.edu.au;deakin.edu.au;swin.edu.au",
        "position": "PhD student;;PhD student;MS student;Undergrad student;Lecturer;Lecturer;Full Professor",
        "bibtex": "@inproceedings{\nwang2025maverick,\ntitle={Maverick: Personalized Edge-Assisted Federated Learning with Contrastive Training},\nauthor={KAIBIN WANG and Qiang He and Zeqian Dong and rui chen and Chuan He and Caslon Chua and Feifei Chen and Yun Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HSbSATEKv7}\n}",
        "github": "",
        "project": "",
        "reviewers": "is9L;Lnji;6cVn;Pxwg;KZNv",
        "site": "https://openreview.net/forum?id=HSbSATEKv7",
        "pdf_size": 0,
        "novelty": "3;4;4;6;7",
        "technical_quality": "4;3;3;6;7",
        "scope": "3;4;2;4;4",
        "confidence": "4;4;2;4;1",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.469693845669907
        ],
        "technical_quality_avg": [
            4.6,
            1.624807680927192
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            3.0,
            1.2649110640673518
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5379143536399189
    },
    {
        "id": "HTATedSTj4",
        "title": "What\u2019s in a Query: Polarity-aware Distribution-based Fair Ranking",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Machine learning-driven rankings, where individuals (or items) are ranked in response to a query, mediate search exposure or attention in a variety of safety-critical settings. Thus, it is important to ensure that such rankings are fair.  Under the goal of equal opportunity, attention allocated to an individual on a ranking interface should be proportional to their relevance across search queries. In this work, we examine amortized fair ranking -- where relevance and attention are cumulated over a sequence of user queries to make fair ranking more feasible. Unlike prior methods that operate on expected amortized attention for each individual, we define new divergence-based measures for attention distribution-aware fairness in ranking (DistFaiR), characterizing unfairness as the divergence between the distribution of attention and relevance corresponding to an individual over time. This allows us to propose new definitions of unfairness, which are more reliable at test time and outperform prior fair ranking baselines. Second, we prove that group fairness is upper-bounded by individual fairness under this definition for a useful sub-class of divergence measures, and experimentally show that maximizing individual fairness through an integer linear programming-based optimization is often beneficial to group fairness. Lastly, we find that prior research in amortized fair ranking ignores critical information about queries, potentially leading to a fairwashing risk in practice by making rankings appear more fair than they actually are.",
        "keywords": "fairness;distribution-based fair ranking;query polarity",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Aparna Balagopalan;Kai Wang;Olawale Elijah Salaudeen;Asia Biega;Marzyeh Ghassemi",
        "authorids": "~Aparna_Balagopalan1;~Kai_Wang5;~Olawale_Elijah_Salaudeen1;~Asia_Biega1;~Marzyeh_Ghassemi2",
        "gender": "F;M;;F;F",
        "homepage": "https://aparna-b.github.io/researcher/;https://guaguakai.github.io/;;https://asiabiega.github.io/;https://www.healthyml.org/",
        "dblp": ";78/2022-40;;130/0373.html;145/6563",
        "google_scholar": "https://scholar.google.ca/citations?user=8Mlyv3oAAAAJ;gGSsQmsAAAAJ;;Whr_kkwAAAAJ;",
        "orcid": ";0000-0002-2446-987X;;;",
        "linkedin": ";guaguakai/;;;",
        "or_profile": "~Aparna_Balagopalan1;~Kai_Wang5;~Olawale_Elijah_Salaudeen1;~Asia_Biega1;~Marzyeh_Ghassemi2",
        "aff": "Massachusetts Institute of Technology;Georgia Institute of Technology;;Max Planck Institute for Security and Privacy;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;gatech.edu;;mpi-sp.org;mit.edu",
        "position": "PhD student;Assistant Professor;;Tenure-Track Faculty;Assistant Professor",
        "bibtex": "@inproceedings{\nbalagopalan2025whats,\ntitle={What{\\textquoteright}s in a Query: Polarity-aware Distribution-based Fair Ranking},\nauthor={Aparna Balagopalan and Kai Wang and Olawale Elijah Salaudeen and Asia Biega and Marzyeh Ghassemi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HTATedSTj4}\n}",
        "github": "",
        "project": "",
        "reviewers": "74e5;jQBR;hZM3;HYmE;p3CP",
        "site": "https://openreview.net/forum?id=HTATedSTj4",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "4;5;6;6;6",
        "scope": "3;4;3;4;4",
        "confidence": "4;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2750095491084634
    },
    {
        "id": "Hb5bV0SPTJ",
        "title": "Graph Embeddings Meet Link Keys Discovery for Entity Matching",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Entity Matching (EM) automates the discovery of identity links between entities within different Knowledge Graphs (KGs). Link keys are crucial for EM, serving as rules allowing to identify identity links across different KGs, possibly described using different ontologies. However, the approach for extracting link keys struggles to scale on large KGs. While embedding-based EM methods efficiently handle large KGs they lack explainability. This paper proposes a novel hybrid EM approach to guarantee the scalability link key extraction approach and improve the explainability of embedding-based EM methods. First, embedding-based EM approaches are used to sample the KGs based on the identity links they generate, thereby reducing the search space to relevant sub-graphs for link key extraction. Second, rules (in the form of link keys) are extracted to explain the generation of identity links by the embedding-based methods. Experimental results demonstrate that the proposed approach allows link key extraction to scale on large KGs, preserving the quality of the extracted link keys. Additionally, it shows that link keys can improve the explainability of the identity links generated by embedding-methods, allowing for the regeneration of 77% of the identity links produced for a specific EM task, thereby providing an approximation of the reasons behind their generation.",
        "keywords": "Entity matching;Knowledge graphs;Link keys;Embedding-based EM;Symbolic EM;Graph embeddings;Language models;Hybrid AI",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chlo\u00e9 Khadija Jradeh;Ensiyeh Raoufi;Jerome David;Pierre LARMANDE;Francois Scharffe;Konstantin Todorov;Cassia Trojahn",
        "authorids": "~Chlo\u00e9_Khadija_Jradeh1;~Ensiyeh_Raoufi1;~Jerome_David1;~Pierre_LARMANDE1;~Francois_Scharffe1;~Konstantin_Todorov1;~Cassia_Trojahn1",
        "gender": "F;F;M;M;;M;",
        "homepage": ";;;https://sites.google.com/site/larmandepierre;http://www.knowledgegraph.tech;;",
        "dblp": ";;10/4191.html;23/1552.html;s/FrancoisScharffe.html;36/6753;61/1342",
        "google_scholar": ";https://scholar.google.com/citations?hl=en;dtfVjUoAAAAJ;https://scholar.google.fr/citations?user=BjYnqe8AAAAJ;T5VXoOUAAAAJ;https://scholar.google.fr/citations?user=eWFy2AwAAAAJ;https://scholar.google.ca/citations?user=x5oq1t8AAAAJ",
        "orcid": "0009-0009-8685-4288;;;0000-0002-2923-9790;;;0000-0003-2840-005X",
        "linkedin": "chlo\u00e9-jradeh-64b890105/;ensiyeh-raoufi/;;pierre-larmande-5110b91a;francoisscharffe;;",
        "or_profile": "~Chlo\u00e9_Khadija_Jradeh1;~Ensiyeh_Raoufi1;~Jerome_David1;~Pierre_LARMANDE1;~Francois_Scharffe1;~Konstantin_Todorov1;~Cassia_Trojahn1",
        "aff": "IRIT;University of Montpelier;University of Grenoble-Alpes;IRD;Universit\u00e9 de Montpellier;LIRMM, University of Montpellier, CNRS;Universit\u00e9 Grenoble Alpes",
        "aff_domain": "irit.fr;umontpellier.fr;univ-grenoble-alpes.fr;ird.fr;umontpellier.fr;lirmm.fr;univ-grenoble-alpes.fr",
        "position": "Postdoc;PhD student;Associate Professor;Researcher;Associate Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\njradeh2025graph,\ntitle={Graph Embeddings Meet Link Keys Discovery for Entity Matching},\nauthor={Chlo{\\'e} Khadija Jradeh and Ensiyeh Raoufi and Jerome David and Pierre LARMANDE and Francois Scharffe and Konstantin Todorov and Cassia Trojahn},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Hb5bV0SPTJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "DsYj;PykV;f8Kc;CeJW",
        "site": "https://openreview.net/forum?id=Hb5bV0SPTJ",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "2;4;6;6",
        "scope": "2;3;4;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            4.5,
            1.6583123951777
        ],
        "scope_avg": [
            3.0,
            0.7071067811865476
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "HeUB4NWB7U",
        "title": "Towards Multimodal Inductive Learning: Adaptively Embedding MMKG via Prototypes",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Multimodal Knowledge Graphs (MMKG) models integrate multimodal contexts to improve link prediction performance. All existing MMKG models follow the transductive setting with a fixed predefined set, meaning that all the entities, relations, and multimodal information in the test graph are observed during training. This hinders their generalization to real-world MMKG with unseen entities and relations. Intuitively, a MMKG model trained on DBpedia cannot infer on Freebase. To address above limitations, we make the first attempt towards inductive learning for MMKG and propose a multimodal \\underline{\\textbf{Ind}}uctive \\underline{\\textbf{MMKG}} model (\\textbf{IndMKG}) that is \\textit{\\textbf{universal}} and \\textit{\\textbf{transferable}} to any MMKG. Distinct from existing transductive methods, our model does not rely on specific trained embeddings; instead, IndMKG generates adaptive embeddings conditioned on any new MMKG via multimodal prototypes. Specifically, we construct class-adaptive prototypes to appropriately characterize the multimodal feature distribution of the given graph and equip IndMKG with robust adaptability to multimodal information across MMKGs. In addition, IndMKG learns non-specific structural embeddings based on meta relations. Such strategies tackle the challenge of notable multimodal feature discrepancies in cross-graph induction and allow the pre-trained IndMKG model to effectively zero-shot generalize to any MMKG. The strong performance in both inductive and transductive settings, across more than 20+ different scenarios, confirms the effectiveness and robustness of IndMKG. Our code is released at https://anonymous.4open.science/r/IndMKG.",
        "keywords": "Inductive Learning;Multimodal Knowledge Graph;Link Prediction;Knowledge Representation Learning and Embedding",
        "primary_area": "",
        "supplementary_material": "",
        "author": "ShunDong Yang;Jing Yang;XiaowenJiang;Yuan Gao;Laurence Tianruo Yang;Ruikun Luo;Jieming Yang",
        "authorids": "~ShunDong_Yang1;~Jing_Yang21;~XiaowenJiang1;~Yuan_Gao19;~Laurence_Tianruo_Yang1;~Ruikun_Luo1;~Jieming_Yang2",
        "gender": "M;F;M;M;M;;",
        "homepage": ";;https://i.csdn.net/#/user-center/profile?spm=1001.2014.3001.5516;;https://scholar.google.com/citations?hl=en&user=a39Yz5cAAAAJ;https://scholar.google.com.hk/citations?user=ULjIKnUAAAAJ&hl=zh-CN&oi=ao;",
        "dblp": ";;;;y/LaurenceTianruoYang;136/6135;",
        "google_scholar": ";https://scholar.google.com/citations?hl=fr;;xXHztrMAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.com.hk/citations?user=ULjIKnUAAAAJ;",
        "orcid": "0000-0001-9584-2160;;0009-0006-9773-1265;;0000-0002-7986-4244;;",
        "linkedin": ";;;;;;",
        "or_profile": "~ShunDong_Yang1;~Jing_Yang21;~XiaowenJiang1;~Yuan_Gao19;~Laurence_Tianruo_Yang1;~Ruikun_Luo1;~Jieming_Yang2",
        "aff": "hainan ;Zhengzhou University;cpss;Zhengzhou University;Huazhong University of Science and Technology;Huazhong University of Science and Technology;",
        "aff_domain": "hainanu.edu.cn;zzu.edu.cn;hainanu.edu.cn;hainu.edu.cn;hust.edu.cn;hust.edu.cn;",
        "position": "MS student;Associate Professor;MS student;Associate Professor;Full Professor;Postdoc;",
        "bibtex": "@inproceedings{\nyang2025towards,\ntitle={Towards Multimodal Inductive Learning: Adaptively Embedding {MMKG} via Prototypes},\nauthor={ShunDong Yang and Jing Yang and XiaowenJiang and Yuan Gao and Laurence Tianruo Yang and Ruikun Luo and Jieming Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HeUB4NWB7U}\n}",
        "github": "",
        "project": "",
        "reviewers": "B3cg;VNek;imjw;arJs;xqmW",
        "site": "https://openreview.net/forum?id=HeUB4NWB7U",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "5;5;5;6;5",
        "scope": "3;3;3;4;4",
        "confidence": "3;2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6454972243679028
    },
    {
        "id": "Hkh2umURYm",
        "title": "Interactive Visualization Recommendation with Hier-SUCB",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Visualization recommendation aims to enable rapid visual analysis of massive datasets. \nIn real-world scenarios, it is essential to quickly gather and comprehend user preferences to cover users from diverse backgrounds, including varying skill levels and analytical tasks. \nPrevious approaches to personalized visualization recommendations are non-interactive and rely on initial user data for new users. As a result, these models cannot effectively explore options or adapt to real-time feedback.\nTo address this limitation, we propose an interactive personalized visualization recommendation ($\\textbf{PVisRec}$) system that learns on user feedback from previous interactions. \nFor more interactive and accurate recommendations, we propose $\\textbf{Hier-SUCB}$, a contextual combinatorial semi-bandit in the PVisRec setting. \nTheoretically, we show an improved overall regret bound with the same rank of time but an improved rank of action space. \nWe further demonstrate the effectiveness of $\\textbf{Hier-SUCB}$ through extensive experiments where it is comparable to offline methods and outperforms other bandit algorithms in the setting of visualization recommendation.",
        "keywords": "visualization recommendation;recommendation system",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Songwen Hu;Ryan A. Rossi;Tong Yu;Junda Wu;Handong Zhao;Sungchul Kim;Shuai Li",
        "authorids": "~Songwen_Hu1;~Ryan_A._Rossi2;~Tong_Yu3;~Junda_Wu1;~Handong_Zhao3;~Sungchul_Kim1;~Shuai_Li3",
        "gender": ";;;M;;M;F",
        "homepage": "https://delen0828.github.io/;;https://www.linkedin.com/in/tong-yu-42790744;https://scholar.google.com/citations?user=_iKeQFwAAAAJ&hl=en;;https://sites.google.com/site/subright;http://shuaili8.github.io",
        "dblp": ";;32/1593-1;295/8249;;61/1573;57/2281-10",
        "google_scholar": ";;https://scholar.google.com/citations?hl=en;_iKeQFwAAAAJ;;v8ISLgIAAAAJ;https://scholar.google.com.hk/citations?user=kMZgQxcAAAAJ",
        "orcid": ";;0000-0002-5991-2050;;;0000-0003-3580-5290;",
        "linkedin": ";;tong-yu-42790744;;;;",
        "or_profile": "~Songwen_Hu1;~Ryan_A._Rossi2;~Tong_Yu3;~Junda_Wu1;~Handong_Zhao3;~Sungchul_Kim1;~Shuai_Li3",
        "aff": "Georgia Institute of Technology;;Adobe Research;University of California, San Diego;;Adobe Systems;John Hopcroft Center, Shanghai Jiao Tong University",
        "aff_domain": "gatech.edu;;adobe.com;ucsd.edu;;adobe.com;sjtu.edu.cn",
        "position": "PhD student;;Senior Research Scientist;PhD student;;Researcher;Assistant Professor",
        "bibtex": "@inproceedings{\nhu2025interactive,\ntitle={Interactive Visualization Recommendation with Hier-{SUCB}},\nauthor={Songwen Hu and Ryan A. Rossi and Tong Yu and Junda Wu and Handong Zhao and Sungchul Kim and Shuai Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Hkh2umURYm}\n}",
        "github": "",
        "project": "",
        "reviewers": "WpCU;3dgN;hoFD;7isq",
        "site": "https://openreview.net/forum?id=Hkh2umURYm",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "5;4;6;5",
        "scope": "4;3;4;4",
        "confidence": "3;1;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.0909090909090909
    },
    {
        "id": "HmunwMJfC3",
        "title": "Highly-efficient minimization of network connectivity in large-scale graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Network connectivity minimization is a fundamental problem in controlling the spread of epidemics and facilitating information propagation in social networks. The problem aims to identify a budget number of key nodes whose removal would minimize the connectivity of a network. However, the existing solutions heavily rely on the number of edges, making it challenging to handle large and densely connected social networks. In this study, we present a fast algorithm that is independent of the number of edges. To achieve this, we first introduce a surrogate matrix that approximates the residual adjacency matrix with arbitrary small predefined error. We then devise an efficient approach for calculating the key nodes by optimizing the eigenvalues of the surrogate matrix. Remarkably, the algorithm has a small time complexity , with a small tunable number. Our algorithm thereby maintains a linear scalability in terms of the number of nodes and is unaffected by the number of edges. Hence, it has the capability to efficiently handle large and dense social networks. At last, we evaluate its performance against state-of-the-art techniques using diverse real-world datasets. The experimental results demonstrate the superiority of our proposed method in terms of both solution quality and computational efficiency.",
        "keywords": "influential node;graph immunication;information diffusion",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Mingyang Zhou;Gang Liu;KeZhong Lu;Hao Liao;Rui Mao",
        "authorids": "~Mingyang_Zhou2;~Gang_Liu9;~KeZhong_Lu1;~Hao_Liao1;~Rui_Mao2",
        "gender": "M;M;;M;M",
        "homepage": ";https://csse.szu.edu.cn/pages/user/index?id=518;;https://csse.szu.edu.cn/pages/user/index?id=542;https://www.sics.ac.cn/mao/szu/eng/",
        "dblp": "195/5899-1;37/2109-28;81/2987.html;74/1078;51/5793",
        "google_scholar": ";;;Tu5ZuREAAAAJ;",
        "orcid": ";;;;",
        "linkedin": ";;;hao-liao-30635127;",
        "or_profile": "~Mingyang_Zhou2;~Gang_Liu9;~KeZhong_Lu1;~Hao_Liao1;~Rui_Mao2",
        "aff": "Shenzhen University;Shenzhen University;Shenzhen University;Shenzhen University;Shenzhen Institute of Computing Sciences+Shenzhen University",
        "aff_domain": "szu.edu.cn;szu.edu.cn;szu.edu.cn;szu.edu.cn;sics.ac.cn+szu.edu.cn",
        "position": "Associate Professor;Lecturer;Full Professor;Associate Professor;Researcher+Full Professor",
        "bibtex": "@inproceedings{\nzhou2025highlyefficient,\ntitle={Highly-efficient minimization of network connectivity in large-scale graphs},\nauthor={Mingyang Zhou and Gang Liu and KeZhong Lu and Hao Liao and Rui Mao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HmunwMJfC3}\n}",
        "github": "",
        "project": "",
        "reviewers": "kVhL;whcc;6jTE;U7Kg",
        "site": "https://openreview.net/forum?id=HmunwMJfC3",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "4;3;5;6",
        "scope": "2;3;4;4",
        "confidence": "2;4;1;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            2.25,
            1.0897247358851685
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.48420012470625223
    },
    {
        "id": "HoIvUVPMwH",
        "title": "Diffusion-based Graph-agnostic Clustering",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Clustering over a graph seeks to partition the nodes therein into disjoint groups such that nodes within the same cluster are tightly-knit, while those across clusters are distant from each other. In practice, graphs are often attended with rich attributes, which are termed attributed graphs. By leveraging the complementary nature of graph topology and node attributes in such graphs, graph neural networks (GNNs) have obtained encouraging performance in graph clustering. However, existing GNN-based approaches strongly rely on the homophilic assumption of the input graph, and thus, largely fail on heterophilic graphs and others embodying numerous missing or noisy links, which are widely present in real life.\n\nTo bridge this gap, this paper presents DGAC, an effective graph-agnostic solution for graph clustering. Particularly, DGAC overcomes the limitations of prior works by exploiting the high-order connectivity of nodes within not only the input graph G but also the affinity graph H underlying the attribute data. To achieve this goal, we first unify the embedding and clustering generations into a coherent framework that optimizes Dirichlet Energy on both G and H. Based thereon, theoretical-grounded solvers are developed for efficient constructions of the embeddings and clusters, which capture high-order semantics from G or H via graph diffusion. On top of that, DGAC includes three optimization loss functions that facilitate effective feature extraction and clustering. Extensive experiments, comparing DGAC against 12 baselines over 12 homophilic or heterophilic graph datasets, showcase that DGAC consistently and considerably outperforms all competitors in terms of clustering quality measured against ground truth labels.",
        "keywords": "Graph Clustering;Graph Diffusion;Graph Neural Network;Heterophily Graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kun XIE;Renchi Yang;Sibo Wang",
        "authorids": "~Kun_XIE2;~Renchi_Yang1;~Sibo_Wang3",
        "gender": "F;;M",
        "homepage": "https://kkkkk001.github.io/;;https://www1.se.cuhk.edu.hk/~swang/",
        "dblp": "98/476-10.html;;131/6529-1",
        "google_scholar": ";;b2gLqsgAAAAJ",
        "orcid": "0009-0000-8921-5531;;0000-0003-1892-6971",
        "linkedin": "kun-xie-0714kkkk;;sibo-wang-b6a60941/?originalSubdomain=hk",
        "or_profile": "~Kun_XIE2;~Renchi_Yang1;~Sibo_Wang3",
        "aff": "The Chinese University of Hong Kong;;The Chinese University of Hong Kong",
        "aff_domain": "se.cuhk.edu.hk;;cuhk.edu.hk",
        "position": "PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\nxie2025diffusionbased,\ntitle={Diffusion-based Graph-agnostic Clustering},\nauthor={Kun XIE and Renchi Yang and Sibo Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=HoIvUVPMwH}\n}",
        "github": "",
        "project": "",
        "reviewers": "QbnD;oYQC;Ziw6;upwL;VmbL",
        "site": "https://openreview.net/forum?id=HoIvUVPMwH",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;5;5;4;5",
        "scope": "4;4;4;4;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "I6kBXiaJdt",
        "title": "MAP the Blockchain World: A Trustless and Scalable Blockchain Interoperability Protocol for Cross-chain Applications",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Blockchain interoperability protocols enable cross-chain asset transfers or data retrievals between isolated chains, which are considered as the core infrastructure for Web 3.0 applications such as decentralized finance protocols. However, existing protocols either face severe scalability issues due to high on-chain and off-chain costs, or suffer from trust concerns because of centralized designs.\n\nIn this paper, we propose \\texttt{MAP}, a trustless blockchain interoperability protocol that relays cross-chain transactions across heterogeneous chains with high scalability. First, within \\texttt{MAP}, we develop a novel cross-chain relay technique, which integrates a unified relay chain architecture and on-chain light clients of different source chains, allowing the retrieval and verification of diverse cross-chain transactions. Furthermore, we reduce cross-chain verification costs by incorporating an optimized zk-based light client scheme that adaptively decouples signature verification overheads from inefficient smart contract execution and offloads them to off-chain provers. For experiments, we conducted the first large-scale evaluation on existing interoperability protocols. With \\texttt{MAP}, the required number of on-chain light clients is reduced from $O(N^2)$ to $O(N)$, with around 35\\% reduction in on-chain costs and 25\\% reduction for off-chain costs when verifying cross-chain transactions.\n  \nTo demonstrate the effectiveness, we deployed \\texttt{MAP} in the real world. By 2024, we have supported over six popular public chains, 50 cross-chain applications and relayed over 200K cross-chain transactions worth over 640 million USD. Based on rich practical experiences, we constructed the first real-world cross-chain dataset to further advance blockchain interoperability research.",
        "keywords": "Web3;Blockchain;Interoperability",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yinfeng CAO;Jiannong Cao;Dongbin Bai;Long Wen;Yang LIU;Ruidong Li",
        "authorids": "~Yinfeng_CAO1;~Jiannong_Cao1;~Dongbin_Bai1;~Long_Wen5;~Yang_LIU158;~Ruidong_Li1",
        "gender": "M;M;M;M;M;M",
        "homepage": "https://cyfaaa.github.io;https://www4.comp.polyu.edu.hk/~csjcao/;https://www4.comp.polyu.edu.hk/~labimcl/profile/dongbin-bai.html;https://www.linkedin.com/in/long-wen-365413105/;;https://sites.google.com/site/liruidong/",
        "dblp": "331/3083;c/JiannongCao;296/1559;08/2939-2.html;;06/7035.html",
        "google_scholar": "xos6JXEAAAAJ;q2jH-3sAAAAJ;r4gfJPMAAAAJ;NfK1MjoAAAAJ;;https://scholar.google.co.jp/citations?user=omtK0FIAAAAJ",
        "orcid": "0000-0003-1048-3299;0000-0002-2725-2529;0009-0006-7125-1992;0009-0009-3515-1814;;",
        "linkedin": ";;;long-wen-365413105/;philllau/;",
        "or_profile": "~Yinfeng_CAO1;~Jiannong_Cao1;~Dongbin_Bai1;~Long_Wen5;~Yang_LIU158;~Ruidong_Li1",
        "aff": "Kanazawa University+Hong Kong Polytechnic University;Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Derivation Technology Limited;;",
        "aff_domain": "kanazawa-u.ac.jp+polyu.edu.hk;polyu.edu.hk;comp.polyu.edu.hk;derivation.info;;",
        "position": "PhD student+PhD student;Full Professor;PhD student;Director;;",
        "bibtex": "@inproceedings{\ncao2025map,\ntitle={{MAP} the Blockchain World: A Trustless and Scalable Blockchain Interoperability Protocol for Cross-chain Applications},\nauthor={Yinfeng CAO and Jiannong Cao and Dongbin Bai and Long Wen and Yang LIU and Ruidong Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=I6kBXiaJdt}\n}",
        "github": "",
        "project": "",
        "reviewers": "TZrP;yuXL;QZbv;43kW;XJ3x",
        "site": "https://openreview.net/forum?id=I6kBXiaJdt",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "3;6;5;6;7",
        "scope": "2;3;4;3;4",
        "confidence": "2;1;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.4,
            1.3564659966250536
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            1.8,
            0.4000000000000001
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3429971702850177
    },
    {
        "id": "ICJysB6LdA",
        "title": "Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large Language Models (LLMs) have achieved impressive results in various tasks but struggle with hallucination problems and lack of relevant knowledge, especially in deep complex reasoning and knowledge-intensive tasks. Knowledge Graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. However, existing KG-based LLM reasoning methods face challenges like handling multi-hop reasoning, multi-entity questions, and effectively utilizing graph structures. To address these issues, we propose Paths-over-Graph (PoG), a novel method that enhances LLM reasoning by integrating knowledge reasoning paths from KGs, improving the interpretability and faithfulness of LLM outputs. PoG tackles multi-hop and multi-entity questions through a three-phase dynamic multi-hop path exploration, which combines the inherent knowledge of LLMs with factual knowledge from KGs. In order to improve the efficiency, PoG prunes irrelevant information from the graph exploration first and introduces efficient three-step pruning techniques that incorporate graph structures, LLM prompting, and a pre-trained language model (e.g., SBERT) to effectively narrow down the explored candidate paths.  This ensures all reasoning paths contain highly relevant information captured from KGs, making the reasoning faithful and interpretable in problem-solving. PoG innovatively utilizes graph structure to prune the irrelevant noise and represents the first method to implement multi-entity deep path detection on KGs for LLM reasoning tasks.\nComprehensive experiments on five benchmark KGQA datasets demonstrate PoG outperforms the state-of-the-art method ToG across GPT-3.5-Turbo and GPT-4, achieving an average accuracy improvement of 18.9\\%. Notably, PoG with GPT-3.5-Turbo surpasses ToG with GPT-4 by up to 23.9\\%.",
        "keywords": "Large Language Models; Knowledge Graph;  Knowledge Graph Question Answerning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xingyu Tan;Xiaoyang Wang;Qing Liu;Xiwei Xu;Xin Yuan;Wenjie Zhang",
        "authorids": "~Xingyu_Tan1;~Xiaoyang_Wang8;~Qing_Liu5;~Xiwei_Xu2;~Xin_Yuan8;~Wenjie_Zhang3",
        "gender": "M;M;;F;F;F",
        "homepage": "https://stevetantan.github.io/;https://research.unsw.edu.au/people/dr-xiaoyang-wang;;;;http://www.cse.unsw.edu.au/~zhangw/",
        "dblp": ";81/1832-2;;47/3196-1;78/713-4;98/5684-1",
        "google_scholar": "https://scholar.google.com.au/citations?user=2gzpDtsAAAAJ;https://scholar.google.com.au/citations?user=TwbvM1oAAAAJ;;https://scholar.google.com.au/citations?user=x9IUq78AAAAJ;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.au/citations?user=yHTJo1kAAAAJ",
        "orcid": "0009-0000-7232-7051;0000-0003-3554-3219;;0000-0002-2273-1862;;0000-0001-6572-2600",
        "linkedin": "xingyu-tan-b90179173/;;;xiwei-sherry-xu-25a6ba21/;;",
        "or_profile": "~Xingyu_Tan1;~Xiaoyang_Wang8;~Qing_Liu5;~Xiwei_Xu2;~Xin_Yuan8;~Wenjie_Zhang3",
        "aff": "University of New South Wales;University of New South Wales;;CSIRO;CSIRO;the university of new south wales",
        "aff_domain": "unsw.edu.au;unsw.edu.au;;data61.csiro.au;data61.csiro.au;cse.unsw.edu.au",
        "position": "PhD student;Lecturer;;Principal Researcher;Researcher;Full Professor",
        "bibtex": "@inproceedings{\ntan2025pathsovergraph,\ntitle={Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning},\nauthor={Xingyu Tan and Xiaoyang Wang and Qing Liu and Xiwei Xu and Xin Yuan and Wenjie Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ICJysB6LdA}\n}",
        "github": "",
        "project": "",
        "reviewers": "jL6Y;LUS8;4RBc;qenB;Hzo5",
        "site": "https://openreview.net/forum?id=ICJysB6LdA",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;4;4;5;6",
        "scope": "3;3;3;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "IMhoJgWANP",
        "title": "Digital Disparities: A Comparative Web Measurement Study Across Economic Boundaries",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "While internet usage is slowly catching up globally, it is still unclear how the web experience differs in developing and developed countries. On the one hand, the web has a notoriously large inertia, with many websites still relying on unencrypted HTTP, deprecated web features, or old and buggy libraries. On the other hand, developing countries are expected to leapfrog and directly adopt the newest technologies by learning from the prior mistakes of more developed countries. Anecdotal evidence suggests that websites in developing and developed regions differ significantly. In this work, we test this hypothesis by measuring differences in web development practices across the two groups of countries, using multiple dimensions: websites' size, complexity, security, privacy, quality, technology adoption, and accessibility. Concretely, we collect the largest dataset to date that compares web development practices across developed and developing regions -- 200,000 websites across 20 countries -- which we aim to open source along with this publication. Our findings reveal that websites in developing regions are generally smaller and simpler, utilizing fewer requests \u2014 an adaptation that improves the performance over slower network conditions common in these areas. However, these sites are less optimized in other critical aspects: they frequently employ inefficient image formats, include unnecessary JavaScript code, lack responsive image designs, and offer limited accessibility features for individuals with disabilities. Notably, our security assessment shows developing regions lagging in HTTPS adoption and vulnerability mitigation, possibly due to lower awareness of best practices.",
        "keywords": "Web development practices;Digital inclusivity;Security and Privacy",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Masudul Hasan Masud Bhuiyan;Matteo Varvello;Cristian-Alexandru Staicu;Yasir Zaki",
        "authorids": "~Masudul_Hasan_Masud_Bhuiyan1;~Matteo_Varvello1;~Cristian-Alexandru_Staicu2;~Yasir_Zaki1",
        "gender": "M;M;M;M",
        "homepage": "https://kal-purush.github.io/;;http://www.staicu.org/;http://yasirzaki.net/",
        "dblp": "334/0713.html;01/6280;;16/3354",
        "google_scholar": "RdZoAlcAAAAJ;xZvdwq0AAAAJ;JmpDeRQAAAAJ;oqyq_gQAAAAJ",
        "orcid": ";;0000-0002-6542-2226;0000-0001-8078-6944",
        "linkedin": ";;crstaicu/;",
        "or_profile": "~Masudul_Hasan_Masud_Bhuiyan1;~Matteo_Varvello1;~Cristian-Alexandru_Staicu2;~Yasir_Zaki1",
        "aff": "CISPA, saarland university, saarland informatics campus;Bell Labs ;;New York University Abu Dhabi",
        "aff_domain": "cispa.saarland;nokia.com;;nyu.edu",
        "position": "PhD student;Principal Researcher;;Assistant Professor",
        "bibtex": "@inproceedings{\nbhuiyan2025digital,\ntitle={Digital Disparities: A Comparative Web Measurement Study Across Economic Boundaries},\nauthor={Masudul Hasan Masud Bhuiyan and Matteo Varvello and Cristian-Alexandru Staicu and Yasir Zaki},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=IMhoJgWANP}\n}",
        "github": "",
        "project": "",
        "reviewers": "bvUM;odYN;zwb6",
        "site": "https://openreview.net/forum?id=IMhoJgWANP",
        "pdf_size": 0,
        "novelty": "5;5;6",
        "technical_quality": "5;6;6",
        "scope": "3;4;4",
        "confidence": "2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.666666666666667,
            0.4714045207910317
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5000000000000001
    },
    {
        "id": "INMoRWNI63",
        "title": "Preserving Label Correlation for Multi-label Text Classification by Prototypical Regularizations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multi-label text classification (MLTC) aims to assign multiple relevant labels to a given sentence. An inherent challenge of MLTC is capturing label correlations compared with multi-class text classification. Existing MLTC models primarily focus on leveraging correlation information but often overlook the common issue of overfitting. Meanwhile, plug-and-play regularization methods struggle to preserve correlations effectively. In this paper, we distinguish two types of label correlations: explicit co-occurring correlation and implicit semantic correlations, and propose two regularization methods based on prototypical label embeddings for two correlation preservation, respectively. Specifically, we first generate the prototypical label embedding of multiple co-occurred labels as an intermediate. We then apply a prototypical label regularization on the distance between the sentence embedding and corresponding prototypical label embedding to alleviate the over-alignment issue caused by binary cross entropy loss and facilitate explicit correlation preservation. We finally extend the vanilla Mixup, which solely mixes multi-hot labels, on prototypical label embedding mixing to promote implicit correlation preservation. Empirical studies show the effectiveness of our regularization methods.",
        "keywords": "Multi-label Text Classification;Prototypical Label;Mixup",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Fanshuang Kong;Richong Zhang;Xiaohui Guo;Junfan Chen;Ziqiao Wang",
        "authorids": "~Fanshuang_Kong1;~Richong_Zhang1;~Xiaohui_Guo2;~Junfan_Chen1;~Ziqiao_Wang1",
        "gender": ";M;M;M;M",
        "homepage": ";http://act.buaa.edu.cn/zhangrc;https://dblp.uni-trier.de/pid/97/738.html;;https://ziqiaowanggeothe.github.io",
        "dblp": ";61/1229;;248/8207-1;222/9220",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-CN;;5C-1TP4AAAAJ;iBL7APIAAAAJ",
        "orcid": ";0000-0002-1207-0300;0000-0002-8851-4211;0000-0001-6807-0089;0000-0003-0504-4830",
        "linkedin": ";;;;ziqiao-wang-987565155/?locale=en_US",
        "or_profile": "~Fanshuang_Kong1;~Richong_Zhang1;~Xiaohui_Guo2;~Junfan_Chen1;~Ziqiao_Wang1",
        "aff": ";Beihang University;China Software Testing Center;Beihang University;Tongji University",
        "aff_domain": ";buaa.edu.cn;cstc.org.cn;buaa.edu.cn;tongji.edu.cn",
        "position": ";Full Professor;Researcher;Associate Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nkong2025preserving,\ntitle={Preserving Label Correlation for Multi-label Text Classification by Prototypical Regularizations},\nauthor={Fanshuang Kong and Richong Zhang and Xiaohui Guo and Junfan Chen and Ziqiao Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=INMoRWNI63}\n}",
        "github": "",
        "project": "",
        "reviewers": "624p;2wPJ;Q4Mq;nmfP;zaXM",
        "site": "https://openreview.net/forum?id=INMoRWNI63",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;4;4;6;6",
        "scope": "3;3;4;3;4",
        "confidence": "3;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.42257712736425823
    },
    {
        "id": "IWt0khtqwi",
        "title": "Behavior Modeling Space Reconstruction for E-Commerce Search",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Delivering superior search services is crucial for enhancing cus- tomer experience and driving revenue growth in e-commerce. Con- ventionally, search systems model user behaviors by combining user preference and query-item relevance statically, often through a fixed logical \u2018and\u2019 relationship. This paper reexamines existing approaches through a unified lens using both causal graphs and Venn diagrams, uncovering two prevalent yet significant issues: entangled preference and relevance effects, and a collapsed model- ing space. To surmount these challenges, our research introduces a novel framework, DRP, which enhances search accuracy through two components to reconstruct the behavior modeling space. Specif- ically, we implement preference editing to proactively remove the relevance effect from preference predictions, yielding untainted user preferences. Additionally, we employ adaptive fusion, which dynamically adjusts fusion criteria to align with the varying pat- terns of relevance and preference, facilitating more nuanced and tailored behavior predictions within the reconstructed modeling space. Empirical validation on two public datasets and a propri- etary e-commerce search dataset underscores the superiority of our proposed methodology, demonstrating marked improvements in performance over existing approaches.",
        "keywords": "Relevance Modeling; E-Commerce Search",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yejing Wang;Chi Zhang;Xiangyu Zhao;Qidong Liu;Maolin Wang;Xuetao Wei;Zitao Liu;Xing Shi;Yang Xudong;ling zhong;Wei Lin",
        "authorids": "~Yejing_Wang1;~Chi_Zhang34;~Xiangyu_Zhao1;~Qidong_Liu2;~Maolin_Wang1;~Xuetao_Wei2;~Zitao_Liu1;~Xing_Shi2;~Yang_Xudong1;~ling_zhong2;~Wei_Lin5",
        "gender": "M;M;M;M;;M;M;M;M;M;M",
        "homepage": ";https://github.com/zc-97;https://zhaoxyai.github.io/;https://liuqidong07.github.io/;;https://cse.sustech.edu.cn/faculty/~weixt/;http://www.zitaoliu.com/;https://www.linkedin.cn/incareer/in/ACoAAAYCccoBA1UvKKQto4LKLb-BDvD9FS1Vhpo;http://yangxudong.github.io;;",
        "dblp": ";91/195-60;08/890-1.html;254/1779-2;;09/5916;210/0898;;;;",
        "google_scholar": ";sot3DLIAAAAJ;;pX_HTHIAAAAJ;;8fNwEScAAAAJ;rRTzNm0AAAAJ;;;;LXSkrXkAAAAJ",
        "orcid": ";0000-0002-3524-6874;0000-0003-2926-4416;0000-0002-0751-2602;;0000-0002-4450-2251;0000-0003-0491-307X;0009-0001-5946-3187;;;",
        "linkedin": ";;;;;;;;;zhongling/;",
        "or_profile": "~Yejing_Wang1;~Chi_Zhang34;~Xiangyu_Zhao1;~Qidong_Liu2;~Maolin_Wang1;~Xuetao_Wei2;~Zitao_Liu1;~Xing_Shi2;~Yang_Xudong1;~ling_zhong2;~Wei_Lin5",
        "aff": "City University of Hong Kong;Harbin Engineering University;City University of Hong Kong;Xi'an Jiaotong University+City University of Hong Kong+Xi'an Jiaotong University;;Southern University of Science and Technology;Jinan University;Alibaba Group;;;",
        "aff_domain": "cityu.edu.hk;hrbeu.edu.cn;cityu.edu.hk;xjtu.edu.cn+cityu.edu.hk+xjtu.edu.cn;;sustech.edu.cn;jnu.edu.cn;alibaba-inc.com;;;",
        "position": "PhD student;PhD student;Assistant Professor;Assistant Professor+PhD student+PhD student;;Associate Professor;Full Professor;Researcher;;;",
        "bibtex": "@inproceedings{\nwang2025behavior,\ntitle={Behavior Modeling Space Reconstruction for E-Commerce Search},\nauthor={Yejing Wang and Chi Zhang and Xiangyu Zhao and Qidong Liu and Maolin Wang and Xuetao Wei and Zitao Liu and Xing Shi and Yang Xudong and ling zhong and Wei Lin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=IWt0khtqwi}\n}",
        "github": "",
        "project": "",
        "reviewers": "yEft;4duU;V3E9;sLSN;BhQK",
        "site": "https://openreview.net/forum?id=IWt0khtqwi",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;4;5;5;5",
        "scope": "3;4;4;4;4",
        "confidence": "2;3;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            11,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.25
    },
    {
        "id": "IfXATERmoO",
        "title": "Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The remarkable ability of diffusion models to generate high-fidelity images has led to their widespread adoption. However, concerns have also arisen regarding their potential to produce Not Safe for Work (NSFW) content and exhibit social biases, impeding their practical use and progress in real-world applications. In response to this challenge, prior work has primarily focused on employing security filters to identify and subsequently exclude toxic text, or alternatively, fine-tuning pre-trained diffusion models to erase sensitive concepts. Unfortunately, existing methods struggle to achieve satisfactory performance in the sense that they can have a significant impact on the normal model output while still failing to prevent the generation of harmful content in some cases. In this paper, we propose a novel self-discovery approach to identifying a semantic direction vector in the embedding space to restrict text embedding within a safe region. Our method circumvents the need for correcting individual words within the input text and steers the entire text prompt towards a safe region in the embedding space, thereby enhancing model robustness against all possibly unsafe prompts. In addition, we employ a Low-Rank Adaptation (LoRA) for semantic direction vector initialization to reduce the impact on the model performance for other semantics. Furthermore, our method can also be integrated with existing methods to improve their socially responsible performance. Extensive experiments on benchmark datasets demonstrate that our method can effectively reduce NSFW content and mitigate social bias generated by diffusion models compared to several state-of-the-art baselines.",
        "keywords": "Diffusion Model;Responsible Generation;Algorithmic Fairness",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhiwen Li;Die Chen;Mingyuan Fan;Cen Chen;Yaliang Li;Yanhao Wang;Wenmeng Zhou",
        "authorids": "~Zhiwen_Li1;~Die_Chen1;~Mingyuan_Fan1;~Cen_Chen1;~Yaliang_Li1;~Yanhao_Wang1;~Wenmeng_Zhou1",
        "gender": "M;F;;F;M;M;",
        "homepage": "https://orcid.org/0009-0005-3910-1698;https://orcid.org/0000-0001-5744-679X;;https://sites.google.com/site/chencenpersonalwebsite/;https://sites.google.com/site/yaliangli/;https://sites.google.com/view/yhwang;",
        "dblp": "136/2545;210/0609;;152/6215-1.html;127/6999.html;123/2365-1;",
        "google_scholar": ";;;https://scholar.google.com.sg/citations?user=3Mn4S9UAAAAJ;CCPBcdYAAAAJ;ULluK_8AAAAJ;",
        "orcid": "0009-0005-3910-1698;0000-0001-5744-679X;;0000-0003-0325-1705;0000-0002-4204-6096;0000-0002-7661-3917;",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhiwen_Li1;~Die_Chen1;~Mingyuan_Fan1;~Cen_Chen1;~Yaliang_Li1;~Yanhao_Wang1;~Wenmeng_Zhou1",
        "aff": "East China Normal University;East China Normal University;;East China Normal University;Alibaba Group;East China Normal University;",
        "aff_domain": "ecnu.edu.cn;dase.ecnu.edu.cn;;dase.ecnu.edu.cn;alibaba-inc.com;ecnu.edu.cn;",
        "position": "MS student;MS student;;Associate Professor;Senior Staff Engineer;Associate Professor;",
        "bibtex": "@inproceedings{\nli2025responsible,\ntitle={Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions},\nauthor={Zhiwen Li and Die Chen and Mingyuan Fan and Cen Chen and Yaliang Li and Yanhao Wang and Wenmeng Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=IfXATERmoO}\n}",
        "github": "",
        "project": "",
        "reviewers": "kQiQ;peMT;rYNY;9Hkg",
        "site": "https://openreview.net/forum?id=IfXATERmoO",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;4;5;6",
        "scope": "3;4;4;3",
        "confidence": "3;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.816496580927726
    },
    {
        "id": "IsiRl5StDm",
        "title": "MAML: Towards a Faster Web in Developing Regions",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The web experience in developing regions remains subpar, primarily due to the growing complexity of modern webpages and insufficient optimization by content providers. Users in these regions typically rely on low-end devices and limited bandwidth, which results in a poor user experience as they download and parse webpages bloated with excessive third-party CSS and JavaScript (JS). To address these challenges, we introduce the Mobile Application Markup Language (MAML), a flat layout-based web specification language that reduces computational and data transmission demands, while replacing the excessive bloat from JS with a new scripting language centered on essential (and popular) web functionalities. Last but not least, MAML is backward compatible as it can be transpiled to minimal HTML/JavaScript/CSS and thus work with legacy browsers. We benchmark MAML in terms of page load times and sizes, using a translator which can automatically port any webpage to MAML. When compared to the popular Google AMP, across 100 testing webpages, MAML offers webpage speedups by tens of seconds under challenging network conditions thanks to its significant size reductions. Next, we run a competition involving 25 university students porting 50 of the above webpages to MAML using a web-based editor we developed. This experiment shows that, with little developer effort, MAML is quite effective in maintaining the visual and functional correctness of the originating webpages.",
        "keywords": "Developing regions;MAML;Web experience;Web simplification",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ayush Pandey;Matteo Varvello;Syed Ishtiaque Ahmed;Shurui Zhou;Lakshmi Subramanian;Yasir Zaki",
        "authorids": "~Ayush_Pandey4;~Matteo_Varvello1;~Syed_Ishtiaque_Ahmed1;~Shurui_Zhou1;~Lakshmi_Subramanian1;~Yasir_Zaki1",
        "gender": "M;M;M;F;M;M",
        "homepage": ";;https://www.ishtiaque.net/;https://www.eecg.utoronto.ca/~shuruiz/;https://cs.nyu.edu/~lakshmi/Lakshmi/Home.html;http://yasirzaki.net/",
        "dblp": ";01/6280;75/7215.html;;;16/3354",
        "google_scholar": "cmRf2iEAAAAJ;xZvdwq0AAAAJ;A42gaP4AAAAJ;6ej1Rm4AAAAJ;https://scholar.google.com.tw/citations?user=sNeVyqoAAAAJ;oqyq_gQAAAAJ",
        "orcid": "0009-0009-0107-0266;;0000-0003-2452-0687;0000-0002-6346-6073;;0000-0001-8078-6944",
        "linkedin": ";;ishtiaqueahmed/;;;",
        "or_profile": "~Ayush_Pandey4;~Matteo_Varvello1;~Syed_Ishtiaque_Ahmed1;~Shurui_Zhou1;~Lakshmi_Subramanian1;~Yasir_Zaki1",
        "aff": "New York University Abu Dhabi;Bell Labs ;University of Toronto;University of Toronto;New York University;New York University Abu Dhabi",
        "aff_domain": "nyu.edu;nokia.com;utoronto.ca;utoronto.ca;nyu.edu;nyu.edu",
        "position": "Researcher;Principal Researcher;Associate Professor;Assistant Professor;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\npandey2025maml,\ntitle={{MAML}: Towards a Faster Web in Developing Regions},\nauthor={Ayush Pandey and Matteo Varvello and Syed Ishtiaque Ahmed and Shurui Zhou and Lakshmi Subramanian and Yasir Zaki},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=IsiRl5StDm}\n}",
        "github": "",
        "project": "",
        "reviewers": "XXYd;xr1S;RZu8;1njZ",
        "site": "https://openreview.net/forum?id=IsiRl5StDm",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "2;6;3;6",
        "scope": "4;4;4;4",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            4.25,
            1.7853571071357126
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "IwMfHn68Hg",
        "title": "Semi-Supervised Anomaly Detection through Denoising-Aware Contrastive Distance Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Semi-supervised anomaly detection (AD) has garnered growing attention due to its ability to effectively combine limited labeled data with abundant unlabeled data. However, current methods of-ten impose artificial constraints on the proportion of unlabeled anomalies in the training set or overlook potential noise from these anomalies, thereby impeding the effective training of models for anomaly detection in real-world scenarios where several anomalies may be present in the unlabeled dataset. Additionally, existing methods often struggle to effectively exploit and model the complex relationships between data instances, which is critical for learning more discriminative features and accurate distance measures. Distance-based methods, in particular, typically rely on Euclidean distance metric, which lacks the flexibility to capture complex correlations across different data dimensions. To address above challenges, we propose CAD, a denoising-aware Contrastive distance learning framework for semi-supervised AD. It introduces a contrastive training objective to facilitate the learning of distinctive representations by contrasting the average distance between anomalies and unlabeled samples. To fully exploit the information from the unlabeled data meanwhile mitigate the effects of noise, we incorporate a two-stage anomaly denoising and expansion strategy to refine the dataset by identifying high-confidence samples from the unlabeled set. Furthermore, we employ a parameterized bilinear tensor distance layer to learn a customized distance metric, enabling the model to capture intricate relationships among data points. Extensive experiments on 10 real-world datasets demonstrate that CAD significantly outperforms existing semi-supervised AD models. Code available at https://github.com/CADrepo/CAD.",
        "keywords": "Anomaly Detection;Representation Learning;Contrastive Learning;Denoising",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jianling Gao;Chongyang Tao;Zhenchao Sun;Xiya Jiang;Shuai Ma",
        "authorids": "~Jianling_Gao1;~Chongyang_Tao1;~Zhenchao_Sun2;~Xiya_Jiang1;~Shuai_Ma1",
        "gender": ";M;;F;M",
        "homepage": ";;;;https://mashuai-ms.github.io/",
        "dblp": ";;;;35/6569",
        "google_scholar": ";x_cOKuwAAAAJ;;mSqK1_IAAAAJ;",
        "orcid": ";;;;",
        "linkedin": ";;;;",
        "or_profile": "~Jianling_Gao1;~Chongyang_Tao1;~Zhenchao_Sun2;~Xiya_Jiang1;~Shuai_Ma1",
        "aff": ";Beihang University;;Beijing University of Posts and Telecommunications;Beihang  University",
        "aff_domain": ";buaa.edu.cn;;bupt.edu.cn;buaa.edu.cn",
        "position": ";Associate Professor;;PhD student;Full Professor",
        "bibtex": "@inproceedings{\ngao2025semisupervised,\ntitle={Semi-Supervised Anomaly Detection through Denoising-Aware Contrastive Distance Learning},\nauthor={Jianling Gao and Chongyang Tao and Zhenchao Sun and Xiya Jiang and Shuai Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=IwMfHn68Hg}\n}",
        "github": "",
        "project": "",
        "reviewers": "iau8;WYiQ;YUYW;EV5q",
        "site": "https://openreview.net/forum?id=IwMfHn68Hg",
        "pdf_size": 0,
        "novelty": "4;4;4;5",
        "technical_quality": "4;5;5;6",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "J1JyyiBsRU",
        "title": "Common Foundations for SHACL, ShEx, and PG-Schema",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The Semantic Web and Graph Database communities have developed three distinct schema languages for RDF and graph-structured data: SHACL, ShEx, and PG-Schema. Each language has its unique approach to defining constraints and validating graph data. In this work, we provide formal, concise definitions of the core components of each of these schema languages. We employ a uniform framework to facilitate a comprehensive comparison between the languages and identify a common set of functionalities, shedding light on both overlapping and distinctive features of the three languages.",
        "keywords": "RDF;property graphs;graph databases;schema languages;graph data validation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shqiponja Ahmetaj;Iovka Boneva;Jan Hidders;Katja Hose;Maxime Jakubowski;Jose Emilio Labra Gayo;Wim Martens;Fabio Mogavero;Filip Murlak;Cem Okulmus;Axel Polleres;Ognjen Savkovic;Mantas \u0160imkus;Dominik Tomaszuk",
        "authorids": "~Shqiponja_Ahmetaj1;~Iovka_Boneva1;~Jan_Hidders1;~Katja_Hose1;~Maxime_Jakubowski1;~Jose_Emilio_Labra_Gayo2;~Wim_Martens2;~Fabio_Mogavero1;~Filip_Murlak1;~Cem_Okulmus1;~Axel_Polleres1;~Ognjen_Savkovic1;~Mantas_\u0160imkus1;~Dominik_Tomaszuk2",
        "gender": "F;F;M;;M;M;M;M;M;M;M;M;M;",
        "homepage": "https://informatics.tuwien.ac.at/people/shqiponja-ahmetaj;https://pro.univ-lille.fr/iovka-boneva/;;http://katja-hose.de/;https://www.mjakubowski.info/;http://labra.weso.es;https://www.theoinf.uni-bayreuth.de/en/team/martens_wim/index.php;https://www.fabiomogavero.com;http://www.mimuw.edu.pl/~fmurlak;https://www.umu.se/en/staff/cem-okulmus/;http://www.polleres.net;;https://www.dbai.tuwien.ac.at/staff/simkus/;",
        "dblp": "144/7445;;h/JanHidders.html;h/KatjaHose.html;299/7778.html;32/2604.html;;53/78;14/4251;242/1925.html;http://dblp.uni-trier.de/pers/hd/p/Polleres:Axel;118/2620.html;01/5959;",
        "google_scholar": "https://scholar.google.at/citations?user=aRW_IDQAAAAJ;;;LbXvZUoAAAAJ;https://scholar.google.be/citations?user=NK55fJcAAAAJ;TGfRNZkAAAAJ;QgkOSXoAAAAJ;6A_0bmcAAAAJ;https://scholar.google.pl/citations?user=lhjxaFQAAAAJ;YM0FnuYAAAAJ;R-SmVOYAAAAJ;;iWJoqO8AAAAJ;",
        "orcid": "0000-0003-3165-3568;0000-0002-2696-7303;0000-0002-8865-4329;0000-0001-7025-8099;0000-0002-7420-1337;0000-0001-8907-5348;0000-0001-9480-3522;0000-0002-5140-5783;0000-0003-0989-3717;0000-0002-7742-0439;0000-0001-5670-1146;;0000-0003-0632-0294;",
        "linkedin": ";;;;;jelabra/;;;fmurlak?originalSubdomain=pl;;axel-polleres-0712461/;;simkus-mantas/;",
        "or_profile": "~Shqiponja_Ahmetaj1;~Iovka_Boneva1;~Jan_Hidders1;~Katja_Hose1;~Maxime_Jakubowski1;~Jose_Emilio_Labra_Gayo2;~Wim_Martens2;~Fabio_Mogavero1;~Filip_Murlak1;~Cem_Okulmus1;~Axel_Polleres1;~Ognjen_Savkovic1;~Mantas_\u0160imkus1;~Dominik_Tomaszuk2",
        "aff": "Technische Universit\u00e4t Wien;Universit\u00e9 de Lille;Birkbeck College, University of London;Technische Universit\u00e4t Wien+Aalborg University;Technische Universit\u00e4t Wien;University of Oviedo;Universit\u00e4t Bayreuth;University of Naples Federico II;RelationalAI+University of Warsaw;Paderborn University+Ume\u00e5 University;Vienna University of Economics and Business;Free University of Bozen;Technische Universit\u00e4t Wien;",
        "aff_domain": "tuwien.ac.at;univ-lille.fr;bbk.ac.uk;tuwien.ac.at+cs.aau.dk;tuwien.ac.at;uniovi.es;uni-bayreuth.de;unina.it;relational.ai+uw.edu.pl;uni-paderborn.de+umu.se;wu.ac.at;unibz.it;tuwien.ac.at;",
        "position": "Postdoc;Associate Professor;Lecturer;Full Professor+Full Professor;Postdoc;Full Professor;Full Professor;Assistant Professor;Consultant/Contractor+Associate Professor;Postdoc+Postdoc;Full Professor;Lecturer;Researcher;",
        "bibtex": "@inproceedings{\nahmetaj2025common,\ntitle={Common Foundations for {SHACL}, ShEx, and {PG}-Schema},\nauthor={Shqiponja Ahmetaj and Iovka Boneva and Jan Hidders and Katja Hose and Maxime Jakubowski and Jose Emilio Labra Gayo and Wim Martens and Fabio Mogavero and Filip Murlak and Cem Okulmus and Axel Polleres and Ognjen Savkovic and Mantas {\\v{S}}imkus and Dominik Tomaszuk},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=J1JyyiBsRU}\n}",
        "github": "",
        "project": "",
        "reviewers": "eLGn;VQAz;kiKN;Csdu;dqMF",
        "site": "https://openreview.net/forum?id=J1JyyiBsRU",
        "pdf_size": 0,
        "novelty": "5;5;6;6;6",
        "technical_quality": "6;6;7;7;6",
        "scope": "3;3;3;4;4",
        "confidence": "3;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            6.4,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            14,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.408248290463863
    },
    {
        "id": "JSSeMdhsye",
        "title": "G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Explainable recommendation has demonstrated significant advantages in informing users about the logic behind recommendations, thereby increasing system transparency, effectiveness, and trustworthiness. To provide personalized and interpretable explanations, existing works often combine the generation capabilities of large language models (LLMs) with collaborative filtering (CF) information. CF information extracted from the user-item interaction graph captures the user behaviors and preferences, which is crucial for providing informative explanations. However, due to the complexity of graph structure, effectively extracting the CF information from graphs still remains a challenge. Moreover, existing methods often struggle with the integration of extracted CF information with LLMs due to its implicit representation and the modality gap between graph structures and natural language explanations. To address these challenges, we propose G-Refer, a framework using Graph Retrieval-augmented large language models (LLMs) for explainable recommendation. Specifically, we first employ a hybrid graph retrieval mechanism to retrieve explicit CF signals from both structural and semantic perspectives. The retrieved CF information is explicitly formulated as human-understandable text by the proposed graph translation and accounts for the explanations generated by LLMs. To bridge the modality gap, we introduce knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of LLMs to process and utilize the retrieved CF information to generate explanations. Extensive experiments show that G-Refer achieves superior performance compared with existing methods in both explainability and stability. Codes and data are available at https://anonymous.4open.science/r/G-Refer.",
        "keywords": "Explainable Recommendation;Large Language Model;GraphRAG",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuhan Li;Xinni Zhang;Linhao Luo;Heng Chang;Yuxiang Ren;Irwin King;Jia Li",
        "authorids": "~Yuhan_Li3;~Xinni_Zhang1;~Linhao_Luo2;~Heng_Chang2;~Yuxiang_Ren1;~Irwin_King1;~Jia_Li4",
        "gender": "M;;;M;M;M;M",
        "homepage": "https://scholar.google.com/citations?user=c8DzpkAAAAAJ&hl=zh-CN;;;https://hchang95.github.io;https://yuxiangren.github.io/;https://www.cse.cuhk.edu.hk/irwin.king/;https://sites.google.com/view/lijia",
        "dblp": "116/8661-1;;;79/5668;;k/IrwinKing;23/6950-9",
        "google_scholar": "c8DzpkAAAAAJ;;;e9NeskoAAAAJ;SSC2dgcAAAAJ;MXvC7tkAAAAJ;1gSbcYoAAAAJ",
        "orcid": "0000-0003-1324-5819;;;0000-0002-4978-8041;;0000-0001-8106-6447;0000-0002-6362-4385",
        "linkedin": ";;;;;irwinking/;",
        "or_profile": "~Yuhan_Li3;~Xinni_Zhang1;~Linhao_Luo2;~Heng_Chang2;~Yuxiang_Ren1;~Irwin_King1;~Jia_Li4",
        "aff": "Hong Kong University of Science and Technology;;;Tsinghua University;Nanjing University+Huawei Technologies Ltd.;The Chinese University of Hong Kong;Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "hkust.edu;;;tsinghua.edu.cn;nju.edu+huawei.com;cuhk.edu.hk;ust.hk",
        "position": "PhD student;;;Researcher;Assistant Professor+Researcher;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nli2025grefer,\ntitle={G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation},\nauthor={Yuhan Li and Xinni Zhang and Linhao Luo and Heng Chang and Yuxiang Ren and Irwin King and Jia Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JSSeMdhsye}\n}",
        "github": "",
        "project": "",
        "reviewers": "2aue;aYvV;nb9W;uTD5",
        "site": "https://openreview.net/forum?id=JSSeMdhsye",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;6;5;5",
        "scope": "4;4;4;4",
        "confidence": "4;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "JWRQawkyz7",
        "title": "Fair Network Communities through Group Modularity",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Communities in networks are groups of nodes that are more densely connected to each other than to the rest of the network, forming clusters with strong internal relationships. When nodes have sensitive attributes, such as demographic groups in social networks, a key question is whether nodes in each group are equally well-connected within each community. We model connectivity fairness through group modularity, an adaptation of modularity that accounts for group structures. We introduce two versions of group modularity grounded on different null models and present fairness-aware community detection algorithms. Finally, we provide experimental results on real and synthetic networks, evaluating both the group modularity of community structure in networks and our fairness-aware algorithms.",
        "keywords": "algorithmic fairness;community detection;clustering;social networks;group modularity",
        "primary_area": "",
        "supplementary_material": "",
        "author": "CHRISTOS GKARTZIOS;Evaggelia Pitoura;Panayiotis Tsaparas",
        "authorids": "~CHRISTOS_GKARTZIOS1;~Evaggelia_Pitoura2;~Panayiotis_Tsaparas2",
        "gender": "M;;",
        "homepage": ";https://www.cs.uoi.gr/~pitoura/;",
        "dblp": ";;",
        "google_scholar": "https://scholar.google.com/citations?hl=el;;",
        "orcid": ";;",
        "linkedin": "christos-gartzios;evaggelia-pitoura-11218931/;",
        "or_profile": "~CHRISTOS_GKARTZIOS1;~Evaggelia_Pitoura2;~Panayiotis_Tsaparas2",
        "aff": "University of Ioannina;;",
        "aff_domain": "uoi.gr;;",
        "position": "PhD student;;",
        "bibtex": "@inproceedings{\ngkartzios2025fair,\ntitle={Fair Network Communities through Group Modularity},\nauthor={CHRISTOS GKARTZIOS and Evaggelia Pitoura and Panayiotis Tsaparas},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JWRQawkyz7}\n}",
        "github": "",
        "project": "",
        "reviewers": "csv5;52cN;QSye;sJfn;qwSg",
        "site": "https://openreview.net/forum?id=JWRQawkyz7",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;4;5;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8017837257372731
    },
    {
        "id": "JWdOPrwBsF",
        "title": "Posted Price Mechanisms for Online Allocation with Diseconomies of Scale",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "This paper addresses the online $k$-selection problem with diseconomies of scale (OSDoS), where a seller seeks to maximize social welfare by optimally pricing items for sequentially arriving buyers, accounting for increasing marginal production costs. Previous studies have investigated deterministic dynamic pricing mechanisms for such settings. However, significant challenges remain, particularly in achieving optimality with small or finite inventories and developing effective randomized posted price mechanisms. To bridge this gap, we propose a novel randomized dynamic pricing mechanism for OSDoS, providing a tighter lower bound on the competitive ratio compared to prior work. Our approach ensures optimal performance in small inventory settings (i.e., when $k$ is small) and surpasses existing online mechanisms in large inventory settings (i.e., when $k$ is large), leading to the best-known posted price mechanism for optimizing online selection and allocation with diseconomies of scale across varying inventory sizes.",
        "keywords": "Online algorithms;Online markets;Posted price mechanisms;Randomized algorithms",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hossein Nekouyan Jazi;Bo Sun;Raouf Boutaba;Xiaoqi Tan",
        "authorids": "~Hossein_Nekouyan_Jazi1;~Bo_Sun8;~Raouf_Boutaba2;~Xiaoqi_Tan1",
        "gender": "M;;M;",
        "homepage": ";;https://rboutaba.cs.uwaterloo.ca;https://xiaoqitan.org",
        "dblp": ";;b/RaoufBoutaba.html;",
        "google_scholar": ";;L1RHDCcAAAAJ;drR_WcAAAAAJ",
        "orcid": ";;0000-0001-7936-6862;",
        "linkedin": "hossein-nekouyan-jazi-4ba452261;;raouf-boutaba-7496b0/?originalSubdomain=ca;",
        "or_profile": "~Hossein_Nekouyan_Jazi1;~Bo_Sun8;~Raouf_Boutaba2;~Xiaoqi_Tan1",
        "aff": "University of Alberta;;University of Waterloo;University of Alberta",
        "aff_domain": "ualberta.ca;;cs.uwaterloo.ca;ualberta.ca",
        "position": "MS student;;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\njazi2025posted,\ntitle={Posted Price Mechanisms for Online Allocation with Diseconomies of Scale},\nauthor={Hossein Nekouyan Jazi and Bo Sun and Raouf Boutaba and Xiaoqi Tan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JWdOPrwBsF}\n}",
        "github": "",
        "project": "",
        "reviewers": "6uuC;ygDg;HZoP;WioX;Kd4A",
        "site": "https://openreview.net/forum?id=JWdOPrwBsF",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;6;4;6;5",
        "scope": "3;3;3;3;4",
        "confidence": "1;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7637626158259732
    },
    {
        "id": "JZKjBN1pUt",
        "title": "TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Large Language Models (LLMs) are increasingly employed in zero-shot documents ranking, yielding commendable results. However, several significant challenges still persist in LLMs for ranking: (1) LLMs are constrained by limited input length, precluding them from processing a large number of documents simultaneously; (2) The output document sequence is influenced by the input order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a balance between cost and ranking performance is quite challenging. To tackle these issues, we introduce a novel documents ranking method called TourRank, which is inspired by the tournament mechanism. This approach alleviates the impact of LLM's limited input length through intelligent grouping, while the tournament-like points system ensures robust ranking, mitigating the influence of the document input sequence. We test TourRank with different LLMs on the TREC DL datasets and the BEIR benchmark. Experimental results show that TourRank achieves state-of-the-art performance at a reasonable cost.",
        "keywords": "Large Language Model for Search;Zero-Shot Ranking",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yiqun Chen;Qi Liu;Yi Zhang;Weiwei Sun;Xinyu Ma;Wei Yang;Daiting Shi;Jiaxin Mao;Dawei Yin",
        "authorids": "~Yiqun_Chen3;~Qi_Liu21;~Yi_Zhang56;~Weiwei_Sun9;~Xinyu_Ma4;~Wei_Yang10;~Daiting_Shi2;~Jiaxin_Mao1;~Dawei_Yin1",
        "gender": "M;;;;M;M;M;M;M",
        "homepage": "https://chenyiqun.github.io/;;https://zhangyics.github.io/;https://sunnweiwei.github.io/;https://albert-ma.github.io/;;https://www.researchgate.net/profile/Daiting-Shi;https://sites.google.com/site/maojiaxin/;https://www.yindawei.com/",
        "dblp": "59/1143-4;;64/6544-50;;;;293/8193;174/8367;",
        "google_scholar": "PYvsVB8AAAAJ;;https://scholar.google.com.hk/citations?user=BgnOEFsAAAAJ;hdUZbxgAAAAJ;DXYzAIkAAAAJ;;;DDXcKKcAAAAJ;GuQ9bpAAAAAJ",
        "orcid": "0009-0008-6135-2604;;;;0000-0002-5511-9370;0009-0004-0151-2160;;0000-0002-9257-5498;0000-0002-0684-6205",
        "linkedin": ";;;;;;;;dwyin/",
        "or_profile": "~Yiqun_Chen3;~Qi_Liu21;~Yi_Zhang56;~Weiwei_Sun9;~Xinyu_Ma4;~Wei_Yang10;~Daiting_Shi2;~Jiaxin_Mao1;~Dawei_Yin1",
        "aff": "Renmin University of China;;ByteDance Inc.;Carnegie Mellon University;Baidu;Kuaishou- \u5feb\u624b\u79d1\u6280+Institute of Automation, Chinese Academy of Sciences;Baidu;Renmin University of China, Tsinghua University;Baidu",
        "aff_domain": "ruc.edu.cn;;bytedance.com;cs.cmu.edu;baidu.com;kuaishou.com+ia.ac.cn;baidu.com;ruc.edu.cn;baidu.com",
        "position": "PhD student;;Search Scientist;PhD student;Researcher;Researcher+PhD student;Researcher;Assistant Professor;Principal Researcher",
        "bibtex": "@inproceedings{\nchen2025tourrank,\ntitle={TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy},\nauthor={Yiqun Chen and Qi Liu and Yi Zhang and Weiwei Sun and Xinyu Ma and Wei Yang and Daiting Shi and Jiaxin Mao and Dawei Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JZKjBN1pUt}\n}",
        "github": "",
        "project": "",
        "reviewers": "e3zJ;qpU3;5WBE;TwB8;tBsa",
        "site": "https://openreview.net/forum?id=JZKjBN1pUt",
        "pdf_size": 0,
        "novelty": "3;5;5;6;6",
        "technical_quality": "5;5;6;4;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.74535599249993
    },
    {
        "id": "JpI18QQBEW",
        "title": "Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The online advertising market has recently reached the 500 billion dollar mark, and to accommodate the need to match a user with the highest bidder at a fraction of a second, it has moved towards a complex, automated and often opaque model that involves numerous agents and intermediaries. Stimulated by the lack of transparency, but also the enormous potential profits, bad actors have found ways to circumvent restrictions, and generate substantial revenue that can support websites with objectionable or even illegal content.\n\nIn this work, we evaluate transparency Web standards and shed light on how shady actors take advantage of gaps to absorb ad revenues while putting the brand safety of advertisers in danger. We collect and study a large corpus of over 7 million websites and show how ad transparency standards can be abused by bad actors to obscure ad revenue flows. We show how identifier pooling can redirect ad revenues from reputable domains to notorious domains serving objectionable content and that the phenomenon is underestimated by previous studies by a factor of 15. Finally, we publish a Web monitoring service that enhances the transparency of supply chains and business relationships among Web entities.",
        "keywords": "Advertising;Transparency;Misinformation;Ad Abuse",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Emmanouil Papadogiannakis;Nicolas Kourtellis;Panagiotis Papadopoulos;Evangelos Markatos",
        "authorids": "~Emmanouil_Papadogiannakis1;~Nicolas_Kourtellis1;~Panagiotis_Papadopoulos1;~Evangelos_Markatos1",
        "gender": "M;;M;",
        "homepage": ";;;",
        "dblp": ";;130/2934;",
        "google_scholar": "YN01tBEAAAAJ;;https://scholar.google.com/citations?view_op=list_works;Wk7e-kIAAAAJ",
        "orcid": "0000-0002-8959-2465;;0000-0002-1928-6534;",
        "linkedin": ";;panos-papadopoulos-phd-7aa80560/;",
        "or_profile": "~Emmanouil_Papadogiannakis1;~Nicolas_Kourtellis1;~Panagiotis_Papadopoulos1;~Evangelos_Markatos1",
        "aff": "University of Crete;;;",
        "aff_domain": "csd.uoc.gr;;;",
        "position": "PhD student;;;",
        "bibtex": "@inproceedings{\npapadogiannakis2025welcome,\ntitle={Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem},\nauthor={Emmanouil Papadogiannakis and Nicolas Kourtellis and Panagiotis Papadopoulos and Evangelos Markatos},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JpI18QQBEW}\n}",
        "github": "",
        "project": "",
        "reviewers": "fGbX;Yf8u;DUS9;rzy3;pPph",
        "site": "https://openreview.net/forum?id=JpI18QQBEW",
        "pdf_size": 0,
        "novelty": "5;5;6;6;6",
        "technical_quality": "5;5;7;6;5",
        "scope": "3;4;4;4;4",
        "confidence": "3;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.16666666666666663
    },
    {
        "id": "JrMdxOWILp",
        "title": "RiemannGFM: Learning a Graph Foundation Model from Structural Geometry",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The foundation model has heralded a new era in artificial intelligence, pretraining a single model to offer cross-domain transferability on different datasets. Graphs are omnipresent non-Euclidean structures, ranging from recommender systems to biochemical structures. Graph neural networks excel at learning graph data, but often lack the generalization capacity. Hence, graph foundation model is drawing increasing attention, and recent efforts have been made to leverage Large Language Models, encouraged by the remarkable success of GPT-4. On the one hand, existing studies primarily focus on text-attributed graphs, while a wider range of real graphs do not contain fruitful textual attributes. On the other hand, the sequential graph description tailored for the Large Language Model neglects the structural complexity, which is a predominant characteristic of the graph. Such limitations motivate an important question: Can we go beyond Large Language Model, and pretrain a universal model to learn the structural knowledge for any graph? The answer in the language or vision domain is a shared vocabulary. We observe the fact that there also exist shared substructures underlying the graph domain, and thereby open the new opportunity of graph foundation model with structure vocabulary (by which any graph can be constructed). The key innovation of this paper is the discovery of a simple yet effective structural vocabulary of trees and cycles, and we explore its inherent connection to Riemannian geometry. Herein, we present a universal pretraining model, RiemannGFM, with geometric contrastive learning. Concretely, we first construct a novel product bundle to incorporate the diverse geometries of the vocabulary. On this constructed space, we stack Riemannian layers where the structural vocabulary, regardless of specific graph, is learnt in Riemannian manifold. This offers the shared structural knowledge for cross-domain transferability, and node encoding is generated in the tangent bundle for arbitrary input graph. Empirical results show the superiority of RiemannGFM on a diversity of real graphs.",
        "keywords": "Graph Neural Network;Foundation Model;Riemannian Geometry",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Li Sun;Zhenhao Huang;Suyang Zhou;Qiqi Wan;Hao Peng;Philip S. Yu",
        "authorids": "~Li_Sun4;~Zhenhao_Huang1;~Suyang_Zhou1;~Qiqi_Wan1;~Hao_Peng7;~Philip_S._Yu1",
        "gender": "M;M;;F;M;M",
        "homepage": ";;https://my.ncepu.edu.cn;https://github.com/WANQIQI77;https://penghao-bdsc.github.io/;https://cs.uic.edu/profiles/philip-yu/",
        "dblp": "57/2405-8;275/9046-1;;;69/7742-1;y/PhilipSYu",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com/citations?hl=zh-CN;;;R25rbyQAAAAJ;D0lL1r0AAAAJ",
        "orcid": "0000-0003-4562-2279;0009-0007-8944-0385;;;0000-0003-0458-5977;0000-0002-3491-5968",
        "linkedin": ";;;;;",
        "or_profile": "~Li_Sun4;~Zhenhao_Huang1;~Suyang_Zhou1;~Qiqi_Wan1;~Hao_Peng7;~Philip_S._Yu1",
        "aff": "North China Electric Power University ;North China Electric Power University;NCEPU;NCEPU;Beihang University;University of Illinois Chicago",
        "aff_domain": "ncepu.edu.cn;ncepubj.edu.cn;ncepu.edu;ncepu.edu;buaa.edu.cn;uic.edu",
        "position": "Associate Professor;MS student;Undergrad student;Undergrad student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nsun2025riemanngfm,\ntitle={Riemann{GFM}: Learning a Graph Foundation Model from Structural Geometry},\nauthor={Li Sun and Zhenhao Huang and Suyang Zhou and Qiqi Wan and Hao Peng and Philip S. Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=JrMdxOWILp}\n}",
        "github": "",
        "project": "",
        "reviewers": "cmta;UWPf;NwrB;ekjU;gpnd",
        "site": "https://openreview.net/forum?id=JrMdxOWILp",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "6;4;5;6;6",
        "scope": "3;4;3;4;4",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6123724356957946
    },
    {
        "id": "Kj2dqxyH8O",
        "title": "Model-Agnostic Social Network Refinement with Diffusion Models for Robust Social Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Social recommendations (SRs) aim to enhance preference modeling by integrating social networks. However, their effectiveness is mainly constrained by two factors: the noisy social connections that may not reflect shared interests, and the limited number of social connections for most users, which hampers the system's ability to fully leverage social influence. Therefore, it is essential to perform social network refinement by removing noisy connections and adding meaningful ones for robust SRs. Inspired by the denoising capability of generative diffusion models, we propose a Model-Agnostic Social Network Refinement framework with Diffusion Models for Robust Social Recommendation (ARD-SR). Specifically, in the forward process, we corrupt the social network by progressively adding position-specific Gaussian noise calibrated to the user preference similarity, better simulating how the social network responds to noise perturbations. The reverse process learns to denoise, guided by each user\u2019s neighborhood preferences from the SR backbone, generating a tailored social network aligned with each user's preference for establishing connections. For effective learning, we design a curriculum-based training mechanism that progressively introduces challenging samples characterized by high sparsity or high noise levels. Finally, ARD-SR and the SR backbone are alternately trained, ensuring a continuous mutual enhancement between the social network refinement and the backbone's user representation learning. To further enhance the quality of the refined social network, (1) we introduce a preference-guided flip operation during inference to improve the input quality; and (2) we modify social connections based on the exponential weighted moving average of ARD-SR's predictions across epochs to reduce fluctuations. Experiments on three datasets show that ARD-SR significantly improves SR performance across multiple SR backbones.",
        "keywords": "Robust Social Recommendation;Diffusion Model;Social Network Refinement;Curriculum Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Youchen Sun;Zhu Sun;Yingpeng Du;Jie Zhang;Yew-Soon Ong",
        "authorids": "~Youchen_Sun1;~Zhu_Sun1;~Yingpeng_Du1;~Jie_Zhang9;~Yew-Soon_Ong1",
        "gender": "M;F;;M;",
        "homepage": ";https://sites.google.com/view/zhusun/home;;https://personal.ntu.edu.sg/zhangj/;",
        "dblp": "356/8070;163/5129-1.html;;84/6889-2;",
        "google_scholar": "lw1jmpwAAAAJ;https://scholar.google.com.sg/citations?user=kJy0fd8AAAAJ;;IFV_RdMAAAAJ;",
        "orcid": "0000-0001-6164-5361;0000-0002-3350-7022;;;",
        "linkedin": "youchen-sun-566ab3174/;;;;",
        "or_profile": "~Youchen_Sun1;~Zhu_Sun1;~Yingpeng_Du1;~Jie_Zhang9;~Yew-Soon_Ong1",
        "aff": "Nanyang Technological University;Singapore University of Technology and Design;;Nanyang Technological University;",
        "aff_domain": "ntu.edu.sg;sutd.edu.sg;;ntu.edu.sg;",
        "position": "PhD student;Assistant Professor;;Full Professor;",
        "bibtex": "@inproceedings{\nsun2025modelagnostic,\ntitle={Model-Agnostic Social Network Refinement with Diffusion Models for Robust Social Recommendation},\nauthor={Youchen Sun and Zhu Sun and Yingpeng Du and Jie Zhang and Yew-Soon Ong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Kj2dqxyH8O}\n}",
        "github": "",
        "project": "",
        "reviewers": "pZxG;ju8x;7yoQ;MTDj",
        "site": "https://openreview.net/forum?id=Kj2dqxyH8O",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;5;4;5",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "KmMSQS6tFn",
        "title": "Path-LLM: A Multi-Modal Path Representation Learning by Aligning and Fusing with Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The advancement of intelligent transportation systems has led to a growing demand for accurate path representations, which are essential for tasks such as travel time estimation, path ranking, and trajectory analysis. However, traditional path representation learning (PRL) methods often focus solely on single-modal road network data, overlooking important physical and regional factors that influence real-world traffic dynamics. To overcome this limitation, we introduce Path-LLM, a multi-modal path representation learning model that integrates large language models (LLMs) into PRL. Our approach leverages LLMs to interpret both topological and textual data, enabling robust multi-modal path representations. To effectively align and merge these modalities, we propose TPalign, a contrastive learning-based pretraining strategy that ensures alignment within the embedding space. We then present TPfusion, a multimodal fusion module that dynamically adjusts the weight of each modality before integration. To further optimize LLM training, we introduce a \\textit{Two-stage Overlapping Curriculum Learning (TOCL)} approach, which progressively increases the complexity of the training data. Finally, we evaluate Path-LLM on two real-world datasets across traditional PRL downstream tasks, achieving up to a 61.84\\% improvement in path ranking performance on the Xi'an dataset. Additionally, Path-LLM demonstrates superior performance in both few-shot and zero-shot learning scenarios. Our code is available at: https://anonymous.4open.science/r/Path-LLM-F053.",
        "keywords": "Path representation learning;Large language models;Curriculum learning;Contrastive learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongfu Wei;Yan Lin;Hongfan Gao;Ronghui Xu;Sean Bin Yang;Jilin Hu",
        "authorids": "~Yongfu_Wei1;~Yan_Lin1;~Hongfan_Gao1;~Ronghui_Xu2;~Sean_Bin_Yang1;~Jilin_Hu1",
        "gender": ";M;;F;;M",
        "homepage": ";https://www.yanlincs.com;;https://xrhics.github.io/homepage/;;https://hujilin1229.github.io/",
        "dblp": ";27/586-6;;86/5186-1;;189/6195.html",
        "google_scholar": ";nHMmG2UAAAAJ;;https://scholar.google.com.hk/citations?user=J01P_rcAAAAJ;;https://scholar.google.dk/citations?user=6eSvRMkAAAAJ",
        "orcid": "0009-0000-1121-2680;0000-0002-2320-9777;;0000-0001-5933-4353;;0000-0002-7739-7769",
        "linkedin": ";;;rhxu/;;",
        "or_profile": "~Yongfu_Wei1;~Yan_Lin1;~Hongfan_Gao1;~Ronghui_Xu2;~Sean_Bin_Yang1;~Jilin_Hu1",
        "aff": "East China Normal University;Aalborg University;;East China Normal University;;East China Normal University+Aalborg University",
        "aff_domain": "stu.ecnu.edu.cn;cs.aau.dk;;ecnu.edu.cn;;ecnu.edu.cn+cs.aau.dk",
        "position": "MS student;Postdoc;;PhD student;;Full Professor+Associate Professor",
        "bibtex": "@inproceedings{\nwei2025pathllm,\ntitle={Path-{LLM}: A Multi-Modal Path Representation Learning by Aligning and Fusing with Large Language Models},\nauthor={Yongfu Wei and Yan Lin and Hongfan Gao and Ronghui Xu and Sean Bin Yang and Jilin Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=KmMSQS6tFn}\n}",
        "github": "",
        "project": "",
        "reviewers": "nMYp;HLbe;5AAR;H1DX;48EW",
        "site": "https://openreview.net/forum?id=KmMSQS6tFn",
        "pdf_size": 0,
        "novelty": "4;5;5;5;7",
        "technical_quality": "3;5;4;6;7",
        "scope": "3;4;4;3;4",
        "confidence": "2;4;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.0,
            1.4142135623730951
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6634034720037774
    },
    {
        "id": "KxXpYU96hW",
        "title": "TimeChain: A Secure and Decentralized Off-chain Storage System for IoT Time Series Data",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Blockchain-based distributed storage systems offer enhanced security, transparency, and lower costs compared to traditional centralized storage, making them ideal for peer-to-peer collaboration. However, with the trend towards the Web of Things (WoT), lower transaction speeds and higher computational requirements limit their access to high-density data such as IoT. To address this, we propose TimeChain, an efficient off-chain blockchain storage system for IoT time series data. TimeChain batches discrete time series data, storing only the hash value of each batch on-chain while keeping the complete data off-chain. This significantly reduces storage overhead on the blockchain and storage latency by 37.4 times. In order to reduce the additional transmission latency in range queries, TimeChain employs an adaptive packaging mechanism. We convert the batching problem to a graph partitioning problem by representing data and historical co-query as graph vertices and edge weights respectively. To reduce the size of the transmission size in data integrity verification, a Locality-Sensitive Hashing (LSH)-based data integrity verification mechanism, which minimizes the data required for integrity checks by transmitting only non-redundant parts. TimeChain also integrates a node selection mechanism based on consensus protocol, which reduces the overhead by combining node selection and consensus processes. Our evaluation shows a reduction in query latency by 64.6% and storage latency by 35.3% compared to existing systems.",
        "keywords": "IoT Series Data;Blockchain;Database",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yixiao Teng;jiamei lv;Ziping Wang;Yi Gao;Wei Dong",
        "authorids": "~Yixiao_Teng1;~jiamei_lv1;~Ziping_Wang1;~Yi_Gao6;~Wei_Dong8",
        "gender": "F;F;M;M;",
        "homepage": ";;;https://yi-gao.github.io/;",
        "dblp": ";;;38/4304-1.html;92/748-1.html",
        "google_scholar": ";P1UZbbbwNa8C;;oyKWoTkAAAAJ;https://scholar.google.com.hk/citations?user=Moqb0qcAAAAJ",
        "orcid": "0009-0009-6671-6734;;0009-0008-2318-1402;;",
        "linkedin": ";;;;",
        "or_profile": "~Yixiao_Teng1;~jiamei_lv1;~Ziping_Wang1;~Yi_Gao6;~Wei_Dong8",
        "aff": "Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "MS student;Researcher;MS student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nteng2025timechain,\ntitle={TimeChain: A Secure and Decentralized Off-chain Storage System for IoT Time Series Data},\nauthor={Yixiao Teng and jiamei lv and Ziping Wang and Yi Gao and Wei Dong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=KxXpYU96hW}\n}",
        "github": "",
        "project": "",
        "reviewers": "2qjB;LVq1;bxv9;fUr4;ppka",
        "site": "https://openreview.net/forum?id=KxXpYU96hW",
        "pdf_size": 0,
        "novelty": "2;3;4;4;6",
        "technical_quality": "3;4;5;4;6",
        "scope": "3;3;4;3;4",
        "confidence": "4;2;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            3.8,
            1.32664991614216
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.8944271909999159
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.1685499656158105
    },
    {
        "id": "L6I2KSXiPN",
        "title": "Seed: Bridging Sequence and Diffusion Models for Road Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Road trajectory generation creates synthetic yet realistic trajectories to tackle data collection costs and privacy concerns. Existing methods generate a trajectory either segment-by-segment using sequence models or holistically in one step using diffusion models. Sequence-based models have good regularity and consistency (i.e., resemble the input trajectories) but lack diversity, while diffusion-based models enhance diversity but sacrifice regularity and consistency. To combine the merits of existing methods, we propose $\\textit{Seed}$, by bridging $\\underline{\\textit{se}}$quenc$\\underline{\\textit{e}}$ and $\\underline{\\textit{d}}$iffusion models for trajectory generation.  In particular, Seed adopts a \\textit{conditional diffusion structure}, where a Transformer models the  movement of each trajectory along the road segments, and conditioned on the Transformer's output, a diffusion model recovers the next road segment from random noise. The rationale is that the Transformer captures sequential movement patterns for regularity and consistency, while the diffusion model introduces diversity by recovering from noise. To train Seed, we adopt Node2vec to learn embeddings for the road segments to prepare model inputs, supervise learning using the task of trajectory reconstruction, and design a curriculum learning strategy to accelerate convergence. We compare Seed with 8 state-of-the-art trajectory generation methods on 3 datasets, and the results show that Seed improves the best-performing baseline by over 50\\%.",
        "keywords": "Trajectory;Data Synthesis;Transformer;Diffusion Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xuan Rao;Shuo Shang;Renhe Jiang;Peng Han;Lisi Chen",
        "authorids": "~Xuan_Rao2;~Shuo_Shang1;~Renhe_Jiang1;~Peng_Han3;~Lisi_Chen1",
        "gender": "M;;M;M;",
        "homepage": "https://kevin-xuan.github.io/;https://sites.google.com/site/jedishang;https://www.renhejiang.com/;https://www.linkedin.com/in/peng-han-062480177/;",
        "dblp": "142/1293;29/8750;213/1173;51/4558-5;",
        "google_scholar": "j1Ny1WQAAAAJ;https://scholar.google.com/citations?hl=en;Yo2lwasAAAAJ;8XxCgFEAAAAJ;",
        "orcid": "0000-0003-1428-8538;0000-0002-1117-2890;0000-0003-2593-4638;0000-0003-1201-2060;",
        "linkedin": ";;renhejiang/;;",
        "or_profile": "~Xuan_Rao2;~Shuo_Shang1;~Renhe_Jiang1;~Peng_Han3;~Lisi_Chen1",
        "aff": "University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;The University of Tokyo;University of Electronic Science and Technology of China;",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;u-tokyo.ac.jp;uestc.edu.cn;",
        "position": "PhD student;Full Professor;Lecturer;Full Professor;",
        "bibtex": "@inproceedings{\nrao2025seed,\ntitle={Seed: Bridging Sequence and Diffusion Models for Road Trajectory Generation},\nauthor={Xuan Rao and Shuo Shang and Renhe Jiang and Peng Han and Lisi Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=L6I2KSXiPN}\n}",
        "github": "",
        "project": "",
        "reviewers": "ztxV;EBGb;7j7s;mipZ;gLNk",
        "site": "https://openreview.net/forum?id=L6I2KSXiPN",
        "pdf_size": 0,
        "novelty": "3;3;4;4;6",
        "technical_quality": "3;4;4;5;6",
        "scope": "3;4;3;2;2",
        "confidence": "3;4;4;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            2.8,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7319250547113999
    },
    {
        "id": "L8MeU0K5Fx",
        "title": "Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Diffusion models (DMs) have emerged as promising approaches for sequential recommendation due to their strong ability to model data distributions and generate high-quality items. Existing work typically adds noise to the next item and progressively denoises it guided by the user's interaction sequence, generating items that closely align with user interests. However, we identify two key issues in this paradigm. First, the sequences are often heterogeneous in length and content, exhibiting noise due to stochastic user behaviors. Using such sequences as guidance may hinder DMs from accurately understanding user interests. Second, DMs are prone to data bias and tend to generate only the popular items that dominate the training dataset, thus failing to meet the personalized needs of different users. To address these issues, we propose Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation (DiQDiff), which aims to extract robust guidance to understand user interests and generate distinguished items for personalized user interests within DMs. To extract robust guidance, DiQDiff introduces Semantic Vector Quantization (SVQ) to quantize sequences into semantic vectors (e.g., collaborative signals and category interests) using a codebook, which can enrich the guidance to better understand user interests. To generate distinguished items, DiQDiff personalizes the generation through Contrastive Discrepancy Maximization (CDM), which maximizes the distance between denoising trajectories using contrastive loss to prevent biased generation for different users. Extensive experiments are conducted to compare DiQDiff with multiple baseline models across four widely-used datasets. The superior recommendation performance of DiQDiff demonstrates its effectiveness in the sequential recommendation.",
        "keywords": "Diffusion model;recommender system;vector quantization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenyu Mao;Shuchang Liu;Haoyang Liu;Haozhe Liu;Xiang Li;Lantao Hu",
        "authorids": "~Wenyu_Mao2;~Shuchang_Liu1;~Haoyang_Liu2;~Haozhe_Liu3;~Xiang_Li49;~Lantao_Hu1",
        "gender": "F;M;;M;M;M",
        "homepage": "https://github.com/maowenyu-11;;;https://github.com/Randolph08;;",
        "dblp": ";335/1645;;;;",
        "google_scholar": ";kivnB4QAAAAJ;;;oMB6_gUAAAAJ;P0EK1y8AAAAJ",
        "orcid": ";0000-0002-1440-911X;;;0009-0000-6958-3388;",
        "linkedin": ";;;;;",
        "or_profile": "~Wenyu_Mao2;~Shuchang_Liu1;~Haoyang_Liu2;~Haozhe_Liu3;~Xiang_Li49;~Lantao_Hu1",
        "aff": "Kuaishou- \u5feb\u624b\u79d1\u6280+University of Science and Technology of China;Kuaishou;;University of Science and Technology of China;Kuaishou- \u5feb\u624b\u79d1\u6280;",
        "aff_domain": "kuaishou.com+mail.ustc.edu.cn;kuaishou.com;;mail.ustc.edu.cn;kuaishou.com;",
        "position": "Intern+MS student;Researcher;;Undergrad student;Engineer;",
        "bibtex": "@inproceedings{\nmao2025distinguished,\ntitle={Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation},\nauthor={Wenyu Mao and Shuchang Liu and Haoyang Liu and Haozhe Liu and Xiang Li and Lantao Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=L8MeU0K5Fx}\n}",
        "github": "",
        "project": "",
        "reviewers": "CqBN;J9tC;tG8v;BwKG;nNmX",
        "site": "https://openreview.net/forum?id=L8MeU0K5Fx",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "3;5;4;5;4",
        "scope": "4;4;3;4;3",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6123724356957948
    },
    {
        "id": "LedrHK34jZ",
        "title": "TAPE: Tailored Posterior Difference for Auditing of Machine Unlearning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Increasing studies focus on machine unlearning as it upholds users' right to be forgotten, under which individuals can request the removal of their specified samples from trained models. However, the auditing of machine unlearning processes remains significantly underexplored. Although some existing methods offer unlearning auditing by leveraging backdoors, these backdoor-based approaches are inefficient and impractical, as they necessitate involvement in the initial model training process to embed the backdoors. In this paper, we propose a TAilored Posterior diffErence (TAPE) method to provide unlearning auditing independently of original model training. We observe that the process of machine unlearning inherently introduces changes in the model, which contains information related to the erased data. TAPE leverages unlearning model differences to assess how much information has been removed through the unlearning operation. Firstly, TAPE mimics the unlearned posterior differences by quickly building unlearned shadow models based on first-order influence estimation. Secondly, we train a Reconstructor model to extract and evaluate the private information of the unlearned posterior differences to audit unlearning. Existing privacy reconstructing methods based on posterior differences are only feasible for model updates of a single sample. To enable the reconstruction effective for multi-sample unlearning requests, we propose two strategies, unlearned data perturbation and unlearned influence-based division, to augment the posterior difference. Extensive experimental results indicate the significant superiority of TAPE over the state-of-the-art unlearning verification methods, at least 4.5$\\times$ efficiency speedup and supporting the auditing for broader unlearning scenarios.",
        "keywords": "Auditing;Machine Unlearning.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weiqi Wang;Zhiyi Tian;An Liu;Shui Yu",
        "authorids": "~Weiqi_Wang2;~Zhiyi_Tian1;~An_Liu1;~Shui_Yu1",
        "gender": "M;;Not Specified;M",
        "homepage": ";;http://web.suda.edu.cn/anliu/;",
        "dblp": ";;52/94-2;90/3575-1.html",
        "google_scholar": "r0O_bbAAAAAJ;;89cdhB4AAAAJ;_WbktxMAAAAJ",
        "orcid": "0000-0002-7905-3126;;0000-0002-6368-576X;",
        "linkedin": ";;;",
        "or_profile": "~Weiqi_Wang2;~Zhiyi_Tian1;~An_Liu1;~Shui_Yu1",
        "aff": "University of Technology Sydney;;Soochow University;University of Technology Sydney",
        "aff_domain": "uts.edu.au;;suda.edu.cn;uts.edu.au",
        "position": "Postdoc;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nwang2025tape,\ntitle={{TAPE}: Tailored Posterior Difference for Auditing of Machine Unlearning},\nauthor={Weiqi Wang and Zhiyi Tian and An Liu and Shui Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=LedrHK34jZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "VJZx;oXvT;oDpE;G4BY",
        "site": "https://openreview.net/forum?id=LedrHK34jZ",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "5;4;5;4",
        "scope": "3;4;1;4",
        "confidence": "2;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.0,
            1.224744871391589
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8703882797784891
    },
    {
        "id": "LfVmZ8vaFp",
        "title": "Off-policy Evaluation for Multiple Actions in the Presence of Unobserved Confounders",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Off-policy evaluation (OPE) is a crucial problem in reinforcement learning (RL), where the goal is to estimate the long-term cumulative reward of a target policy using historical data generated by a potentially different behaviour policy. In many real-world applications, such as precision medicine and recommendation systems, unobserved confounders may influence the action, reward, and state transition dynamics, which leads to biased estimates if not properly addressed. While existing methods for handling unobserved confounders in OPE focus on single-action settings, they are less effective in multi-action scenarios commonly found in practical applications, where an agent can take multiple actions simultaneously. In this paper, we propose a novel auxiliary variable-aided method for OPE in multi-action settings with unobserved confounders. Our approach overcomes the limitations of traditional auxiliary variable methods for multi-action scenarios by requiring only a single auxiliary variable, relaxing the need for as many auxiliary variables as the actions. Through theoretical analysis, we prove that our method provides an unbiased estimation of the target policy value. Empirical evaluations demonstrate that our estimator achieves better performance compared to existing baseline methods, highlighting its effectiveness and reliability in addressing unobserved confounders in multi-action OPE settings.",
        "keywords": "Off-policy Evaluation;Multiple Actions;Unobserved confounder;Treatment Recommendation;Deconfounding",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Haolin Wang;Lin Liu;Jiuyong Li;Ziqi Xu;Jixue Liu;Zehong Cao;Debo Cheng",
        "authorids": "~Haolin_Wang10;~Lin_Liu4;~Jiuyong_Li1;~Ziqi_Xu1;~Jixue_Liu1;~Zehong_Cao1;~Debo_Cheng1",
        "gender": "M;Not Specified;M;M;M;M;",
        "homepage": ";https://people.unisa.edu.au/lin.liu;https://people.unisa.edu.au/jiuyong.li;https://iron13.github.io/;http://people.unisa.edu.au/jixue.liu;https://czh513.github.io;",
        "dblp": ";61/2115-3;20/1583;255/6518-1;l/JixueLiu.html;202/1523.html;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;QP6jqRwAAAAJ;https://scholar.google.com.au/citations?user=WYeM3yYAAAAJ;znODztEAAAAJ;https://scholar.google.com.au/citations?user=Ztoa054AAAAJ;yaZg9lIAAAAJ;",
        "orcid": "0000-0002-0477-4973;0000-0003-2843-5738;0000-0002-9023-1878;0000-0003-1748-5801;0000-0002-0794-0404;0000-0003-3656-0328;",
        "linkedin": ";;jiuyongli/?originalSubdomain=au;ziqi-xu-846510113/;;;",
        "or_profile": "~Haolin_Wang10;~Lin_Liu4;~Jiuyong_Li1;~Ziqi_Xu1;~Jixue_Liu1;~Zehong_Cao1;~Debo_Cheng1",
        "aff": "University of South Australia;University of South Australia, Australia;University of South Australia, Australia;Royal Melbourne Institute of Technology;University of South Australia, Australia;Adelaide University;",
        "aff_domain": "unisa.edu.au;unisa.edu.au;unisa.edu.au;rmit.edu.au;unisa.edu.au;adelaide.edu.au;",
        "position": "PhD student;Full Professor;Full Professor;Assistant Professor;Associate Professor;Principal Researcher;",
        "bibtex": "@inproceedings{\nwang2025offpolicy,\ntitle={Off-policy Evaluation for Multiple Actions in the Presence of Unobserved Confounders},\nauthor={Haolin Wang and Lin Liu and Jiuyong Li and Ziqi Xu and Jixue Liu and Zehong Cao and Debo Cheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=LfVmZ8vaFp}\n}",
        "github": "",
        "project": "",
        "reviewers": "GBwh;kUCz;4UAG;tgc1;WBNo",
        "site": "https://openreview.net/forum?id=LfVmZ8vaFp",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "5;4;4;4;5",
        "scope": "3;3;1;4;3",
        "confidence": "2;2;1;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.4,
            0.4898979485566356
        ],
        "scope_avg": [
            2.8,
            0.9797958971132712
        ],
        "confidence_avg": [
            2.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "MBMUhXlzuU",
        "title": "TriG-NER: Triplet-Grid Framework for Discontinuous Named Entity Recognition",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Discontinuous Named Entity Recognition (DNER) presents a challenging problem where entities may be scattered across multiple non-adjacent tokens, making traditional sequence labelling approaches inadequate. Existing methods predominantly rely on custom tagging schemes to handle these discontinuous entities, resulting in models tightly coupled to specific tagging strategies and lacking generalisability across diverse datasets. To address these challenges, we propose TriG-NER, a novel Triplet-Grid Framework that introduces a generalisable approach to learning robust token-level representations for discontinuous entity extraction. Our framework applies triplet loss at the token level, where similarity is defined by word pairs existing within the same entity, effectively pulling together similar and pushing apart dissimilar ones. This approach enhances entity boundary detection and reduces the dependency on specific tagging schemes by focusing on word-pair relationships within a flexible grid structure. We evaluate TriG-NER on three benchmark DNER datasets and demonstrate significant improvements over existing grid-based architectures. These results underscore our framework\u2019s effectiveness in capturing complex entity structures and its adaptability to various tagging schemes, setting a new benchmark for discontinuous entity extraction.",
        "keywords": "Discontinuous Named Entity Recognition;Medical Named Entity Recognition;Medical Text Mining",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rina Carines Cabral;Caren Han;Areej Alhassan;Riza Batista-Navarro;Goran Nenadic;Josiah Poon",
        "authorids": "~Rina_Carines_Cabral1;~Caren_Han1;~Areej_Alhassan1;~Riza_Batista-Navarro1;~Goran_Nenadic1;~Josiah_Poon1",
        "gender": ";F;F;F;M;M",
        "homepage": ";https://drcarenhan.github.io/;;https://research.manchester.ac.uk/en/persons/riza.batista;http://www.manchester.ac.uk/research/gnenadic/personaldetails;",
        "dblp": ";24/10567;;92/11424;;25/2453",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.au/citations?hl=en;;fRBJmp9gk_cC;https://scholar.google.com.tw/citations?user=CyTXHuUAAAAJ;Q7U0O0gAAAAJ",
        "orcid": ";;0000-0001-7780-9463;;;0000-0003-3371-8628",
        "linkedin": ";;;;;josiah-poon-43931782/",
        "or_profile": "~Rina_Carines_Cabral1;~Caren_Han1;~Areej_Alhassan1;~Riza_Batista-Navarro1;~Goran_Nenadic1;~Josiah_Poon1",
        "aff": "University of Sydney;University of Melbourne+University of Western Australia+University of Sydney;University of Manchester;University of Manchester;University of Manchester;University of Sydney",
        "aff_domain": "usyd.edu.au;unimelb.edu.au+uwa.edu.au+sydney.edu.au;manchester.ac.uk;manchester.ac.uk;cs.manchester.ac.uk;sydney.edu.au",
        "position": "PhD student;Associate Professor+Associate Professor+Associate Professor;PhD student;Associate Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\ncabral2025trigner,\ntitle={TriG-{NER}: Triplet-Grid Framework for Discontinuous Named Entity Recognition},\nauthor={Rina Carines Cabral and Caren Han and Areej Alhassan and Riza Batista-Navarro and Goran Nenadic and Josiah Poon},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MBMUhXlzuU}\n}",
        "github": "",
        "project": "",
        "reviewers": "DATg;4DwX;6TZa;qnoN;Jkyb",
        "site": "https://openreview.net/forum?id=MBMUhXlzuU",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "5;4;6;5;6",
        "scope": "4;4;4;3;4",
        "confidence": "4;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.07142857142857142
    },
    {
        "id": "MFUD557wr7",
        "title": "LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As the number and sophistication of cyber attacks have increased, threat hunting has become a critical aspect of active security, enabling proactive detection and mitigation of threats before they cause significant harm.\nOpen-source cyber threat intelligence (OSCTI) is a valuable resource for threat hunters, however, it often comes in unstructured formats that require further manual analysis.\nPrevious studies aimed at automating OSCTI analysis are limited since (1) they failed to provide actionable outputs, (2) they did not take advantage of images present in OSCTI sources, and (3) they focused on on-premises environments, overlooking the growing importance of cloud environments.\nTo address these gaps, we propose LLMCloudHunter, a novel framework that leverages large language models (LLMs) to automatically generate generic-signature detection rule candidates from textual and visual OSCTI data.\nWe evaluated the quality of the rules generated by the proposed framework using 20 annotated real-world cloud threat reports.\nThe results show that our framework achieved a precision of 83\\% and recall of 99\\% for the task of accurately extracting API calls made by the threat actor and a precision of 99\\% with a recall of 97\\% for IoCs.\nAdditionally, 99.18\\% of the generated detection rule candidates were successfully compiled and converted into Splunk queries.",
        "keywords": "Cyber threat intelligence (CTI);Large language model (LLM);Threat hunting;Cloud;Sigma rules",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuval Schwartz;Lavi Ben-Shimol;Dudu Mimran;Yuval Elovici;Asaf Shabtai",
        "authorids": "~Yuval_Schwartz1;~Lavi_Ben-Shimol1;~Dudu_Mimran1;~Yuval_Elovici1;~Asaf_Shabtai1",
        "gender": "M;M;M;M;",
        "homepage": ";;https://www.dudumimran.com;https://cyber.bgu.ac.il/yuval/;",
        "dblp": ";;;38/4086;",
        "google_scholar": ";;;https://scholar.google.co.il/citations?user=ruZDm9QAAAAJ;",
        "orcid": "0009-0007-0126-7080;0009-0003-8948-3386;0009-0004-9610-6156;0000-0002-9641-128X;",
        "linkedin": "yuval-schwartz;lavi-ben-shimol/;;yuval-elovici-0baa4a4/?originalSubdomain=il;",
        "or_profile": "~Yuval_Schwartz1;~Lavi_Ben-Shimol1;~Dudu_Mimran1;~Yuval_Elovici1;~Asaf_Shabtai1",
        "aff": "Ben Gurion University of the Negev;Ben Gurion University of the Negev;Cyber @ BGU;Ben Gurion University of the Negev, Technion;",
        "aff_domain": "post.bgu.ac.il;bgu.ac.il;cyber.bgu.ac.il;bgu.ac.il;",
        "position": "MS student;PhD student;Researcher;Full Professor;",
        "bibtex": "@inproceedings{\nschwartz2025llmcloudhunter,\ntitle={{LLMC}loudHunter: Harnessing {LLM}s for Automated Extraction of Detection Rules from Cloud-Based {CTI}},\nauthor={Yuval Schwartz and Lavi Ben-Shimol and Dudu Mimran and Yuval Elovici and Asaf Shabtai},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MFUD557wr7}\n}",
        "github": "",
        "project": "",
        "reviewers": "ccnP;EPx6;vsLM;VcVv;FXDS",
        "site": "https://openreview.net/forum?id=MFUD557wr7",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "2;3;5;4;6",
        "scope": "2;3;3;4;4",
        "confidence": "4;2;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.0,
            1.4142135623730951
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.0,
            0.8944271909999159
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "MHOhNKeJk8",
        "title": "Graph Meets LLM for Review Personalization based on User Votes",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Review personalization aims at presenting the most relevant reviews of a product according to the preferences of the individual user. Existing studies of review personalization use the reviews authored by the user as a proxy for their preferences, and henceforth as a means for learning and evaluating personalization quality. In this work, we suggest using review votes rather than authorship for personalization. We suggest MAGLLM, an approach that leverages heterogeneous graphs for modeling the relationships among reviews, products, and users, with large language model (LLM) to enrich user representation on the graph. Our evaluation over a unique public dataset that includes user voting information indicates that the vote signal yields substantially higher personalization performance across a variety of recommendation methods and e-commerce domains. It also indicates that our graph-LLM approach outperforms comparative baselines and algorithmic alternatives. We conclude with concrete recommendations for e-commerce platforms seeking to enhance their review personalization experience.",
        "keywords": "personalization;e-commerce;product reviews",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sharon Hirsch;Lilach Zitnitski;Slava Novgorodov;Ido Guy;Bracha Shapira",
        "authorids": "~Sharon_Hirsch1;~Lilach_Zitnitski1;~Slava_Novgorodov2;~Ido_Guy1;~Bracha_Shapira1",
        "gender": "F;F;M;;F",
        "homepage": ";;http://slavanov.com;;",
        "dblp": "262/3457;;;46/650;74/6180",
        "google_scholar": "https://scholar.google.co.il/citations?user=amx0cS4AAAAJ;;;iiXF7KkAAAAJ;https://scholar.google.com.tw/citations?user=1biUWpIAAAAJ",
        "orcid": "0000-0003-3503-510X;;;;0000-0003-4943-9324",
        "linkedin": ";lilah-zitnitski/;;;bracha-shapira-0b461b6/",
        "or_profile": "~Sharon_Hirsch1;~Lilach_Zitnitski1;~Slava_Novgorodov2;~Ido_Guy1;~Bracha_Shapira1",
        "aff": "Ben Gurion University of the Negev+eBay Inc.;;Tel Aviv University;Meta Facebook+Ben-Gurion University of the Negev;Ben Gurion University of the Negev",
        "aff_domain": "post.bgu.ac.il+ebay.com;;tau.ac.il;facebook.com+bgu.ac.il;bgu.ac.il",
        "position": "PhD student+Researcher;;Researcher;Facebook+Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nhirsch2025graph,\ntitle={Graph Meets {LLM} for Review Personalization based on User Votes},\nauthor={Sharon Hirsch and Lilach Zitnitski and Slava Novgorodov and Ido Guy and Bracha Shapira},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MHOhNKeJk8}\n}",
        "github": "",
        "project": "",
        "reviewers": "wPnZ;S8jz;XVmV;7FhA",
        "site": "https://openreview.net/forum?id=MHOhNKeJk8",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "3;3;6;5",
        "scope": "4;3;4;4",
        "confidence": "3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.25,
            1.299038105676658
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9045340337332909
    },
    {
        "id": "MeD7Pq8FgM",
        "title": "A Theory-Driven Approach to Inner Product Matrix Estimation for Incomplete Data: An Eigenvalue Perspective",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Addressing the critical challenge of data incompleteness in inner product matrix estimation, we introduce a novel eigenvalue correction method designed to precisely reconstruct true inner product matrices from incomplete data. Utilizing random matrix theory, our method adjusts the eigenvalue distribution of the estimated inner product matrix to align with the ground-truth. This approach significantly reduces estimation errors for both inner product matrices and the derived Euclidean distance matrices, thereby enhancing the effectiveness of similarity searches on incomplete data. Our method surpasses traditional data imputation and similarity calibration techniques in both maximum inner product search and nearest neighbor search tasks, demonstrating marked advancements in managing incomplete data. It exhibits robust performance across various missing rates and diverse scenarios.",
        "keywords": "Inner Product Matrix Estimation;Incomplete Data;Eigenvalue Distribution;Random Matrix Theory",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Fangchen Yu;Yicheng Zeng;Jianfeng Mao;Wenye Li",
        "authorids": "~Fangchen_Yu1;~Yicheng_Zeng1;~Jianfeng_Mao1;~Wenye_Li1",
        "gender": "M;M;M;M",
        "homepage": "https://sciyu.github.io/;http://sribd.cn/en/teacher/558;https://sds.cuhk.edu.cn/en/teacher/268;",
        "dblp": "305/0356;232/0043;;39/5505",
        "google_scholar": "fQtgwlgAAAAJ;;https://scholar.google.com.hk/citations?user=cDzZKz8AAAAJ;",
        "orcid": "0000-0002-1256-2719;;;",
        "linkedin": "fangchen-yu-614a98212/;;;",
        "or_profile": "~Fangchen_Yu1;~Yicheng_Zeng1;~Jianfeng_Mao1;~Wenye_Li1",
        "aff": "Shanghai AI Laboratory+Mohamed bin Zayed University of Artificial Intelligence+The Chinese University of Hong Kong, Shenzhen;Shenzhen Research Institute of Big Data;The Chinese University of Hong Kong, Shenzhen;The Hong Kong University of Science and Technology (Guangzhou)+The Chinese University of Hong Kong, Shenzhen",
        "aff_domain": "pjlab.org.cn+mbzuai.ac.ae+link.cuhk.edu.cn;sribd.cn;cuhk.edu.cn;hkust-gz.edu.cn+cuhk.edu.cn",
        "position": "Intern+Visiting student+PhD student;Researcher;Associate Professor;Associate Professor+Associate Professor",
        "bibtex": "@inproceedings{\nyu2025a,\ntitle={A Theory-Driven Approach to Inner Product Matrix Estimation for Incomplete Data: An Eigenvalue Perspective},\nauthor={Fangchen Yu and Yicheng Zeng and Jianfeng Mao and Wenye Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MeD7Pq8FgM}\n}",
        "github": "",
        "project": "",
        "reviewers": "4bGZ;MVgR;sjyn;Zt79;WKGS",
        "site": "https://openreview.net/forum?id=MeD7Pq8FgM",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;6;5;6;6",
        "scope": "4;3;3;3;4",
        "confidence": "3;2;2;1;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.49999999999999994
    },
    {
        "id": "MipDf3C38E",
        "title": "ITMPRec: Intention-based Targeted Multi-round Proactive Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Personalized user preference driven recommendations have seamlessly intertwined with our daily lives. However, item providers may expect specific items to gradually increase their appeal to users over the course of users\u2019 long-term interactions with the system, but few studies pay attention to this problem. In this paper, we propose a novel intention-based targeted multi-round proactive recommendation method, dubbed ITMPRec. Specifically, we first choose a set of target items from the target category, by conducting a pre-match strategy. Afterward, we utilize a multi-round nudging recommendation method, in which we design a module to quantify the intention-level dynamic evolution of users so that we could choose more appropriate intermediate items during guidance. Besides, we model each user\u2019s sensitivity to the changes in representation induced by the intermediate items they accept. Finally, we propose a design for a Large Language Model (LLM)\nagent as a pluggable component to simulate user feedback. This design offers an alternative to the traditional click model based on distribution, relying on the agent\u2019s external knowledge and reasoning capabilities. Through extensive experiments on four public datasets, we demonstrate the superiority of ITMPRec compared to seven baseline models. The code repository is available at https://anonymous.4open.science/r/ITMPRec-D821.",
        "keywords": "sequential recommendation;proactive recommendation;intention;LLM",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yahong Lian;Chunyao Song;Tingjian Ge",
        "authorids": "~Yahong_Lian1;~Chunyao_Song1;~Tingjian_Ge1",
        "gender": "F;F;M",
        "homepage": "https://github.com/YahongANN/YahongANN.github.io;https://cc.nankai.edu.cn/2021/0323/c13620a549970/page.htm;http://www.cs.uml.edu/~ge/",
        "dblp": ";131/4844;25/2228",
        "google_scholar": ";8q8-yYcAAAAJ;XRGH69EAAAAJ",
        "orcid": "0000-0002-2820-5273;0000-0002-5715-5092;0000-0003-2225-8291",
        "linkedin": ";;",
        "or_profile": "~Yahong_Lian1;~Chunyao_Song1;~Tingjian_Ge1",
        "aff": "Nankai University;Nankai University;University of Massachusetts at Lowell",
        "aff_domain": "nankai.edu.cn;nankai.edu.cn;uml.edu",
        "position": "PhD student;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nlian2025itmprec,\ntitle={{ITMPR}ec: Intention-based Targeted Multi-round Proactive Recommendation},\nauthor={Yahong Lian and Chunyao Song and Tingjian Ge},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MipDf3C38E}\n}",
        "github": "",
        "project": "",
        "reviewers": "zD5H;LZK5;YFKe;kLzQ;GEaM",
        "site": "https://openreview.net/forum?id=MipDf3C38E",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6",
        "technical_quality": "3;4;5;4;5",
        "scope": "3;3;4;4;4",
        "confidence": "4;3;2;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.294174202707276
    },
    {
        "id": "MrY7zuMy5p",
        "title": "Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental Health Meme Classification",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The expression of mental health symptoms through non-traditional means, such as memes, has gained remarkable attention over the past few years, with users often highlighting their mental health struggles through figurative intricacies within memes. While humans rely on commonsense knowledge to interpret these complex expressions,\u00a0current Multimodal Language Models (MLMs) struggle to capture these figurative aspects inherent in memes. To address this gap, we introduce a novel dataset, AxiOM, derived from the GAD anxiety questionnaire, which categorizes memes into six fine-grained anxiety symptoms. Next, we propose a commonsense and domain-enriched framework, M3H, to enhance MLMs\u2019 ability to interpret figurative language and commonsense knowledge. The overarching goal remains to first understand and then classify the mental health symptoms expressed in memes. We benchmark M3H against 6 competitive baselines (with 20 variations), demonstrating substantial improvements in both quantitative and qualitative metrics, including a detailed human evaluation. We observe a clear improvement of 4.20% and 4.66% on weighted-F1 metric. To assess the generalizability, we perform extensive experiments on a publicly available dataset, RESTORE, for depressive symptom identification, presenting an extensive ablation study that highlights the contribution of each module in both datasets. Our findings reveal key limitations in existing models and the advantage of employing commonsense understanding to enhance figurative understanding.",
        "keywords": "Meme;Mental Health;Classification;Commonsense",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Abdullah Mazhar;Zuhair Hasan Shaik;Aseem Srivastava;Polly Ruhnke;Lavanya Vaddavalli;Sri Keshav Katragadda;Shweta Yadav;Md Shad Akhtar",
        "authorids": "~Abdullah_Mazhar1;~Zuhair_Hasan_Shaik2;~Aseem_Srivastava1;~Polly_Ruhnke1;~Lavanya_Vaddavalli1;~Sri_Keshav_Katragadda1;~Shweta_Yadav1;~Md_Shad_Akhtar1",
        "gender": "M;M;M;F;F;M;;",
        "homepage": ";https://zuhashaik.github.io/;https://as3eem.github.io;;;;https://shwetanlp.github.io/;",
        "dblp": ";384/9570;;;;;206/5459;184/8579.html",
        "google_scholar": ";hisrasAAAAAJ;kgykojoAAAAJ;;;;dMK8VBkAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0002-4344-271X;;;;;0000-0003-0001-4464;",
        "linkedin": "abdullah-mazhar-129259164/;zuhashaik/;https://linkedin.com/in/as3eem;polly-ruhnke-573440224/;lavanya-vaddavalli-184a88126/;keshav51/;;",
        "or_profile": "~Abdullah_Mazhar1;~Zuhair_Hasan_Shaik2;~Aseem_Srivastava1;~Polly_Ruhnke1;~Lavanya_Vaddavalli1;~Sri_Keshav_Katragadda1;~Shweta_Yadav1;~Md_Shad_Akhtar1",
        "aff": "Indraprastha Institute of Information Technology, Delhi;Mohamed bin Zayed University of Artificial Intelligence+Microsoft Research+Indian Institute of Information Technology Dharwad;Mohamed bin Zayed University of Artificial Intelligence+Indraprastha Institute of Information Technology, Delhi;;University of Illinois at Chicago;;University of Illinois at Chicago;Indraprastha Institute of Information Technology, Delhi",
        "aff_domain": "iiitd.ac.in;mbzuai.ac.ae+research.microsoft.com+iiitdwd.ac.in;mbzuai.ac.ae+iiitd.ac.in;;uic.edu;;uic.edu;iiitd.ac.in",
        "position": "PhD student;Researcher+Intern+Undergrad student;Postdoc+PhD student;;MS student;;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nmazhar2025figurativecumcommonsense,\ntitle={Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental Health Meme Classification},\nauthor={Abdullah Mazhar and Zuhair Hasan Shaik and Aseem Srivastava and Polly Ruhnke and Lavanya Vaddavalli and Sri Keshav Katragadda and Shweta Yadav and Md Shad Akhtar},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MrY7zuMy5p}\n}",
        "github": "",
        "project": "",
        "reviewers": "auoU;LrKG;PB7X",
        "site": "https://openreview.net/forum?id=MrY7zuMy5p",
        "pdf_size": 0,
        "novelty": "5;5;6",
        "technical_quality": "3;5;4",
        "scope": "4;4;4",
        "confidence": "4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            4.0,
            0.816496580927726
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5000000000000001
    },
    {
        "id": "MyywdOeyn0",
        "title": "LargePiG for Hallucination-Free Query Generation: Your Large Language Model is Secretly a Pointer Generator",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent research on query generation has focused on using Large Language Models (LLMs), which despite bringing state-of-the-art performance, also introduce issues with hallucinations in the generated queries. In this work, we introduce relevance hallucination and factuality hallucination as a new typology for hallucination problems brought by query generation based on LLMs. We propose an effective way to separate content from form in LLM-generated queries, which preserves the factual knowledge extracted and integrated from the inputs and compiles the syntactic structure, including function words, using the powerful linguistic capabilities of the LLM. Specifically, we introduce a model-agnostic and training-free method that turns the **Large** Language Model into a **P**o**i**nter-**G**enerator (**LargePiG**), where the pointer attention distribution leverages the LLM's inherent attention weights, and the copy probability is derived from the difference between the vocabulary distribution of the model\u2019s high layers and the last layer. To validate the effectiveness of LargePiG, we constructed two datasets for assessing the hallucination problems in query generation, covering both document and video scenarios. Empirical studies on various LLMs demonstrated the superiority of LargePiG on both datasets. Additional experiments also verified that LargePiG could reduce hallucination in large vision language models and improve the accuracy of document-based question answering and factuality evaluation tasks.",
        "keywords": "Query Generation;Hallucination;Pointer Generator",
        "primary_area": "",
        "supplementary_material": "",
        "author": "ZhongXiang Sun;Zihua Si;Xiaoxue Zang;Kai Zheng;Yang Song;Xiao Zhang;Jun Xu",
        "authorids": "~ZhongXiang_Sun2;~Zihua_Si1;~Xiaoxue_Zang1;~Kai_Zheng1;~Yang_Song6;~Xiao_Zhang7;~Jun_Xu1",
        "gender": "M;M;;M;M;M;M",
        "homepage": "https://jeryi-sun.github.io/;;;;http://sonyis.me;https://pinkfloyd1989.github.io/Xiao_Zhang/;https://gsai.ruc.edu.cn/~junxu",
        "dblp": "300/7634;;;73/3928-7.html;24/4470-8;49/4478-34;90/514-1",
        "google_scholar": "4n5whr0AAAAJ;https://scholar.google.com/citations?hl=zh-CN;;https://scholar.google.com/citations?hl=zh-CN;tvWB_yUAAAAJ;https://scholar.google.com.hk/citations?user=5FZ6wbAAAAAJ;su14mcEAAAAJ",
        "orcid": "0000-0002-6109-4704;;;;;0000-0001-7397-5632;",
        "linkedin": ";;;;;;",
        "or_profile": "~ZhongXiang_Sun2;~Zihua_Si1;~Xiaoxue_Zang1;~Kai_Zheng1;~Yang_Song6;~Xiao_Zhang7;~Jun_Xu1",
        "aff": "Renmin University of China;Renmin University of China;;Kuaishou;Kuaishou Technology;Renmin University of China;Renmin University of China",
        "aff_domain": "ruc.edu.cn;ruc.edu.cn;;kuaishou.com;kuaishou.com;ruc.edu.cn;ruc.edu.cn",
        "position": "PhD student;MS student;;Researcher;VP of Engineering;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nsun2025largepig,\ntitle={LargePiG for Hallucination-Free Query Generation: Your Large Language Model is Secretly a Pointer Generator},\nauthor={ZhongXiang Sun and Zihua Si and Xiaoxue Zang and Kai Zheng and Yang Song and Xiao Zhang and Jun Xu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MyywdOeyn0}\n}",
        "github": "",
        "project": "",
        "reviewers": "Dqyd;jkN1;boKf;mbLP",
        "site": "https://openreview.net/forum?id=MyywdOeyn0",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "3;5;4;6",
        "scope": "3;4;4;4",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "MzdHvKQz8y",
        "title": "Before & After: The Effect of EU's 2022 Code of Practice on Disinformation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Over the past few years, the European Commission has made significant steps to reduce disinformation in cyberspace. One of those steps has been the introduction of the 2022 \"Strengthened Code of Practice on Disinformation\". Signed by leading online platforms, this Strengthened Code of Practice on Disinformation is an attempt to combat disinformation on the Web. The Code of Practice includes a variety of measures including the demonetization of disinformation, urging, for example, advertisers \"to avoid the placement of advertising next to Disinformation content\".\n\nIn this work, we set out to explore what was the impact of the Code of Practice and especially to explore to what extent ad networks continue to advertise on dis-/mis-information sites. We perform a historical analysis and find that, although at a hasty glance things may seem to be improving, there is really no significant reduction in the amount of advertising relationships among popular misinformation websites and major ad networks. In fact, we show that ad networks have withdrawn mostly from unpopular misinformation websites with very few visitors, but still form relationships with highly unreliable websites that account for the majority of misinformation traffic. To make matters worse, we show that ad networks continue to place advertisements of legitimate companies next to misinformation content. In fact we show that major ad networks place ads in almost 400 misinformation websites of our dataset.",
        "keywords": "Disinformation;Online Advertising;Code of Practice on Disinformation;ads.txt;sellers.json",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Emmanouil Papadogiannakis;Panagiotis Papadopoulos;Nicolas Kourtellis;Evangelos Markatos",
        "authorids": "~Emmanouil_Papadogiannakis1;~Panagiotis_Papadopoulos1;~Nicolas_Kourtellis1;~Evangelos_Markatos1",
        "gender": "M;M;;",
        "homepage": ";;;",
        "dblp": ";130/2934;;",
        "google_scholar": "YN01tBEAAAAJ;https://scholar.google.com/citations?view_op=list_works;;Wk7e-kIAAAAJ",
        "orcid": "0000-0002-8959-2465;0000-0002-1928-6534;;",
        "linkedin": ";panos-papadopoulos-phd-7aa80560/;;",
        "or_profile": "~Emmanouil_Papadogiannakis1;~Panagiotis_Papadopoulos1;~Nicolas_Kourtellis1;~Evangelos_Markatos1",
        "aff": "University of Crete;;;",
        "aff_domain": "csd.uoc.gr;;;",
        "position": "PhD student;;;",
        "bibtex": "@inproceedings{\npapadogiannakis2025before,\ntitle={Before \\& After: The Effect of {EU}'s 2022 Code of Practice on Disinformation},\nauthor={Emmanouil Papadogiannakis and Panagiotis Papadopoulos and Nicolas Kourtellis and Evangelos Markatos},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=MzdHvKQz8y}\n}",
        "github": "",
        "project": "",
        "reviewers": "riGX;vRTb;yzmi;uUMb;sH7j",
        "site": "https://openreview.net/forum?id=MzdHvKQz8y",
        "pdf_size": 0,
        "novelty": "4;5;6;6;6",
        "technical_quality": "4;5;6;5;6",
        "scope": "4;3;4;4;4",
        "confidence": "3;2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3952847075210474
    },
    {
        "id": "N73Yz5SQK9",
        "title": "Kronecker Generative Models for Power Law Patterns in Real-World Hypergraphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Do real-world hypergraphs obey any patterns? Are power laws fundamental in hypergraphs as they are in real-world graphs? What generator can reproduce these patterns? A hypergraph is a generalization of a conventional graph, and it consists of nodes and hyperedges, with each hyperedge joining any number of nodes. Hypergraphs are adept at representing group interactions where two or more entities interact simultaneously, such as collaborative research and group discussions.\n\nIn a wide range of real-world hypergraphs, we discover power-law or log-logistic distributions in eight structural properties. To simulate these observed patterns, we introduce HyRec, a tractable and realistic generative model leveraging the Kronecker product. We mathematically demonstrate that HyRec accurately reproduces both the patterns we observed and typical evolutionary trends found in real-world hypergraphs. To fit the parameters of HyRec to large-scale hypergraphs, we design SingFit, a fast and space-efficient algorithm successfully applied to eleven real-world hypergraphs with up to one million nodes and hyperedges.\n\nThis paper makes the following contributions: (a) Discoveries: we identify multiple patterns that real-world hypergraphs obey, (b) Model: we propose HyRec, a tractable and realistic model capable of reproducing real-world hypergraphs efficiently (spec., with fewer than 1,000 parameters) with the support of SingFit, and (c) Proofs: we prove that HyRec adheres to these patterns.",
        "keywords": "Hypergraph;Structural pattern;Generative model;Kronecker graphs",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Minyoung Choe;Jihoon Ko;Taehyung Kwon;Kijung Shin;Christos Faloutsos",
        "authorids": "~Minyoung_Choe1;~Jihoon_Ko2;~Taehyung_Kwon1;~Kijung_Shin2;~Christos_Faloutsos1",
        "gender": ";;M;M;M",
        "homepage": "https://young917.github.io;;https://kbrother.github.io/;https://kijungs.github.io/;https://www.cs.cmu.edu/~christos/",
        "dblp": "283/6275;127/7344;175/2163;153/2052;f/CFaloutsos",
        "google_scholar": "BspjsQIAAAAJ;_m0bPIQAAAAJ;https://scholar.google.co.kr/citations?user=Ld_e3xIAAAAJ;https://scholar.google.co.kr/citations?user=Yp3Cz5AAAAAJ;nd8lQQIAAAAJ",
        "orcid": ";;0000-0002-6177-7329;0000-0002-2872-1526;0000-0003-2996-9790",
        "linkedin": ";;;kijungshin/;christos-faloutsos-43a7aa2/",
        "or_profile": "~Minyoung_Choe1;~Jihoon_Ko2;~Taehyung_Kwon1;~Kijung_Shin2;~Christos_Faloutsos1",
        "aff": "Korea Advanced Institute of Science & Technology;Moloco;Korea Advanced Institute of Science & Technology;Korea Advanced Institute of Science & Technology;Amazon+Carnegie Mellon University",
        "aff_domain": "kaist.ac.kr;moloco.com;kaist.ac.kr;kaist.ac.kr;amazon.com+cmu.edu",
        "position": "PhD student;Machine Learning Engineer;PhD student;Associate Professor;Researcher+Full Professor",
        "bibtex": "@inproceedings{\nchoe2025kronecker,\ntitle={Kronecker Generative Models for Power Law Patterns in Real-World Hypergraphs},\nauthor={Minyoung Choe and Jihoon Ko and Taehyung Kwon and Kijung Shin and Christos Faloutsos},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=N73Yz5SQK9}\n}",
        "github": "",
        "project": "",
        "reviewers": "njdc;coko;PJV5;Bf7c;2fRM",
        "site": "https://openreview.net/forum?id=N73Yz5SQK9",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "2;4;6;5;6",
        "scope": "3;3;3;3;3",
        "confidence": "2;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.6,
            1.4966629547095764
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6813851438692471
    },
    {
        "id": "NAKKtyXE4R",
        "title": "Provably Robust Federated Reinforcement Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Federated reinforcement learning (FRL) allows agents to jointly learn a global decision-making policy under the guidance of a central server. While FRL has advantages, its decentralized design makes it prone to poisoning attacks. To mitigate this, Byzantine-robust aggregation techniques tailored for FRL have been introduced. Yet, in our work, we reveal that these current Byzantine-robust techniques are not immune to our newly introduced Normalized attack. Distinct from previous attacks that targeted enlarging the distance of policy updates before and after an attack, our Normalized attack emphasizes on maximizing the angle of deviation between these updates. To counter these threats, we develop an ensemble FRL approach that is provably secure against both known and our newly proposed attacks. Our ensemble method involves training multiple global policies, where each is learnt by a group of agents using any foundational aggregation rule. These well-trained global policies then individually predict the action for a specific test state. The ultimate action is chosen based on a majority vote for discrete action systems or the geometric median for continuous ones. Our experimental results across different settings show that the Normalized attack can greatly disrupt non-ensemble Byzantine-robust methods, and our ensemble approach offers substantial resistance against poisoning attacks.",
        "keywords": "Federated Reinforcement Learning;Poisoning Attacks;Robustness",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Minghong Fang;Xilong Wang;Neil Zhenqiang Gong",
        "authorids": "~Minghong_Fang1;~Xilong_Wang1;~Neil_Zhenqiang_Gong1",
        "gender": "M;M;",
        "homepage": "https://minghongfang.com/;https://wxl-lxw.github.io/;",
        "dblp": "157/0863;;",
        "google_scholar": "L6vkkC8AAAAJ;LHTTGy0AAAAJ;",
        "orcid": "0000-0002-1365-3911;;",
        "linkedin": ";xilong-wang-780252226/;",
        "or_profile": "~Minghong_Fang1;~Xilong_Wang1;~Neil_Zhenqiang_Gong1",
        "aff": "University of Louisville;Duke University;",
        "aff_domain": "louisville.edu;duke.edu;",
        "position": "Assistant Professor;PhD student;",
        "bibtex": "@inproceedings{\nfang2025provably,\ntitle={Provably Robust Federated Reinforcement Learning},\nauthor={Minghong Fang and Xilong Wang and Neil Zhenqiang Gong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NAKKtyXE4R}\n}",
        "github": "",
        "project": "",
        "reviewers": "rh9F;FNid;syHo;9eoe;ytEg",
        "site": "https://openreview.net/forum?id=NAKKtyXE4R",
        "pdf_size": 0,
        "novelty": "3;3;4;6;6",
        "technical_quality": "3;3;4;6;5",
        "scope": "3;4;3;4;3",
        "confidence": "4;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8427009716003844
    },
    {
        "id": "NB9JFH6OtY",
        "title": "Broken Access: On the Challenges of Screen Reader Assisted Two-Factor and Passwordless Authentication",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In today's technology-driven world, web services have opened up new opportunities for blind and visually impaired people to interact independently. Securing interactions with these services is crucial; however, currently deployed methods of web authentication mainly concentrate on sighted users, overlooking the specific needs of the blind and visually impaired community. In this paper, we address this critical gap by investigating the security and accessibility aspects of these web authentication methods when adopted by blind and visually impaired users. We model web authentication for such users as screen reader assisted authentication and introduce an evaluation framework called Authentication Workflows Accessibility Review and Evaluation (AWARE). Using AWARE, we then systematically assessed popular PC-based and smartphone-based screen readers against different types of deployed web authentication methods, including variants of 2FA and passwordless schemes, to simulate real-world scenarios for blind and visually impaired individuals. We analyzed these screen reader assisted authentication interactions with authentication methods in three settings: using a terminal (PC) with screen readers, a combination of the terminal (PC) and smartphone with screen readers, and smartphones with integrated screen readers. The results of our study underscore significant weaknesses in all of our observed screen reader assisted authentication scenarios for real-life authentication methods. These weaknesses, encompassing specific accessibility issues caused by imprecise screen reader instructions, highlight vulnerability concerning observed scenarios for both real-world and research literature based attacks, including phishing, concurrency, fatigue, cross-service, and shoulder surfing.\n\nBroadly, our AWARE framework can be used by authentication system designers as a precursor to user studies which are typically time-consuming and tedious to perform, independently allowing to unfold security and accessibility problems early which designers can address prior to full-fledged user testing of more isolated issues.",
        "keywords": "Screen Reader Assisted Authentication;2FA/MFA Accessibility;Blind User Security;Accessible Authentication Vulnerabilities",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Md Mojibur Rahman Redoy Akanda;Ahmed Tanvir Mahdad;Nitesh Saxena",
        "authorids": "~Md_Mojibur_Rahman_Redoy_Akanda1;~Ahmed_Tanvir_Mahdad1;~Nitesh_Saxena4",
        "gender": "M;M;",
        "homepage": "https://people.tamu.edu/~redoy.akanda/;https://people.tamu.edu/~mahdad/Home.html;https://nsaxena.engr.tamu.edu/",
        "dblp": ";;25/1169.html",
        "google_scholar": "EBFFXpgAAAAJ;kzSQsk4AAAAJ;_x5BEjoAAAAJ",
        "orcid": "0000-0002-2874-316X;;",
        "linkedin": "md-akanda/;;",
        "or_profile": "~Md_Mojibur_Rahman_Redoy_Akanda1;~Ahmed_Tanvir_Mahdad1;~Nitesh_Saxena4",
        "aff": "Texas A&M University - College Station;Texas A&M University - College Station;Texas A&M University - College Station",
        "aff_domain": "tamu.edu;tamu.edu;tamu.edu",
        "position": "PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nakanda2025broken,\ntitle={Broken Access: On the Challenges of Screen Reader Assisted Two-Factor and Passwordless Authentication},\nauthor={Md Mojibur Rahman Redoy Akanda and Ahmed Tanvir Mahdad and Nitesh Saxena},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NB9JFH6OtY}\n}",
        "github": "",
        "project": "",
        "reviewers": "VU5m;Hr9H;oQCK;QfgP",
        "site": "https://openreview.net/forum?id=NB9JFH6OtY",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "3;4;6;5",
        "scope": "3;3;4;4",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "NBHOdQJ1VE",
        "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent studies have indicated that Large Language Models (LLMs) harbor an inherent understanding of truthfulness, yet often fail to express fully and generate false statements. This gap between \"knowing\" and \"telling\" poses a challenge for ensuring the truthfulness of generated content. Inspired by recent work on the practice of encoding human-interpretable concepts linearly within large language models, we treat truthfulness as a specially linearly encoded concept within LLMs, and introduce Adaptive Activation Steering (ACT), a tuning-free method that adaptively shifts LLM's activations in the \"truthful\" direction during inference. ACT addresses diverse categories of hallucinations by utilizing diverse truthfulness-related steering vectors and adjusting the steering intensity adaptively. Applied as an add-on across various models, ACT significantly improves truthfulness in LLaMA ($\\uparrow$ 142\\%), LLaMA2 ($\\uparrow$ 24\\%), Alpaca ($\\uparrow$ 36\\%), Vicuna ($\\uparrow$ 28\\%), LLaMA2-Chat ($\\uparrow$ 19\\%), and LLaMA3($\\uparrow$ 34\\%).\nFurthermore, we verify ACT's scalability across larger models (13B, 33B, 65B), underscoring the adaptability of ACT to large-scale language models.\nCode: https://anonymous.4open.science/r/ACT24.",
        "keywords": "Large Language Model;Hallucination;Tuning-Free",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tianlong Wang;Xianfeng Jiao;Yinghao Zhu;Zhongzhi Chen;Yifan He;Xu Chu;Junyi Gao;Yasha Wang;Liantao Ma",
        "authorids": "~Tianlong_Wang1;~Xianfeng_Jiao3;~Yinghao_Zhu1;~Zhongzhi_Chen1;~Yifan_He6;~Xu_Chu1;~Junyi_Gao1;~Yasha_Wang3;~Liantao_Ma1",
        "gender": "M;M;M;;M;;M;M;Not Specified",
        "homepage": ";;https://yhzhu99.github.io;https://scholar.google.com/citations?user=D3S6g3IAAAAJ&hl=en&oi=ao;https://github.com/YifanJoven;;http://aboutme.vixerunt.org;;https://scholar.google.com/citations?view_op=list_works&hl=en&user=necbkJkAAAAJ",
        "dblp": "258/5623;;98/10801;;;;236/0032;70/2725.html;193/6198",
        "google_scholar": ";oJT09LgAAAAJ;LYrsSoEAAAAJ;D3S6g3IAAAAJ;;;5-1DeBsAAAAJ;;https://scholar.google.com/citations?view_op=list_works",
        "orcid": "0009-0002-7292-6868;;0000-0002-2640-6477;;;;0000-0002-4951-8682;;0000-0001-5233-0624",
        "linkedin": ";;yinghao-zhu;;;;;;",
        "or_profile": "~Tianlong_Wang1;~Xianfeng_Jiao3;~Yinghao_Zhu1;~Zhongzhi_Chen1;~Yifan_He6;~Xu_Chu1;~Junyi_Gao1;~Yasha_Wang3;~Liantao_Ma1",
        "aff": "Peking University;;The University of Hong Kong+Beihang University;;Peking University;;University of Edinburgh;Peking University;Peking University",
        "aff_domain": "stu.pku.edu.cn;;hku.hk+buaa.edu.cn;;stu.pku.edu.cn;;ed.ac.uk;pku.edu.cn;pku.edu.cn",
        "position": "MS student;;PhD student+MS student;;MS student;;PhD student;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025adaptive,\ntitle={Adaptive Activation Steering: A Tuning-Free {LLM} Truthfulness Improvement Method for Diverse Hallucinations Categories},\nauthor={Tianlong Wang and Xianfeng Jiao and Yinghao Zhu and Zhongzhi Chen and Yifan He and Xu Chu and Junyi Gao and Yasha Wang and Liantao Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NBHOdQJ1VE}\n}",
        "github": "",
        "project": "",
        "reviewers": "81KL;5ajs;B8jV;VGKP;yU9r",
        "site": "https://openreview.net/forum?id=NBHOdQJ1VE",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "5;4;4;6;6",
        "scope": "3;2;3;4;3",
        "confidence": "2;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            5.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5590169943749476
    },
    {
        "id": "NCzoNYsX5s",
        "title": "Horizontal Federated Heterogeneous Graph Learning: A Multi-Scale Adaptive Solution to Data Distribution Challenges",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Federated heterogeneous graph learning, an extension of federated learning, enables effective representation of complex multidimensional relationships while preserving data privacy. In horizontal federated heterogeneous graph learning, data from different parties often differ in topology and semantic distributions, causing sensitivity to distribution imbalance and amplifying the complexity of the topological structure. This interaction makes it difficult for models to learn shared representations, leading to increased instability during training. To address these challenges, this paper proposes a novel multi-scale adaptive horizontal federated heterogeneous graph learning method MAFedHGL. A random masking mechanism forces the model to infer missing connections. The model also captures multi-hop and multi-path connections using high-order topology mining, enhancing robustness against structural heterogeneity. Dynamic semantic consistency modeling uses a masking matrix to recover and integrate diverse node attributes, ensuring both global and local semantic consistency. Using clustering coefficients as aggregation weights enables clients with richer structural information to contribute more effectively to the global model, improving adaptability and performance across varying data distributions in horizontal federated heterogeneous graph learning. Extensive experiments on multiple public heterogeneous graph datasets validate that the proposed method outperforms state-of-the-art methods in both performance and robustness across various data distribution scenarios.",
        "keywords": "federated heterogeneous graph learning;federated learning;heterogeneous information network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jia Wang;Yawen Li;Zhe Xue;Yingxia Shao;Zeli Guan;Wenling Li",
        "authorids": "~Jia_Wang14;~Yawen_Li3;~Zhe_Xue2;~Yingxia_Shao1;~Zeli_Guan1;~Wenling_Li1",
        "gender": "M;F;M;;M;M",
        "homepage": ";https://teacher.bupt.edu.cn/liyawen/en/index.htm;https://teacher.bupt.edu.cn/xuezhe/en/index.htm;;;https://shi.buaa.edu.cn/liwenling/zh_CN/index.htm",
        "dblp": ";30/4774-1;116/7294;;;",
        "google_scholar": "k9Vy_ykAAAAJ;;;;;",
        "orcid": ";0000-0003-2662-3444;0000-0001-6123-0043;;0000-0002-8822-0897;",
        "linkedin": ";;;;;",
        "or_profile": "~Jia_Wang14;~Yawen_Li3;~Zhe_Xue2;~Yingxia_Shao1;~Zeli_Guan1;~Wenling_Li1",
        "aff": "Beijing University of Posts and Telecommunications;Beijing University of Posts and Telecommunications;Beijing University of Posts and Telecommunications;;Beijing University of Posts and Telecommunications;Beihang University",
        "aff_domain": "bupt.edu.cn;bupt.edu.cn;bupt.edu.cn;;bupt.edu.cn;buaa.edu.cn",
        "position": "PhD student;Associate Professor;Full Professor;;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nwang2025horizontal,\ntitle={Horizontal Federated Heterogeneous Graph Learning: A Multi-Scale Adaptive Solution to Data Distribution Challenges},\nauthor={Jia Wang and Yawen Li and Zhe Xue and Yingxia Shao and Zeli Guan and Wenling Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NCzoNYsX5s}\n}",
        "github": "",
        "project": "",
        "reviewers": "FR6Y;Ud4a;bduA;sdoM",
        "site": "https://openreview.net/forum?id=NCzoNYsX5s",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "5;5;6;5",
        "scope": "3;4;4;3",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "NPjUo4aeVf",
        "title": "MDEval: Evaluating and Enhancing Markdown Awareness in Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs) are expected to offer structured Markdown responses for the sake of readability in web chatbots (e.g., ChatGPT). Although there are a myriad of metrics to evaluate LLMs, they fail to evaluate the readability from the view of output content structure. To this end, we focus on an overlooked yet important metric --- Markdown Awareness, which directly impacts the readability and structure of the content generated by these language models. In this paper, we introduce MDEval, a comprehensive benchmark to assess Markdown Awareness for LLMs, by constructing a dataset with 20K instances covering 10 subjects in English and Chinese. Unlike traditional model-based evaluations, MDEval provides excellent interpretability by combining model-based generation tasks and statistical methods. Our results demonstrate that MDEval achieves a Spearman correlation of 0.791 and an accuracy of 84.1% with human, outperforming existing methods by a large margin. Extensive experimental results also show that through fine-tuning over our proposed dataset, less performant open-source models are able to achieve comparable performance to GPT-4o in terms of Markdown Awareness. To ensure reproducibility and transparency, MDEval is open sourced at https://anonymous.4open.science/r/MDEval-Benchmark-1730/.",
        "keywords": "Large Language Models;Benchmark;Markdown Awareness;Structured Response;Web Chatbot Readability",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhongpu Chen;Yinfeng Liu;Long Shi;Zhi-Jie Wang;Xingyan Chen;Yu Zhao;Fuji Ren",
        "authorids": "~Zhongpu_Chen1;~Yinfeng_Liu2;~Long_Shi2;~Zhi-Jie_Wang2;~Xingyan_Chen1;~Yu_Zhao3;~Fuji_Ren2",
        "gender": "M;M;M;M;M;M;M",
        "homepage": "https://zhongpu.info;https://github.com/1960377635;;https://cszjwang.github.io/;https://it.swufe.edu.cn/info/1107/7804.htm;https://it.swufe.edu.cn/info/1106/7612.htm;",
        "dblp": "192/2215.html;;;26/11197.html;211/5842.html;57/2056-19;",
        "google_scholar": ";;https://scholar.google.com.hk/citations?hl=zh-CN;;zBfczkgAAAAJ;J3yW0aYAAAAJ;eyLJ0fMAAAAJ",
        "orcid": ";;;;;0000-0002-8454-0025;",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhongpu_Chen1;~Yinfeng_Liu2;~Long_Shi2;~Zhi-Jie_Wang2;~Xingyan_Chen1;~Yu_Zhao3;~Fuji_Ren2",
        "aff": "Southwest University of Finance and Economics;Southwest University of Finance and Economics;Southwest University of Finance and Economics;Chongqing University;Beijing University of Posts and Telecommunications+Southwest University of Finance and Economics;Southwest University of Finance and Economics;University of Electronic Science and Technology of China",
        "aff_domain": "swufe.edu.cn;swufe.edu.cn;swufe.edu.cn;cqu.edu.cn;bupt.edu.cn+swufe.edu.cn;swufe.edu.cn;uestc.edu.cn",
        "position": "Assistant Professor;MS student;Associate Professor;Associate Professor;Associate Professor+Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nchen2025mdeval,\ntitle={{MDE}val: Evaluating and Enhancing Markdown Awareness in Large Language Models},\nauthor={Zhongpu Chen and Yinfeng Liu and Long Shi and Zhi-Jie Wang and Xingyan Chen and Yu Zhao and Fuji Ren},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NPjUo4aeVf}\n}",
        "github": "",
        "project": "",
        "reviewers": "hYx3;PEJi;4NUu;bz9m;N2e1",
        "site": "https://openreview.net/forum?id=NPjUo4aeVf",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "3;4;4;5;6",
        "scope": "1;2;3;4;3",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            2.6,
            1.019803902718557
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.875
    },
    {
        "id": "NWcYybtI7r",
        "title": "A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Zero-shot named entity recognition (NER) aims to develop entity recognition systems from unannotated text corpora. This task presents substantial challenges due to minimal human intervention. Recent work has adapted large language models (LLMs) for zero-shot NER by crafting specialized prompt templates. And it advances the models\u2019 self-learning ability by incorporating self-annotated demonstrations. Two important challenges persist: (i) Correlations between contexts surrounding entities are overlooked, leading to wrong type predictions or entity omissions. (ii) The indiscriminate use of task demonstrations, retrieved through shallow similarity-based strategies, severely misleads the inferences made by LLMs.\n\nIn this paper, we introduce CMAS, or cooperative multi-agent system, a framework for zero-shot NER that uses the collective intelligence and tailored abilities of multiple agents to address the challenges outlined above. Cooperative multi-agent system (CMAS) has four main agents: (i) a self-annotator, (ii) a type-related feature (TRF) extractor, (iii) a demonstration discriminator, and (iv) an overall predictor. To explicitly capture correlations between contexts surrounding entities, CMAS reformulates NER into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence. Moreover, pseudo-labels for TRFs are generated using mutual-information criteria without requiring human effort, facilitating the prediction of the TRF extractor. To assess the quality of demonstrations, a demonstration discriminator is established to incorporate the self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence and enabling controllable utilization of demonstrations.\n\nExperimental results show that CMAS significantly improves zero-shot NER performance across six benchmarks, including both domain-specific and general-domain scenarios. Furthermore, CMAS demonstrates its effectiveness in few-shot settings and with various LLM backbones.",
        "keywords": "Information extraction;Named entity recognition;Zero-shot learning;Large language models;Multi-agent system",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zihan Wang;Ziqi Zhao;Yougang Lyu;Zhumin Chen;Maarten de Rijke;Zhaochun Ren",
        "authorids": "~Zihan_Wang13;~Ziqi_Zhao2;~Yougang_Lyu1;~Zhumin_Chen1;~Maarten_de_Rijke1;~Zhaochun_Ren1",
        "gender": "M;M;;;;M",
        "homepage": "https://wzh-nlp.github.io/;https://github.com/ZiqiZhao1;;https://ir.sdu.edu.cn/~zhuminchen/~zhuminchen_en.htm;https://staff.fnwi.uva.nl/m.derijke/;https://renzhaochun.github.io/",
        "dblp": "152/5077-2;;;88/1081;r/MdRijke;58/10440",
        "google_scholar": "npvYA9MAAAAJ;;;;https://scholar.google.com/citations?hl=en;fPcIPt0AAAAJ",
        "orcid": "0000-0003-0493-2668;0009-0008-3011-5745;;0000-0003-4592-4074;0000-0002-1086-0202;0000-0002-9076-6565",
        "linkedin": ";;;;;zhaochun-ren-460491296/?locale=nl_NL",
        "or_profile": "~Zihan_Wang13;~Ziqi_Zhao2;~Yougang_Lyu1;~Zhumin_Chen1;~Maarten_de_Rijke1;~Zhaochun_Ren1",
        "aff": "University of Amsterdam;Shandong University;;Shandong University;University of Amsterdam;Leiden University",
        "aff_domain": "uva.nl;sdu.edu.cn;;sdu.edu.cn;uva.nl;liacs.leidenuniv.nl",
        "position": "PhD student;MS student;;Full Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nwang2025a,\ntitle={A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition},\nauthor={Zihan Wang and Ziqi Zhao and Yougang Lyu and Zhumin Chen and Maarten de Rijke and Zhaochun Ren},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NWcYybtI7r}\n}",
        "github": "",
        "project": "",
        "reviewers": "TKZu;HkrK;ukEa",
        "site": "https://openreview.net/forum?id=NWcYybtI7r",
        "pdf_size": 0,
        "novelty": "3;5;5",
        "technical_quality": "4;6;5",
        "scope": "3;4;3",
        "confidence": "3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.333333333333333,
            0.9428090415820634
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5
    },
    {
        "id": "NdudrFgLmT",
        "title": "Cutting through the Confusion: A Measurement Study of Homograph Domains in Ethereum Name Service",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In recent years, the Ethereum Name Service (ENS) has garnered significant attention within the community for enabling the use of Unicode in domain names, thereby facilitating the inclusion of a wide array of character sets such as Greek, Cyrillic, Arabic, and Chinese.\nWhile this feature enhances the versatility and global accessibility of domain names, it concurrently introduces a substantial security\nvulnerability due to the presence of homoglyphs\u2014characters that are visually similar to others across Unicode and ASCII sets. These\nsimilarities can be exploited in homoglyph attacks, posing a distinct threat to domain name integrity. This study investigates the prevalence and security implications of homoglyph domains within the ENS ecosystem, revealing that these domains present a more\npronounced security concern compared to their counterparts in the traditional Domain Name System (DNS). Despite community efforts to counteract this issue through a normalization process prior to domain resolution, our analysis uncovers significant discrepancies in how the normalization processes are applied across various applications. This inconsistency could result in the same domain name being resolved to different addresses in different applications, underscoring a critical vulnerability. To systematically evaluate this inconsistency, we designed a tool for detecting application-level discrepancies in domain normalization process without requiring access to the application\u2019s source code. Our evaluation on hundreds of real-world Web3 applications identifies widespread deviations from established homoglyph mitigation practices, with more than 60% digital wallets and 80% dApps (decentralized applications) not able to produce consistent ENS resolving results, potentially impacting millions of users. This analysis underscores the urgent need for a standardized implementation of normalization processes to safeguard the integrity and security of ENS domains.",
        "keywords": "Ethereum Name Service;Homoglyph Attack",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jianwei Huang;Sridatta Raghavendra Chintapalli;Mengxiao Wang;Guofei Gu",
        "authorids": "~Jianwei_Huang2;~Sridatta_Raghavendra_Chintapalli1;~Mengxiao_Wang1;~Guofei_Gu1",
        "gender": "M;M;M;M",
        "homepage": ";https://acelab.tamu.edu/people-all/;https://jackson-cmd.github.io/;http://faculty.cs.tamu.edu/guofei/",
        "dblp": ";;;64/1147",
        "google_scholar": "SsyfuP4AAAAJ;;;https://scholar.google.com.tw/citations?user=SRC3O-4AAAAJ",
        "orcid": ";;;",
        "linkedin": ";sridatta-raghavendra-chintapalli/;;",
        "or_profile": "~Jianwei_Huang2;~Sridatta_Raghavendra_Chintapalli1;~Mengxiao_Wang1;~Guofei_Gu1",
        "aff": "Texas A&M University - College Station;;Texas A&M University - College Station;Texas A&M University - College Station",
        "aff_domain": "tamu.edu;;tamu.edu;tamu.edu",
        "position": "PhD student;;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025cutting,\ntitle={Cutting through the Confusion: A Measurement Study of Homograph Domains in Ethereum Name Service},\nauthor={Jianwei Huang and Sridatta Raghavendra Chintapalli and Mengxiao Wang and Guofei Gu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NdudrFgLmT}\n}",
        "github": "",
        "project": "",
        "reviewers": "FfKc;Z4i6;MmVy;22AZ;FeZZ",
        "site": "https://openreview.net/forum?id=NdudrFgLmT",
        "pdf_size": 0,
        "novelty": "2;4;4;5;5",
        "technical_quality": "3;3;4;4;5",
        "scope": "4;3;3;3;3",
        "confidence": "4;3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            3.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7319250547113999
    },
    {
        "id": "NeLC3TDnvV",
        "title": "ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the proliferation of images in online content, language-guided image retrieval (LGIR) has emerged as a research hotspot over the past decade, encompassing a variety of subtasks with diverse input forms. While the development of large multimodal models (LMMs) has significantly facilitated these tasks, existing approaches often address them in isolation, requiring the construction of separate systems for each task. This not only increases system complexity and maintenance costs, but also exacerbates challenges stemming from language ambiguity and complex image content, making it difficult for retrieval systems to provide accurate and reliable results. To this end, we propose ImageScope, a training-free, three-stage framework that leverages collective reasoning to unify LGIR tasks. The key insight behind the unification lies in the compositional nature of language, which transforms diverse LGIR tasks into a generalized text-to-image retrieval process, along with the reasoning of LMMs serving as a universal verification to refine the results. To be specific, in the first stage, we improve the robustness of the framework by synthesizing search intents across varying levels of semantic granularity using chain-of-thought (CoT) reasoning. In the second and third stages, we then reflect on retrieval results by verifying predicate propositions locally, and performing pairwise evaluations globally. Experiments conducted on six LGIR datasets demonstrate that ImageScope outperforms competitive baselines. Comprehensive evaluations and ablation studies further confirm the effectiveness of our design.",
        "keywords": "Language-Guided Image Retrieval;Large Multimodal Model;Collective Reasoning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Pengfei Luo;Jingbo Zhou;Tong Xu;Yuan Xia;Linli Xu;Enhong Chen",
        "authorids": "~Pengfei_Luo1;~Jingbo_Zhou1;~Tong_Xu2;~Yuan_Xia1;~Linli_Xu1;~Enhong_Chen1",
        "gender": ";M;M;M;;M",
        "homepage": "https://github.com/pengfei-luo;https://zhoujingbo.github.io/;http://staff.ustc.edu.cn/~tongxu/;;;http://staff.ustc.edu.cn/~cheneh",
        "dblp": "119/0304;82/8538;70/6770-1.html;120/8069;;07/258",
        "google_scholar": "jENHDFcAAAAJ;;;ld7Nk-UAAAAJ;;Q9h02J0AAAAJ",
        "orcid": "0000-0003-0889-7660;0000-0003-2677-7021;0000-0003-4246-5386;;;0000-0002-4835-4102",
        "linkedin": ";;;;;",
        "or_profile": "~Pengfei_Luo1;~Jingbo_Zhou1;~Tong_Xu2;~Yuan_Xia1;~Linli_Xu1;~Enhong_Chen1",
        "aff": "University of Science and Technology of China;Baidu Research+National University of Singapore;University of Science and Technology of China;Baidu;;University of Science and Technology of China",
        "aff_domain": "mail.ustc.edu.cn;baidu.com+nus.edu.sg;ustc.edu.cn;baidu.com;;ustc.edu.cn",
        "position": "PhD student;Researcher+Postdoc;Full Professor;Researcher;;Full Professor",
        "bibtex": "@inproceedings{\nluo2025imagescope,\ntitle={ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning},\nauthor={Pengfei Luo and Jingbo Zhou and Tong Xu and Yuan Xia and Linli Xu and Enhong Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=NeLC3TDnvV}\n}",
        "github": "",
        "project": "",
        "reviewers": "8JT8;zD7a;CVkx;k2fy",
        "site": "https://openreview.net/forum?id=NeLC3TDnvV",
        "pdf_size": 0,
        "novelty": "4;5;6;7",
        "technical_quality": "3;4;6;7",
        "scope": "4;4;4;4",
        "confidence": "4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            5.0,
            1.5811388300841898
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7745966692414834
    },
    {
        "id": "OG1qScEqHK",
        "title": "Training-free Graph Anomaly Detection: A Simple Approach via Singular Value Decomposition",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph anomaly detection has been widely applied in real-world applications, where deep learning-based methods have demonstrated promise.\nHowever, prior methods often suffer from various limitations, such as poor detection accuracy, long training time, complicated training schemes, and lack of scalability.\nTo combat this dilemma, we propose TFGAD, a simple yet effective training-free approach for graph anomaly detection.\nParticularly, TFGAD comprises two transformation matrices, each of which serves to process one type of node feature (attributes or local structure).\nNotably, these matrices can be optimally determined via singular value decomposition, thus requiring no prior training.\nFurther, we tailor a lightweight anomaly scoring function, which integrates the reconstruction error of attributes with the projection length of local structures to quantify graph anomalies.\nExtensive experiments demonstrate that TFGAD leads to significant improvements over state-of-the-art reconstruction-/contrastive-based deep learning baselines while reaching much less runtime and memory overhead.",
        "keywords": "anomaly detection;attributed graphs;training-free;singular value decomposition",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Cheng Zhou;Gx Li;Hao Weng;Yiyu Xiang",
        "authorids": "~Cheng_Zhou9;~Gx_Li1;~Hao_Weng1;~Yiyu_Xiang1",
        "gender": ";;M;M",
        "homepage": "https://github.com/chengzhou14;;https://github.com/Amanwith;https://github.com/Yiyu-xiang",
        "dblp": ";23/8127.html;;",
        "google_scholar": ";;;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Cheng_Zhou9;~Gx_Li1;~Hao_Weng1;~Yiyu_Xiang1",
        "aff": "Xidian University;Xidian University;Xidian University;Xidian University",
        "aff_domain": "xidian.edu.cn;xidian.edu.cn;xidian.edu.cn;xidian.edu.cn",
        "position": "PhD student;Associate Professor;MS student;MS student",
        "bibtex": "@inproceedings{\nzhou2025trainingfree,\ntitle={Training-free Graph Anomaly Detection: A Simple Approach via Singular Value Decomposition},\nauthor={Cheng Zhou and Gx Li and Hao Weng and Yiyu Xiang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OG1qScEqHK}\n}",
        "github": "",
        "project": "",
        "reviewers": "F2RN;n6g2;5s9R;LJPW;cDmb",
        "site": "https://openreview.net/forum?id=OG1qScEqHK",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "3;3;5;5;5",
        "scope": "3;4;3;4;4",
        "confidence": "4;4;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.2,
            0.9797958971132712
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3429971702850177
    },
    {
        "id": "OHtjMJABg0",
        "title": "Aegis: Post-Training Attribute Unlearning in Federated Recommender Systems against Attribute Inference Attacks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As privacy concerns in recommender systems become increasingly prominent, federated recommender systems (FedRecs) have emerged as a promising distributed training paradigm. FedRecs enable the collaborative training of a shared global recommendation model without requiring the exchange of raw client interaction data. However, models trained using standard FedRec methods remain vulnerable to personal information leakage, particularly through attribute inference attacks, which can expose sensitive user attributes such as gender and race. In this paper, we address these user sensitive attributes as targets for federated unlearning. To protect users' sensitive information, attribute unlearning aims to eliminate sensitive attributes from user embeddings, thereby preventing inference attacks while preserving recommendation performance. We introduce a novel post-training federated unlearning framework, Aegis, which performs unlearning based on private attribute requests after the model has been trained, minimizing the degradation in recommendation accuracy. Aegis employs an information-theoretic multi-component loss function to balance privacy protection and recommendation performance. Additionally, Aegis adapts to scenarios where training interaction data may be unavailable, reflecting real-world centralized protection scenarios. Comprehensive evaluations on various benchmark datasets demonstrate that our proposed method effectively safeguards user privacy while maintaining high-quality recommendations.",
        "keywords": "Federated Unlearning;",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenhan Wu;Jiawei Jiang;Chuang Hu",
        "authorids": "~Wenhan_Wu4;~Jiawei_Jiang1;~Chuang_Hu1",
        "gender": "M;M;M",
        "homepage": ";http://bluesjjw.github.io/;",
        "dblp": ";185/1521-1;188/0034",
        "google_scholar": ";G_Hg-j0AAAAJ;",
        "orcid": "0009-0008-7090-3666;0000-0003-0051-0046;0000-0002-9051-3242",
        "linkedin": ";;",
        "or_profile": "~Wenhan_Wu4;~Jiawei_Jiang1;~Chuang_Hu1",
        "aff": "Wuhan University;Wuhan University;University of Macau",
        "aff_domain": "whu.edu;whu.edu.cn;um.edu.mo",
        "position": "MS student;Full Professor;Researcher",
        "bibtex": "@inproceedings{\nwu2025aegis,\ntitle={Aegis: Post-Training Attribute Unlearning in Federated Recommender Systems against Attribute Inference Attacks},\nauthor={Wenhan Wu and Jiawei Jiang and Chuang Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OHtjMJABg0}\n}",
        "github": "",
        "project": "",
        "reviewers": "H3vh;UVkF;SKiN;vJDK;Dw4G",
        "site": "https://openreview.net/forum?id=OHtjMJABg0",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "3;4;6;5;5",
        "scope": "4;3;4;4;3",
        "confidence": "3;4;4;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            1.0954451150103321
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.22821773229381925
    },
    {
        "id": "OJNhyGPVlw",
        "title": "Leveraging heterogeneous spillover in maximizing contextual bandit rewards",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recommender systems relying on contextual multi-armed bandits continuously improve relevant item recommendations by taking into account the contextual information. The objective of bandit algorithms is to learn the best arm (e.g., best item to recommend) for each user and thus maximize the cumulative rewards from user engagement with the recommendations. The context that these algorithms typically consider are the user and item attributes. However, in the context of social networks where $\\textit{the action of one user can influence the actions and rewards of other users,}$ neighbors' actions are also a very important context, as they can have not only predictive power but also can impact future rewards through spillover. Moreover, influence susceptibility can vary for different people based on their preferences and the closeness of ties to other users which leads to heterogeneity in the spillover effects. Here, we present a framework that allows contextual multi-armed bandits to account for such heterogeneous spillovers when choosing the best arm for each user. Our experiments on several semi-synthetic and real-world datasets show that our framework leads to significantly higher rewards than existing state-of-the-art solutions that ignore the network information and potential spillover.",
        "keywords": "recommender systems;multi-armed bandits;information diffusion;social networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "AHMED SAYEED FARUK;Elena Zheleva",
        "authorids": "~AHMED_SAYEED_FARUK1;~Elena_Zheleva1",
        "gender": "M;F",
        "homepage": ";http://www.cs.uic.edu/~elena",
        "dblp": ";01/5750.html",
        "google_scholar": "mdMOOAUAAAAJ;https://scholar.google.com.tw/citations?user=Ug7VoyQAAAAJ",
        "orcid": "0009-0005-5823-1623;",
        "linkedin": "ahmed-sayeed-faruk/?originalSubdomain=bd;",
        "or_profile": "~AHMED_SAYEED_FARUK1;~Elena_Zheleva1",
        "aff": "University of Illinois at Chicago;University of Illinois Chicago",
        "aff_domain": "uic.edu;uic.edu",
        "position": "PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nfaruk2025leveraging,\ntitle={Leveraging heterogeneous spillover in maximizing contextual bandit rewards},\nauthor={AHMED SAYEED FARUK and Elena Zheleva},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OJNhyGPVlw}\n}",
        "github": "",
        "project": "",
        "reviewers": "g5gp;wHGM;brgb;Zisf;Y3mM",
        "site": "https://openreview.net/forum?id=OJNhyGPVlw",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "5;5;5;4;6",
        "scope": "3;4;4;4;4",
        "confidence": "2;3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8451542547285165
    },
    {
        "id": "OLLYLTb8FC",
        "title": "HySAE: An Efficient Semantic-Enhanced Representation Learning Model for Knowledge Hypergraph Link Prediction",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Representation learning technique is an effective link prediction paradigm to alleviate the incompleteness of knowledge hypergraphs. However, the $n$-ary complex semantic information inherent in knowledge hypergraphs causes existing methods to face the dual limitations of weak effectiveness and low efficiency. In this paper, we propose a novel knowledge hypergraph representation learning model, HySAE, which can achieve a satisfactory trade-off between effectiveness and efficiency. Concretely, HySAE builds an efficient semantic-enhanced 3D scalable end-to-end embedding architecture to sufficiently capture knowledge hypergraph $n$-ary complex semantic information with fewer parameters, which can significantly reduce the computational cost of the model. In particular, we also design an efficient position-aware entity role semantic embedding way and two enhanced semantic learning strategies to further improve the effectiveness and scalability of our proposed method. Extensive experimental results on all datasets demonstrate that HySAE consistently outperforms state-of-the-art baselines, with an average improvement of 9.15\\%, a maximum improvement of 39.44\\%, an average 10.39x faster, and 75.79\\% fewer parameters.",
        "keywords": "Knowledge Hypergraph;Knowledge Representation Learning;Link Prediction",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhao Li;Xin Wang;Zhao Jun;Feng Feng;Zirui Chen;Jianxin Li",
        "authorids": "~Zhao_Li11;~Xin_Wang39;~Zhao_Jun2;~Feng_Feng2;~Zirui_Chen1;~Jianxin_Li4",
        "gender": ";M;M;M;M;M",
        "homepage": ";http://www.tjudb.cn/dbgroup/Xin_Wang;https://em.nxu.edu.cn/info/1568/8794.htm;;http://github.com/zirui-chen;https://www.deakin.edu.au/about-deakin/people/jianxin-li",
        "dblp": ";10/5630-30;;;;l/JianxinLi",
        "google_scholar": ";https://scholar.google.com/citations?hl=en;;;;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0001-9651-0651;;0009-0009-7060-1841;;0000-0002-9059-330X",
        "linkedin": ";;;;;",
        "or_profile": "~Zhao_Li11;~Xin_Wang39;~Zhao_Jun2;~Feng_Feng2;~Zirui_Chen1;~Jianxin_Li4",
        "aff": ";Tianjin University;;;Tianjin University;Edith Cowan University",
        "aff_domain": ";tju.edu.cn;;;tju.edu.cn;ecu.edu.au",
        "position": ";Full Professor;;;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nli2025hysae,\ntitle={Hy{SAE}: An Efficient Semantic-Enhanced Representation Learning Model for Knowledge Hypergraph Link Prediction},\nauthor={Zhao Li and Xin Wang and Zhao Jun and Feng Feng and Zirui Chen and Jianxin Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OLLYLTb8FC}\n}",
        "github": "",
        "project": "",
        "reviewers": "AYUf;VtDF;mq6S;ikyX;42xt",
        "site": "https://openreview.net/forum?id=OLLYLTb8FC",
        "pdf_size": 0,
        "novelty": "3;4;6;7;7",
        "technical_quality": "4;5;6;6;7",
        "scope": "4;4;4;3;4",
        "confidence": "4;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            1.624807680927192
        ],
        "technical_quality_avg": [
            5.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2010075630518424
    },
    {
        "id": "OPevCIS7X4",
        "title": "Catalysts of Conversation: Examining Interaction Dynamics Between Topic Initiators and Commentors in Alzheimer's Disease Online Communities",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Informal caregivers (e.g.,family members or friends) of people living with Alzheimer\u2019s Disease and Related Dementias (ADRD) face substantial challenges and often seek informational or emotional support through online communities.\nUnderstanding the factors that drive engagement within these platforms is crucial, as it can enhance their long-term value for caregivers by ensuring that these communities effectively meet their needs.\n\nThis study investigated the user interaction dynamics within two large, popular ADRD communities, TalkingPoint and ALZConnected, focusing on topic initiator engagement, initial post content, and the linguistic patterns of comments at the thread level. Using analytical methods such as propensity score matching, topic modeling, and predictive modeling, we found that active topic initiator engagement drives higher comment volumes, and reciprocal replies from topic initiators encourage further commentor engagement at the community level. Practical caregiving topics prompt more re-engagement of topic initiators, while emotional support topics attract more comments from other commentors. Additionally, the linguistic complexity and emotional tone of a comment influence its likelihood of receiving replies from topic initiators. \n\nThese findings highlight the importance of fostering active and reciprocal engagement and providing effective strategies to enhance sustainability in ADRD caregiving and broader health-related online communities.",
        "keywords": "Alzheimer's Disease;Online Communities;Informal Caregivers;User Engagement;Social Media Analytics",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Congning Ni;Qingxia Chen;Lijun Song;Patricia Commiskey;Qingyuan Song;Bradley A. Malin;Zhijun Yin",
        "authorids": "~Congning_Ni1;~Qingxia_Chen1;~Lijun_Song2;~Patricia_Commiskey1;~Qingyuan_Song1;~Bradley_Malin1;~Zhijun_Yin2",
        "gender": "F;F;F;F;M;;M",
        "homepage": ";https://www.vumc.org/biostatistics/person/qingxia-cindy-chen#:~:text=Qingxia%20%22Cindy%22%20Chen.%20PhD,;https://my.vanderbilt.edu/lijunsong/;;;;",
        "dblp": ";;;;;;",
        "google_scholar": "ovVin3oAAAAJ;DgLgzKEAAAAJ#:~:text=Articles%201%E2%80%9320.%20%E2%80%AAProfessor%20of;267kOgIAAAAJ;;;;6-3JvK8AAAAJ",
        "orcid": "0000-0001-6950-6948;0000-0003-0507-1847;;0000-0001-6376-4698;0000-0002-2999-8690;;",
        "linkedin": "congning-ni/;;;;;;",
        "or_profile": "~Congning_Ni1;~Qingxia_Chen1;~Lijun_Song2;~Patricia_Commiskey1;~Qingyuan_Song1;~Bradley_Malin1;~Zhijun_Yin2",
        "aff": "Vanderbilt University;Vanderbilt University Medical Center;Vanderbilt University;Vanderbilt University;Vanderbilt University;;Vanderbilt University Medical Center",
        "aff_domain": "vanderbilt.edu;vumc.org;vanderbilt.edu;vanderbilt.edu;vanderbilt.edu;;vumc.org",
        "position": "PhD student;Full Professor;Associate Professor;Researcher;PhD student;;Assistant Professor",
        "bibtex": "@inproceedings{\nni2025catalysts,\ntitle={Catalysts of Conversation: Examining Interaction Dynamics Between Topic Initiators and Commentors in Alzheimer's Disease Online Communities},\nauthor={Congning Ni and Qingxia Chen and Lijun Song and Patricia Commiskey and Qingyuan Song and Bradley A. Malin and Zhijun Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OPevCIS7X4}\n}",
        "github": "",
        "project": "",
        "reviewers": "gmrb;EXmt;PnWG;5L7n;vjvS",
        "site": "https://openreview.net/forum?id=OPevCIS7X4",
        "pdf_size": 0,
        "novelty": "3;3;4;5;6",
        "technical_quality": "5;4;4;3;6",
        "scope": "2;2;4;4;3",
        "confidence": "3;3;4;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.4,
            1.019803902718557
        ],
        "scope_avg": [
            3.0,
            0.8944271909999159
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2711630722733202
    },
    {
        "id": "OnR2dQHuTU",
        "title": "ODNS Clustering: Unveiling Client-side Dependency in Open DNS Infrastructure",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "There are over a million open DNS servers in the wild. However, not all servers perform recursive queries directly. Instead, many DNS forwarders forward queries to upstream recursive servers or other DNS forwarders for name resolving on their behalf. \nThe groups of open servers that have such dependencies on each other form ODNS Clusters. The dependencies can result in vulnerabilities; yet we have little knowledge of the ODNS cluster structure. \nIn this work, we measure the inter-dependence of open DNS resolvers and find that 1.9 million open DNS servers form only 81,636 ODNS clusters. We further analyze the characteristics of the clustered ODNS structure. The key observations include biased cluster size distribution, discrepancy of ODNS infrastructures among countries, concentration in major public DNS server providers, and potential security and resilience risks due to the dependence.",
        "keywords": "DNS infrastructure; Open resolver; Internet Measurement;",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenhao Wu;Zhaohua Wang;Li Qinxin;Zihan Li;Yi Li;Jin Yan;Zhenyu Li",
        "authorids": "~Wenhao_Wu15;~Zhaohua_Wang1;~Li_Qinxin1;~Zihan_Li14;~Yi_Li32;~Jin_Yan2;~Zhenyu_Li2",
        "gender": "M;;F;M;;F;M",
        "homepage": "https://f-555.github.io;;https://www.ict.ac.cn/;https://github.com/AIandLCC;;;https://zhenyulee.github.io",
        "dblp": ";;;;;;58/5750-1",
        "google_scholar": "kWDaPREAAAAJ;;;;;;",
        "orcid": ";0000-0002-8733-4841;;;;0009-0003-8693-4639;",
        "linkedin": ";;;;;;",
        "or_profile": "~Wenhao_Wu15;~Zhaohua_Wang1;~Li_Qinxin1;~Zihan_Li14;~Yi_Li32;~Jin_Yan2;~Zhenyu_Li2",
        "aff": "University of Chinese Academy of Sciences+Institute of Computing Technology, Chinese Academy of Sciences;Computer Network Information Center, Chinese Academy of Sciences;, Chinese Academy of Sciences;Chinese Academy of Sciences; University of Chinese Academy of Sciences;;;",
        "aff_domain": "ucas.ac.cn+ict.ac.cn;cnic.cn;ict.ac.cn;ict.ac.cn;;;",
        "position": "PhD student+PhD student;Postdoc;MS student;PhD student;;;",
        "bibtex": "@inproceedings{\nwu2025odns,\ntitle={{ODNS} Clustering: Unveiling Client-side Dependency in Open {DNS} Infrastructure},\nauthor={Wenhao Wu and Zhaohua Wang and Li Qinxin and Zihan Li and Yi Li and Jin Yan and Zhenyu Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=OnR2dQHuTU}\n}",
        "github": "",
        "project": "",
        "reviewers": "gH6n;Vu5U;hhJ2;PP2s;qUHA",
        "site": "https://openreview.net/forum?id=OnR2dQHuTU",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "3;3;5;6;5",
        "scope": "3;3;3;4;3",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.4,
            1.2
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8134892168199606
    },
    {
        "id": "P0a179w9wS",
        "title": "Online bidding under RoS constraints without knowing the value",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We consider the problem of bidding in online advertising, where an advertiser aims to maximize value while adhering to budget and Return-on-Spend (RoS) constraints.  Unlike prior work that assumes knowledge of the value generated by winning each impression ({e.g.,} conversions), we address the more realistic setting where the advertiser must simultaneously learn the optimal bidding strategy and the value of each impression opportunity. This introduces a challenging exploration-exploitation dilemma: the advertiser must balance exploring different bids to estimate impression values with exploiting current knowledge to bid effectively. To address this, we propose a novel Upper Confidence Bound (UCB)-style algorithm that carefully manages this trade-off. Via a rigorous theoretical analysis, we prove that our algorithm achieves  $\\tilde{O}(\\sqrt{T\\log(|\\mathcal{B}|T)})$ regret and constraint violation, where $T$ is the number of bidding rounds and $\\mathcal{B}$ is the domain of possible bids. This  establishes the first optimal regret and constraint violation bounds for bidding in the online setting with unknown impression values. Moreover, our algorithm is computationally efficient and  simple to implement.  We validate our theoretical findings through experiments on synthetic data, demonstrating that our algorithm exhibits strong empirical performance compared to existing approaches.",
        "keywords": "autobidding;online bidding;RoS;return on spend;constrained bandits;UCB",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sushant Vijayan;Zhe Feng;Swati Padmanabhan;Karthikeyan Shanmugam;Arun Suggala;Di Wang",
        "authorids": "~Sushant_Vijayan1;~Zhe_Feng3;~Swati_Padmanabhan1;~Karthikeyan_Shanmugam1;~Arun_Suggala1;~Di_Wang4",
        "gender": "M;M;F;M;M;",
        "homepage": ";https://scholar.harvard.edu/zfeng/home;https://web.mit.edu/pswt/www/;https://sites.google.com/corp/view/karthikeyan-shanmugam/;;",
        "dblp": ";36/1508-4;237/9510;;164/7327;",
        "google_scholar": ";MKbTrgIAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.ca/citations?user=m4DyPcUAAAAJ;CKgmfDMAAAAJ;",
        "orcid": ";;;0009-0008-2879-5868;;",
        "linkedin": "sushant-vijayan-3574886a/;;;;;",
        "or_profile": "~Sushant_Vijayan1;~Zhe_Feng3;~Swati_Padmanabhan1;~Karthikeyan_Shanmugam1;~Arun_Suggala1;~Di_Wang4",
        "aff": "Tata Institute of Fundamental Research;Google;Massachusetts Institute of Technology+University of Washington;Google Deepmind;Google;",
        "aff_domain": "tifr.res.edu;google.com;mit.edu+uw.edu;google.com;google.com;",
        "position": "PhD student;Researcher;Postdoc+PhD student;Researcher;Researcher;",
        "bibtex": "@inproceedings{\nvijayan2025online,\ntitle={Online bidding under RoS constraints without knowing the value},\nauthor={Sushant Vijayan and Zhe Feng and Swati Padmanabhan and Karthikeyan Shanmugam and Arun Suggala and Di Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=P0a179w9wS}\n}",
        "github": "",
        "project": "",
        "reviewers": "pkJi;k6Qq;anHM;ryeb;PQFo",
        "site": "https://openreview.net/forum?id=P0a179w9wS",
        "pdf_size": 0,
        "novelty": "2;4;5;5;5",
        "technical_quality": "3;5;5;4;5",
        "scope": "3;4;4;3;4",
        "confidence": "3;3;4;1;4",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            1.0954451150103321
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "P0v1DmKrHq",
        "title": "Spache: Accelerating Ubiquitous Web Browsing via Schedule-Driven Space Caching",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In this paper, we perform a systematic study to explore a pivotal problem facing the web community: is current distributed web cache ready for future satellite Internet? First, through a worldwide performance measurement based on the RIPE Atlas platform and Starlink, the largest low-earth orbit (LEO) satellite network (LSN) today, we identify that the uneven deployment of current distributed cache servers, inter-ISP meandering routes and the last-mile congestion on LEO links prevent existing terrestrial web cache from providing low-latency web access for users in emerging LSNs. Second, we propose Spache, a novel web caching system which addresses the limitations of existing ground-only cache by exploiting a bold idea: integrating web cache into LEO satellites to achieve ubiquitous and low-latency web services. Specifically, Spache leverages a key feature of LSNs called communication schedule to efficiently prefetch web contents on satellites, and adopts a schedule-driven partitioning strategy to avoid cache pollution involved by LEO mobility. Finally, we implement a prototype of Spache, and evaluate it based on real-world HTTP traces and real-data-driven LSN simulation. Extensive evaluations demonstrate that as compared to existing distributed caching solutions, Spache can improve cache hit ratio by 19.8% on average, reduce latency by up to 17.7%, and sustain consistently low user-to-cache latency for global LSN users.",
        "keywords": "LEO;Cache;Satellite Networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qi Zhang;Qian Wu;Zeqi Lai;Jihao Li;Hewu Li;Yuyu liu;Yuanjie Li;Jun Liu",
        "authorids": "~Qi_Zhang45;~Qian_Wu8;~Zeqi_Lai2;~Jihao_Li2;~Hewu_Li1;~Yuyu_liu3;~Yuanjie_Li3;~Jun_Liu28",
        "gender": ";F;M;;;;M;F",
        "homepage": ";https://www.insc.tsinghua.edu.cn/info/1157/2452.htm;https://lzq8272587.github.io/;;;;http://www.yuanjiel.com;https://www.insc.tsinghua.edu.cn/info/1157/2459.htm",
        "dblp": ";;;;;;;95/3736-63",
        "google_scholar": ";;https://scholar.google.com.hk/citations?user=rH0hRIcAAAAJ;2Ws8ov0AAAAJ;;;;",
        "orcid": "0009-0008-3148-6003;;;;;;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Qi_Zhang45;~Qian_Wu8;~Zeqi_Lai2;~Jihao_Li2;~Hewu_Li1;~Yuyu_liu3;~Yuanjie_Li3;~Jun_Liu28",
        "aff": "Zhongguancun Laboratory;Tsinghua University;;Zhongguancun Laboratory;;;Tsinghua University;Tsinghua University",
        "aff_domain": "zgclab.edu.cn;tsinghua.edu.cn;;zgclab.edu.cn;;;tsinghua.edu.cn;tsinghua.edu.cn",
        "position": "Researcher;Associate Professor;;Assistant Professor;;;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nzhang2025spache,\ntitle={Spache: Accelerating Ubiquitous Web Browsing via Schedule-Driven Space Caching},\nauthor={Qi Zhang and Qian Wu and Zeqi Lai and Jihao Li and Hewu Li and Yuyu liu and Yuanjie Li and Jun Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=P0v1DmKrHq}\n}",
        "github": "",
        "project": "",
        "reviewers": "53K6;gySG;eypN;UbAU;V4LB",
        "site": "https://openreview.net/forum?id=P0v1DmKrHq",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "5;4;4;7;6",
        "scope": "4;4;3;4;4",
        "confidence": "2;4;1;1;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.0,
            1.0954451150103321
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6123724356957946
    },
    {
        "id": "P0x8J5gCPP",
        "title": "The Poorest Man in Babylon: A Longitudinal Study of Cryptocurrency Investment Scams",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Governments and regulatory bodies have recognized investment scams as the most prevalent forms of cryptocurrency fraud. These scams typically use professional-looking websites to lure unsuspecting victims with promises of unrealistically high returns. In this paper, we introduce Crimson, a distributed system designed to continuously detect cryptocurrency investment scam websites as they are created in the wild. Over the first 8 months of 2024, Crimson processed approximately 6 billion domain names and classified 43, 572 unique cryptocurrency investment scam websites in real-time. Beyond detection, we provide insights into the design and infrastructure of these websites that can help users recognize scam patterns and assist hosting providers in detecting and blocking such sites. Among others, we discovered that most investment scam websites use similar templates and that 52% of all scam websites were hosted on just 10% of all resolved IP addresses, indicating a concentration of scam operations within a small subset of hosting providers. Furthermore, we investigate the inclusion of our detected scam websites in blacklists used by popular web browsers and applications, finding that the vast majority of these websites were absent. On the financial side, by analyzing the incoming transactions to scammer wallets on 6.7% of the sites detected by Crimson, we observe an estimated lower bound of 2.04M USD in losses because of cryptocurrency investment scams, pointing to tens of millions of dollars of losses in total.",
        "keywords": "Cryptocurrency;Scam;Ethereum;Bitcoin",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Muhammad Muzammil;Abisheka Pitumpe;Xigao Li;Amir Rahmati;Nick Nikiforakis",
        "authorids": "~Muhammad_Muzammil1;~Abisheka_Pitumpe1;~Xigao_Li1;~Amir_Rahmati1;~Nick_Nikiforakis2",
        "gender": ";F;M;M;",
        "homepage": "https://muhammad-muzammil.github.io/;https://abisheka-pitumpe.github.io/;https://xigaoli.com;https://amir.rahmati.com;https://securitee.org/",
        "dblp": ";;;125/0358;",
        "google_scholar": "r2KdqeMAAAAJ;E6B4GhAAAAAJ;;_Y_YRLAAAAAJ;VgrmjeYAAAAJ",
        "orcid": ";0009-0001-3962-7092;;0000-0001-7361-1898;",
        "linkedin": ";abisheka-pitumpe/;;ameerr/;",
        "or_profile": "~Muhammad_Muzammil1;~Abisheka_Pitumpe1;~Xigao_Li1;~Amir_Rahmati1;~Nick_Nikiforakis2",
        "aff": ", State University of New York at Stony Brook;, State University of New York at Stony Brook;Meta Facebook;State University of New York, Stony Brook+Stony Brook University;Stony Brook University",
        "aff_domain": "cs.stonybrook.edu;cs.stonybrook.edu;meta.com;stonybrook.edu+cs.stonybrook.edu;cs.stonybrook.edu",
        "position": "PhD student;PhD student;Researcher;Assistant Professor+Assistant Professor;Associate Professor",
        "bibtex": "@inproceedings{\nmuzammil2025the,\ntitle={The Poorest Man in Babylon: A Longitudinal Study of Cryptocurrency Investment Scams},\nauthor={Muhammad Muzammil and Abisheka Pitumpe and Xigao Li and Amir Rahmati and Nick Nikiforakis},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=P0x8J5gCPP}\n}",
        "github": "",
        "project": "",
        "reviewers": "6kXF;bh5t;Sd6M;v8ox;vyfj",
        "site": "https://openreview.net/forum?id=P0x8J5gCPP",
        "pdf_size": 0,
        "novelty": "4;4;4;6;6",
        "technical_quality": "4;4;4;6;6",
        "scope": "4;4;3;4;4",
        "confidence": "4;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.16666666666666666
    },
    {
        "id": "POGlYL3YxN",
        "title": "CATALOG: Exploiting Joint Temporal Dependencies for Enhanced Phishing Detection on Ethereum",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Phishing attacks on Ethereum have increased with its growing adoption, creating significant challenges as phishing and non-phishing\nusers often display similar behavior. Additionally, while the network as a whole experiences high activity, individual user behavior\nis typically sparse, making it difficult to detect phishing patterns. Current methods frequently fail to tackle these challenges and often\nneglect the temporal sequence of transactions, resulting in data leakage and reduced performance. In this paper, we propose a novel\napproach that addresses these gaps by focusing on the association of two key aspects: (1) local temporal behavior fluctuations of individual users and (2) deviations from global transaction patterns within the network. To aim this, we introduce CATALOG (CApturing joint TemporAl dependencies from LOcal and Global user behaviour), a novel representation learning model that jointly captures the local and global behavioral patterns of a user and their correlations by leveraging a dual cross-attention mechanism paired with a bi-directional Masked Language Modelling (MLM) based pipelined transformer framework. Our proposed model simultaneously learns from local behavioral shifts and global market trends along with a contextually enriched embeddings, effectively distinguishing phishing from non-phishing users, while addressing the existing research gaps. Extensive experiments on real-world Ethereum transaction data show that our framework improves phishing detection by 7-8% in F1-Score compared to existing models. Furthermore, it generalizes effectively across Ethereum versions 1.0 and 2.0, demonstrating the robustness of our approach.",
        "keywords": "Ethereum;Phishing Scams;Security;Representation Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Medhasree Ghosh;Swapnil Srivastava;Apoorva Upadhyaya;Raju Halder;Joydeep Chandra",
        "authorids": "~Medhasree_Ghosh1;~Swapnil_Srivastava1;~Apoorva_Upadhyaya1;~Raju_Halder1;~Joydeep_Chandra1",
        "gender": "F;M;F;M;M",
        "homepage": ";;;https://www.iitp.ac.in/~halder/;https://www.iitp.ac.in/~joydeep",
        "dblp": ";;https://dblp.org/search?q=apoorva+upadhyaya;;59/4869.html",
        "google_scholar": "DsGb9mgAAAAJ;;kRwvOfUAAAAJ;https://scholar.google.com/citations?hl=en;42t8V90AAAAJ",
        "orcid": "0000-0002-0106-6912;0009-0004-2860-7645;;0000-0002-8873-8258;0000-0001-5994-9024",
        "linkedin": "medhasree-ghosh-080018233;swapnil-srivastava-933176229/;;;",
        "or_profile": "~Medhasree_Ghosh1;~Swapnil_Srivastava1;~Apoorva_Upadhyaya1;~Raju_Halder1;~Joydeep_Chandra1",
        "aff": "Indian Institute of Technology, Patna, Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of Technology, Patna, Dhirubhai Ambani Institute Of Information and Communication Technology;L3S Research Center, Leibniz University Hannover+L3S Research Center, Leibniz University Hannover;Indian Institute of Technology, Patna, Dhirubhai Ambani Institute Of Information and Communication Technology;Indian Institute of Technology, Patna",
        "aff_domain": "iitp.ac.in;iitp.ac.in;l3s.de+l3s.de;iitp.ac.in;iitp.ac.in",
        "position": "PhD student;Undergrad student;PhD student+Researcher;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nghosh2025catalog,\ntitle={{CATALOG}: Exploiting Joint Temporal Dependencies for Enhanced Phishing Detection on Ethereum},\nauthor={Medhasree Ghosh and Swapnil Srivastava and Apoorva Upadhyaya and Raju Halder and Joydeep Chandra},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=POGlYL3YxN}\n}",
        "github": "",
        "project": "",
        "reviewers": "gSip;878E;9K2D;hNbs",
        "site": "https://openreview.net/forum?id=POGlYL3YxN",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "5;5;5;6",
        "scope": "3;4;4;3",
        "confidence": "3;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6622661785325219
    },
    {
        "id": "PcoMtzeNk3",
        "title": "Dynamic Graph Unlearning: A General and Efficient Post-Processing Method via Gradient Transformation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Dynamic graph neural networks (DGNNs) have emerged and been widely deployed in various web applications (e.g., Reddit) to serve users (e.g., personalized content delivery) due to their remarkable ability to learn from complex and dynamic user interaction data. Despite benefiting from high-quality services, users have raised privacy concerns, such as misuse of personal data (e.g., dynamic user-user/item interaction) for model training, requiring DGNNs to ''forget'' their data to meet AI governance laws (e.g., the ''right to be forgotten\" in GDPR). However, current static graph unlearning studies cannot $\\textit{unlearn dynamic graph elements}$ and exhibit limitations such as the model-specific design or reliance on pre-processing, which disenable their practicability in dynamic graph unlearning. To this end, we study the dynamic graph unlearning for the first time and propose an $\\textit{effective}$, $\\textit{efficient}$, $\\textit{general}$, and $\\textit{post-processing}$ method to implement DGNN unlearning. Specifically, we first formulate dynamic graph unlearning in the context of continuous-time dynamic graphs, and then propose a method called Gradient Transformation that directly maps the unlearning request to the desired parameter update. Comprehensive evaluations on six real-world datasets and state-of-the-art DGNN backbones demonstrate its effectiveness (e.g., limited drop or obvious improvement in utility) and efficiency (e.g., 7.23$\\times$ speed-up) advantages. Additionally, our method has the potential to handle future unlearning requests with significant performance gains (e.g., 32.59$\\times$ speed-up).",
        "keywords": "Dynamic Graphs;Unlearning;Privacy;GNN;Trustworthiness",
        "primary_area": "",
        "supplementary_material": "",
        "author": "He Zhang;Bang Wu;Xiangwen Yang;Xingliang YUAN;Xiaoning Liu;Xun Yi",
        "authorids": "~He_Zhang4;~Bang_Wu1;~Xiangwen_Yang1;~Xingliang_YUAN2;~Xiaoning_Liu1;~Xun_Yi1",
        "gender": ";M;M;;F;M",
        "homepage": ";;;http://xyuancs.github.io;;https://www.rmit.edu.au/contact/staff-contacts/academic-staff/y/yi-professor-xun",
        "dblp": ";;;21/8884;51/5617-2;94/4423",
        "google_scholar": ";XwgdW5sAAAAJ;;https://scholar.google.com.hk/citations?user=81yWaCoAAAAJ;https://scholar.google.com.au/citations?user=hjxSs-UAAAAJ;https://scholar.google.ca/citations?user=oDRazncAAAAJ",
        "orcid": ";0009-0001-0204-7246;;0000-0002-3701-4946;;0000-0001-7351-5724",
        "linkedin": ";;xiangwen-yang-272572158;;;",
        "or_profile": "~He_Zhang4;~Bang_Wu1;~Xiangwen_Yang1;~Xingliang_YUAN2;~Xiaoning_Liu1;~Xun_Yi1",
        "aff": ";Royal Melbourne Institute of Technology;Monash University;University of Melbourne;Royal Melbourne Institute of Technology;Royal Melbourne Institute of Technology",
        "aff_domain": ";rmit.edu.au;monash.edu;unimelb.edu.au;rmit.edu.au;rmit.edu.au",
        "position": ";Lecturer;Software Programmer;Associate Professor;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025dynamic,\ntitle={Dynamic Graph Unlearning: A General and Efficient Post-Processing Method via Gradient Transformation},\nauthor={He Zhang and Bang Wu and Xiangwen Yang and Xingliang YUAN and Xiaoning Liu and Xun Yi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=PcoMtzeNk3}\n}",
        "github": "",
        "project": "",
        "reviewers": "jvaN;KXMb;PZ82;L9ja;wrki",
        "site": "https://openreview.net/forum?id=PcoMtzeNk3",
        "pdf_size": 0,
        "novelty": "3;5;5;6;6",
        "technical_quality": "4;5;5;4;6",
        "scope": "4;4;4;4;1",
        "confidence": "3;2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.4,
            1.2
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.372677996249965
    },
    {
        "id": "PrmAeIReL1",
        "title": "MER-Inspector: Assessing Model Extraction Risks from An Attack-Agnostic Perspective",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Information leakage issues in machine learning-based Web applications have attracted increasing attention. While the risk of data privacy leakage has been rigorously analyzed, the theory of model function leakage, known as Model Extraction Attacks (MEAs), has not been well studied. In this paper, we are the first to understand MEAs theoretically from an attack-agnostic perspective and to propose analytical metrics for evaluating model extraction risks. By using the Neural Tangent Kernel (NTK) theory, we formulate the linearized MEA as a regularized kernel classification problem and then derive the fidelity gap and generalization error bounds of the attack performance. Based on these theoretical analyses, we propose a new theoretical metric called Model Recovery Complexity (MRC), which measures the distance of weight changes between the victim and surrogate models to quantify risk. Additionally, we find that victim model accuracy, which shows a strong positive correlation with model extraction risk, can serve as an empirical metric. By integrating these two metrics, we propose a framework, namely Model Extraction Risk Inspector (MER-Inspector), to compare the extraction risks of models under different model architectures by utilizing relative metric values. We conduct extensive experiments on 16 model architectures and 5 datasets. The experimental results demonstrate that the proposed metrics have a high correlation with model extraction risks, and MER-Inspector can accurately compare the extraction risks of any two models with up to 89.58\\%.",
        "keywords": "Model extraction attacks;neural tangent kernel;model extraction risk;risk measure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinwei Zhang;Haibo Hu;Qingqing Ye;Li Bai;Huadi Zheng",
        "authorids": "~Xinwei_Zhang5;~Haibo_Hu2;~Qingqing_Ye1;~Li_Bai3;~Huadi_Zheng1",
        "gender": "M;M;F;F;M",
        "homepage": "https://xinweizhang1998.github.io/;https://www.haibohu.org;https://www.qingqingye.net/;https://bailibl.github.io/;https://scholar.google.com.hk/citations?user=PB_khhQAAAAJ&hl=en",
        "dblp": "55/9870-2;90/5236-1;194/0001-1;181/2902-4;198/9507.html",
        "google_scholar": "OdBgAwkAAAAJ;N3DjoZYAAAAJ;u9xzOh4AAAAJ;;",
        "orcid": "0000-0002-1267-5182;0000-0002-9008-2112;0000-0003-1547-2847;0000-0002-7202-3178;",
        "linkedin": ";haibo-hu-33b09419/;;;",
        "or_profile": "~Xinwei_Zhang5;~Haibo_Hu2;~Qingqing_Ye1;~Li_Bai3;~Huadi_Zheng1",
        "aff": "Hong Kong Polytechnic University;Hong Kong Polytechnic University;The Hong Kong Polytechnic University;Hong Kong Polytechnic University;Hong Kong Science and Technology Park",
        "aff_domain": "polyu.edu.hk;polyu.edu.hk;polyu.edu.hk;polyu.edu.hk;hkstp.org",
        "position": "PhD student;Full Professor;Assistant Professor;PhD student;Researcher",
        "bibtex": "@inproceedings{\nzhang2025merinspector,\ntitle={{MER}-Inspector: Assessing Model Extraction Risks from An Attack-Agnostic Perspective},\nauthor={Xinwei Zhang and Haibo Hu and Qingqing Ye and Li Bai and Huadi Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=PrmAeIReL1}\n}",
        "github": "",
        "project": "",
        "reviewers": "qPyH;dMCo;Tbpt;CeZ8;CePH",
        "site": "https://openreview.net/forum?id=PrmAeIReL1",
        "pdf_size": 0,
        "novelty": "4;4;5;6;7",
        "technical_quality": "5;3;6;5;6",
        "scope": "3;3;4;3;3",
        "confidence": "2;3;4;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.04583492485141057
    },
    {
        "id": "PsVEUofCZE",
        "title": "Generating with Fairness: A Modality-Diffused Counterfactual Framework for Incomplete Multimodal Recommendations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Incomplete scenario is a prevalent, practical, yet challenging setting in Multimodal Recommendations (MMRec), where some item modalities are missing due to various factors. Recently, a few efforts have sought to improve the recommendation accuracy by exploring generic structures from incomplete data. However, two significant gaps persist: 1) the difficulty in accurately generating missing data due to the limited ability to capture modality distributions; and 2) the critical but overlooked visibility bias, where items with missing modalities are more likely to be disregarded due to the prioritization of items' multimodal data over user preference alignment. This bias raises serious concerns about the fair treatment of items. To bridge these two gaps, we propose a novel Modality-Diffused Counterfactual (MoDiCF) framework for incomplete multimodal recommendations. MoDiCF features two key modules: a novel modality-diffused data completion module and a new counterfactual multimodal recommendation module. The former, equipped with a particularly designed multimodal generative framework, accurately generates and iteratively refines missing data from learned modality-specific distribution spaces. The latter, grounded in the causal perspective, effectively mitigates the negative causal effects of visibility bias and thus assures fairness in recommendations. Both modules work collaboratively to address the two aforementioneds significant gaps for generating more accurate and fair results. Extensive experiments on three real-world datasets demonstrate the superior performance of MoDiCF in terms of both recommendation accuracy and fairness. The code and processed datasets are released at https://anonymous.4open.science/r/MoDiCF-EEF5.",
        "keywords": "Multimodal recommendations;Missing modalities;Visibility bias",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jin Li;Shoujin Wang;Qi Zhang;Shui Yu;Fang Chen",
        "authorids": "~Jin_Li5;~Shoujin_Wang1;~Qi_Zhang25;~Shui_Yu1;~Fang_Chen3",
        "gender": "M;M;M;M;F",
        "homepage": "https://www.linkedin.com/in/jin-li-8a698a290/;https://shoujinwang1.github.io/;https://sites.google.com/view/qizhang-bit-uts/home;;https://profiles.uts.edu.au/Fang.Chen",
        "dblp": "48/1097-28;16/8492;52/323-20;90/3575-1.html;52/488-1.html",
        "google_scholar": "jmIpUa0AAAAJ;BQ0mBRIAAAAJ;8UAk1p4AAAAJ;_WbktxMAAAAJ;EMVGAKgAAAAJ",
        "orcid": "0000-0001-5737-3594;0000-0003-1133-9379;0000-0002-1037-1361;;0000-0003-4971-8729",
        "linkedin": ";;;;",
        "or_profile": "~Jin_Li5;~Shoujin_Wang1;~Qi_Zhang25;~Shui_Yu1;~Fang_Chen3",
        "aff": "University of Technology Sydney;University of Technology Sydney;Tongji University;University of Technology Sydney;University of Technology Sydney (UTS)+University of New South Wales",
        "aff_domain": "student.uts.edu.au;uts.edu.au;tongji.edu.cn;uts.edu.au;uts.eud.au+unsw.edu.au",
        "position": "PhD student;Lecturer;Researcher;Full Professor;Full Professor+Full Professor",
        "bibtex": "@inproceedings{\nli2025generating,\ntitle={Generating with Fairness: A Modality-Diffused Counterfactual Framework for Incomplete Multimodal Recommendations},\nauthor={Jin Li and Shoujin Wang and Qi Zhang and Shui Yu and Fang Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=PsVEUofCZE}\n}",
        "github": "",
        "project": "",
        "reviewers": "7P8P;YRPU;w9qJ",
        "site": "https://openreview.net/forum?id=PsVEUofCZE",
        "pdf_size": 0,
        "novelty": "4;5;5",
        "technical_quality": "5;4;5",
        "scope": "4;3;4",
        "confidence": "4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9999999999999998
    },
    {
        "id": "QOMe82Z4pa",
        "title": "Joint Optimal Transport and Embedding for Network Alignment",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Network alignment, which aims to find node correspondence across different networks, is the cornerstone of various downstream multi-network and Web mining tasks. Most of the embedding-based methods indirectly model cross-network node relationships by contrasting positive and negative node pairs sampled from hand-crafted strategies, which are vulnerable to graph noises and leads to potential misalignment of nodes. Another line of works based on the optimal transport (OT) theory directly model cross-network node relationships and generate noise-reduced alignments. However, OT methods heavily rely on fixed, pre-defined cost functions that prohibit end-to-end training and are hard to generalize. In this paper, we aim to unify the embedding and OT-based methods in a mutually beneficial manner and propose a joint optimal transport and embedding framework for network alignment named JOENA. For one thing (OT for embedding), through a simple yet effective transformation, the noise-reduced OT mapping serves as an adaptive sampling strategy directly modeling all cross-network node pairs for robust embedding learning. For another (embedding for OT), on top of the learned node embeddings, the OT cost can be gradually trained along the learning process in an end-to-end fashion, which further enhances the alignment quality. With a unified objective, the mutual benefits of both methods can be achieved by an alternating optimization schema with guaranteed convergence. Extensive experiments on real-world networks validate the effectiveness and scalability of JOENA, achieving up to 16% improvement in MRR and 20 times speedup compared with the state-of-the-art alignment methods.",
        "keywords": "Network Alignment;Optimal Transport;Network Embedding",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qi Yu;Zhichen Zeng;Yuchen Yan;Lei Ying;R. Srikant;Hanghang Tong",
        "authorids": "~Qi_Yu8;~Zhichen_Zeng1;~Yuchen_Yan1;~Lei_Ying1;~R._Srikant1;~Hanghang_Tong3",
        "gender": "M;;;M;;",
        "homepage": ";https://zhichenz98.github.io/;;http://leiying.engin.umich.edu/;;http://tonghanghang.org",
        "dblp": ";345/6632-1;;27/4818;s/RSrikant;58/1757",
        "google_scholar": "6cyMsFUAAAAJ;rFdX368AAAAJ;;7f3HKI8AAAAJ;;RaINcuUAAAAJ",
        "orcid": ";0000-0002-5534-3401;;;;0000-0003-4405-3887",
        "linkedin": "qi-leo-yu/;;;;;htong/",
        "or_profile": "~Qi_Yu8;~Zhichen_Zeng1;~Yuchen_Yan1;~Lei_Ying1;~R._Srikant1;~Hanghang_Tong3",
        "aff": "University of Illinois Urbana-Champaign;University of Illinois Urbana-Champaign;;University of Michigan, Ann Arbor;University of Illinois, Urbana Champaign+University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign",
        "aff_domain": "illinois.edu;illinois.edu;;umich.edu;+illinois.edu;illinois.edu",
        "position": "Research Assistant;PhD student;;Professor;+Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nyu2025joint,\ntitle={Joint Optimal Transport and Embedding for Network Alignment},\nauthor={Qi Yu and Zhichen Zeng and Yuchen Yan and Lei Ying and R. Srikant and Hanghang Tong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=QOMe82Z4pa}\n}",
        "github": "",
        "project": "",
        "reviewers": "k34y;tJwR;4qBZ;eBrw",
        "site": "https://openreview.net/forum?id=QOMe82Z4pa",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;4;5;5",
        "scope": "4;3;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "QOxEHegLSg",
        "title": "Revisiting Dynamic Graph Clustering via Matrix Factorization",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Dynamic graph clustering aims to detect and track time-varying clusters in dynamic graphs, revealing the evolutionary mechanisms of complex real-world dynamic systems. Matrix factorization-based methods are promising approaches for this task; however, these methods often struggle with scalability and can be time-consuming when applied to large-scale dynamic graphs. Moreover, they tend to lack robustness and are vulnerable to real-world noisy data. To address these issues, we make three key contributions. First, to improve scalability, we propose temporal separated matrix factorization, where a single matrix is divided into multiple smaller matrices for independent factorization, resulting in faster computation. Second, to improve robustness, we introduce bi-clustering regularization, which jointly optimizes graph embedding and clustering, thereby filtering out noisy features from the graph embeddings. Third, to further enhance effectiveness and efficiency, we propose selective embedding updating, where we update only the embeddings of dynamic nodes while the embeddings of static nodes are fixed among different timestamps. Experimental results on six synthetic and five real-world benchmarks demonstrate the scalability, robustness and effectiveness of our proposed method. Our code is available on Github https://anonymous.4open.science/r/RS-MF-50FE/README.md.",
        "keywords": "Dynamic Graph Clustering;Temporal Graphs;Dynamic Community Detection.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Dongyuan Li;Satoshi Kosugi;Ying Zhang;Manabu Okumura;Feng Xia;Renhe Jiang",
        "authorids": "~Dongyuan_Li1;~Satoshi_Kosugi1;~Ying_Zhang16;~Manabu_Okumura2;~Feng_Xia1;~Renhe_Jiang1",
        "gender": "M;;F;;M;M",
        "homepage": "https://clearloveyuan.github.io/;https://satoshi-kosugi.github.io/;https://zhangying9128.github.io/;;http://xia.ai;https://www.renhejiang.com/",
        "dblp": "23/9793;247/1236;13/6769-65;;62/3147;213/1173",
        "google_scholar": "Pgo9ZZ0AAAAJ;3RoLn48AAAAJ;tbDNsHsAAAAJ;;HDFA2VYAAAAJ;Yo2lwasAAAAJ",
        "orcid": "0000-0002-4462-3563;;0009-0000-9627-8768;;0000-0002-8324-1859;0000-0003-2593-4638",
        "linkedin": "dongyuan-li-2471b726b/?originalSubdomain=jp;;;;fxia61;renhejiang/",
        "or_profile": "~Dongyuan_Li1;~Satoshi_Kosugi1;~Ying_Zhang16;~Manabu_Okumura2;~Feng_Xia1;~Renhe_Jiang1",
        "aff": "The University of Tokyo+Institute of Science Tokyo;Tokyo Institute of Technology+Institute of Science Tokyo;RIKEN;;Royal Melbourne Institute of Technology;The University of Tokyo",
        "aff_domain": "u-tokyo.ac.jp+titech.ac.jp;titech.ac.jp+isct.ac.jp;riken.jp;;rmit.edu.au;u-tokyo.ac.jp",
        "position": "Assistant Professor+Researcher;Assistant Professor+Assistant Professor;Postdoc;;Full Professor;Lecturer",
        "bibtex": "@inproceedings{\nli2025revisiting,\ntitle={Revisiting Dynamic Graph Clustering via Matrix Factorization},\nauthor={Dongyuan Li and Satoshi Kosugi and Ying Zhang and Manabu Okumura and Feng Xia and Renhe Jiang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=QOxEHegLSg}\n}",
        "github": "",
        "project": "",
        "reviewers": "56Cn;jDbX;Q3Mz;43zU;2Pin",
        "site": "https://openreview.net/forum?id=QOxEHegLSg",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "5;5;5;4;6",
        "scope": "4;4;3;3;4",
        "confidence": "3;2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.16666666666666663
    },
    {
        "id": "Qr0SUHj72t",
        "title": "Worst-Case-Optimal Joins on Graphs with Topological Relations",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Spatial data play an important role in many applications built over knowledge graphs, and are frequently referenced in queries posed to public query services, such as that of Wikidata. Querying for spatial data presents a significant challenge, as dealing with topological relations such as adjacent or contains implies dealing with inferred information, such as through the transitivity of the containment relation. However, despite all the recent advances in querying knowledge graphs, we still lack techniques specifically tailored for topological information. Applications looking to incorporate topological relations must either materialize the inferred relations, incurring high space and maintenance overheads, or query them with less efficient recursive algorithms, incurring high runtime overheads.\n\nIn this paper we address the problem of leveraging topological information in knowledge graphs by designing efficient algorithms to process these queries. Our solution involves building a specific index that stores the topological information in a convenient compact form, and includes specialized algorithms that infer every possible relation from the basic topological facts in the graph. We show that, while using essentially the same space required to solve standard graph pattern queries, we can incorporate topological predicates, accounting for all the inferred information, all within worst-case-optimal time. We implement our scheme and show experimentally that it outperforms baseline solutions by a notable margin.",
        "keywords": "geospatial graphs;topological graphs;graph query processing;worst-case optimal joins",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jos\u00e9 Fuentes-Sep\u00falveda;Adri\u00e1n G\u00f3mez-Brand\u00f3n;Aidan Hogan;Ayleen Irribarra-Cort\u00e9s;Gonzalo Navarro;Juan L Reutter",
        "authorids": "~Jos\u00e9_Fuentes-Sep\u00falveda1;~Adri\u00e1n_G\u00f3mez-Brand\u00f3n1;~Aidan_Hogan1;~Ayleen_Irribarra-Cort\u00e9s1;~Gonzalo_Navarro2;~Juan_L_Reutter1",
        "gender": ";M;M;F;M;M",
        "homepage": ";;http://aidanhogan.com/;;http://www.dcc.uchile.cl/gnavarro;http://jreutter.sitios.ing.uc.cl/",
        "dblp": ";;h/AidanHogan;;;36/27",
        "google_scholar": "https://scholar.google.cl/citations?user=fms2_fYAAAAJ;6l2H9P8AAAAJ;http://scholar.google.com/citations?user=CP-fgY4AAAAJ;;;",
        "orcid": "0000-0002-3962-6495;0000-0002-1216-2176;0000-0001-9482-1982;0009-0005-3288-9590;;",
        "linkedin": ";;;;;",
        "or_profile": "~Jos\u00e9_Fuentes-Sep\u00falveda1;~Adri\u00e1n_G\u00f3mez-Brand\u00f3n1;~Aidan_Hogan1;~Ayleen_Irribarra-Cort\u00e9s1;~Gonzalo_Navarro2;~Juan_L_Reutter1",
        "aff": "Universidad de Concepcion;Universidad de La Coru\u00f1a;DCC, Universidad de Chile;Universidad de Concepcion;Universidad de Chile;Pontificia Universidad Cat\u00f3lica",
        "aff_domain": "udec.cl;udc.es;uchile.cl;udec.cl;uchile.cl;uc.cl",
        "position": "Assistant Professor;Assistant Professor;Associate Professor;PhD student;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nfuentes-sepulveda2025worstcaseoptimal,\ntitle={Worst-Case-Optimal Joins on Graphs with Topological Relations},\nauthor={Jos{\\'e} Fuentes-Sep{\\'u}lveda and Adri{\\'a}n G{\\'o}mez-Brand{\\'o}n and Aidan Hogan and Ayleen Irribarra-Cort\u00e9s and Gonzalo Navarro and Juan L Reutter},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Qr0SUHj72t}\n}",
        "github": "",
        "project": "",
        "reviewers": "nAT9;DM3r;se8L;dpCy",
        "site": "https://openreview.net/forum?id=Qr0SUHj72t",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "6;6;6;6",
        "scope": "2;3;3;4",
        "confidence": "2;1;2;1",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            6.0,
            0.0
        ],
        "scope_avg": [
            3.0,
            0.7071067811865476
        ],
        "confidence_avg": [
            1.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "QtYgNQhEFX",
        "title": "Roles of Network and Identity in Hashtag Diffusion",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The diffusion of culture online (e.g., hashtags) is theorized to be influenced by many interacting social factors (e.g., network _and_ identity). However, most existing computational cascade models model just a single factor (e.g., network _or_ identity). This work offers a new framework for teasing apart the mechanisms underlying hashtag cascades. We curate a new dataset of 1,337 hashtags representing cultural innovation online, develop a 10-factor evaluation framework for comparing empirical and synthetic cascades, and show that a combined network+identity model performs better than a network- or identity-only counterfactual. We also explore the heterogeneity in this result: While a combined network+identity model best predicts the popularity of cascades, a network-only model has better performance in predicting cascade growth and an identity-only model in adopter composition. The network+identity model most strongly outperforms the counterfactuals among hashtags used for expressing racial or regional identity and talking about sports or news. In fact, we are able to predict what combination of network and/or identity best models each hashtag and use this to further improve performance. In sum, our results imply the utility of multi-factor models in predicting cascades, in order to account for the varied ways in which network, identity, and other social factors play a role in the diffusion of hashtags on Twitter.",
        "keywords": "information diffusion;hashtags;social networks;social identity;Twitter",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Aparna Ananthasubramaniam;Yufei Louise Zhu;David Jurgens;Daniel Romero",
        "authorids": "~Aparna_Ananthasubramaniam1;~Yufei_Louise_Zhu1;~David_Jurgens1;~Daniel_Romero1",
        "gender": ";F;M;M",
        "homepage": ";;http://jurgens.people.si.umich.edu;https://www.si.umich.edu/people/daniel-romero/",
        "dblp": ";;48/4613.html;",
        "google_scholar": ";nsLGt4UAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.com.tw/citations?user=c4M3MQoAAAAJ",
        "orcid": ";0000-0003-1166-2133;0000-0002-2135-9878;",
        "linkedin": ";yufei-louise-zhu-umich/;;",
        "or_profile": "~Aparna_Ananthasubramaniam1;~Yufei_Louise_Zhu1;~David_Jurgens1;~Daniel_Romero1",
        "aff": ";;University of Michigan - Ann Arbor;University of Michigan - Ann Arbor",
        "aff_domain": ";;umich.edu;umich.edu",
        "position": ";;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nananthasubramaniam2025roles,\ntitle={Roles of Network and Identity in Hashtag Diffusion},\nauthor={Aparna Ananthasubramaniam and Yufei Louise Zhu and David Jurgens and Daniel Romero},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=QtYgNQhEFX}\n}",
        "github": "",
        "project": "",
        "reviewers": "DSp6;14Yp;KXgt;CwtY;MMzn",
        "site": "https://openreview.net/forum?id=QtYgNQhEFX",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "3;4;6;5;6",
        "scope": "3;2;3;3;4",
        "confidence": "4;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6454972243679028
    },
    {
        "id": "Qu2itILaoZ",
        "title": "WeInfer: Unleashing the Power of WebGPU on LLM Inference in Web Browsers",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Web-based large language model (LLM) has garnered significant attention from both academia and industry due to its potential to combine the benefits of on-device computation with the accessibility and portability of Web applications. The advent of WebGPU, a modern browser API that enables Web applications to access and utilize a device's GPU, has opened up new possibilities for GPU-accelerated LLM inference within browsers. Several frameworks have been developed to support Web-based LLM inference with WebGPU. However, our experiment reveals that these frameworks exhibit inefficiencies in GPU utilization, influencing the LLM inference speed. These inefficiencies primarily arise from underutilizing the full capabilities of WebGPU, particularly in resource management and execution synchronization. To address these limitations, we present WeInfer, an efficient Web-based LLM inference framework specifically designed to unleash the power of WebGPU. WeInfer incorporates two key innovations: 1) buffer reuse strategies that reduce the overhead associated with resource preparation, optimizing the lifecycle management of WebGPU buffers, and 2) an asynchronous pipeline that decouples resource preparation from GPU execution, enabling parallelized computation and deferred result fetching to improve overall efficiency. We conduct extensive evaluations across 9 different LLMs and 5 heterogeneous devices, covering a broad spectrum of model architectures and hardware configurations. The experimental results demonstrate that WeInfer delivers substantial improvements in decoding speed, achieving up to a $3.76\\times$ performance boost compared with WebLLM, the state-of-the-art Web-based LLM inference framework.",
        "keywords": "Large Language Model;WebGPU;Inference Acceleration",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhiyang Chen;Yun Ma;Haiyang SHEN;Mugeng Liu",
        "authorids": "~Zhiyang_Chen3;~Yun_Ma1;~Haiyang_SHEN1;~Mugeng_Liu1",
        "gender": ";M;;M",
        "homepage": ";;;",
        "dblp": ";75/7811-2;;375/3225",
        "google_scholar": ";1hnJ3TgAAAAJ;;LzfXRiAAAAAJ",
        "orcid": ";;;0009-0002-7625-8721",
        "linkedin": ";;;",
        "or_profile": "~Zhiyang_Chen3;~Yun_Ma1;~Haiyang_SHEN1;~Mugeng_Liu1",
        "aff": ";Peking University;;Peking University",
        "aff_domain": ";pku.edu.cn;;pku.edu.cn",
        "position": ";Assistant Professor;;PhD student",
        "bibtex": "@inproceedings{\nchen2025weinfer,\ntitle={WeInfer: Unleashing the Power of Web{GPU} on {LLM} Inference in Web Browsers},\nauthor={Zhiyang Chen and Yun Ma and Haiyang SHEN and Mugeng Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Qu2itILaoZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "4uZB;64jk;feVq;jSz3",
        "site": "https://openreview.net/forum?id=Qu2itILaoZ",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "5;6;5;5",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6622661785325219
    },
    {
        "id": "QxbPLl3q8f",
        "title": "SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates. The code is available at \\url{https://anonymous.4open.science/r/SymAgent/}.",
        "keywords": "Large Language Models;Knowledge Graphs;Language Agent;Self-Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ben Liu;Jihai Zhang;Fangquan Lin;Cheng Yang;Min Peng;Wotao Yin",
        "authorids": "~Ben_Liu2;~Jihai_Zhang2;~Fangquan_Lin1;~Cheng_Yang3;~Min_Peng2;~Wotao_Yin1",
        "gender": "M;M;M;M;F;M",
        "homepage": ";https://dblp.org/pid/148/8257.html;;;;http://wotaoyin.com",
        "dblp": ";148/8257-1;279/6367.html;;;76/2265",
        "google_scholar": ";;;5QdPzoAAAAAJ;;kpQGGFUAAAAJ",
        "orcid": "0000-0001-5031-9368;;;;0000-0002-8766-1105;0000-0001-6697-9731",
        "linkedin": ";;;;;",
        "or_profile": "~Ben_Liu2;~Jihai_Zhang2;~Fangquan_Lin1;~Cheng_Yang3;~Min_Peng2;~Wotao_Yin1",
        "aff": "Wuhan University;Alibaba Group;Alibaba Group;Alibaba Group;Wuhan University;Alibaba Group US",
        "aff_domain": "whu.edu.cn;alibaba-inc.com;alibaba-inc.com;antgroup.com;whu.edu.cn;alibaba-inc.com",
        "position": "PhD student;Researcher;Researcher;Researcher;Full Professor;Principal Researcher",
        "bibtex": "@inproceedings{\nliu2025symagent,\ntitle={SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs},\nauthor={Ben Liu and Jihai Zhang and Fangquan Lin and Cheng Yang and Min Peng and Wotao Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=QxbPLl3q8f}\n}",
        "github": "",
        "project": "",
        "reviewers": "sYgg;mSzE;fXa3;kziN",
        "site": "https://openreview.net/forum?id=QxbPLl3q8f",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "4;5;6;5",
        "scope": "3;3;4;3",
        "confidence": "3;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "R8mBAsykEG",
        "title": "Reinforcement-Learning Based Covert Social Influence Operations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "How might reinforcement-learning based covert social influence operations (CSIOs) be run, given that the CSIO agent wants to maximize influence and minimize discoverability of malicious accounts? And how successful can they be, given that both social platform bot detectors and humans might report them to the social platform?  To answer these questions, we propose RL_CSIO, an RL-based methodology for running CSIOs and run 4 CSIOs with IRB-approval over a period of 5 days using a panel of 225 human subjects. We explore 8 research questions based on the data collected. The results show that RL_CSIO agents successfully trade off influence and discoverability - but in ways that are nuanced and unexpected.",
        "keywords": "Influence Operations; Human-Bot Interaction; Social Media; Human Subject Study",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Saurabh Kumar;Valerio La Gatta;Andrea Pugliese;Andrew Pulver;VS Subrahmanian;Jiazhi Zhang;Youzhi Zhang",
        "authorids": "~Saurabh_Kumar7;~Valerio_La_Gatta1;~Andrea_Pugliese2;~Andrew_Pulver1;~VS_Subrahmanian1;~Jiazhi_Zhang2;~Youzhi_Zhang2",
        "gender": "M;M;M;M;M;M;",
        "homepage": "https://skmtr1.github.io/;;https://sites.google.com/unical.it/andreapugliese;;https://vssubrah.github.io/;;https://youzhi333.github.io/index.html",
        "dblp": "89/11294-7.html;;https://dblp.uni-trier.de/pid/p/APugliese.html;;s/VSSubrahmanian.html;;131/9490-1",
        "google_scholar": "FXA94pIAAAAJ;n1AQBRYAAAAJ;XtoIxe0AAAAJ;;PLt9wB8AAAAJ;;i2j5DmwAAAAJ",
        "orcid": "0000-0001-5909-5567;0000-0002-5941-4684;0000-0003-4385-958X;;0000-0001-7191-0296;;0000-0002-2984-734X",
        "linkedin": ";;;andrew-pulver-8412981b5/;v-s-subrahmanian-8500577/;jiazhi-zhang-31b785290?trk=contact-info;",
        "or_profile": "~Saurabh_Kumar7;~Valerio_La_Gatta1;~Andrea_Pugliese2;~Andrew_Pulver1;~VS_Subrahmanian1;~Jiazhi_Zhang2;~Youzhi_Zhang2",
        "aff": "Indian Institute of Technology Hyderabad;Northwestern University;University of Calabria, Italy;;Northwestern University;;Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences+Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences",
        "aff_domain": "iith.ac.in;northwestern.edu;unical.it;;northwestern.edu;;cair-cas.org.hk+cair-cas.org.hk",
        "position": "Assistant Professor;Postdoc;Associate Professor;;Full Professor;;Associate Professor+Assistant Professor",
        "bibtex": "@inproceedings{\nkumar2025reinforcementlearning,\ntitle={Reinforcement-Learning Based Covert Social Influence Operations},\nauthor={Saurabh Kumar and Valerio La Gatta and Andrea Pugliese and Andrew Pulver and VS Subrahmanian and Jiazhi Zhang and Youzhi Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=R8mBAsykEG}\n}",
        "github": "",
        "project": "",
        "reviewers": "oihp;skyo;LQdt;Uc6R",
        "site": "https://openreview.net/forum?id=R8mBAsykEG",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "3;4;6;5",
        "scope": "2;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.8660254037844386
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "R8mltlB42N",
        "title": "7 Days Later: Analyzing Phishing-Site Lifespan After Detected",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Phishing attacks continue to be a major threat to internet users, causing data breaches, financial losses, and identity theft. This study provides an in-depth analysis of the lifespan and evolution of phishing websites, focusing on their survival strategies and evasion techniques. We analyze 286,237 unique phishing URLs over five months using a custom web crawler based on Puppeteer and Chromium. Our crawler runs on a 30-minute cycle, systematically checking the operational status of phishing websites by collecting their HTTP status codes, screenshots, HTML, and HTTP data. Temporal and survival analyses, along with statistical tests, are used to examine phishing website lifecycles, evolution, and evasion tactics. Our findings show that the average lifespan of phishing websites is 54 hours (2.25 days) with a median of 5.46 hours, indicating rapid takedown of many sites while a subset remains active longer. Interestingly, logistic-themed phishing websites (e.g., USPS) operate within a compressed timeframe (1.76 hours) compared to other brands (e.g., Facebook). We further analyze detection effectiveness using Google Safe Browsing (GSB). We find that GSB detects only 18.4% of phishing websites, taking an average of 4.5 days. Notably, 83.93% of phishing sites are already taken down before GSB detection, meaning GSB requires more prompt detection. Moreover, 16.07% of phishing sites persist beyond this point, surviving for an additional 7.2 days on average, resulting in an average total lifespan of approximately 12 days. We reveal that DNS resolution error is the main cause (67%) of phishing website takedowns. Finally, we uncover that phishing sites with extensive visual changes (more than 100 times) exhibit a median lifespan of 17 days, compared to 1.93 hours for those with minimal modifications. These results highlight the dynamic nature of phishing attacks, the challenges in detection and prevention, and the need for more rapid and comprehensive countermeasures against evolving phishing tactics.",
        "keywords": "Phishing;Measurement",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kiho Lee;Kyungchan Lim;Hyoungshick Kim;Yonghwi Kwon;Doowon Kim",
        "authorids": "~Kiho_Lee1;~Kyungchan_Lim1;~Hyoungshick_Kim1;~Yonghwi_Kwon3;~Doowon_Kim1",
        "gender": "M;M;M;M;",
        "homepage": "https://github.com/0xk1h0;;https://seclab.skku.edu/people/hyoungshick-kim/;http://yongkwon.info;",
        "dblp": ";;64/5383;139/7034.html;",
        "google_scholar": "https://scholar.google.co.kr/citations?user=MOTHTpcAAAAJ;3h9ziwEAAAAJ;;YK3KT3kAAAAJ;",
        "orcid": "0000-0002-8713-3863;;;;",
        "linkedin": "kiho-lee-a253b5249/;;;;",
        "or_profile": "~Kiho_Lee1;~Kyungchan_Lim1;~Hyoungshick_Kim1;~Yonghwi_Kwon3;~Doowon_Kim1",
        "aff": "University of Tennessee, Knoxville;, University of Tennessee, Knoxville;Sungkyunkwan University;University of Maryland, College Park;",
        "aff_domain": "utk.edu;eecs.utk.edu;skku.edu;umd.edu;",
        "position": "Researcher;PhD student;Full Professor;Assistant Professor;",
        "bibtex": "@inproceedings{\nlee2025,\ntitle={7 Days Later: Analyzing Phishing-Site Lifespan After Detected},\nauthor={Kiho Lee and Kyungchan Lim and Hyoungshick Kim and Yonghwi Kwon and Doowon Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=R8mltlB42N}\n}",
        "github": "",
        "project": "",
        "reviewers": "tW1L;M5vD;QzPE;3fU1",
        "site": "https://openreview.net/forum?id=R8mltlB42N",
        "pdf_size": 0,
        "novelty": "3;4;4;4",
        "technical_quality": "4;4;4;4",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            3.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.0,
            0.0
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "RGCJqDywu0",
        "title": "Distinctiveness Maximization in Datasets Assemblage",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In this paper, given a user\u2019s query set and budget, we aim to use\nthe limited budget to help users assemble a set of datasets that\ncan enrich a base dataset by introducing the maximum number\nof distinct tuples (i.e., maximizing distinctiveness). We prove this\nproblem to be NP-hard. A greedy algorithm using exact distinctiveness\ncomputation attains an approximation ratio of (1-e^{-1})/2, but\nit lacks efficiency and scalability due to its frequent computation\nof the exact distinctiveness marginal gain of any candidate dataset\nfor selection. This requires scanning through every tuple in candidate\ndatasets and thus is unaffordable in practice. To overcome this\nlimitation, we propose an efficient machine learning (ML)-based\nmethod for estimating the distinctiveness marginal gain of any\ncandidate dataset. This effectively eliminates the need to test each\ntuple individually. Estimating the distinctiveness marginal gain of\na dataset involves estimating the number of distinct tuples in the\ntuple sets returned by each query in a query set across multiple\ndatasets. This can be viewed as the cardinality estimation for a\nquery set on a set of datasets, and the proposed method is the first\nto tackle this cardinality estimation problem. This is a significant\nadvancement over prior methods that were limited to single-query\ncardinality estimation on a single dataset and struggled with identifying\noverlaps among tuple sets returned by each query in a query\nset across multiple datasets. Extensive experiments using five realworld\ndata pools demonstrate that our algorithm, which utilizes\nML-based distinctiveness estimation, outperforms all relevant baselines\nin effectiveness, efficiency, and scalability. A case study on two\ndownstream ML tasks also highlights its potential to find datasets\nwith more useful tuples to enhance the performance of ML tasks.",
        "keywords": "datasets assemblage;distinctiveness maximization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tingting Wang;Shixun Huang;Zhifeng Bao;Shane Culpepper;Volkan Dedeoglu;Reza Arablouei",
        "authorids": "~Tingting_Wang3;~Shixun_Huang1;~Zhifeng_Bao2;~Shane_Culpepper1;~Volkan_Dedeoglu1;~Reza_Arablouei1",
        "gender": "F;M;;M;M;M",
        "homepage": "https://ttingtingwang.github.io/;https://shixunh.io/;;https://culpepper.io;;https://people.csiro.au/A/R/Reza-Arablouei",
        "dblp": ";213/9136;;03/489;;78/2639",
        "google_scholar": "https://scholar.google.com.au/citations?hl=zh-CN;NLEeOI4AAAAJ;;OFlBSEEAAAAJ;https://scholar.google.com.au/citations?user=KAVUjk8AAAAJ;https://scholar.google.com.au/citations?user=KyLy_hoAAAAJ",
        "orcid": "0000-0002-4912-7171;;;0000-0002-1902-9087;0000-0002-2567-2423;0000-0002-6932-2900",
        "linkedin": ";;;;volkandedeoglu/;reza-arablouei-00749250/",
        "or_profile": "~Tingting_Wang3;~Shixun_Huang1;~Zhifeng_Bao2;~Shane_Culpepper1;~Volkan_Dedeoglu1;~Reza_Arablouei1",
        "aff": "The University of Queensland+Royal Melbourne Institute of Technology;University of Wollongong;;University of Queensland;CSIRO;CSIRO",
        "aff_domain": "uq.edu.au+rmit.edu.au;uow.edu.au;;uq.edu.au;csiro.au;csiro.au",
        "position": "Visiting student+PhD student;Assistant Professor;;Full Professor;Researcher;Researcher",
        "bibtex": "@inproceedings{\nwang2025distinctiveness,\ntitle={Distinctiveness Maximization in Datasets Assemblage},\nauthor={Tingting Wang and Shixun Huang and Zhifeng Bao and Shane Culpepper and Volkan Dedeoglu and Reza Arablouei},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RGCJqDywu0}\n}",
        "github": "",
        "project": "",
        "reviewers": "nHk5;zzxs;XvJp;S5oh;VM4m",
        "site": "https://openreview.net/forum?id=RGCJqDywu0",
        "pdf_size": 0,
        "novelty": "3;4;4;6;6",
        "technical_quality": "3;4;4;5;6",
        "scope": "4;3;2;4;4",
        "confidence": "3;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.2
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.408248290463863
    },
    {
        "id": "RLpXUQgbfK",
        "title": "Aggregate to Adapt: Node-Centric Aggregation for Multi-Source-Free Graph Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Unsupervised graph domain adaptation (UGDA) focuses on transferring knowledge from labeled source graph to unlabeled target graph under domain discrepancies. Most existing UGDA methods are designed to adapt information from a single source domain, which cannot effectively exploit the complementary knowledge from multiple source domains. Furthermore, their assumptions that the labeled source graphs are accessible throughout the training procedure might not be practical due to privacy, regulation, and storage concerns. In this paper, we investigate multi-source-free unsupervised graph domain adaptation, i.e., exploring knowledge adaptation from multiple source domains to the unlabeled target domain without utilizing labeled source graphs but relying solely on source pre-trained models. Unlike previous multi-source domain adaptation approaches that aggregate predictions at model level, we introduce a novel model named GraphATA which conducts adaptation at node granularity. Specifically, we parameterize each node with its own graph convolutional matrix by automatically aggregating weight matrices from multiple source models according to its local context, thus realizing dynamic adaptation over graph structured data. We also demonstrate the capability of GraphATA to generalize to both model-centric and layer-centric methods. Comprehensive experiments on various public datasets show that our GraphATA can consistently surpass recent state-of-the-art baselines with different gains. Our source codes and datasets are available at https://anonymous.4open.science/r/GraphATA-C0D8.",
        "keywords": "Graph Neural Networks;Graph Domain Adaptation;Unsupervised Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhen Zhang;Bingsheng He",
        "authorids": "~Zhen_Zhang14;~Bingsheng_He1",
        "gender": "M;M",
        "homepage": "https://cszhangzhen.github.io/;http://www.comp.nus.edu.sg/~hebs/",
        "dblp": "19/5112-23;h/BingshengHe.html",
        "google_scholar": "8hclVjIAAAAJ;https://scholar.google.com.tw/citations?user=RogYLKYAAAAJ",
        "orcid": "0000-0001-5769-8786;0000-0001-8618-4581",
        "linkedin": ";bingsheng-he-7734b131",
        "or_profile": "~Zhen_Zhang14;~Bingsheng_He1",
        "aff": "National University of Singapore;National University of Singapore",
        "aff_domain": "nus.edu.sg;nus.edu.sg",
        "position": "Postdoc;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025aggregate,\ntitle={Aggregate to Adapt: Node-Centric Aggregation for Multi-Source-Free Graph Domain Adaptation},\nauthor={Zhen Zhang and Bingsheng He},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RLpXUQgbfK}\n}",
        "github": "",
        "project": "",
        "reviewers": "3XB8;CZML;aNbD;MSUh;HnQ2",
        "site": "https://openreview.net/forum?id=RLpXUQgbfK",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "5;4;4;5;5",
        "scope": "4;4;3;3;4",
        "confidence": "3;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4082482904638631
    },
    {
        "id": "RRgFr8D3PW",
        "title": "WaSCR: A WebAssembly Instruction-Timing Side Channel Repairer",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "WebAssembly (Wasm) is a platform-independent, low-level binary language that enables near-native performance in web applications. Given its growing importance in the web ecosystem, securing WebAssembly programs becomes increasingly important. A key security concern with WebAssembly is the threat of instruction-timing side-channel attacks, which exploit timing variations in branch instructions dependent on sensitive data, allowing attackers to infer sensitive information through timing measurement. \n\nIn this paper, we introduce WaSCR, an automated WebAssembly instruction-timing Side-Channel Repairer. WaSCR uses control and data dependencies to trace the flow of sensitive data and prevent its leakage. It employs rule-based code transformations to linearize the program, eliminating branches dependent on sensitive data and substituting them with constant-time selectors. Our evaluation demonstrates that WaSCR effectively eliminates instruction-timing side channels while maintaining program correctness, with efficient repairs and moderate performance overhead.",
        "keywords": "WebAssembly;Side-channel Attack;Static Program Analysis;Program Repair",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Liyan Huang;Junzhou He;Chao Wang;Weihang Wang",
        "authorids": "~Liyan_Huang1;~Junzhou_He1;~Chao_Wang4;~Weihang_Wang3",
        "gender": "M;Not Specified;M;",
        "homepage": "https://github.com/hly2019;https://jz2000.de;https://sites.usc.edu/chaowang;",
        "dblp": ";;;",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;https://scholar.google.com/citations?hl=en;",
        "orcid": "0009-0003-4929-1478;;;",
        "linkedin": "liyan-huang-b9776328a/;;;",
        "or_profile": "~Liyan_Huang1;~Junzhou_He1;~Chao_Wang4;~Weihang_Wang3",
        "aff": "University of Southern California+University of Southern California;University of Southern California;University of Southern California;",
        "aff_domain": "usc.edu+usc.edu;usc.edu;usc.edu;",
        "position": "PhD student+MS student;MS student;Full Professor;",
        "bibtex": "@inproceedings{\nhuang2025wascr,\ntitle={Wa{SCR}: A WebAssembly Instruction-Timing Side Channel Repairer},\nauthor={Liyan Huang and Junzhou He and Chao Wang and Weihang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RRgFr8D3PW}\n}",
        "github": "",
        "project": "",
        "reviewers": "Rjyd;KJZG;qLg7;ABnH",
        "site": "https://openreview.net/forum?id=RRgFr8D3PW",
        "pdf_size": 0,
        "novelty": "1;5;5;5",
        "technical_quality": "1;5;6;6",
        "scope": "3;3;3;3",
        "confidence": "4;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.7320508075688772
        ],
        "technical_quality_avg": [
            4.5,
            2.0615528128088303
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.816496580927726
    },
    {
        "id": "RTjTPTbH3g",
        "title": "Heterogeneous Graph Transfer Learning for Category-aware Cross-Domain Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Cross-domain sequential recommendation (CDSR) is proposed to alleviate the data sparsity issue while capturing users' sequential preferences. However, most existing methods do not explore the item transition patterns across different domains and can also not be applied to a multi-domain scenario. Moreover, previous methods rely on overlapping users as bridges to transfer knowledge, which struggles to capture the complex associations across domains without sufficient overlapping users. In this paper, we introduce item attributes into CDSR, and propose a heterogeneous graph transfer learning method to address these issues. Specifically, we construct a cross-domain heterogeneous graph to allow the association of user, item, and category nodes from different domains, and enhance the flexibility of the model by enabling message propagation between more nodes through edge expansion based on the semantic similarity and co-occurrence probability. In addition, we devise meta-paths from different perspectives for nodes at item, user and category levels to guide information aggregation, which can transfer knowledge across domains and reduce the reliance on the number of overlapping users. We further design attention modules to capture users' dynamic preferences from the item sequences they have interacted with in each domain, and explore the transition patterns within category sequences which reflect users' coarse-grained preferences. Finally, we perform knowledge transfer across different domains, and predict the most likely items that users will interact with in each domain. Extensive empirical studies on three real-world datasets indicate that our HGTL significantly outperforms the state-of-the-art baselines in all cases. The source codes of our HGTL and the datasets are available at https://anonymous.4open.science/r/HGTL-C135.",
        "keywords": "Cross-Domain Recommendation;Sequential Recommendation;Heterogeneous Graph;Transfer Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zitao Xu;Xiaoqing Chen;Weike Pan;Zhong Ming",
        "authorids": "~Zitao_Xu1;~Xiaoqing_Chen2;~Weike_Pan1;~Zhong_Ming1",
        "gender": "M;;;",
        "homepage": "http://none.com;https://scholar.google.com/citations?hl=zh-CN&user=6ZHE8DUAAAAJ&view_op=list_works&gmla=AETOMgEY6RCNLFlKLfXCMDfIE14UtRToGIG7N3EqoRPB_fN5VOEXGYK13uw068tznn_SbQKudgm6p47jJYOHipGtQzoNABD_BjHhdL2_vaPRDSzW_Og;;",
        "dblp": "356/7891.html;80/5676-4;;",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-CN;;",
        "orcid": "0009-0009-4922-2011;0000-0001-7288-7374;;",
        "linkedin": ";;;",
        "or_profile": "~Zitao_Xu1;~Xiaoqing_Chen2;~Weike_Pan1;~Zhong_Ming1",
        "aff": "Shenzhen University;Shenzhen University;;",
        "aff_domain": "szu.edu.cn;szu.edu.cn;;",
        "position": "MS student;MS student;;",
        "bibtex": "@inproceedings{\nxu2025heterogeneous,\ntitle={Heterogeneous Graph Transfer Learning for Category-aware Cross-Domain Sequential Recommendation},\nauthor={Zitao Xu and Xiaoqing Chen and Weike Pan and Zhong Ming},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RTjTPTbH3g}\n}",
        "github": "",
        "project": "",
        "reviewers": "Xtzy;TGNq;Z2Y6;oH3g",
        "site": "https://openreview.net/forum?id=RTjTPTbH3g",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "5;4;6;5",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "RUWbZJ6y3i",
        "title": "Fine-Grained Data Inference via Incomplete Multi-Granularity Data",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Urban fine-grained data map inference, leveraging information from coarse-grained maps, has emerged as a significant area of research due to the growing complexity and data heterogeneity in urban environments. Existing methods have a priori assumption that a coarse-grained data map, one fixed-size granularity, transforms into a fine-grained data map, also one fixed-size granularity. However, in the actual scenarios, the collected coarse-grained data maps are often incomplete and have significantly distinct granularities in various urban areas, which results in incomplete heterogeneous data, i.e., multi-granularity data maps in terms of spatial information. Meanwhile, different granularity data maps are needed for various urban downstream tasks, which is a multi-task problem. To that end, this paper proposes a novel framework, a multi-granularity super-resolution data map inference framework (MGSR), designed to harness spatio-temporal information to transform incomplete coarse-grained multi-granularity data maps into fine-grained multi-granularity data maps. Specifically, we design a granularity alignment network to align multi-granularity information and address missing data on each granularity map by leveraging the other granularity maps with a well-designed self-supervised task. Then, we introduce a feature extraction network to capture spatio-temporal dependencies and extract features. Finally, we devise a recurrent super-resolution network with shared parameters to infer multi-granularity data maps. We conduct extensive experiments on three real-world benchmark datasets and demonstrate that MGSR significantly outperforms the state-of-the-art methods for multi-granularity urban data map inference, and reduces RMSE and MAE by up to 40.1% and 50.3%, respectively. The source code has been released at https://anonymous.4open.science/r/MGSR-7E5C.",
        "keywords": "Multi-Granularity Data;Super-Resolution;Fine-Grained Inference;Spatio-Temporal Data",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hepeng Gao;Yijun Su;Funing Yang;Yongjian Yang",
        "authorids": "~Hepeng_Gao1;~Yijun_Su2;~Funing_Yang3;~Yongjian_Yang1",
        "gender": "M;M;F;M",
        "homepage": ";https://www.suyijun.tech/;https://ccst.jlu.edu.cn/info/1209/17381.htm;https://dblp.org/pid/01/6376.html",
        "dblp": ";;231/3383;01/6376.html",
        "google_scholar": ";;;",
        "orcid": "0000-0002-7481-6235;;;",
        "linkedin": ";;;",
        "or_profile": "~Hepeng_Gao1;~Yijun_Su2;~Funing_Yang3;~Yongjian_Yang1",
        "aff": "Jilin University;;Jilin University;",
        "aff_domain": "jlu.edu.cn;;jlu.edu.cn;",
        "position": "PhD student;;Associate Professor;",
        "bibtex": "@inproceedings{\ngao2025finegrained,\ntitle={Fine-Grained Data Inference via Incomplete Multi-Granularity Data},\nauthor={Hepeng Gao and Yijun Su and Funing Yang and Yongjian Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RUWbZJ6y3i}\n}",
        "github": "",
        "project": "",
        "reviewers": "DGWi;qETq;F4F3",
        "site": "https://openreview.net/forum?id=RUWbZJ6y3i",
        "pdf_size": 0,
        "novelty": "4;4;6",
        "technical_quality": "4;4;6",
        "scope": "3;3;4",
        "confidence": "3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            0.9428090415820634
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.9428090415820634
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5
    },
    {
        "id": "RatT4hCcVf",
        "title": "Casual Insights into Parler's Content Moderation Shift: Effects on Toxicity and Factuality",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Social media platforms employ various content moderation techniques to remove harmful, offensive, and hate speech content. The moderation level varies across platforms; even over time, it can evolve in a platform. For example, Parler, a fringe social media platform popular among conservative users, was known to have the least restrictive moderation policies, claiming to have open discussion spaces for their users. However, after linking the 2021 US Capitol Riots and the activity of some groups on Parler, such as QAnon and Proud Boys, on January 12, 2021, Parler was removed from the Apple and Google App Store and suspended from Amazon Cloud hosting service. Parler would have to modify their moderation policies to return to these online stores. After a month of downtime, Parler was back online with a new set of user guidelines, which reflected stricter content moderation.\n\nIn this paper, we studied the moderation changes performed by Parler and their effect on the toxicity of its content. We collected a large longitudinal Parler dataset with 17M parleys from 432K active users from February 2021 to January 2022, after its return to the Internet and App Store. To the best of our knowledge, this is the first study investigating the changes in content moderation policies of Parler using data-driven approaches and also the first Parler dataset after its brief hiatus. Our quasi-experimental analysis indicates that after the change in Parler\u2019s moderation, all forms of toxicity saw a significant decrease (\ud835\udc5d < 0.001). Finally, we found an increase in the factuality of the news sites being shared, as well as a decrease in the number of conspiracy/pseudoscience sources.",
        "keywords": "Parler;Content Moderation;Hate Speech;Moderation Changes;Social Media",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Nihal Kumarswamy;Mohit Singhal;Shirin Nilizadeh",
        "authorids": "~Nihal_Kumarswamy1;~Mohit_Singhal1;~Shirin_Nilizadeh1",
        "gender": "Not Specified;;",
        "homepage": "https://scholar.google.com/citations?user=KiZgYGoAAAAJ&hl=en;https://msinghal10.github.io/;",
        "dblp": "304/8313.html;252/6782;",
        "google_scholar": "KiZgYGoAAAAJ;8MNR5Y8AAAAJ;",
        "orcid": "0000-0002-0900-7634;;",
        "linkedin": "nihalkumarswamy/;;",
        "or_profile": "~Nihal_Kumarswamy1;~Mohit_Singhal1;~Shirin_Nilizadeh1",
        "aff": ";Northeastern University;",
        "aff_domain": ";northeastern.edu;",
        "position": ";Assistant Professor;",
        "bibtex": "@inproceedings{\nkumarswamy2025casual,\ntitle={Casual Insights into Parler's Content Moderation Shift: Effects on Toxicity and Factuality},\nauthor={Nihal Kumarswamy and Mohit Singhal and Shirin Nilizadeh},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=RatT4hCcVf}\n}",
        "github": "",
        "project": "",
        "reviewers": "eC26;xYy4;byje;qAi4",
        "site": "https://openreview.net/forum?id=RatT4hCcVf",
        "pdf_size": 0,
        "novelty": "3;3;4;5",
        "technical_quality": "3;2;4;6",
        "scope": "4;3;3;3",
        "confidence": "4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            3.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            3.75,
            1.479019945774904
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5222329678670935
    },
    {
        "id": "SbEFbBhNRd",
        "title": "Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Time series classification (TSC) is a cornerstone of modern web applications, powering tasks such as financial data analysis, network traffic monitoring, and user behavior analysis. \nIn recent years, deep neural networks (DNNs) have greatly enhanced the performance of TSC models in these critical domains.\nHowever, DNNs are vulnerable to backdoor attacks, where attackers can covertly implant triggers into models to induce malicious outcomes. \nExisting backdoor attacks targeting DNN-based TSC models remain elementary. \nIn particular, early methods borrow trigger designs from computer vision, which are ineffective for time series data. \nMore recent approaches utilize generative models for trigger generation, but at the cost of significant computational complexity.\n\nIn this work, we analyze the limitations of existing attacks and introduce an enhanced method, *FreqBack*. \nDrawing inspiration from the fact that DNN models inherently capture frequency domain features in time series data, we identify that improper perturbations in the frequency domain are the root cause of ineffective attacks. \nTo address this, we propose to generate triggers both effectively and efficiently, guided by frequency analysis. \nFreqBack exhibits substantial performance across five models and eight datasets, achieving an impressive attack success rate of over 90%, while maintaining less than a 3% drop in model accuracy on clean data.",
        "keywords": "Time Series Classification;Backdoor Attack;Frequency Domain Analysis",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuanmin Huang;Mi Zhang;Zhaoxiang Wang;Wenxuan Li;Min Yang",
        "authorids": "~Yuanmin_Huang1;~Mi_Zhang2;~Zhaoxiang_Wang1;~Wenxuan_Li1;~Min_Yang12",
        "gender": "M;F;M;F;M",
        "homepage": ";https://mi-zhang-fdu.github.io/index.html;;;https://secsys.fudan.edu.cn/",
        "dblp": "305/0436-1;84/2519-1;;;02/1640-2",
        "google_scholar": "It4kkfwAAAAJ;https://scholar.google.com.hk/citations?user=lXL7QxMAAAAJ;https://scholar.google.com/citations?view_op=list_works;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0000-0002-4843-5201;0000-0003-3567-3478;;0009-0005-7636-5190;0000-0001-9714-5545",
        "linkedin": ";;;;",
        "or_profile": "~Yuanmin_Huang1;~Mi_Zhang2;~Zhaoxiang_Wang1;~Wenxuan_Li1;~Min_Yang12",
        "aff": "Fudan University;Fudan University;Fudan University;Fudan University;Fudan University",
        "aff_domain": "fudan.edu.cn;fudan.edu.cn;fudan.edu.cn;fudan.edu.cn;fudan.edu.cn",
        "position": "PhD student;Full Professor;MS student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025revisiting,\ntitle={Revisiting Backdoor Attacks on Time Series Classification in the Frequency Domain},\nauthor={Yuanmin Huang and Mi Zhang and Zhaoxiang Wang and Wenxuan Li and Min Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=SbEFbBhNRd}\n}",
        "github": "",
        "project": "",
        "reviewers": "89BM;8KbM;G5Ax;PiuV;679P",
        "site": "https://openreview.net/forum?id=SbEFbBhNRd",
        "pdf_size": 0,
        "novelty": "3;5;6;6;6",
        "technical_quality": "3;5;6;5;6",
        "scope": "3;4;4;3;4",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8134892168199606
    },
    {
        "id": "Sem9fdWZlq",
        "title": "Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multi-criteria (MC) recommender systems, which utilize MC rating information for recommendation, are increasingly widespread in various e-commerce domains. However, the MC recommendation using training-based collaborative filtering, requiring consideration of multiple ratings compared to single-criterion counterparts, often poses practical challenges in achieving state-of-the-art performance along with scalable model training. To solve this problem, we propose CA-GF, a training-free MC recommendation method, which is built upon criteria-aware graph filtering for efficient yet accurate MC recommendations. Specifically, first, we construct an item--item similarity graph using an MC user-expansion graph. Next, we design CA-GF composed of the following key components, including 1) criterion-specific graph filtering where the optimal filter for each criterion is found using various types of polynomial low-pass filters and 2) criteria preference-infused aggregation where the smoothed signals from each criterion are aggregated. We demonstrate that CA-GF is (a) efficient: providing the computational efficiency, offering the extremely fast runtime of less than 0.2 seconds even on the largest benchmark dataset, (b) accurate: outperforming benchmark MC recommendation methods, achieving substantial accuracy gains up to 24% compared to the best competitor, and (c) interpretable: providing interpretations for the contribution of each criterion to the model prediction based on visualizations.",
        "keywords": "Collaborative filtering; criteria preference; graph filtering; low-pass filter; multi-criteria recommender system",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jin-Duk Park;Jaemin Yoo;Won-Yong Shin",
        "authorids": "~Jin-Duk_Park1;~Jaemin_Yoo1;~Won-Yong_Shin1",
        "gender": ";M;M",
        "homepage": ";https://jaeminyoo.github.io/;https://sites.google.com/site/midasyonsei/faculty?authuser=0",
        "dblp": ";211/2843;05/2819",
        "google_scholar": ";https://scholar.google.co.kr/citations?user=LcxcTRUAAAAJ;PwOjMLEAAAAJ",
        "orcid": ";0000-0001-7237-5117;0000-0002-6533-3469",
        "linkedin": ";jaemin-yoo-8b3678142/;",
        "or_profile": "~Jin-Duk_Park1;~Jaemin_Yoo1;~Won-Yong_Shin1",
        "aff": ";KAIST;Yonsei University",
        "aff_domain": ";kaist.ac.kr;yonsei.ac.kr",
        "position": ";Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\npark2025criteriaaware,\ntitle={Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation},\nauthor={Jin-Duk Park and Jaemin Yoo and Won-Yong Shin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Sem9fdWZlq}\n}",
        "github": "",
        "project": "",
        "reviewers": "X1uk;NH5m;HsHt;xSFa",
        "site": "https://openreview.net/forum?id=Sem9fdWZlq",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;4;5;6",
        "scope": "4;4;3;3",
        "confidence": "3;4;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.674199862463242
    },
    {
        "id": "Sl44OmnjJF",
        "title": "The First Early Evidence of the Use of Browser Fingerprinting for Online Tracking",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "While advertising has become commonplace in today's online interactions, there is a notable dearth of research investigating the extent to which browser fingerprinting is harnessed for user tracking and targeted advertising. Prior studies only measured whether fingerprinting-related scripts are being run on the websites but that in itself \\textit{does not} necessarily mean that fingerprinting is being used for the privacy-invasive purpose of online tracking because fingerprinting might be deployed for the defensive purposes of bot/fraud detection and user authentication. It is imperative to address the mounting concerns regarding the utilization of browser fingerprinting in the realm of online advertising. \n\nTo understand the privacy-invasive use of fingerprinting for user tracking, this paper introduces a new framework ``FPTrace'' (fingerprinting-based tracking assessment and comprehensive evaluation framework) designed to identify alterations in advertisements resulting from adjustments in browser fingerprinting settings. Our approach involves emulating genuine user interactions, capturing advertiser bid data, and closely monitoring HTTP information. Using FPTrace, we conduct a large scale measurement study to identify whether browser fingerprinting is being used for the purpose of user tracking and ad targeting. The results we have obtained provide robust evidence supporting the utilization of browser fingerprinting for the purposes of advertisement tracking and targeting. This is substantiated by significant disparities in bid values and a reduction in HTTP records subsequent to changes in fingerprinting. \n%Additionally, our study delved into the impact of browser fingerprinting on the restoration of cookies, and no conclusive evidence to support browser fingerprinting's direct involvement in cookie restoration. \nWe additionally demonstrate the potential use of fingerprinting for privacy-evading online tracking purposes even when users opt out of tracking under GDPR/CCPA regulations.\nIn conclusion, our research unveils the widespread employment of browser fingerprinting in online advertising, prompting critical considerations regarding user privacy and data security within the digital advertising landscape.",
        "keywords": "Measurement studies of privacy issues;Privacy policies;Web privacy",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zengrui Liu;Jimmy Dani;Yinzhi Cao;Shujiang Wu;Nitesh Saxena",
        "authorids": "~Zengrui_Liu1;~Jimmy_Dani1;~Yinzhi_Cao1;~Shujiang_Wu1;~Nitesh_Saxena4",
        "gender": "M;M;M;M;",
        "homepage": ";https://people.tamu.edu/~danijy/;http://yinzhicao.org/;https://www.linkedin.com/in/shujiang-wu-3911371aa/;https://nsaxena.engr.tamu.edu/",
        "dblp": ";;28/8733.html;205/3035.html;25/1169.html",
        "google_scholar": ";occFbWAAAAAJ;0jBP_aEAAAAJ;3yQomhcAAAAJ;_x5BEjoAAAAJ",
        "orcid": "0000-0002-7936-8435;0000-0002-7581-9104;;;",
        "linkedin": ";;;shujiang-wu-3911371aa/;",
        "or_profile": "~Zengrui_Liu1;~Jimmy_Dani1;~Yinzhi_Cao1;~Shujiang_Wu1;~Nitesh_Saxena4",
        "aff": "Nanjing University of Finance and Economics;Texas A&M University - College Station;Johns Hopkins University;Beihang University+F5.Inc;Texas A&M University - College Station",
        "aff_domain": "nufe.edu.cn;tamu.edu;jhu.edu;buaa.edu.cn+f5.com;tamu.edu",
        "position": "Instructor;PhD student;Associate Professor;Associate Professor+Researcher;Full Professor",
        "bibtex": "@inproceedings{\nliu2025the,\ntitle={The First Early Evidence of the Use of Browser Fingerprinting for Online Tracking},\nauthor={Zengrui Liu and Jimmy Dani and Yinzhi Cao and Shujiang Wu and Nitesh Saxena},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Sl44OmnjJF}\n}",
        "github": "",
        "project": "",
        "reviewers": "wwgK;AMTJ;LfLB;MxTL;2KpN",
        "site": "https://openreview.net/forum?id=Sl44OmnjJF",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;5;3;5;5",
        "scope": "3;3;3;3;3",
        "confidence": "3;4;2;4;1",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.8,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7333587976225691
    },
    {
        "id": "Sr3mmpCHM9",
        "title": "Learning by Comparing: Boosting Multimodal Affective Computing through Ordinal Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multimodal affective computing aims to integrate information from multiple modalities for the analysis of human affective states, opinion tendencies, behavior intentions, etc. Previous studies primarily focus on approximating predictions to annotated labels, often neglecting the ordinal nature of affective states. In this paper, we address this issue by exploring ordinal learning, and a Multimodal Ordinal Affective Computing (MOAC) framework is designed to enhance the understanding of the nature of affective concepts. Specifically, we propose coarse-grained label-level ordinal learning that prompts the model to \\textit{learn to compare} in the label space, encouraging higher predictive values for samples annotated with larger labels over those with smaller labels. Moreover, a regularization loss is proposed to prevent the output distributions from deviating significantly from the annotated label distributions. Fine-grained feature-level ordinal learning is then performed via the feature difference operation and the neutral embedding. The former compares samples in the feature space, calculating the difference between features of different samples to generate `new' features for a more robust training. The latter seeks to reduce the difficulty of prediction by estimating the difference between the target multimodal representations and a neutral reference.  We first demonstrate MOAC in multimodal sentiment analysis, which is a regression task that aligns well with the function of ordinal learning. Then we extend MOAC to classification tasks including multimodal humor detection and sarcasm detection to evaluate its generalizability. Experiments suggest that MOAC outperforms state-of-the-art methods.",
        "keywords": "Multimodal Data;Multimodal Affective Computing;Ordinal Learning;Sentiment Analysis",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sijie Mai;Ying Zeng;Haifeng Hu",
        "authorids": "~Sijie_Mai1;~Ying_Zeng3;~Haifeng_Hu3",
        "gender": "M;;M",
        "homepage": ";;",
        "dblp": "245/8717;;28/5938-1.html",
        "google_scholar": "pLHqgLIAAAAJ;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.hk/citations?user=gieROVcAAAAJ",
        "orcid": "0000-0001-9763-375X;;",
        "linkedin": ";;",
        "or_profile": "~Sijie_Mai1;~Ying_Zeng3;~Haifeng_Hu3",
        "aff": "South China Normal University;Sun Yat-sen University;Sun Yat-Sen University",
        "aff_domain": "scnu.edu.cn;sysu.edu.cn;sysu.edu.cn",
        "position": "Full Professor;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nmai2025learning,\ntitle={Learning by Comparing: Boosting Multimodal Affective Computing through Ordinal Learning},\nauthor={Sijie Mai and Ying Zeng and Haifeng Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Sr3mmpCHM9}\n}",
        "github": "",
        "project": "",
        "reviewers": "Pnde;JEqZ;pXzB;radr;rYvz",
        "site": "https://openreview.net/forum?id=Sr3mmpCHM9",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "4;5;5;5;6",
        "scope": "2;3;3;3;4",
        "confidence": "2;4;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            3.0,
            0.8944271909999159
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2795084971874737
    },
    {
        "id": "T2iIppZjhp",
        "title": "Filtering Discomforting Recommendations with Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Personalized algorithms can inadvertently expose users to discomforting recommendations, potentially triggering negative consequences. The subjectivity of discomfort and the black-box nature of these algorithms make it challenging to effectively identify and filter such content. To address this, we first conducted a formative study to understand users' practices and expectations regarding discomforting recommendation filtering. Then, we designed a Large Language Model (LLM)-based tool named DiscomfortFilter, which constructs an editable preference profile for a user and helps the user express filtering needs through conversation to mask discomforting preferences within the profile. Based on the edited profile, DiscomfortFilter facilitates the discomforting recommendations filtering in a plug-and-play manner, maintaining flexibility and transparency. The constructed preference profile improves LLM reasoning and simplifies user alignment, enabling a 3.8B open-source LLM to rival top commercial models in an offline proxy task. A one-week user study with 24 participants demonstrated the effectiveness of DiscomfortFilter, while also highlighting its potential impact on platform recommendation outcomes. We conclude by discussing the ongoing challenges, highlighting its relevance to broader research, assessing stakeholder impact, and outlining future research directions.",
        "keywords": "discomforting recommendation filtering;large language model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiahao Liu;Yiyang Shao;Peng Zhang;Dongsheng Li;Hansu Gu;Chao Chen;Longzhi Du;Tun Lu;Ning Gu",
        "authorids": "~Jiahao_Liu5;~Yiyang_Shao1;~Peng_Zhang31;~Dongsheng_Li2;~Hansu_Gu1;~Chao_Chen5;~Longzhi_Du1;~Tun_Lu1;~Ning_Gu2",
        "gender": "M;F;M;M;;;M;M;M",
        "homepage": ";https://hsyy04.notion.site;https://cscw.fudan.edu.cn/pengzhang/list.htm;http://recmind.cn;;;;;https://cscw.fudan.edu.cn/",
        "dblp": ";;;254/0830-2.html;00/7447;66/3019-16;65/10076;41/2472;",
        "google_scholar": ";;;VNg5rA8AAAAJ;;gmK_nHYAAAAJ;;;https://scholar.google.com.au/citations?user=AUnPpaUAAAAJ",
        "orcid": "0000-0002-5654-5902;;;0000-0003-3103-8442;;0000-0003-3911-8711;;0000-0002-6633-4826;0000-0002-2915-974X",
        "linkedin": ";;;;;;;;",
        "or_profile": "~Jiahao_Liu5;~Yiyang_Shao1;~Peng_Zhang31;~Dongsheng_Li2;~Hansu_Gu1;~Chao_Chen5;~Longzhi_Du1;~Tun_Lu1;~Ning_Gu2",
        "aff": "Fudan University;Fudan University;;Microsoft Research Asia;Amazon;;;Fudan University;Fudan University",
        "aff_domain": "fudan.edu.cn;fudan.edu.cn;;microsoft.com;amazon.com;;;fudan.edu.cn;fudan.edu.cn",
        "position": "PhD student;MS student;;Principal Researcher;Researcher;;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025filtering,\ntitle={Filtering Discomforting Recommendations with Large Language Models},\nauthor={Jiahao Liu and Yiyang Shao and Peng Zhang and Dongsheng Li and Hansu Gu and Chao Chen and Longzhi Du and Tun Lu and Ning Gu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=T2iIppZjhp}\n}",
        "github": "",
        "project": "",
        "reviewers": "vA7n;Cxqb;d939;fLog",
        "site": "https://openreview.net/forum?id=T2iIppZjhp",
        "pdf_size": 0,
        "novelty": "3;4;5;7",
        "technical_quality": "4;4;4;7",
        "scope": "3;4;3;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.479019945774904
        ],
        "technical_quality_avg": [
            4.75,
            1.299038105676658
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "T45fHPzr6n",
        "title": "REACT: Residual-Adaptive Contextual Tuning for Fast Model Adaptation in Threat Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Web and mobile systems show constant distribution shifts due to the evolvement of services, users, and threats, severely degrading the performance of threat detection models trained on prior distributions. Fast model adaptation with minimal data from new distributions is essential for maintaining reliable security measures. A key challenge in this context is the lack of ground truth, which undermines the ability of existing solutions to align classes across shifted distributions. Moreover, the limited new data often fails to represent the underlying distribution, providing sparse and potentially noisy information for adaptation. In this paper, we propose REACT, a novel framework that adapts model weights using a few unlabeled data and contextual insights. We leverage the inherent data imbalance in threat detection and meta-train weights to generalize majority patterns across varying distributions, eliminating the reliance on labels for alignment. REACT decomposes a neural network into two complementary components: meta weights as a shared foundation of general knowledge, and residual adaptive weights as adjustments for specific shifts. To compensate for the limited availability of new data, REACT trains a hypernetwork to predict adaptive weights based on data and contextual information, enabling knowledge sharing across distributions. The meta weights and the hypernetwork are updated alternately, maximizing both generalization and adaptability. REACT is model-agnostic, applicable to various neural networks. We provide convergence analysis and conduct extensive experiments across multiple datasets and models. REACT improves AUROC by 14.85% over models without adaptation, outperforming the state-of-the-art.",
        "keywords": "Threat detection;Distribution shift;Model adaptation;Meta learning;Hypernetwork",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiayun Zhang;Junshen Xu;Bugra Can;Yi Fan",
        "authorids": "~Jiayun_Zhang1;~Junshen_Xu1;~Bugra_Can1;~Yi_Fan4",
        "gender": ";M;M;F",
        "homepage": "https://jiayunz.github.io/;https://daviddmc.github.io/;;",
        "dblp": "189/5595;;234/8895;",
        "google_scholar": "02tAJn0AAAAJ;qNk6tgcAAAAJ;fTi6PuoAAAAJ;",
        "orcid": "0000-0002-3562-5794;;;",
        "linkedin": "jiayun-zhang-a71a60287/;;;yi-fan-501a8b25/",
        "or_profile": "~Jiayun_Zhang1;~Junshen_Xu1;~Bugra_Can1;~Yi_Fan4",
        "aff": "Amazon Web Services+University of California, San Diego;;Amazon Web Services, Inc.;Amazon",
        "aff_domain": "amazon.com+ucsd.edu;;amazon.com;amazon.com",
        "position": "Researcher+PhD student;;Applied Scientist;Researcher",
        "bibtex": "@inproceedings{\nzhang2025react,\ntitle={{REACT}: Residual-Adaptive Contextual Tuning for Fast Model Adaptation in Threat Detection},\nauthor={Jiayun Zhang and Junshen Xu and Bugra Can and Yi Fan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=T45fHPzr6n}\n}",
        "github": "",
        "project": "",
        "reviewers": "Lwog;TNh4;KstS;nGGd;8vas",
        "site": "https://openreview.net/forum?id=T45fHPzr6n",
        "pdf_size": 0,
        "novelty": "2;3;4;6;6",
        "technical_quality": "5;4;5;6;6",
        "scope": "4;3;2;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.6
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "T4wMdeFEjX",
        "title": "Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. \nPrevious methods manually parse tool documentation and create in-context demonstrations, transforming tools into structured formats for LLMs to use in their step-by-step reasoning.\nHowever, this manual process requires domain expertise and struggles to scale to large toolsets. \n% The LLMs show diminished  performance when in-context examples are incomplete.\nAdditionally, these methods rely heavily on ad-hoc inference technique or special tokens to integrate free-form LLM generation with tool-calling actions, limiting the LLM's flexibility in handling diverse tool specifications and integrating multiple tools.\n\nIn this work, we propose AutoTools, a framework that enables LLMs to automate the tool-use workflow.\nSpecifically, the LLM automatically transforms tool documentation into callable functions, verifying syntax and runtime correctness. \nThen, the LLM integrates these functions into executable programs to solve practical tasks, flexibly grounding tool-use actions into its reasoning processes.\nExtensive experiments on existing and newly collected, more challenging benchmarks illustrate the superiority of our framework.\nInspired by these promising results, we further investigate how to improve the expertise of LLMs, especially open-source LLMs with fewer parameters, within AutoTools.\nThus, we propose a method for AutoTools-learning, training the LLMs with three learning tasks on 34k instances of high-quality synthetic data, including documentation understanding, relevance learning and function programming.\nFine-grained results validate the effectiveness of our overall training approach and each individual task. Our methods are an important step towards the use of LLMs for solving real-world tasks with external tools.",
        "keywords": "Large language model;Tool Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhengliang Shi;Shen Gao;Lingyong Yan;Yue Feng;Xiuyi Chen;Zhumin Chen;Dawei Yin;Suzan Verberne;Zhaochun Ren",
        "authorids": "~Zhengliang_Shi1;~Shen_Gao1;~Lingyong_Yan1;~Yue_Feng1;~Xiuyi_Chen1;~Zhumin_Chen1;~Dawei_Yin1;~Suzan_Verberne1;~Zhaochun_Ren1",
        "gender": "M;M;M;F;M;;M;F;M",
        "homepage": "https://scholar.google.com/citations?user=4UlXbpQAAAAJ&hl=zh-CN;https://shengaopku.github.io/;https://yanlingyong.net;;;https://ir.sdu.edu.cn/~zhuminchen/~zhuminchen_en.htm;https://www.yindawei.com/;https://liacs.leidenuniv.nl/~verbernes/;https://renzhaochun.github.io/",
        "dblp": "336/6263.html;85/7967;254/8048;13/6965-2.html;218/7190;88/1081;;86/5095;58/10440",
        "google_scholar": "4UlXbpQAAAAJ;Xb5yz-YAAAAJ;NksMJFcAAAAJ;ZNOC0lYAAAAJ;https://scholar.google.com/citations?hl=en;;GuQ9bpAAAAAJ;https://scholar.google.nl/citations?user=-IHDKA0AAAAJ;fPcIPt0AAAAJ",
        "orcid": "0000-0002-9658-4906;0000-0003-1301-3700;;;;0000-0003-4592-4074;0000-0002-0684-6205;0000-0002-9609-9505;0000-0002-9076-6565",
        "linkedin": ";;;;;;dwyin/;suzanverberne/;zhaochun-ren-460491296/?locale=nl_NL",
        "or_profile": "~Zhengliang_Shi1;~Shen_Gao1;~Lingyong_Yan1;~Yue_Feng1;~Xiuyi_Chen1;~Zhumin_Chen1;~Dawei_Yin1;~Suzan_Verberne1;~Zhaochun_Ren1",
        "aff": "Shandong University;University of Electronic Science and Technology of China;Baidu Inc.;University of Birmingham;Baidu;Shandong University;Baidu;Universiteit Leiden;Leiden University",
        "aff_domain": "sdu.edu.cn;uestc.edu.cn;baidu.com;bham.ac.uk;baidu.com;sdu.edu.cn;baidu.com;universiteitleiden.nl;liacs.leidenuniv.nl",
        "position": "MS student;Researcher;Search Scientist;Assistant Professor;Researcher;Full Professor;Principal Researcher;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nshi2025tool,\ntitle={Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents},\nauthor={Zhengliang Shi and Shen Gao and Lingyong Yan and Yue Feng and Xiuyi Chen and Zhumin Chen and Dawei Yin and Suzan Verberne and Zhaochun Ren},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=T4wMdeFEjX}\n}",
        "github": "",
        "project": "",
        "reviewers": "JL4C;D5Sf;KaCF;b29a;bxXN",
        "site": "https://openreview.net/forum?id=T4wMdeFEjX",
        "pdf_size": 0,
        "novelty": "3;4;4;4;6",
        "technical_quality": "5;5;5;5;6",
        "scope": "3;2;2;2;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.2,
            0.39999999999999997
        ],
        "scope_avg": [
            2.6,
            0.8
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "Tcnj6GusdY",
        "title": "Assessing Compliance in Digital Advertising: A Deep Dive into Acceptable Ads Standards",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Online ads are a source of revenue for millions of websites. However, their intrusive and disruptive nature can impact the user experience of site visitors. Specialized tools such as browser extensions have emerged that block such advertisements from displaying. To restore balance in the favor of domain owners who lost revenue due to ad-filtering, online ad standards were defined to strike a middle ground between user choice and monetization. This paper presents a comprehensive analysis of the compliance of online digital advertisements with the most prevailing ad standard: the Acceptable Ads Standards. We selected 10,000 domains by intersecting Tranco's top 100K domains with the Acceptable Ads exception list. This subset highlights popular sites that are expected to adhere to specific advertising standards. The Acceptable Ads Standards, initiated by the Acceptable Ads Committee, seeks a balance between user experience and ad effectiveness, allowing certain non-intrusive ads defined by size, placement and type limitations. Our research methodology includes a quantitative analysis of ad formats and compliance rates. In this study, we conclude that almost 10\\% of the partner websites when crawled with Acceptable Ads' exception list have at-least one non-compliant ad on the landing page. Our analysis also reveals the design flaws in Acceptable Ads Exception list that allows publishers to bypass ad size and format limitations. Leveraging this understanding, we also propose improvements to the exception list that can avoid violating ads from being rendered and ensure user experience of millions of site visitors who rely on Acceptable Ads is improved.",
        "keywords": "Web Measurement;Online Advertisements;Privacy;Fairness;Transparency",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ahsan Zafar;Anupam Das",
        "authorids": "~Ahsan_Zafar1;~Anupam_Das1",
        "gender": "M;M",
        "homepage": ";",
        "dblp": ";84/5118-1.html",
        "google_scholar": "NbzWQZsAAAAJ;",
        "orcid": "0000-0002-5659-2805;",
        "linkedin": ";",
        "or_profile": "~Ahsan_Zafar1;~Anupam_Das1",
        "aff": "North Carolina State University;North Carolina State University",
        "aff_domain": "ncsu.edu;ncsu.edu",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nzafar2025assessing,\ntitle={Assessing Compliance in Digital Advertising: A Deep Dive into Acceptable Ads Standards},\nauthor={Ahsan Zafar and Anupam Das},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Tcnj6GusdY}\n}",
        "github": "",
        "project": "",
        "reviewers": "jNYo;ZpTa;JU3d;BRLY;Y586",
        "site": "https://openreview.net/forum?id=Tcnj6GusdY",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "3;6;6;6;5",
        "scope": "4;4;4;4;4",
        "confidence": "4;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.49999999999999994
    },
    {
        "id": "TkYee1NOvy",
        "title": "The Agenda-Setting Function of Social Media",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "As people increasingly use social media as a primary news source, it becomes critical to understand how online platforms affect peoples' experience of the news.  Through the media effects of agenda-setting and framing, different news sources can vary in their influence on public opinion regarding which issues people consider important and how particular aspects of these issues should be interpreted.  However, little is known about how issues and frames shift and segregate across partisan lines as traditional news on social media gets filtered by the selective exposure effects of social media.  In this study, we investigate the issues and frames invoked in news article shares across Reddit over 16 years and measure their traditional media and social media partisanship.  We measure the change between production (news articles posted on Reddit) and consumption (news articles posted on Reddit, weighted by their score). We find that issues are shared in a co-partisan manner across traditional media and social media lines. Issues are also more polarized in social media than traditional media and more polarized in consumption than production. We find that frames across several issues are also subject to co-partisan sharing behavior. In contrast to the significant polarization of news outlets on Reddit in 2016, issues and frames do not polarize more over time. Finally, looking at case studies of frames within specific issues, we disaggregate the shift from production to consumption by distinguishing between issues where the frames polarize and issues that simply receive less exposure on one side of the political spectrum. Our results give insight into broader phenomena like political polarization by highlighting the dimensions of precisely what polarizes and how polarization occurs. Overall, our study showcases the importance of understanding how social media distorts the perception of the news via its agenda-setting and framing functions.",
        "keywords": "agenda-setting;framing;news on social media;political polarization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rachel Minyoung Kim;Ashton Anderson",
        "authorids": "~Rachel_Minyoung_Kim1;~Ashton_Anderson1",
        "gender": "F;",
        "homepage": ";http://www.cs.toronto.edu/~ashton/",
        "dblp": ";21/8524",
        "google_scholar": ";https://scholar.google.co.uk/citations?user=FMSltawAAAAJ",
        "orcid": ";",
        "linkedin": "rachelm-kim/;",
        "or_profile": "~Rachel_Minyoung_Kim1;~Ashton_Anderson1",
        "aff": "Carnegie Mellon University;Department of Computer Science, University of Toronto",
        "aff_domain": "cmu.edu;cs.toronto.edu",
        "position": "PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nkim2025the,\ntitle={The Agenda-Setting Function of Social Media},\nauthor={Rachel Minyoung Kim and Ashton Anderson},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=TkYee1NOvy}\n}",
        "github": "",
        "project": "",
        "reviewers": "h93L;mw8e;6xvY;UDDD",
        "site": "https://openreview.net/forum?id=TkYee1NOvy",
        "pdf_size": 0,
        "novelty": "3;3;6;7",
        "technical_quality": "4;5;7;7",
        "scope": "3;4;4;4",
        "confidence": "3;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.7853571071357126
        ],
        "technical_quality_avg": [
            5.75,
            1.299038105676658
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.14002800840280097
    },
    {
        "id": "TnMgdBdD0m",
        "title": "Procurement Auctions with Best and Final Offers",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study sequential procurement auctions where the sellers are provided with a \"best and final offer\" (BAFO) strategy. This strategy allows each seller $i$ to effectively ``freeze'' their price while remaining active in the auction, and it signals to the buyer, as well as all other sellers, that seller $i$ would reject any price lower than that. This is in contrast to prior work, e.g., on descending auctions, where the options provided to each seller are to either accept a price reduction or reject it and drop out. As a result, the auctions that we consider induce different extensive form games and our goal is to study the subgame perfect equilibria of these games. We focus on settings involving multiple sellers who have full information regarding each other's cost (i.e., the minimum price that they can accept) and a single buyer (the auctioneer) who has no information regarding these costs. Our main result shows that the auctions enhanced with the BAFO strategy can guarantee efficiency in every subgame perfect equilibrium, even if the buyer's valuation function is an arbitrary monotone function. This is in contrast to prior work which required that the buyer's valuation satisfies restrictive properties, like gross substitutes, to achieve efficiency. We then also analyze the seller's cost in these subgame perfect equilibria and we show that it can vary significantly across different efficient outcomes, depending on the structure of the buyer's valuation function.",
        "keywords": "best and final offer;procurement auction;subgame perfect equilibrium",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Vasilis Gkatzelis;R. Preston McAfee;Renato Paes Leme",
        "authorids": "~Vasilis_Gkatzelis1;~R._Preston_McAfee1;~Renato_Paes_Leme1",
        "gender": ";M;",
        "homepage": ";https://mc4f.ee;",
        "dblp": ";62/2039;https://dblp.org/pers/hd/l/Leme:Renato_Paes",
        "google_scholar": ";Hz6wymsAAAAJ;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Vasilis_Gkatzelis1;~R._Preston_McAfee1;~Renato_Paes_Leme1",
        "aff": ";Research, Google;Google",
        "aff_domain": ";research.google.com;google.com",
        "position": ";Principal Researcher;Researcher",
        "bibtex": "@inproceedings{\ngkatzelis2025procurement,\ntitle={Procurement Auctions with Best and Final Offers},\nauthor={Vasilis Gkatzelis and R. Preston McAfee and Renato Paes Leme},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=TnMgdBdD0m}\n}",
        "github": "",
        "project": "",
        "reviewers": "sZvH;wYkG;kGXz;uwNC;Jycz",
        "site": "https://openreview.net/forum?id=TnMgdBdD0m",
        "pdf_size": 0,
        "novelty": "3;3;4;6;7",
        "technical_quality": "3;3;3;6;7",
        "scope": "1;3;1;1;4",
        "confidence": "1;2;3;1;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.624807680927192
        ],
        "technical_quality_avg": [
            4.4,
            1.7435595774162693
        ],
        "scope_avg": [
            2.0,
            1.2649110640673518
        ],
        "confidence_avg": [
            2.2,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.464420364012824
    },
    {
        "id": "TtN2bsAAS9",
        "title": "Grasp the Key Takeaways from Source Domain for Few Shot Graph Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in node classification tasks on individual graphs. However, existing GNNs trained within a specific domain (a.k.a., source domain) frequently exhibit unsatisfied performance when transferred to another domain (a.k.a., target domain), due to the domain gap. To tackle this issue, Few Shot Graph Domain Adaptation (FSGDA) is introduced to the node classification task, facilitating knowledge transfer from a fully labeled source graph to a target graph with minimal annotations for each class. An intuitive solution is directly training the GNN with labeled source and target samples together. Nevertheless, there are two issues in this procedure: (1) When the annotations on the target domain used for training are extremely sparse, the GNN performance may significantly be damaged by nodes with the source-domain bias not aligning with the target-domain distribution. (2) Apart from the biased nodes, the low-value nodes among the remaining nodes impede the GNN learning for the core nodes, like the limited target training nodes. To address the above issues, we propose a new method for FSGDA, named GraphInflu, whose core idea is to grasp the key takeaways from the source domain to facilitate the adaptation process. It contains two characteristic modules, including the Supportive Node Selector and the Soft Logic-Inspired Node Reweighting. The former aims to identify the most influential set of source nodes based on their contribution to improving performance on target nodes. The latter further focuses more on the core nodes in the selected influential set, which closely align with the target nodes especially those presenting challenging predictions. Extensive experiments validate the efficacy of GraphInflu by overcoming the current state-of-the-art methods. Our code is available at\nhttps://anonymous.4open.science/r/GraphInflu-E8E7.",
        "keywords": "Graph Domain Adaptation;Few-shot Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiangwei Lv;Jingyuan Chen;Mengze Li;Yongduo Sui;Zemin Liu;Beishui Liao",
        "authorids": "~Xiangwei_Lv1;~Jingyuan_Chen3;~Mengze_Li2;~Yongduo_Sui1;~Zemin_Liu1;~Beishui_Liao1",
        "gender": "M;F;M;M;M;M",
        "homepage": ";https://scholar.google.com/citations?user=o_G2qa0AAAAJ&hl=en;https://www.researchgate.net/profile/Mengze-Li-13;https://yongduosui.github.io/;https://zemin-liu.github.io/;https://person.zju.edu.cn/en/beishui",
        "dblp": "305/8524;;173/5918-1;277/5175;17/964.html;05/1856.html",
        "google_scholar": "https://scholar.google.com.hk/citations?user=799XXUYAAAAJ;o_G2qa0AAAAJ;;VD9g6ogAAAAJ;IxHO1nkAAAAJ;MhaBczQAAAAJ",
        "orcid": "0000-0002-7682-7317;0000-0003-0415-6937;0000-0002-3482-234X;0000-0003-4492-147X;0000-0001-6262-9435;0000-0002-9653-217X",
        "linkedin": ";;;yongduosui/;;",
        "or_profile": "~Xiangwei_Lv1;~Jingyuan_Chen3;~Mengze_Li2;~Yongduo_Sui1;~Zemin_Liu1;~Beishui_Liao1",
        "aff": "Zhejiang University;Zhejiang University;Hong Kong University of Science and Technology;Tencent;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;hkust.edu.hk;tencent.com;zju.edu.cn;zju.edu.cn",
        "position": "PhD student;Assistant Professor;Postdoc;Researcher;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nlv2025grasp,\ntitle={Grasp the Key Takeaways from Source Domain for Few Shot Graph Domain Adaptation},\nauthor={Xiangwei Lv and Jingyuan Chen and Mengze Li and Yongduo Sui and Zemin Liu and Beishui Liao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=TtN2bsAAS9}\n}",
        "github": "",
        "project": "",
        "reviewers": "79YH;3CwF;inq8;xUGq",
        "site": "https://openreview.net/forum?id=TtN2bsAAS9",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "4;5;5;5",
        "scope": "3;3;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "U3TzIAg5Dg",
        "title": "GraphHash: Graph Clustering Enables Parameter Efficiency in Recommender Systems",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Deep recommender systems rely heavily on large embedding tables to handle high-cardinality categorical features such as user/item identifiers, and face significant memory constraints at scale. To tackle this challenge, hashing techniques are often employed to map multiple entities to the same embedding and thus reduce the size of the embedding tables. Concurrently, graph-based collaborative signals have emerged as powerful tools in recommender systems, yet their potential for optimizing embedding table reduction remains unexplored. This paper introduces GraphHash, the first graph-based approach that leverages modularity-based bipartite graph clustering on user-item interaction graphs to reduce embedding table sizes. We demonstrate that the modularity objective has a theoretical connection to message-passing, which provides a foundation for our method. By employing fast clustering algorithms, GraphHash serves as a computationally efficient proxy for message-passing during preprocessing and a plug-and-play graph-based alternative to traditional ID hashing. Extensive experiments show that GraphHash substantially outperforms diverse hashing baselines on both retrieval and click-through-rate prediction tasks. In particular, GraphHash achieves on average a 101.52% improvement in recall when reducing the embedding table size by more than 75%, highlighting the value of graph-based collaborative information for model reduction.",
        "keywords": "Recommender systems;Efficiency;Hashing Trick;Graph ML",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinyi Wu;Donald Loveland;Runjin Chen;Yozen Liu;Xin Chen;Leonardo Neves;Ali Jadbabaie;Mingxuan Ju;Neil Shah;Tong Zhao",
        "authorids": "~Xinyi_Wu3;~Donald_Loveland2;~Runjin_Chen1;~Yozen_Liu1;~Xin_Chen64;~Leonardo_Neves1;~Ali_Jadbabaie1;~Mingxuan_Ju1;~Neil_Shah2;~Tong_Zhao3",
        "gender": "F;M;;;;M;M;M;M;M",
        "homepage": "https://xinyiwu98.github.io;https://www.donaldloveland.com;;https://www.linkedin.com/in/yozen-liu-531a67130/;;https://research.snap.com/team/leonardo-neves;http://www.mit.edu/~jadbabai/www;https://jumxglhf.github.io;http://nshah.net;https://tzhao.io/",
        "dblp": "98/7827;;;242/8056.html;;180/2571;83/3158;234/2715;71/7771;94/6503-3",
        "google_scholar": ";mycopgEAAAAJ;;i3U2JjEAAAAJ;;https://scholar.google.com/citations?hl=en;ZBc_WwYAAAAJ;qNoO67AAAAAJ;Qut69OgAAAAJ;05cRc-MAAAAJ",
        "orcid": ";0009-0004-3257-0128;;;;0009-0008-9539-5100;;0009-0008-9054-3856;0000-0003-3261-8430;0000-0001-7660-1732",
        "linkedin": ";;;;;lrmneves/;;;;",
        "or_profile": "~Xinyi_Wu3;~Donald_Loveland2;~Runjin_Chen1;~Yozen_Liu1;~Xin_Chen64;~Leonardo_Neves1;~Ali_Jadbabaie1;~Mingxuan_Ju1;~Neil_Shah2;~Tong_Zhao3",
        "aff": "Massachusetts Institute of Technology;University of Michigan;;Snap Inc.;;Snap Inc.;Massachusetts Institute of Technology;Snap Inc.;Snap Inc.;Snap Inc.",
        "aff_domain": "mit.edu;umich.edu;;snapchat.com;;snapchat.com;mit.edu;snap.com;snap.com;snap.com",
        "position": "PhD student;PhD student;;Researcher;;Principal Researcher;Full Professor;Research Scientist;Research Scientist;Researcher",
        "bibtex": "@inproceedings{\nwu2025graphhash,\ntitle={GraphHash: Graph Clustering Enables Parameter Efficiency in Recommender Systems},\nauthor={Xinyi Wu and Donald Loveland and Runjin Chen and Yozen Liu and Xin Chen and Leonardo Neves and Ali Jadbabaie and Mingxuan Ju and Neil Shah and Tong Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=U3TzIAg5Dg}\n}",
        "github": "",
        "project": "",
        "reviewers": "AC7v;XaBD;btey;PtvC;wFbp",
        "site": "https://openreview.net/forum?id=U3TzIAg5Dg",
        "pdf_size": 0,
        "novelty": "4;4;5;6;7",
        "technical_quality": "5;4;4;5;7",
        "scope": "4;4;4;4;4",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            1.0954451150103321
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.14002800840280097
    },
    {
        "id": "U3jslTfxTm",
        "title": "Personalized Denoising Implicit Feedback for Robust Recommender System",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "While implicit feedback is foundational to modern recommender systems, factors such as human error, uncertainty, and ambiguity in user behavior inevitably introduce significant noise into this feedback, adversely affecting the accuracy and robustness of recommendations. To address this issue, existing methods typically aim to reduce the training weight of noisy feedback or discard it entirely, based on the observation that noisy interactions often exhibit higher losses in the overall loss distribution. However, we identify two key issues: (1) there is a significant overlap between normal and noisy interactions in the overall loss distribution, and (2) this overlap becomes even more pronounced when transitioning from pointwise loss functions (e.g., BCE loss) to pairwise loss functions (e.g., BPR loss). This overlap leads traditional methods to misclassify noisy interactions as normal, and vice versa. To tackle these challenges, we further investigate the loss overlap and find that for a given user, there is a clear distinction between normal and noisy interactions in the user's personal loss distribution. Based on this insight, we propose a resampling strategy to Denoise using the user's Personal Loss distribution, named PLD, which aims to reduce the probability of noisy interactions being optimized. Specifically, during each optimization iteration, we create a candidate item pool for each user and resample the items from this pool based on the user's personal loss distribution, prioritizing normal interactions. Additionally, we conduct a theoretical analysis to validate PLD's effectiveness and suggest ways to further enhance its performance. Extensive experiments conducted on three datasets with varying noise ratios demonstrate PLD's efficacy and robustness.",
        "keywords": "Robust Recommender System;Denoising Recommendation;Implicit Feedback",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kaike Zhang;Qi Cao;Yunfan Wu;Fei Sun;Huawei Shen;Xueqi Cheng",
        "authorids": "~Kaike_Zhang1;~Qi_Cao1;~Yunfan_Wu1;~Fei_Sun3;~Huawei_Shen1;~Xueqi_Cheng1",
        "gender": "M;F;M;M;M;M",
        "homepage": "https://kaike-zhang.github.io/;https://caoqi92.github.io/biography/;https://profile.yunfan.info;http://ofey.me;https://www.ict.ac.cn/sourcedb/cn/jssrck/201402/t20140221_4037648.html;https://people.ucas.ac.cn/~cxq?language=en",
        "dblp": "139/1710;40/5905;289/3320;51/394-1;;44/912",
        "google_scholar": ";FflWb1gAAAAJ;L6Pwc_kAAAAJ;OlRxBhcAAAAJ;;hY8aLqAAAAAJ",
        "orcid": ";;0000-0001-6994-6791;0000-0002-6146-148X;0000-0002-1081-8119;",
        "linkedin": ";;;;;",
        "or_profile": "~Kaike_Zhang1;~Qi_Cao1;~Yunfan_Wu1;~Fei_Sun3;~Huawei_Shen1;~Xueqi_Cheng1",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences, China;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy",
        "aff_domain": "ict.ac.cn;ict.ac.cn;ict.ac.cn;ict.ac.cn;ict.ac.cn;ict.ac.cn",
        "position": "PhD student;Associate Professor;PhD student;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025personalized,\ntitle={Personalized Denoising Implicit Feedback for Robust Recommender System},\nauthor={Kaike Zhang and Qi Cao and Yunfan Wu and Fei Sun and Huawei Shen and Xueqi Cheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=U3jslTfxTm}\n}",
        "github": "",
        "project": "",
        "reviewers": "EJ4t;m2fj;YqFP;vvZK;is3p",
        "site": "https://openreview.net/forum?id=U3jslTfxTm",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6",
        "technical_quality": "4;4;5;6;5",
        "scope": "3;4;4;4;4",
        "confidence": "4;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6864064729836442
    },
    {
        "id": "UJVv4KHMp0",
        "title": "PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Large language models (LLMs) enhanced with retrieval-augmented generation (RAG) have introduced a new paradigm for web search. However, the limited context awareness of LLMs degrades their performance on RAG tasks. Existing methods to enhance context awareness are often inefficient, incurring time or memory overhead during inference, and many are tailored to specific position embeddings. In this paper, we propose \\textbf{P}osition-\\textbf{E}mbedding-\\textbf{A}gnostic attention \\textbf{R}e-weighting (\\textit{PEAR}), which enhances the context awareness of LLMs with zero inference overhead. Specifically, on a proxy task focused on context copying, we first detect heads which suppress the models' context awareness, thereby diminishing RAG performance. To weaken the impact of these heads, we re-weight their outputs with learnable coefficients. The LLM (with frozen parameters) is optimized by adjusting these coefficients to minimize loss on the proxy task. During inference, the optimized coefficients are fixed to re-weight these heads, regardless of the specific task at hand. Our proposed \\textit{PEAR} offers two major advantages over previous approaches: (1) It introduces zero additional inference overhead in terms of memory usage or inference time, while outperforming competitive baselines in accuracy and efficiency across various RAG tasks. (2) It is independent of position embedding algorithms, ensuring broader applicability.",
        "keywords": "Retrieval-Augmented Generation;Large Language Model;Context Awareness;Re-weighting Attention Heads",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tao Tan;Yining Qian;Ang Lv;Hongzhan Lin;Songhao Wu;yongbo wang;Feng Wang;Jingtong Wu;xin lu;Rui Yan",
        "authorids": "~Tao_Tan6;~Yining_Qian1;~Ang_Lv1;~Hongzhan_Lin2;~Songhao_Wu1;~yongbo_wang4;~Feng_Wang8;~Jingtong_Wu1;~xin_lu17;~Rui_Yan2",
        "gender": "M;;M;M;;M;;;;M",
        "homepage": "https://github.com/TTArch/GSAI;https://github.com/ambition-daisy;https://trestad.github.io;https://github.com/p1nksnow;;https://www.antgroup.com/;;https://www.antgroup.com/;https://antgroup.com/;https://gsai.ruc.edu.cn/english/ruiyan",
        "dblp": ";;326/5506;292/1751-2.html;;;90/4225-23;;;19/2405-1",
        "google_scholar": ";;https://scholar.google.com/citations?view_op=list_works;;;;;;;eLw6g-UAAAAJ",
        "orcid": "0009-0009-2149-0807;;0000-0002-8027-2270;0009-0001-4029-810X;;;;;;0000-0002-3356-6823",
        "linkedin": ";;;;;;;;;",
        "or_profile": "~Tao_Tan6;~Yining_Qian1;~Ang_Lv1;~Hongzhan_Lin2;~Songhao_Wu1;~yongbo_wang4;~Feng_Wang8;~Jingtong_Wu1;~xin_lu17;~Rui_Yan2",
        "aff": "Renmin University of China;Southeast University;Renmin University of China;Renmin University of China;;;;;;Renmin University of China",
        "aff_domain": "ruc.edu.cn;seu.edu.cn;ruc.edu.cn;ruc.edu.cn;;;;;;ruc.edu.cn",
        "position": "MS student;MS student;PhD student;MS student;;;;;;Associate Professor",
        "bibtex": "@inproceedings{\ntan2025pear,\ntitle={{PEAR}: Position-Embedding-Agnostic Attention Re-weighting Enhances Retrieval-Augmented Generation with Zero Inference Overhead},\nauthor={Tao Tan and Yining Qian and Ang Lv and Hongzhan Lin and Songhao Wu and yongbo wang and Feng Wang and Jingtong Wu and xin lu and Rui Yan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=UJVv4KHMp0}\n}",
        "github": "",
        "project": "",
        "reviewers": "XCGR;3gt1;VgWN;pgak;KKYJ",
        "site": "https://openreview.net/forum?id=UJVv4KHMp0",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;5;6;5;6",
        "scope": "4;4;4;3;4",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "URmGwzxCC1",
        "title": "Unleashing the Potential of Multi-Channel Fusion in Retrieval for Personalized Recommendations",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recommender systems (RS) are pivotal in managing information overload in modern digital services. A key challenge in RS is efficiently processing vast item pools to deliver highly personalized recommendations under strict latency constraints. Multi-stage cascade ranking addresses this by employing computationally efficient retrieval methods to cover diverse user interests, followed by more precise ranking models to refine the results. In the retrieval stage, multi-channel retrieval is often used to generate distinct item subsets from different candidate generators, leveraging the complementary strengths of these methods to maximize coverage. However, forwarding all retrieved items overwhelms downstream rankers, necessitating truncation. Despite advancements in individual retrieval methods, multi-channel fusion, the process of efficiently merging multi-channel retrieval results, remains underexplored. We are the first to identify and systematically investigate multi-channel fusion in the retrieval stage. Current industry practices often rely on heuristic approaches and manual designs, which often lead to suboptimal performance. Moreover, traditional gradient-based methods like SGD are unsuitable for this task due to the non-differentiable nature of the selection process. In this paper, we explore advanced channel fusion strategies by assigning systematically optimized weights to each channel. We utilize black-box optimization techniques, including the Cross Entropy Method and Bayesian Optimization for global weight optimization, alongside policy gradient-based approaches for personalized merging. Our methods enhance both personalization and flexibility, achieving significant performance improvements across multiple datasets and yielding substantial gains in real-world deployments, offering a scalable solution for optimizing multi-channel fusion in retrieval.",
        "keywords": "Recommender Systems;Multi-Channel Fusion;Personalization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Junjie Huang;Jiarui Qin;Jianghao Lin;Ziming Feng;Weinan Zhang;Yong Yu",
        "authorids": "~Junjie_Huang5;~Jiarui_Qin1;~Jianghao_Lin1;~Ziming_Feng1;~Weinan_Zhang1;~Yong_Yu1",
        "gender": "F;M;M;M;M;",
        "homepage": ";https://jiaruiqin.me;https://linjianghao.com;https://www.cmbchina.com/;http://wnzhang.net;https://apex.sjtu.edu.cn/members/yyu",
        "dblp": ";227/2898;188/7862.html;127/6107.html;28/10261-1;43/5685.html",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.hk/citations?user=JPBGjOYAAAAJ;vb30mvwAAAAJ;;Qzss0GEAAAAJ;",
        "orcid": "0000-0002-5637-0735;0000-0002-9064-885X;0000-0002-8953-3203;;0000-0002-0127-2425;0000-0003-4457-2820",
        "linkedin": ";;;;;",
        "or_profile": "~Junjie_Huang5;~Jiarui_Qin1;~Jianghao_Lin1;~Ziming_Feng1;~Weinan_Zhang1;~Yong_Yu1",
        "aff": "Shanghai Jiaotong University;Tencent+Huawei Technologies Ltd.;Shanghai Jiaotong University;China Merchants Bank;;Shanghai Jiaotong University",
        "aff_domain": "sjtu.edu.cn;tencent.com+huawei.com;sjtu.edu.cn;cmbchina.com;;sjtu.edu.cn",
        "position": "PhD student;Researcher+Researcher;PhD student;Senior Engineer;;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025unleashing,\ntitle={Unleashing the Potential of Multi-Channel Fusion in Retrieval for Personalized Recommendations},\nauthor={Junjie Huang and Jiarui Qin and Jianghao Lin and Ziming Feng and Weinan Zhang and Yong Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=URmGwzxCC1}\n}",
        "github": "",
        "project": "",
        "reviewers": "2PLS;QawU;dR2J;GmXQ;LPdM",
        "site": "https://openreview.net/forum?id=URmGwzxCC1",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "5;4;6;6;6",
        "scope": "3;4;3;4;4",
        "confidence": "2;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5590169943749476
    },
    {
        "id": "UVd7Qg9Mul",
        "title": "A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Web refresh crawling is the problem of keeping a cache of web pages fresh, that is, having the most recent copy available when a page is requested, given a limited bandwidth available to the crawler. Under the assumption that the change and request events, resp., to each web page follow independent Poisson processes, the optimal scheduling policy was derived by Azar et. al (2018). In this paper, we study an extension of this problem where side information indicating content changes, such as various types of web pings, e.g., signals from sitemaps, content delivery networks, etc., is available. Incorporating such side information into the crawling policy is challenging, because (i) the signals can be noisy with false positive events and with missing change events; and (ii) the crawler should achieve a fair performance over web pages regardless of the quality of the side information, which might differ from web page to web page. We propose a scalable crawling algorithm which (i) uses the noisy side information in an optimal way under mild assumptions; (ii) can be deployed without heavy centralized computation; (iii) is able to crawl web pages at a constant total rate without spikes in the total bandwidth usage over any time interval, and automatically adapt to the new optimal solution when the total bandwidth changes without centralized computation. Experiments clearly demonstrate the versatility of our approach.",
        "keywords": "web search;crawling;sitemap;side information;content-change indicating signal",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Julian Zimmert;Robert Istvan Busa-Fekete;Andr\u00e1s Gy\u00f6rgy;Linhai Qiu;Hyomin Choi;Tzu-Wei Sung;Hao Shen;Sharmila Subramaniam;Li Xiao",
        "authorids": "~Julian_Zimmert1;~Robert_Istvan_Busa-Fekete1;~Andr\u00e1s_Gy\u00f6rgy2;~Linhai_Qiu1;~Hyomin_Choi1;~Tzu-Wei_Sung1;~Hao_Shen10;~Sharmila_Subramaniam1;~Li_Xiao11",
        "gender": ";M;;;F;M;M;;M",
        "homepage": ";;;http://physbam.stanford.edu/~lqiu/;;;https://www.google.com/;;",
        "dblp": "190/7636;69/4876;;;;207/8221.html;;19/2293.html;",
        "google_scholar": ";UNtKl1MAAAAJ;;;;https://scholar.google.com/citations?hl=en;;;",
        "orcid": ";;;;;;;;",
        "linkedin": ";;;;hyominchoi/;tzu-wei-sung;;;lixiao2",
        "or_profile": "~Julian_Zimmert1;~Robert_Istvan_Busa-Fekete1;~Andr\u00e1s_Gy\u00f6rgy2;~Linhai_Qiu1;~Hyomin_Choi1;~Tzu-Wei_Sung1;~Hao_Shen10;~Sharmila_Subramaniam1;~Li_Xiao11",
        "aff": "Google;Google Research;;Google;Google;Google;Google;Google;Google",
        "aff_domain": "google.com;google.com;;google.com;google.com;google.com;google.com;google.com;google.com",
        "position": "Postdoc;Researcher;;Software Engineer;Researcher;Researcher;Researcher;Software Engineer;Principal Researcher",
        "bibtex": "@inproceedings{\nzimmert2025a,\ntitle={A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals},\nauthor={Julian Zimmert and Robert Istvan Busa-Fekete and Andr{\\'a}s Gy{\\\"o}rgy and Linhai Qiu and Hyomin Choi and Tzu-Wei Sung and Hao Shen and Sharmila Subramaniam and Li Xiao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=UVd7Qg9Mul}\n}",
        "github": "",
        "project": "",
        "reviewers": "peJ8;rSNs;7pC5;mSVS",
        "site": "https://openreview.net/forum?id=UVd7Qg9Mul",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "4;4;5;6",
        "scope": "4;3;3;4",
        "confidence": "2;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.30151134457776363
    },
    {
        "id": "UXZ8gFtNvo",
        "title": "Robust Deep Signed Graph Clustering via Weak Balance Theory",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Signed graph clustering is a critical technique for discovering community structures in graphs that exhibit both positive and negative relationships. We have identified two significant challenges in this domain: i) existing signed spectral methods are highly vulnerable to noise, which is prevalent in real-world scenarios; ii) the guiding principle ``an enemy of my enemy is my friend'', rooted in \\textit{Social Balance Theory}, often narrows or disrupts cluster boundaries in mainstream signed graph neural networks. Addressing these challenges, we propose the \\underline{D}eep \\underline{S}igned \\underline{G}raph \\underline{C}lustering framework (DSGC), which leverages \\textit{Weak Balance Theory} to enhance preprocessing and encoding for robust representation learning. First, DSGC introduces Violation Sign-Refine to denoise the signed network by correcting noisy edges with high-order neighbor information. Subsequently, Density-based Augmentation enhances semantic structures by adding positive edges within clusters and negative edges across clusters, following \\textit{Weak Balance} principles. The framework then utilizes \\textit{Weak Balance} principles to develop clustering-oriented signed neural networks to broaden cluster boundaries by emphasizing distinctions between negatively linked nodes. Finally, DSGC optimizes clustering assignments by minimizing a regularized clustering loss. Comprehensive experiments on synthetic and real-world datasets demonstrate DSGC consistently outperforms all baselines, establishing a new benchmark in signed graph clustering. The code is provided in https://anonymous.4open.science/r/DSGC-C05C/.",
        "keywords": "Representation learning; Balance theory; Signed graph clustering",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Peiyao Zhao;Xin Li;Zeyu Zhang;Mingzhong Wang;Xueying Zhu;Lejian Liao",
        "authorids": "~Peiyao_Zhao1;~Xin_Li31;~Zeyu_Zhang3;~Mingzhong_Wang2;~Xueying_Zhu1;~Lejian_Liao2",
        "gender": ";F;;M;F;M",
        "homepage": ";https://cs.bit.edu.cn/szdw/jsml/js/lixin/index.htm;;https://www.usc.edu.au/staff/dr-mingzhong-wang;;https://openreview.net/profile?id=~Lejian_Liao1",
        "dblp": ";09/1365-33.html;;12/5272;;",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-TW;;Jj30mIUAAAAJ;;",
        "orcid": ";0000-0003-4257-4347;;0000-0002-6533-8104;0000-0003-1522-4587;",
        "linkedin": ";;;;;",
        "or_profile": "~Peiyao_Zhao1;~Xin_Li31;~Zeyu_Zhang3;~Mingzhong_Wang2;~Xueying_Zhu1;~Lejian_Liao2",
        "aff": ";Beijing Institute of Technology;;University of the Sunshine Coast;Beijing Institute of Technology;Beijing Institute of Technology, Tsinghua University",
        "aff_domain": ";bit.edu.cn;;usc.edu.au;bit.edu.cn;bit.edu.cn",
        "position": ";Associate Professor;;Assistant Professor;MS student;Full Professor",
        "bibtex": "@inproceedings{\nzhao2025robust,\ntitle={Robust Deep Signed Graph Clustering via Weak Balance Theory},\nauthor={Peiyao Zhao and Xin Li and Zeyu Zhang and Mingzhong Wang and Xueying Zhu and Lejian Liao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=UXZ8gFtNvo}\n}",
        "github": "",
        "project": "",
        "reviewers": "G9xJ;f1yf;AgZJ;Hcwh;kauj",
        "site": "https://openreview.net/forum?id=UXZ8gFtNvo",
        "pdf_size": 0,
        "novelty": "3;5;5;6;6",
        "technical_quality": "5;5;5;6;5",
        "scope": "3;3;4;3;4",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            5.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4564354645876385
    },
    {
        "id": "UhPUR9cnRJ",
        "title": "Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent research on explainable recommendation generally frames the task as a standard text generation problem, and evaluates models simply based on the textual similarity between the predicted and ground-truth explanations. However, this approach fails to consider one crucial aspect of the systems: whether their outputs accurately reflect the users' (post-purchase) sentiments, i.e., whether and why they would like and/or dislike the recommended items. To shed light on this issue, we introduce new datasets and evaluation methods that focus on the users' sentiments. Specifically, we construct the datasets by explicitly extracting users' positive and negative opinions from their post-purchase reviews using an LLM, and propose to evaluate systems based on whether the generated explanations 1) align well with the users' sentiments, and 2) accurately identify both positive and negative opinions of users on the target items. We benchmark several recent models on our datasets and demonstrate that achieving strong performance on existing metrics does not ensure that the generated explanations align well with the users' sentiments. Lastly, we find that existing models can provide more sentiment-aware explanations when the users' (predicted) ratings for the target items are directly fed into the models as input. We will release our code and datasets upon acceptance.",
        "keywords": "Explainable recommendation;Recommender systems;Large language model;Transformer;Personalization;Sentiment analysis",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ryotaro Shimizu;Takashi Wada;Yu Wang;Johannes Kruse;Sean O'Brien;Sai Htaung Kham;Linxin Song;Yuya Yoshikawa;Yuki Saito;Fugee Tsung;Masayuki Goto;Julian McAuley",
        "authorids": "~Ryotaro_Shimizu1;~Takashi_Wada1;~Yu_Wang24;~Johannes_Kruse1;~Sean_O'Brien1;~Sai_Htaung_Kham1;~Linxin_Song1;~Yuya_Yoshikawa1;~Yuki_Saito1;~Fugee_Tsung1;~Masayuki_Goto1;~Julian_McAuley1",
        "gender": "M;M;M;M;M;M;M;;M;M;M;M",
        "homepage": ";https://twadada.github.io/;https://wangyu-ustc.github.io/;https://johanneskruse.github.io/;;;https://linxins97.github.io/;https://yuya-y.com;;https://ieda.ust.hk/dfaculty/tsung/;http://www.it.mgmt.waseda.ac.jp/;http://cseweb.ucsd.edu/~jmcauley/",
        "dblp": "315/2865;92/5752-1;;;;;330/3920.html;36/8341;;95/2794;;29/3483",
        "google_scholar": "https://scholar.google.co.jp/citations?user=imbW88cAAAAJ;RLwFtDsAAAAJ;https://scholar.google.com/citations?hl=en;N_zRKd8AAAAJ;https://scholar.google.com/citations?hl=en;;https://scholar.google.com.hk/citations?user=IjqXzSwAAAAJ;Wp_Yho8AAAAJ;5biyD0oAAAAJ;yQVoXS0AAAAJ;;icbo4M0AAAAJ",
        "orcid": "0000-0002-4841-1824;;;0009-0007-5830-0611;;0009-0005-8803-5842;0009-0009-7349-8990;;0000-0003-0492-414X;0000-0002-0575-8254;0000-0003-1929-9359;0000-0003-0955-7588",
        "linkedin": "ryotaro-shimizu-5b60ab202/;;;johanneskruse/;https://linkedin.com/in/cal-sean-obrien;saihtaungkham/;;;;ftsung/;;",
        "or_profile": "~Ryotaro_Shimizu1;~Takashi_Wada1;~Yu_Wang24;~Johannes_Kruse1;~Sean_O'Brien1;~Sai_Htaung_Kham1;~Linxin_Song1;~Yuya_Yoshikawa1;~Yuki_Saito1;~Fugee_Tsung1;~Masayuki_Goto1;~Julian_McAuley1",
        "aff": "University of California, San Diego+ZOZO Research;ZOZO NEXT;University of California, San Diego;Technical University of Denmark;University of California, San Diego;;Salesforce Research+University of Southern California;STAIR Lab, Chiba Institute of Technology;ZOZO Research;Hong Kong University of Science and Technology (Guangzhou)+Hong Kong University of Science and Technology;Waseda University;University of California, San Diego, University of California, San Diego",
        "aff_domain": "ucsd.edu+zozo.com;zozo.com;ucsd.edu;dtu.dk;ucsd.edu;;salesforce.com+usc.edu;stair.center;zozo.com;hkust-gz.edu.cn+ust.hk;waseda.ac.jp;eng.ucsd.edu",
        "position": "Researcher+Researcher;Researcher;PhD student;PhD student;PhD student;;Intern+PhD student;Senior Research Scientist;Researcher;Full Professor+Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nshimizu2025disentangling,\ntitle={Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation},\nauthor={Ryotaro Shimizu and Takashi Wada and Yu Wang and Johannes Kruse and Sean O'Brien and Sai Htaung Kham and Linxin Song and Yuya Yoshikawa and Yuki Saito and Fugee Tsung and Masayuki Goto and Julian McAuley},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=UhPUR9cnRJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "UUMe;Tsqz;hUQ9;FfXj;rhoR",
        "site": "https://openreview.net/forum?id=UhPUR9cnRJ",
        "pdf_size": 0,
        "novelty": "2;4;5;5;5",
        "technical_quality": "3;3;4;6;5",
        "scope": "3;2;4;4;4",
        "confidence": "2;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            12,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.4900980294098034
    },
    {
        "id": "V0c1fUe5Md",
        "title": "Gamblers or Delegatees: Identifying Hidden Participant Roles in Crypto Casinos",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the development of blockchain technology, crypto gambling has gained popularity due to its high level of anonymity. However, similar to traditional casinos, crypto casinos are controlled by a few internal $\\textit{Delegatees}$, making it impossible for them to achieve complete transparency and fairness. These delegatees are hidden among $\\textit{gamblers}$ and are difficult to identify and distinguish in anonymous and large-scale blockchain transaction networks. This paper proposes an unsupervised dual-stage role identification method to adaptively identify key roles and hidden delegatees in label-sparse crypto casinos. Specifically, inspired by voting-style transaction patterns, we propose a novel voting influence metric for key node identification. This metric is based on one-dimensional structural entropy to capture global dissemination capability. Subsequently, we develop a multi-view graph neural network framework enhanced with two-dimensional global structural entropy minimization and self-supervised contrastive learning to improve the robustness and interpretability of hidden role partitioning. Experiments on real-world cases of the most mainstream blockchains\u2014Ethereum, TRON, and Arbitrum\u2014demonstrate that our proposed method effectively reveals distinct role compositions and collusion patterns, distinguishing between gamblers and delegatees. Our results achieve a higher match with identities confirmed by judicial authorities than existing methods, indicating the effectiveness and generalizability of our approach in enhancing security and regulation oversight.",
        "keywords": "Crypto gambling;Anonymity;Security;Delegatees;Role identification;Graph Neural Networks;Structural Entropy",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiaxin Wang;Qianang Mao;Hongliang SUN;Jiaqi Yan",
        "authorids": "~Jiaxin_Wang5;~Qianang_Mao1;~Hongliang_SUN1;~Jiaqi_Yan2",
        "gender": "M;;M;M",
        "homepage": ";;;https://im.nju.edu.cn/yjq/list.htm",
        "dblp": ";;;",
        "google_scholar": "Vm54jdoAAAAJ;;https://scholar.google.com/citations?hl=en;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Jiaxin_Wang5;~Qianang_Mao1;~Hongliang_SUN1;~Jiaqi_Yan2",
        "aff": "Nanjing University;;;Nanjing University",
        "aff_domain": "nju.edu.cn;;;nju.edu.cn",
        "position": "PhD student;;;Full Professor",
        "bibtex": "@inproceedings{\nwang2025gamblers,\ntitle={Gamblers or Delegatees: Identifying Hidden Participant Roles in Crypto Casinos},\nauthor={Jiaxin Wang and Qianang Mao and Hongliang SUN and Jiaqi Yan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=V0c1fUe5Md}\n}",
        "github": "",
        "project": "",
        "reviewers": "1gnv;zEUz;aNjB;g73r;vqAs",
        "site": "https://openreview.net/forum?id=V0c1fUe5Md",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "4;6;5;5;5",
        "scope": "4;4;4;3;3",
        "confidence": "4;3;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5345224838248488
    },
    {
        "id": "V2NNpFBo9w",
        "title": "Hyperbolic-Euclidean Deep Mutual Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph neural networks (GNNs) exhibit powerful performance in handling graph data, with Euclidean and hyperbolic variants excelling in processing grid-based and hierarchical structures, respectively. However, existing methods focus on learning specific structures that are linked to the inherent properties of the underlying space, and fail to fully exploit their complementary properties in distinct geometric spaces, thereby limiting their ability to efficiently model and represent complex graph structures. In this paper, we propose a Hyperbolic-Euclidean Deep Mutual Learning (H-EDML) framework, which leverages the unique properties of hyperbolic space to effectively capture the hierarchical relationships present in graph data, while also utilizes the familiar Euclidean space to handle local interactions. Specifically, We design a topology mutual learning module to bolster the capacity of each single model to perceive the holistic topological structure of the graph. Then, we integrate a decision mutual learning module to further advance the models' comprehensive judgment capabilities towards graph data, thereby strengthening the robustness and generalization. Furthermore, we employ an attention-based probabilistic integration strategy for the final prediction to alleviate potential disparities in decision-making among different models. Extensive experiments on node classification are conducted on five real-world graph datasets and the results show that our proposed H-EDML achieves competitive performances compared to the state-of-the-art methods.",
        "keywords": "Mutual learning;Graph neural network;Hyperbolic geometry;Euclidean geometry",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Haifang Cao;Yu Wang;Jialu Li;Pengfei Zhu;Qinghua Hu",
        "authorids": "~Haifang_Cao1;~Yu_Wang33;~Jialu_Li4;~Pengfei_Zhu1;~Qinghua_Hu1",
        "gender": "M;M;F;M;M",
        "homepage": "https://caohaifang123.github.io/;https://wangyutju.github.io/;;http://aiskyeye.com/;http://cic.tju.edu.cn/faculty/huqinghua/index.html",
        "dblp": ";02/5889-106;32/11008;40/6172-1.html;",
        "google_scholar": "https://scholar.google.com.tw/citations?view_op=list_works;;;https://scholar.google.com/citations?hl=zh-TW;TVSNq_wAAAAJ",
        "orcid": ";;0000-0002-6504-8625;0000-0002-4310-9140;0000-0001-7765-8095",
        "linkedin": ";;;;",
        "or_profile": "~Haifang_Cao1;~Yu_Wang33;~Jialu_Li4;~Pengfei_Zhu1;~Qinghua_Hu1",
        "aff": "Tianjin University;Tianjin University;Tianjin University;Tianjin University;Tianjin University",
        "aff_domain": "tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn",
        "position": "PhD student;Associate Professor;PhD student;Full Professor;Professor",
        "bibtex": "@inproceedings{\ncao2025hyperboliceuclidean,\ntitle={Hyperbolic-Euclidean Deep Mutual Learning},\nauthor={Haifang Cao and Yu Wang and Jialu Li and Pengfei Zhu and Qinghua Hu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=V2NNpFBo9w}\n}",
        "github": "",
        "project": "",
        "reviewers": "7FTQ;4qQP;LEDd",
        "site": "https://openreview.net/forum?id=V2NNpFBo9w",
        "pdf_size": 0,
        "novelty": "5;5;6",
        "technical_quality": "5;5;6",
        "scope": "3;3;4",
        "confidence": "2;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            0.816496580927726
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8660254037844387
    },
    {
        "id": "V8lBZMzahD",
        "title": "Dual Intention Escape: Jailbreak Attack against Large Language Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recently, the jailbreak attack, which generates adversarial prompts to bypass safety measures and mislead large language models (LLMs) to output harmful answers, has attracted extensive interest due to its potential to reveal the vulnerabilities of LLMs. However, ignoring the exploitation of the characteristics in intention understanding, existing studies could only generate prompts with weak attacking ability, failing to evade defenses (e.g., sensitive word detect) and causing malice(e.g., harmful outputs). Motivated by the mechanism in the psychology of human misjudgment, we propose a dual intention escape (DIE) jailbreak attack framework to generate more stealthy and toxic prompts to deceive LLMs to output harmful content. \nFor stealthiness, inspired by the anchoring effect, we designed the Intention-anchored Malicious Concealment(IMC) module that hides the harmful intention behind a generated anchor intention by the recursive decomposition block and contrary intention nesting block. \nSince the anchor intention will be received first, the LLMs might pay less attention to the harmful intention and enter response status.\nFor toxicity, we propose the Intention-reinforced Malicious Inducement (IMI) module based on the availability bias mechanism in a progressive malicious prompting approach.\nDue to the ongoing emergence of statements correlated to harmful intentions, the output content of LLMs will be closer to these more accessible intentions, $\\textit{i.e.}$, more toxic.\nWe conducted extensive experiments under black-box settings, supporting that DIE could achieve 100\\% ASR-R and 92.9\\% ASR-G against GPT3.5-turbo.",
        "keywords": "large language models;jailbreak attacks;dual intention escape",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yanni Xue;Jiakai Wang;Zixin Yin;Yuqing Ma;Haotong Qin;Renshuai Tao;Xianglong Liu",
        "authorids": "~Yanni_Xue1;~Jiakai_Wang1;~Zixin_Yin1;~Yuqing_Ma2;~Haotong_Qin1;~Renshuai_Tao1;~Xianglong_Liu3",
        "gender": ";M;M;F;M;;",
        "homepage": ";https://jiakaiwangcn.github.io/;;https://vickyfox.github.io/;https://htqin.github.io/;;",
        "dblp": ";202/9216;03/683;;262/3626.html;;",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com/citations?hl=en;wWBVpyEAAAAJ;mK6n-KgAAAAJ;;",
        "orcid": ";0000-0001-5884-3412;;;;;",
        "linkedin": "yanni-xue/;;;;;;",
        "or_profile": "~Yanni_Xue1;~Jiakai_Wang1;~Zixin_Yin1;~Yuqing_Ma2;~Haotong_Qin1;~Renshuai_Tao1;~Xianglong_Liu3",
        "aff": "Beihang University;Zhongguancun Laboratory;;Beihang University;ETHZ - ETH Zurich;;",
        "aff_domain": "buaa.edu.cn;mail.zgclab.edu.cn;;buaa.edu.cn;ethz.ch;;",
        "position": "MS student;Researcher;;Associate Professor;Postdoc;;",
        "bibtex": "@inproceedings{\nxue2025dual,\ntitle={Dual Intention Escape: Jailbreak Attack against Large Language Models},\nauthor={Yanni Xue and Jiakai Wang and Zixin Yin and Yuqing Ma and Haotong Qin and Renshuai Tao and Xianglong Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=V8lBZMzahD}\n}",
        "github": "",
        "project": "",
        "reviewers": "bnhv;t1UE;gKBc;Em4M;GYx9",
        "site": "https://openreview.net/forum?id=V8lBZMzahD",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "3;4;4;5;5",
        "scope": "3;4;4;3;4",
        "confidence": "3;3;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6666666666666665
    },
    {
        "id": "V9fqhh4jCU",
        "title": "Helios: Learning and Adaptation of Matching Rules for Continual In-Network Malicious Traffic Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Network Intrusion Detection Systems (NIDS) are critical for web security by identifying and blocking malicious traffic.\nIn-network NIDS leverage programmable switches for high-speed traffic processing. However, they are unable to reconcile the fine-grained classification of known classes and the identification of unseen attacks. Moreover, they lack support for incremental updates.\nIn this paper, we propose Helios, an in-network malicious traffic detection system, for continual adaptation in attack-incremental scenarios.\nFirst, we design a novel Supervised Mixture Prototypical Learning (SMPL) method combined with clustering initialization to learn prototypes that encapsulate the knowledge, based on the weighted infinity norm distance.  SMPL enables known class classification and unseen attack identification through similarity comparison between prototypes and samples.\nThen, we design boundary calibration and overlap refinement to transform learned prototypes into priority-guided matching rules, ensuring precise and efficient in-network deployment.\nAdditionally, Helios supports incremental prototype learning and rule updates, achieving low-cost hardware reconfiguration.\nWe implement Helios on a Tofino switch and evaluation on three datasets shows that Helios achieves superior performance in classifying known classes (92\\%+ in ACC and F1) as well as identifying unseen attacks (62\\% - 98\\% in TPR).\nHelios has also reduced resource consumption and reconfiguration time, demonstrating its scalability and efficiency for real-world deployment.",
        "keywords": "Malicious traffic detection;Programmable switches;Prototypical learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhenning Shi;Dan Zhao;Yijia Zhu;Guorui Xie;Qing Li;Yong Jiang",
        "authorids": "~Zhenning_Shi3;~Dan_Zhao2;~Yijia_Zhu1;~Guorui_Xie1;~Qing_Li15;~Yong_Jiang3",
        "gender": ";F;M;M;M;M",
        "homepage": ";;;https://xgr19.github.io/;https://smartinternet.group/qing-li/;",
        "dblp": ";10/3489-3;;270/6072;181/2689-6;74/1552-1.html",
        "google_scholar": ";;;DaHzpI0AAAAJ;54AuaywAAAAJ;",
        "orcid": ";0000-0001-9016-5594;;0000-0001-7532-9116;0000-0002-6071-473X;0000-0002-4260-1395",
        "linkedin": ";;yijia-zhu-2191852a2/;;;",
        "or_profile": "~Zhenning_Shi3;~Dan_Zhao2;~Yijia_Zhu1;~Guorui_Xie1;~Qing_Li15;~Yong_Jiang3",
        "aff": ";Peng Cheng Laborotary;Xidian University;Pengcheng Laboratory;Pengcheng Laboratory+Pengcheng Laboratory;Tsinghua University",
        "aff_domain": ";pcl.ac.cn;xidian.edu.cn;pcl.ac.cn;pcl.ac.cn+pcl.ac.cn;tsinghua.edu.cn",
        "position": ";Researcher;Undergrad student;Assistant Researcher;Full Professor+Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nshi2025helios,\ntitle={Helios: Learning and Adaptation of Matching Rules for Continual In-Network Malicious Traffic Detection},\nauthor={Zhenning Shi and Dan Zhao and Yijia Zhu and Guorui Xie and Qing Li and Yong Jiang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=V9fqhh4jCU}\n}",
        "github": "",
        "project": "",
        "reviewers": "WFqz;SFwM;Phqm",
        "site": "https://openreview.net/forum?id=V9fqhh4jCU",
        "pdf_size": 0,
        "novelty": "5;5;5",
        "technical_quality": "4;6;5",
        "scope": "3;3;3",
        "confidence": "2;1;1",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.0
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            1.3333333333333333,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "VVbmdn95oG",
        "title": "Linear-Time Algorithms for Representative Subset Selection From Data Streams",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Representative subset selection from data streams is a critical problem with wide-ranging applications in web data mining and machine learning, such as social media marketing, big data summarization, and recommendation systems. This problem is often framed as maximizing a monotone submodular function subject to a knapsack constraint, where each data element in the stream has an associated cost, and the goal is to select elements within a budget $B$ to maximize revenue. However, existing algorithms typically rely on restrictive assumptions about the costs of data elements, and their performance bounds heavily depend on the budget $B$. As a result, these algorithms are only effective in limited scenarios and have super-linear time complexity, making them unsuitable for large-scale data streams. In this paper, we introduce the first linear-time streaming algorithms for this problem, without any assumptions on the data stream, while also minimizing memory usage. Specifically, our single-pass streaming algorithm achieves an approximation ratio of $1/8-\\epsilon$ under $\\mathcal{O}(n)$ time complexity and $\\mathcal{O}(k\\log\\frac{1}{\\epsilon})$ space complexity, where $k$ is the largest cardinality of any feasible solution. Our multi-pass streaming algorithm improves this to a $(1/2-\\epsilon)$-approximation using only three passes over the stream, with $\\mathcal{O}(\\frac{n}{\\epsilon}\\log\\frac{1}{\\epsilon})$ time complexity and $\\mathcal{O}(\\frac{k}{\\epsilon}\\log\\frac{1}{\\epsilon})$ space complexity. Extensive experiments across various applications related to web data mining and social media marketing demonstrate the superiority of our algorithms in terms of both effectiveness and efficiency.",
        "keywords": "web data mining;streaming algorithm;data summarization;submodular maximization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shuang Cui;Kai Han;Jing Tang",
        "authorids": "~Shuang_Cui1;~Kai_Han5;~Jing_Tang5",
        "gender": "M;M;M",
        "homepage": "https://scholar.google.com/citations?user=2e_9NCQAAAAJ&hl=zh-CN;;https://sites.google.com/view/jtang",
        "dblp": ";51/4757-3;83/663-4",
        "google_scholar": "2e_9NCQAAAAJ;n3GdeCUAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0001-6080-4850;0000-0002-6302-5366;0000-0002-0785-707X",
        "linkedin": ";;",
        "or_profile": "~Shuang_Cui1;~Kai_Han5;~Jing_Tang5",
        "aff": "Soochow University;Shanghai University of Finance and Economics;The Hong Kong University of Science and Technology (Guangzhou)+Hong Kong University of Science and Technology",
        "aff_domain": "suda.edu.cn;mail.shufe.edu.cn;hkust-gz.edu.cn+ust.hk",
        "position": "Associate Professor;Full Professor;Assistant Professor+Assistant Professor",
        "bibtex": "@inproceedings{\ncui2025lineartime,\ntitle={Linear-Time Algorithms for Representative Subset Selection From Data Streams},\nauthor={Shuang Cui and Kai Han and Jing Tang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=VVbmdn95oG}\n}",
        "github": "",
        "project": "",
        "reviewers": "AZiR;RwQv;4JNB;9ijt",
        "site": "https://openreview.net/forum?id=VVbmdn95oG",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "5;6;4;5",
        "scope": "2;4;3;4",
        "confidence": "1;4;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            2.5,
            1.118033988749895
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7745966692414834
    },
    {
        "id": "VWQwwMxFht",
        "title": "Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding Indistinguishability",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Pre-trained models (PTMs) are widely adopted across various downstream tasks in the machine learning supply chain. Adopting untrustworthy PTMs introduces significant security risks, where adversaries can poison the model supply chain by embedding hidden malicious behaviors (backdoors) into PTMs. However, existing backdoor attacks to PTMs can only achieve partially task-agnostic and the embedded backdoors are easily erased during the fine-tuning process. This makes it challenging for the backdoors to persist and propagate through the supply chain. In this paper, we propose a novel and severer backdoor attack, TransTroj, which enables the backdoors embedded in PTMs to efficiently transfer in the model supply chain. In particular, we first formalize this attack as an indistinguishability problem between poisoned and clean samples in the embedding space. We decompose embedding indistinguishability into pre- and post-indistinguishability, representing the similarity of the poisoned and reference embeddings before and after the attack. Then, we propose a two-stage optimization that separately optimizes triggers and victim PTMs to achieve embedding indistinguishability.  We evaluate TransTroj on four PTMs and six downstream tasks. Experimental results show that our method significantly outperforms SOTA task-agnostic backdoor attacks -- achieving nearly 100% attack success rate on most downstream tasks -- and demonstrates robustness under various system settings. Our findings underscore the urgent need to secure the model supply chain against such transferable backdoor attacks. The code is available at [https://anonymous.4open.science/r/TransTroj](https://anonymous.4open.science/r/TransTroj).",
        "keywords": "Backdoor attack;Pre-trained model;Model Supply Chain",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hao Wang;Shangwei Guo;Jialing He;Hangcheng Liu;Tianwei Zhang;Tao Xiang",
        "authorids": "~Hao_Wang66;~Shangwei_Guo1;~Jialing_He2;~Hangcheng_Liu1;~Tianwei_Zhang1;~Tao_Xiang2",
        "gender": "M;M;F;M;M;M",
        "homepage": "https://haowang.wang;http://www.cs.cqu.edu.cn/info/1332/5290.htm;;;https://personal.ntu.edu.sg/tianwei.zhang/index.html;",
        "dblp": ";176/6479;221/6024.html;277/7585;77/7902-4;22/4460-1.html",
        "google_scholar": "54HD4zQAAAAJ;wQrVkBYAAAAJ;5zrA6H8AAAAJ;NRlgD90AAAAJ;9vpiYDIAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": "0009-0001-2350-9032;;;0000-0002-4392-2254;;0000-0002-9439-4623",
        "linkedin": ";;;;;",
        "or_profile": "~Hao_Wang66;~Shangwei_Guo1;~Jialing_He2;~Hangcheng_Liu1;~Tianwei_Zhang1;~Tao_Xiang2",
        "aff": "Chongqing University;Chongqing University;Chongqing University;Nanyang Technological University;Nanyang Technological University;Chongqing University",
        "aff_domain": "cqu.edu.cn;cqu.edu.cn;cqu.edu.cn;ntu.edu.sg;ntu.edu.sg;cqu.edu.cn",
        "position": "PhD student;Associate Professor;Assistant Professor;Postdoc;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nwang2025model,\ntitle={Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding Indistinguishability},\nauthor={Hao Wang and Shangwei Guo and Jialing He and Hangcheng Liu and Tianwei Zhang and Tao Xiang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=VWQwwMxFht}\n}",
        "github": "",
        "project": "",
        "reviewers": "1Mrj;KKZH;LcRh;Dgbf",
        "site": "https://openreview.net/forum?id=VWQwwMxFht",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "5;5;6;6",
        "scope": "3;3;4;4",
        "confidence": "3;2;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6363636363636364
    },
    {
        "id": "W4dHcodACr",
        "title": "Optimizing Revenue through User Coupon Recommendations in Truthful Online Ad Auctions",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Online advertising serves as the primary revenue source for numerous Internet companies, which typically sell advertising slots through auctions. Conventional online ad auctions assume constant click-through rates (CTRs) and conversion rates (CVRs) for ads during the auction process. However, this paper studies a new scenario where advertisers can offer coupons to users, thereby influencing both CTRs and CVRs and consequently, the platform's revenue.\n\nWe study how to recommend user coupons to advertisers in truthful auction systems. We model the interaction between the platform and the advertisers as an extensive-form game, where advertisers first report coupon bids to the platform to receive coupon recommendations, and then participate in auctions by reporting their auction bids. Our research identifies a sufficient condition under which the advertisers' optimal strategy is to report their valuations truthfully in both the recommendation and auction stages.\n\nWe construct two mechanisms based on these findings. The first mechanism is a distribution-free mechanism, which is easily implementable in industrial systems; and the second is a revenue-optimal mechanism that offers simpler implementation compared to existing work. Both synthetic and industrial experiments show that our mechanisms improve the platform's revenue. Notably, our revenue-optimal mechanism achieves the same outcome compared to existing work by Liu et al., while offering a simpler implementation.",
        "keywords": "mechanism design; auction; coupon",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaodong Liu;Yiming Ding;Xiao Lin;changchengli;Peng Jiang;Weiran Shen",
        "authorids": "~Xiaodong_Liu2;~Yiming_Ding4;~Xiao_Lin4;~changchengli1;~Peng_Jiang6;~Weiran_Shen1",
        "gender": "M;M;M;M;M;M",
        "homepage": ";;;http://baidu.com;;https://www.weiran-shen.info/",
        "dblp": ";;09/1280-2;;;159/2147",
        "google_scholar": ";;;;https://scholar.google.com/citations?hl=en;-lXgERkAAAAJ",
        "orcid": ";;;;0000-0002-9266-0780;0000-0003-4366-9276",
        "linkedin": "%E6%99%93%E5%86%AC-%E5%88%98-036a75115/;%E4%B8%80%E9%B8%A3-%E4%B8%81-2815431b8/;;;;",
        "or_profile": "~Xiaodong_Liu2;~Yiming_Ding4;~Xiao_Lin4;~changchengli1;~Peng_Jiang6;~Weiran_Shen1",
        "aff": ";;;;Kuaishou Technology;Renmin University of China",
        "aff_domain": ";;;;kuaishou.com;ruc.edu.cn",
        "position": ";;;;Vice President;Associate Professor",
        "bibtex": "@inproceedings{\nliu2025optimizing,\ntitle={Optimizing Revenue through User Coupon Recommendations in Truthful Online Ad Auctions},\nauthor={Xiaodong Liu and Yiming Ding and Xiao Lin and changchengli and Peng Jiang and Weiran Shen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=W4dHcodACr}\n}",
        "github": "",
        "project": "",
        "reviewers": "1Lfu;s6UX;ZzD1;1QMK;yD8Z",
        "site": "https://openreview.net/forum?id=W4dHcodACr",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "3;5;5;5;7",
        "scope": "3;3;4;4;3",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            5.0,
            1.2649110640673518
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.19611613513818407
    },
    {
        "id": "W8cPNZbKuA",
        "title": "Mitigating the Participation Bias by Balancing Extreme Ratings",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Rating aggregation plays a crucial role in various fields, such as product recommendations, hotel rankings, and teaching evaluations. However, traditional averaging methods can be affected by participation bias, where some raters do not participate in the rating process, leading to potential distortions. In this paper, we consider a robust rating aggregation task under the participation bias. We assume that raters may not reveal their ratings with a certain probability depending on their individual ratings, resulting in partially observed samples. Our goal is to minimize the expected squared loss between the aggregated ratings and the average of all underlying ratings (possibly unobserved) in the worst-case scenario.\n\n  We focus on two settings based on whether the sample size (i.e. the number of raters) is known. In the first setting, where the sample size is known, we propose an aggregator, named as the Balanced Extremes Aggregator. It estimates unrevealed ratings with a balanced combination of extreme ratings. When the sample size is unknown, we derive another aggregator, the Polarizing-Averaging Aggregator, which becomes optimal as the sample size grows to infinity. Numerical results demonstrate the superiority of our proposed aggregators to participation bias, compared to simple averaging.",
        "keywords": "Rating Aggregation;Participation Bias;Robustness",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongkang Guo;Yuqing Kong;Jialiang Liu",
        "authorids": "~Yongkang_Guo1;~Yuqing_Kong1;~Jialiang_Liu1",
        "gender": "M;F;M",
        "homepage": ";https://cfcs.pku.edu.cn/yuqkong/;https://github.com/ljlhhh000",
        "dblp": ";https://dblp.uni-trier.de/pers/k/Kong:Yuqing.html;",
        "google_scholar": "8E7FdhkAAAAJ;;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Yongkang_Guo1;~Yuqing_Kong1;~Jialiang_Liu1",
        "aff": "Peking University;Peking University;Peking University",
        "aff_domain": "pku.edu.cn;pku.edu.cn;stu.pku.edu.cn",
        "position": "PhD student;Assistant Professor;Undergrad student",
        "bibtex": "@inproceedings{\nguo2025mitigating,\ntitle={Mitigating the Participation Bias by Balancing Extreme Ratings},\nauthor={Yongkang Guo and Yuqing Kong and Jialiang Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=W8cPNZbKuA}\n}",
        "github": "",
        "project": "",
        "reviewers": "MD95;m1tU;EAXw;1nS9;vrzJ",
        "site": "https://openreview.net/forum?id=W8cPNZbKuA",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;5;6;5;6",
        "scope": "3;4;4;4;3",
        "confidence": "1;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6454972243679028
    },
    {
        "id": "WQZbJjzLkd",
        "title": "Peripheral Instinct: How External Devices Breach Browser Sandboxes",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Browser APIs such as WebHID, WebUSB, Web Serial, and Web MIDI enable web applications to interact directly with external devices.\n  The support of such APIs in Chromium-based browsers, such as Chrome and Edge, radically changes the threat model for peripherals and increases the attack surface. \n  In the past, devices could assume a trusted host, i.e., the operating system.\n  Now, the host is a potentially malicious website and cannot be trusted. \n  \n  We show how this changed threat model leads to security and privacy problems, up to a complete compromise of the operating system. \n  While the API specifications list initial security considerations, they shift the responsibility to (unprepared) device vendors. \n  We systematically analyze the security implications of external devices exposed by such new APIs.\n  By reverse-engineering peripheral devices of several popular widespread vendors, we show that many vendors allow controlling devices via Web APIs up to reprogramming or even fully replacing the firmware. \n  Consequently, web attackers can reprogram devices with malicious payloads and custom firmware without requiring any physical interaction.\n  To demonstrate the security implications, we build several full-chain exploits, leading to arbitrary code execution on the victim system, circumventing the browser sandbox. \n  Our research shows that browser security should not rely on the secure implementation of third-party hardware.",
        "keywords": "Browser Security;Web API;HID;USB;Firmware",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Leon Trampert;Lorenz Hetterich;Lukas Gerlach;Mona Schappert;Christian Rossow;Michael Schwarz",
        "authorids": "~Leon_Trampert1;~Lorenz_Hetterich1;~Lukas_Gerlach2;~Mona_Schappert1;~Christian_Rossow1;~Michael_Schwarz3",
        "gender": "M;M;M;;M;M",
        "homepage": "https://leon.trampert.me/;;https://lukasgerlach.me;;https://christian-rossow.de/;https://cispa.de/en/people/c02misc",
        "dblp": ";;;;08/6024;08/1117-1.html",
        "google_scholar": "Ej7KWxUAAAAJ;https://scholar.google.de/citations?user=6lvczZcAAAAJ;e7EqorkAAAAJ;;https://scholar.google.de/citations?user=lNn4hRMAAAAJ;https://scholar.google.at/citations?user=2HPadJUAAAAJ",
        "orcid": "0009-0001-6891-965X;0009-0007-1201-0299;;;0000-0003-2470-8444;0000-0001-6744-3410",
        "linkedin": ";;;;christian-rossow-6943b64/;",
        "or_profile": "~Leon_Trampert1;~Lorenz_Hetterich1;~Lukas_Gerlach2;~Mona_Schappert1;~Christian_Rossow1;~Michael_Schwarz3",
        "aff": "CISPA Helmholtz Center for Information Security+Universit\u00e4t des Saarlandes;CISPA, saarland university, saarland informatics campus;CISPA Helmholtz Center for Information Security+Universit\u00e4t des Saarlandes;;CISPA Helmholtz Center for Information Security;CISPA Helmholtz Center for Information Security",
        "aff_domain": "cispa.de+uni-saarland.de;cispa.saarland;cispa.de+uni-saarland.de;;cispa.de;cispa.de",
        "position": "PhD student+PhD student;PhD student;PhD student+PhD student;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ntrampert2025peripheral,\ntitle={Peripheral Instinct: How External Devices Breach Browser Sandboxes},\nauthor={Leon Trampert and Lorenz Hetterich and Lukas Gerlach and Mona Schappert and Christian Rossow and Michael Schwarz},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=WQZbJjzLkd}\n}",
        "github": "",
        "project": "",
        "reviewers": "cUXT;jRaD;9z4j;2MFU;ihpo",
        "site": "https://openreview.net/forum?id=WQZbJjzLkd",
        "pdf_size": 0,
        "novelty": "3;3;3;3;4",
        "technical_quality": "3;3;3;3;6",
        "scope": "4;4;2;4;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            3.2,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            3.6,
            1.2
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "WTYgCjmCKQ",
        "title": "xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task Fusion in Recommender Systems",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recommender systems need to optimize various types of user feedback, e.g., clicks, likes, and shares. A typical recommender system handling multiple types of feedback has two components: a multi-task learning (MTL) module, predicting feedback such as click-through rate and like rate; and a multi-task fusion (MTF) module, integrating these predictions into a single score for item ranking. MTF is essential for ensuring user satisfaction, as it directly influences recommendation outcomes. Recently, reinforcement learning (RL) has been applied to MTF tasks to improve long-term user satisfaction. However, existing RL-based MTF methods are formula-based methods, which only adjust limited coefficients within pre-defined formulas. The pre-defined formulas restrict the RL search space and become a bottleneck for MTF. To overcome this, we propose a formula-free MTF framework. We demonstrate that any suitable fusion function can be expressed as a composition of single-variable monotonic functions, as per the Sprecher Representation Theorem. Leveraging this, we introduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined formulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we employ a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By expanding the MTF search space, xMTF outperforms existing methods in extensive offline and online experiments. xMTF has been deployed online, serving over 100 million users.",
        "keywords": "Multi-Task Fusion;Reinforcement Learning;Recommender System",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yang Cao;Changhao Zhang;Xiaoshuang Chen;Kaiqiao Zhan;Ben Wang",
        "authorids": "~Yang_Cao28;~Changhao_Zhang2;~Xiaoshuang_Chen3;~Kaiqiao_Zhan1;~Ben_Wang4",
        "gender": ";;M;;M",
        "homepage": ";;;;https://cn.linkedin.com/in/%E7%8A%87-%E7%8E%8B-26315566",
        "dblp": ";;;;",
        "google_scholar": "K71gbCEAAAAJ;;;7phrAWgAAAAJ;",
        "orcid": "0000-0002-4724-5289;;0000-0003-1267-1680;;",
        "linkedin": ";;;;",
        "or_profile": "~Yang_Cao28;~Changhao_Zhang2;~Xiaoshuang_Chen3;~Kaiqiao_Zhan1;~Ben_Wang4",
        "aff": "Kuaishou- \u5feb\u624b\u79d1\u6280;;;kwai inc.;",
        "aff_domain": "kuaishou.com;;;kwai.com;",
        "position": "Researcher;;;Researcher;",
        "bibtex": "@inproceedings{\ncao2025xmtf,\ntitle={x{MTF}: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task Fusion in Recommender Systems},\nauthor={Yang Cao and Changhao Zhang and Xiaoshuang Chen and Kaiqiao Zhan and Ben Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=WTYgCjmCKQ}\n}",
        "github": "",
        "project": "",
        "reviewers": "DDQq;g2tD;9VmM;ZvK5;EBYW",
        "site": "https://openreview.net/forum?id=WTYgCjmCKQ",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;5;5;5;6",
        "scope": "3;4;3;4;4",
        "confidence": "3;3;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "WcuXvn3HVk",
        "title": "AERO: Enhancing Sharding Blockchain via Deep Reinforcement Learning for Account Migration",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Sharding blockchain networks face significant scalability challenges due to high frequencies of cross-shard transactions and uneven workload distributions among shards. To address these scalability issues, account migration offers a promising solution. However, existing migration solutions struggle with the high computational overhead and insufficient capture of complex transaction patterns. We propose AERO, a deep reinforcement learning framework for efficient account migration in sharding blockchains. AERO employs a prefix-based grouping strategy to enable group-level migration decisions and capture complex transaction patterns and relationships between accounts. We also implement a sharding blockchain system called AEROChain, which integrates our decentralized AERO and aligns with the blockchain decentralization principle. Extensive evaluation with real Ethereum transaction data demonstrates that AERO improves the system throughput by 31.77% compared to existing solutions, effectively reducing cross-shard transactions and balancing shard workloads.",
        "keywords": "Blockchain;Sharding;Account migration;Reinforcement learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Mingxuan Song;Pengze Li;Bohan Zhou;Shenglin Yin;Zhen Xiao;Jieyi Long",
        "authorids": "~Mingxuan_Song1;~Pengze_Li1;~Bohan_Zhou1;~Shenglin_Yin1;~Zhen_Xiao2;~Jieyi_Long1",
        "gender": ";M;M;;M;M",
        "homepage": ";;https://www.zhihu.com/people/Zhoubh;;http://zhenxiao.com;",
        "dblp": ";;;302/2012;;95/2892",
        "google_scholar": "w_MNPVMAAAAJ;;https://scholar.google.com/citations?hl=zh-CN;;9sq1eeUAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0001-7015-0491;0000-0001-5495-7631;0000-0002-5216-9946;;",
        "linkedin": ";;;;;jieyilong/",
        "or_profile": "~Mingxuan_Song1;~Pengze_Li1;~Bohan_Zhou1;~Shenglin_Yin1;~Zhen_Xiao2;~Jieyi_Long1",
        "aff": "Peking University;Peking University;Peking University;Peking University;Peking University;Theta Labs, Inc.",
        "aff_domain": "pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn;pku.edu.cn;thetalabs.org",
        "position": "PhD student;PhD student;MS student;PhD student;Full Professor;Principal Researcher",
        "bibtex": "@inproceedings{\nsong2025aero,\ntitle={{AERO}: Enhancing Sharding Blockchain via Deep Reinforcement Learning for Account Migration},\nauthor={Mingxuan Song and Pengze Li and Bohan Zhou and Shenglin Yin and Zhen Xiao and Jieyi Long},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=WcuXvn3HVk}\n}",
        "github": "",
        "project": "",
        "reviewers": "vQLF;c4Zs;nQDL;3bMu",
        "site": "https://openreview.net/forum?id=WcuXvn3HVk",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "5;5;5;6",
        "scope": "3;3;4;3",
        "confidence": "3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7071067811865475
    },
    {
        "id": "WwDCWneGzP",
        "title": "Subgraph-Aware Training of Language Models for Knowledge Graph Completion Using Structure-Aware Contrastive Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Fine-tuning pre-trained language models (PLMs) has recently shown a potential to improve knowledge graph completion (KGC). However, most PLM-based methods focus solely on encoding textual information, neglecting the long-tailed nature of knowledge graphs and their various topological structures, e.g., subgraphs, shortest paths, and degrees. We claim that this is a major obstacle to achieving higher accuracy of PLMs for KGC. To this end, we propose a Subgraph-Aware Training framework for KGC (SATKGC) with two ideas: (i) subgraph-aware mini-batching to encourage hard negative sampling and to mitigate an imbalance in the frequency of entity occurrences during training, and (ii) new contrastive learning to focus more on harder in-batch negative triples and harder positive triples in terms of the structural properties of the knowledge graph. To the best of our knowledge, this is the first study to comprehensively incorporate the structural inductive bias of the knowledge graph into fine-tuning PLMs. Extensive experiments on three KGC benchmarks demonstrate the superiority of SATKGC. Our code is available (https://anonymous.4open.science/r/SATKGC-61B0/README.md).",
        "keywords": "Knowledge Graph;Contrastvie Learning;Hard Negative Sampling",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Youmin Ko;Hyemin Yang;Taeuk Kim;Hyunjoon Kim",
        "authorids": "~Youmin_Ko1;~Hyemin_Yang1;~Taeuk_Kim1;~Hyunjoon_Kim1",
        "gender": "M;F;M;M",
        "homepage": "https://github.com/meaningful96;https://github.com/Hyemeee;https://galsang.github.io;https://sites.google.com/view/hyudatalab/members",
        "dblp": "383/8071;;205/3110;45/7699",
        "google_scholar": ";;eH5uq7wAAAAJ;VoZ1dUkAAAAJ",
        "orcid": "0009-0007-9369-6842;;0000-0001-6919-7727;0009-0009-4019-312X",
        "linkedin": "meainingful96-92a763252/;;\ud0dc\uc6b1-\uae40-07125a13a/;hyunjoon-kim/",
        "or_profile": "~Youmin_Ko1;~Hyemin_Yang1;~Taeuk_Kim1;~Hyunjoon_Kim1",
        "aff": "Hanyang University;Hanyang University;Hanyang University;Hanyang University",
        "aff_domain": "hanyang.ac.kr;hanyang.ac.kr;hanyang.ac.kr;hanyang.ac.kr",
        "position": "PhD student;MS student;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nko2025subgraphaware,\ntitle={Subgraph-Aware Training of Language Models for Knowledge Graph Completion Using Structure-Aware Contrastive Learning},\nauthor={Youmin Ko and Hyemin Yang and Taeuk Kim and Hyunjoon Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=WwDCWneGzP}\n}",
        "github": "",
        "project": "",
        "reviewers": "tXuk;4tPq;8q3y;oWwK",
        "site": "https://openreview.net/forum?id=WwDCWneGzP",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "5;6;6;6",
        "scope": "3;4;3;2",
        "confidence": "4;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            5.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.0,
            0.7071067811865476
        ],
        "confidence_avg": [
            2.75,
            1.0897247358851685
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6622661785325219
    },
    {
        "id": "WzbU8SFXfJ",
        "title": "Personalized Image Generation with Large Multimodal Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Personalized content filtering, such as recommender systems, has become a critical infrastructure to alleviate information overload. However, these systems merely filter existing content and are constrained by its limited diversity, making it difficult to meet users\u2019 varied content needs. To address this limitation, personalized content generation has emerged as a promising direction with broad applications. Nevertheless, most existing research focuses on personalized text generation, with relatively little attention given to personalized image generation. The limited work in personalized image generation faces challenges in accurately capturing users\u2019 visual preferences and needs from noisy user-interacted images and complex multimodal instructions. Worse still, there is a lack of supervised data for training personalized image generation models. \n\nTo overcome the challenges, we propose a Personalized Image Generation Framework named Pigeon, which adopts exceptional large multimodal models with three dedicated modules to capture users\u2019 visual preferences and needs from noisy user history and multimodal instructions. To alleviate the data scarcity, we introduce a two-stage preference alignment scheme, comprising masked preference reconstruction and pairwise preference alignment, to align Pigeon with the personalized image generation task. We apply Pigeon to personalized sticker and movie poster generation, where extensive quantitative results and human evaluation highlight the superiority of Pigeon over various generative baselines.",
        "keywords": "Personalized Image Generation;Large Multimodal Models;Preference Alignment",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yiyan Xu;Wenjie Wang;Yang Zhang;Tang Biao;Peng Yan;Fuli Feng;Xiangnan He",
        "authorids": "~Yiyan_Xu1;~Wenjie_Wang1;~Yang_Zhang24;~Tang_Biao1;~Peng_Yan4;~Fuli_Feng1;~Xiangnan_He1",
        "gender": "F;M;M;;M;M;M",
        "homepage": ";https://wenjiewwj.github.io/;http://home.ustc.edu.cn/~zy2015/;;https://yanpeng80.github.io/;https://fulifeng.github.io/;http://staff.ustc.edu.cn/~hexn",
        "dblp": "336/2834;38/1956-7;06/6785-72;;;183/9198;59/1007",
        "google_scholar": "D3EVI7YAAAAJ;Ma5DtmoAAAAJ;M9NcazMAAAAJ;;https://scholar.google.com/citations?hl=en;https://scholar.google.com.sg/citations?user=QePM4u8AAAAJ;https://scholar.google.com.sg/citations?user=X45Go24AAAAJ",
        "orcid": "0000-0002-5937-7289;0000-0002-5199-1428;0000-0002-7863-5183;;0000-0002-6211-4543;0000-0002-5828-9842;0000-0001-8472-7992",
        "linkedin": ";;;;;;",
        "or_profile": "~Yiyan_Xu1;~Wenjie_Wang1;~Yang_Zhang24;~Tang_Biao1;~Peng_Yan4;~Fuli_Feng1;~Xiangnan_He1",
        "aff": "University of Science and Technology of China;University of Science and Technology of China;National University of Singapore;;Meituan;University of Science and Technology of China;University of Science and Technology of China",
        "aff_domain": "ustc.edu.cn;ustc.edu.cn;nus.edu.sg;;meituan.com;ustc.edu.cn;ustc.edu.cn",
        "position": "PhD student;Full Professor;Postdoc;;Tech Leader;Full Professor;Professor",
        "bibtex": "@inproceedings{\nxu2025personalized,\ntitle={Personalized Image Generation with Large Multimodal Models},\nauthor={Yiyan Xu and Wenjie Wang and Yang Zhang and Tang Biao and Peng Yan and Fuli Feng and Xiangnan He},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=WzbU8SFXfJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "uXwM;nXFf;Y9yF;H2Zr;EgvQ",
        "site": "https://openreview.net/forum?id=WzbU8SFXfJ",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "3;5;6;6;7",
        "scope": "1;3;3;3;4",
        "confidence": "4;1;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.4,
            1.3564659966250536
        ],
        "scope_avg": [
            2.8,
            0.9797958971132712
        ],
        "confidence_avg": [
            3.0,
            1.0954451150103321
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.15655607277128739
    },
    {
        "id": "X8oa3cJEfv",
        "title": "Not All Benignware Are Alike: Enhancing Clean-Label Attacks on Malware Classifiers",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Machine learning (ML) based malware classifiers are widely deployed in web applications. Training such classifiers often relies on crowdsourced threat feeds, creating a natural attack point. Recent studies show that attackers can misguide models by injecting trigger embedded samples during training. In the malware domain, attackers are typically limited to clean-label attacks, where they lack control over data labeling. However, clean-label attacks often suffer from suboptimal performance due to competition between trigger features and original clean features during training. Existing studies typically construct poisoned samples by embedding triggers into randomly selected benignware (a method referred to as \"random selection\"). However, not all benignware are equally suitable for trigger embedding, as the degree of competition between trigger features and original clean features may vary among different benignware. To enhance the effectiveness of clean-label attacks, we propose a simple yet effective sample selection method, called $\\textbf{P}$oisoning $\\textbf{M}$alware-$\\textbf{S}$imilar $\\textbf{B}$enignware $\\textbf{(PMSB)}$, to identify samples to be poisoned. It reduces the competition between trigger features and original clean features during model training, thereby enhancing the influence of trigger features on the model's decision-making. Additionally, to identify malware-similar benignware, we introduce three distance metrics from different perspectives for sample selection, allowing it to adapt to varying data distributions. Extensive evaluations on three datasets under different attack settings demonstrate the superiority and broad applicability of PMSB, achieving an improvement in attack success rate of over 23.97%.",
        "keywords": "backdoor attack;clean-label attack;ML malware classification",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xutong Wang;Yun Feng;Bingsheng Bi;Yaqin Cao;Ze Jin;Xinyu Liu;Yuling Liu;Yunpeng Li",
        "authorids": "~Xutong_Wang1;~Yun_Feng2;~Bingsheng_Bi2;~Yaqin_Cao1;~Ze_Jin2;~Xinyu_Liu20;~Yuling_Liu2;~Yunpeng_Li7",
        "gender": ";;M;F;M;F;M;M",
        "homepage": ";;;;https://people.ucas.edu.cn/~jinze?language=en;;http://people.ucas.edu.cn/~yulingliu;https://scholar.google.com/citations?user=CDyIJocAAAAJ&hl=en",
        "dblp": ";;;;;98/738-19.html;;",
        "google_scholar": "https://scholar.google.com.hk/citations?user=RCe1Ae4AAAAJ;;;;;;https://scholar.google.com.hk/citations?user=phDkQ60AAAAJ;CDyIJocAAAAJ",
        "orcid": ";;;0009-0005-5277-8046;;0000-0002-8449-839X;0000-0002-2740-9362;0000-0002-5156-889X",
        "linkedin": ";;%E7%82%B3%E6%99%9F-%E6%AF%95-093a2b323/;;;;;",
        "or_profile": "~Xutong_Wang1;~Yun_Feng2;~Bingsheng_Bi2;~Yaqin_Cao1;~Ze_Jin2;~Xinyu_Liu20;~Yuling_Liu2;~Yunpeng_Li7",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences;;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering\uff0cCAS;Institute of Information Engineering, Chinese Academy of Sciences+Institute of Information Engineering, Chinese Academy of Sciences",
        "aff_domain": "iie.ac.cn;;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn+iie.ac.cn",
        "position": "PhD student;;MS student;PhD student;Associate Professor;Postdoc;Full Professor;Associate Professor+PhD student",
        "bibtex": "@inproceedings{\nwang2025not,\ntitle={Not All Benignware Are Alike: Enhancing Clean-Label Attacks on Malware Classifiers},\nauthor={Xutong Wang and Yun Feng and Bingsheng Bi and Yaqin Cao and Ze Jin and Xinyu Liu and Yuling Liu and Yunpeng Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=X8oa3cJEfv}\n}",
        "github": "",
        "project": "",
        "reviewers": "9bXi;XXYs;3DiK;wHJj;DK7Z",
        "site": "https://openreview.net/forum?id=X8oa3cJEfv",
        "pdf_size": 0,
        "novelty": "2;4;5;5;5",
        "technical_quality": "4;4;5;5;5",
        "scope": "4;3;3;2;2",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            2.8,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "XNvag15LFb",
        "title": "A Context-Aware Framework for Integrating Ad Auctions and Recommendations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recently, many e-commerce platforms have favored presenting a mixed list of ads and organic content to users. The widely-used approach separately ranks ads and organic items, then sequentially inserts ads into the list of organic items. However, this method yields sub-optimal results. Firstly, it only ensures that each generated ad and organic item list achieves local optimality, while the predetermined insertion order fails to guarantee global optimality. Secondly, this approach overlooks the mutual effect between organic items and ads, resulting in an incomplete utilization of contextual information. Besides, it cannot prevent strategic behavior by advertisers. Therefore, we propose a context-aware integrated framework to address these issues. This framework applies automated mechanism design to integrated ad auctions for the first time. Specifically, it models ads and organic items simultaneously along with their contextual information and employs a learning-based approach to prevent advertisers from engaging in strategic behavior. Afterward, the framework directly generates a mixed list, enhancing the overall performance. We also propose $\\textbf{T}$ransformer encoder-based $\\textbf{I}$ntegrated $\\textbf{C}$ontextual $\\textbf{Net}$work (TICNet) to generate the optimal integrated contextual ad auction. Finally, we validate the effectiveness of TICNet on synthetic and real-world datasets. Our experimental results demonstrate that TICNet significantly outperforms baseline models across multiple metrics.",
        "keywords": "Contextual Information;Integrated Ad Auction;Transformer;Automated Mechanism Design",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuchao Ma;Weian Li;Yuejia Dou;Zhiyuan Su;Changyuan Yu;Qi Qi",
        "authorids": "~Yuchao_Ma2;~Weian_Li1;~Yuejia_Dou1;~Zhiyuan_Su2;~Changyuan_Yu1;~Qi_Qi2",
        "gender": "M;;M;M;M;",
        "homepage": "https://chaoym.github.io/;;https://douyuejia.github.io;https://zhiyuansu0326.github.io/;;",
        "dblp": "59/8392.html;;277/2882;;https://dblp.uni-trier.de/pid/00/2225.html;",
        "google_scholar": "jJPdWKYAAAAJ;;;5T0sVTgAAAAJ;;",
        "orcid": ";;0009-0008-9489-7838;0009-0008-9117-7923;;",
        "linkedin": ";;;;;",
        "or_profile": "~Yuchao_Ma2;~Weian_Li1;~Yuejia_Dou1;~Zhiyuan_Su2;~Changyuan_Yu1;~Qi_Qi2",
        "aff": "Renmin University of China;;Renmin University of China;Renmin University of China+Dalhousie University;Tsinghua University;",
        "aff_domain": "ruc.edu.cn;;ruc.edu.cn;ruc.edu.cn+dal.ca;tsinghua.edu.cn;",
        "position": "PhD student;;PhD student;Undergrad student+Researcher;Researcher;",
        "bibtex": "@inproceedings{\nma2025a,\ntitle={A Context-Aware Framework for Integrating Ad Auctions and Recommendations},\nauthor={Yuchao Ma and Weian Li and Yuejia Dou and Zhiyuan Su and Changyuan Yu and Qi Qi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=XNvag15LFb}\n}",
        "github": "",
        "project": "",
        "reviewers": "yYxM;rh4s;tHc8;5iVA",
        "site": "https://openreview.net/forum?id=XNvag15LFb",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;4;5;6",
        "scope": "3;3;3;4",
        "confidence": "3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4472135954999579
    },
    {
        "id": "XqP7B37qML",
        "title": "Relying on the Metrics of Evaluated Agents",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Online platforms and regulators face a continuing  problem of designing effective evaluation metrics. While tools for collecting and processing data continue to progress, this has not addressed the problem of *unknown unknowns*, or fundamental informational limitations on part of the evaluator. To guide the choice of metrics in the face of this informational problem, we turn to the evaluated agents themselves, who may have more information about how to measure their own outcomes. We model this interaction as an agency game, where we ask: *When does an agent have an incentive to reveal the observability of a metric to their evaluator?* We show that an agent will prefer to reveal metrics that differentiate the most difficult tasks from the rest, and conceal metrics that differentiate the easiest. We further show that the agent can prefer to reveal a metric *garbled* with noise over both fully concealing and fully revealing. This indicates an economic value to privacy that yields Pareto improvement for both the agent and evaluator. We demonstrate these findings on data from online rideshare platforms.",
        "keywords": "Information elicitation;evaluation metrics;principal agent games;unknown unknowns",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Serena Lutong Wang;Michael Jordan;Katrina Ligett;R. Preston McAfee",
        "authorids": "~Serena_Lutong_Wang1;~Michael_Jordan1;~Katrina_Ligett1;~R._Preston_McAfee1",
        "gender": "F;M;;M",
        "homepage": "https://serenalwang.com/;http://www.cs.berkeley.edu/~jordan/;;https://mc4f.ee",
        "dblp": "222/1672;j/MichaelIJordan;;62/2039",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.tw/citations?user=yxUduqMAAAAJ;;Hz6wymsAAAAJ",
        "orcid": ";0000-0001-8935-817X;;",
        "linkedin": ";;;",
        "or_profile": "~Serena_Lutong_Wang1;~Michael_Jordan1;~Katrina_Ligett1;~R._Preston_McAfee1",
        "aff": "University of California, Berkeley+Google;University of California, Berkeley;;Research, Google",
        "aff_domain": "berkeley.edu+google.com;berkeley.edu;;research.google.com",
        "position": "PhD student+Software Engineer;Full Professor;;Principal Researcher",
        "bibtex": "@inproceedings{\nwang2025relying,\ntitle={Relying on the Metrics of Evaluated Agents},\nauthor={Serena Lutong Wang and Michael Jordan and Katrina Ligett and R. Preston McAfee},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=XqP7B37qML}\n}",
        "github": "",
        "project": "",
        "reviewers": "paTJ;1opm;MjmS;HVd3",
        "site": "https://openreview.net/forum?id=XqP7B37qML",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "4;4;6;6",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            5.0,
            1.0
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "Xzg8OETs6Z",
        "title": "Leveraging Invariant Principle for Heterophilic Graph Structure Distribution Shifts",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Heterophilic  Graph Neural Networks (HGNNs) have shown promising results for semi-supervised learning tasks on graphs. Notably, most real-world heterophilic graphs are composed of a mixture of nodes with different neighbor patterns, exhibiting local node-level homophilic and heterophilic structures. However, existing works are only devoted to designing better unified HGNN backbones for node classification tasks on heterophilic and homophilic graph benchmarks simultaneously, and their analyses of HGNN performance concerning nodes are only based on the determined data distribution without exploring the effect caused by the difference of structural pattern between training and testing nodes. How to learn invariant node representations on heterophilic graphs to handle this structure difference or distribution shifts remains unexplored. In this paper, we first discuss the limitations of previous graph-based invariant learning methods in addressing the heterophilic graph structure distribution shifts from the perspective of data augmentation. Then, we propose HEI, a framework capable of generating invariant node representations through incorporating heterophily information, node's estimated neighbor pattern, to infer latent environments without augmentation, which are then used for invariant prediction. We provide detailed theoretical guarantees to clarify the reasonability of HEI. Extensive experiments on various benchmarks and backbones can also demonstrate the effectiveness and robustness of our method compared with existing state-of-the-art baselines.",
        "keywords": "Graph Representation Learning;Node Classification;Invariant Learning;Distribution Shifts;Heterophily and Homophily",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jinluan Yang;Zhengyu Chen;Teng Xiao;Yong Lin;Wenqiao Zhang;Kun Kuang",
        "authorids": "~Jinluan_Yang1;~Zhengyu_Chen3;~Teng_Xiao2;~Yong_Lin2;~Wenqiao_Zhang1;~Kun_Kuang2",
        "gender": ";;;;M;M",
        "homepage": ";;;;;https://cn.linkedin.com/in/kun-kuang-915877a4",
        "dblp": ";;;;250/4486.html;",
        "google_scholar": ";;;;https://scholar.google.com/citations?hl=zh-CN;",
        "orcid": ";;;;0000-0002-5988-7609;0000-0001-7024-9790",
        "linkedin": ";;;;;",
        "or_profile": "~Jinluan_Yang1;~Zhengyu_Chen3;~Teng_Xiao2;~Yong_Lin2;~Wenqiao_Zhang1;~Kun_Kuang2",
        "aff": ";;;;Zhejiang University;Zhejiang University",
        "aff_domain": ";;;;zju.edu.cn;zju.edu.cn",
        "position": ";;;;Assistant Professor;Associate Professor",
        "bibtex": "@inproceedings{\nyang2025leveraging,\ntitle={Leveraging Invariant Principle for Heterophilic Graph Structure Distribution Shifts},\nauthor={Jinluan Yang and Zhengyu Chen and Teng Xiao and Yong Lin and Wenqiao Zhang and Kun Kuang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=Xzg8OETs6Z}\n}",
        "github": "",
        "project": "",
        "reviewers": "rt81;E7mo;3cCB;HaHw;UALA",
        "site": "https://openreview.net/forum?id=Xzg8OETs6Z",
        "pdf_size": 0,
        "novelty": "3;4;4;6;6",
        "technical_quality": "4;5;3;5;6",
        "scope": "3;4;4;3;4",
        "confidence": "3;4;1;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.2
        ],
        "technical_quality_avg": [
            4.6,
            1.019803902718557
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.485912657903775
    },
    {
        "id": "YHW5w2hZcZ",
        "title": "Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In the literature, prior studies on Video Anomaly Detection (VAD) mainly focus on detecting whether each video frame is abnormal or not in the video, which largely ignore the structured video semantic information (i.e., what, when, and where does the abnormal event happen), though this structured information could be employed to construct a more precise and efficient system for abnormal event monitoring and retrieval. With this in mind, we propose a new chat-paradigm Multi-scene Video Abnormal Event Extraction and Localization (M-VAE) task, aiming to extract the abnormal event quadruples (i.e., subject, event type, object, scene) and localize such event. Further, this paper believes that this new task faces two key challenges, i.e., global-local spatial modeling and global-local spatial balancing. To this end, this paper proposes a Global-local Spatial-sensitive Large Language Model (LLM) named Sherlock, i.e., acting like Sherlock Holmes to track down the criminal events, for this M-VAE task. Specifically, this approach designs a Global-local Spatial-enhanced MoE (GSM) module and a Spatial Imbalance Regulator (SIR) to address the above two challenges respectively. Extensive experiments on our constructed M-VAE instruction dataset show the significant advantages of Sherlock over several advanced Video-LLMs. This justifies the importance of global-local spatial information for the M-VAE task and the effectiveness of Sherlock in capturing such information.",
        "keywords": "Multi-scene Video;Video Abnormal Event;Spatial-sensitive LLM",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Junxiao Ma;Jingjing Wang;Jiamin Luo;Peiying Yu;Guodong Zhou",
        "authorids": "~Junxiao_Ma1;~Jingjing_Wang4;~Jiamin_Luo1;~Peiying_Yu1;~Guodong_Zhou1",
        "gender": "M;M;F;;M",
        "homepage": "https://myaccount.google.com/u/1/?hl=zh-CN;https://djingwang.github.io/;https://github.com/BonnieLuo;;http://nlp.suda.edu.cn/~gdzhou/",
        "dblp": ";62/2638;;;",
        "google_scholar": ";;;;",
        "orcid": "0009-0008-6437-2061;0009-0006-3619-1525;;0009-0000-7989-135X;0000-0002-7887-5099",
        "linkedin": ";;;;",
        "or_profile": "~Junxiao_Ma1;~Jingjing_Wang4;~Jiamin_Luo1;~Peiying_Yu1;~Guodong_Zhou1",
        "aff": "School of Computer Science and Technology;Soochow University+Microsoft (Asia);Suzhou University;Soochow University;Soochow University, China",
        "aff_domain": "stu.suda.edu;suda.edu.cn+microsoft.com;suda.edu.cn;suda.edu.cn;suda.edu.cn",
        "position": "MS student;Associate Professor+Senior Technical Consultant;PhD student;MS student;Full Professor",
        "bibtex": "@inproceedings{\nma2025sherlock,\ntitle={Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive {LLM}},\nauthor={Junxiao Ma and Jingjing Wang and Jiamin Luo and Peiying Yu and Guodong Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=YHW5w2hZcZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "3jCy;mnYG;iYzY;mzEX;yHFr",
        "site": "https://openreview.net/forum?id=YHW5w2hZcZ",
        "pdf_size": 0,
        "novelty": "3;4;4;4;6",
        "technical_quality": "5;4;5;5;6",
        "scope": "3;3;4;4;3",
        "confidence": "3;4;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.25000000000000006
    },
    {
        "id": "YiIdHqqoCd",
        "title": "Beyond Utility: Evaluating LLM as Recommender",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the rapid development of Large Language Models (LLMs), recent studies employed LLMs as recommenders to provide personalized information services for distinct users. Despite efforts to improve the accuracy of LLM-based recommendation models, relatively little attention is paid to beyond-utility dimensions. Moreover, there are unique evaluation aspects of LLM-based recommendation models, which have been largely ignored. \nTo bridge this gap, we explore four new evaluation dimensions and propose a multidimensional evaluation framework. The new evaluation dimensions include: 1) history length sensitivity, 2) candidate position bias, 3) generation-involved performance, and 4) hallucinations. All four dimensions have the potential to impact performance, but are largely unnecessary for consideration in traditional systems. Using this multidimensional evaluation framework, along with traditional aspects, we evaluate the performance of seven LLM-based recommenders, with three prompting strategies, comparing them with six traditional models on both ranking and re-ranking tasks on four datasets. We find that LLMs excel at handling tasks with prior knowledge and shorter input histories in the ranking setting, and perform better in the re-ranking setting, beating traditional models across multiple dimensions. However, LLMs exhibit substantial candidate position bias issues, and some models hallucinate non-existent items much more often than others. We intend our evaluation framework and observations to benefit future research on the use of LLMs as recommenders. The code and data are available at\nhttps://anonymous.4open.science/r/EvaLLMasRecommender-3118/.",
        "keywords": "Large Language Model;Recommendation System;Multidimensional Evaluation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chumeng Jiang;Jiayin Wang;Weizhi Ma;Charles L. A. Clarke;Shuai Wang;Chuhan Wu;Min Zhang",
        "authorids": "~Chumeng_Jiang1;~Jiayin_Wang2;~Weizhi_Ma1;~Charles_L._A._Clarke3;~Shuai_Wang34;~Chuhan_Wu2;~Min_Zhang15",
        "gender": "F;F;M;;;M;F",
        "homepage": "https://www.linkedin.com/in/chumeng-jiang-0b2bab321;https://alice1998.github.io;http://mawz12.github.io;;http://lucaswang16.github.io;https://wuch15.github.io;http://www.thuir.cn/group/~mzhang",
        "dblp": "351/9511;;169/1390;;;212/1864;83/5342-6",
        "google_scholar": ";;FO3lHi4AAAAJ;;;OG1cMswAAAAJ;0HtCYQEAAAAJ",
        "orcid": "0009-0005-6247-2497;0000-0001-8875-1850;0000-0001-5604-7527;;0009-0002-6297-9085;0000-0001-5730-8792;0000-0003-3158-1920",
        "linkedin": "chumeng-jiang-0b2bab321;;;;;%E6%A5%9A%E6%B6%B5-%E6%AD%A6-271a47110/;",
        "or_profile": "~Chumeng_Jiang1;~Jiayin_Wang2;~Weizhi_Ma1;~Charles_L._A._Clarke3;~Shuai_Wang34;~Chuhan_Wu2;~Min_Zhang15",
        "aff": "Tsinghua University;Tsinghua University;Tsinghua University;;Huawei Technologies Ltd.;WeChat AI, Tencent+Noah\u2019s Ark Lab, Huawei;Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;mail.tsinghua.edu.cn;tsinghua.edu.cn;;huawei.com;tencent.com+huawei.com;tsinghua.edu.cn",
        "position": "PhD student;PhD student;Assistant Professor;;Researcher;Researcher+Researcher;Full Professor",
        "bibtex": "@inproceedings{\njiang2025beyond,\ntitle={Beyond Utility: Evaluating {LLM} as Recommender},\nauthor={Chumeng Jiang and Jiayin Wang and Weizhi Ma and Charles L. A. Clarke and Shuai Wang and Chuhan Wu and Min Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=YiIdHqqoCd}\n}",
        "github": "",
        "project": "",
        "reviewers": "Xto6;CKD3;39Zc;rDHt",
        "site": "https://openreview.net/forum?id=YiIdHqqoCd",
        "pdf_size": 0,
        "novelty": "3;3;5;5",
        "technical_quality": "4;3;5;5",
        "scope": "4;4;4;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.0
        ],
        "technical_quality_avg": [
            4.25,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "YkujiV56g7",
        "title": "Angular Distance-Guided Neighbor Selection for Graph-Based Approximate Nearest Neighbor Search",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph-based approximate nearest neighbor search (ANNS) algorithms are widely used to identify the most similar vectors to a given query vector.  Graph-based ANNS consists of two stages: constructing a graph and searching on the graph for a given query vector. While reducing the query response time is of great practical importance, less attention has been paid to improving the online search method than the offline graph construction method. This paper provides an extensive experimental analysis on the popular greedy search and other search optimization strategies. We also propose a novel angular distance-guided search method for graph-based ANNS (ADA-NNS) to improve search efficiency. The key innovation of ADA-NNS is introducing a low-cost neighbor selection mechanism based on approximate similarity score derived from angular distance estimation, which effectively filters out less relevant neighbors. We compare state-of-the-art search techniques, including FINGER, on six datasets using different similarity metrics. It provides a comprehensive perspective on their tradeoffs in terms of throughput, latency, and recall. Our evaluation shows that ADA-NNS achieves 34%-107% higher queries per second (QPS) than the greedy search at 95% recall@10 on HNSW, one of the most popular graph structures for ANNS.",
        "keywords": "Approximate Nearest Neighbor Search;Similarity search;Graph-based Approximate Nearest Neighbor Search",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sungjun Jung;Yongsang Park;Haeun Lee;Young H. Oh;Jae W. Lee",
        "authorids": "~Sungjun_Jung1;~Yongsang_Park2;~Haeun_Lee1;~Young_H._Oh1;~Jae_W._Lee1",
        "gender": "M;;F;M;M",
        "homepage": ";;;https://younghwanoh.github.io;https://iamjaelee.github.io/www/",
        "dblp": "227/6030.html;;;149/4002;21/4685",
        "google_scholar": "s_jzdVIAAAAJ;https://scholar.google.com/citations?view_op=list_works;;https://scholar.google.co.kr/citations?user=4x1sO8gAAAAJ;PA-QN6IAAAAJ",
        "orcid": ";;;0000-0001-5971-9093;0000-0002-4266-4919",
        "linkedin": "migueljung/;;haeunlee99/;youngh-oh;jae-w-lee-6486796/",
        "or_profile": "~Sungjun_Jung1;~Yongsang_Park2;~Haeun_Lee1;~Young_H._Oh1;~Jae_W._Lee1",
        "aff": "Seoul National University;Seoul National University;Seoul National University;Ajou University;Seoul National University",
        "aff_domain": "snu.ac.kr;snu.ac.kr;snu.ac.kr;ajou.ac.kr;snu.ac.kr",
        "position": "PhD student;MS student;MS student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\njung2025angular,\ntitle={Angular Distance-Guided Neighbor Selection for Graph-Based Approximate Nearest Neighbor Search},\nauthor={Sungjun Jung and Yongsang Park and Haeun Lee and Young H. Oh and Jae W. Lee},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=YkujiV56g7}\n}",
        "github": "",
        "project": "",
        "reviewers": "JyXb;wa2m;EDEa;Y7iC;YDTy",
        "site": "https://openreview.net/forum?id=YkujiV56g7",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;5;5;5;5",
        "scope": "2;4;3;3;4",
        "confidence": "1;2;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.8,
            0.39999999999999997
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.4,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6864064729836442
    },
    {
        "id": "YsnZ4cbwRS",
        "title": "Quantitative Runtime Monitoring of Ethereum Transaction Attacks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The rapid growth of decentralized applications, while revolutionizing financial transactions, has created an attractive target for malicious attacks. Existing approaches to detecting attacks often rely on predefined rules or simplistic and overly-specialized models, which lack the flexibility to handle the wide spectrum of diverse and dynamically changing attack types.\nTo address this challenge, we present a general, extensible framework, MoE (Monitoring Ethereum), that leverages runtime verification to detect a wide range of attacks on Ethereum. MoE features an expressive attack modeling language, based on Metric First-order Temporal Logic, that can formalize a wide range of attacks. We integrate a novel semantic lifting approach that extracts vital system behaviors for various attacks utilizing the monitoring tool MonPoly. We further equip MoE with quantitative capabilities to evaluate the similarity between a transaction and an attack formula to identify more attacks, including near-miss attacks.\nWe carry out extensive experiments with MoE on a labeled benchmark and a large-scale dataset containing over one million transactions. On the labeled benchmark, MoE successfully detects 92.0% attacks and achieves 45.0% more recall rate than another state-of-the-art tool. MoE finds 3,319 attacks with 95.4% precision on the large dataset. Furthermore, MoE uses quantitative analysis to uncover 8% more attacks. Notably, the average time for monitoring a transaction is less than 23 ms, positioning MoE as a promising practical solution for real-time attack detection for Ethereum.",
        "keywords": "Ethereum;Runtime Monitoring;Ethereum Attack Detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinyao Xu;Ziyu Mao;Jianzhong Su;Xingwei Lin;David A. Basin;Jun Sun;Jingyi Wang",
        "authorids": "~Xinyao_Xu1;~Ziyu_Mao1;~Jianzhong_Su3;~Xingwei_Lin1;~David_A._Basin1;~Jun_Sun12;~Jingyi_Wang7",
        "gender": "F;;M;M;M;M;",
        "homepage": ";https://github.com/zerrymore;https://demonhero0.github.io/;;https://people.inf.ethz.ch/basin/;https://sunjun.site;",
        "dblp": ";;;;b/DavidABasin;;",
        "google_scholar": "AwGD3KIAAAAJ;;-wdUfC8AAAAJ;Zv_rC0AAAAAJ;https://scholar.google.ch/citations?user=-BA-kHYAAAAJ;https://scholar.google.com.sg/citations?user=DVsEyn0AAAAJ;",
        "orcid": ";;;;0000-0001-9271-0007;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Xinyao_Xu1;~Ziyu_Mao1;~Jianzhong_Su3;~Xingwei_Lin1;~David_A._Basin1;~Jun_Sun12;~Jingyi_Wang7",
        "aff": "Zhejiang University;Zhejiang University;SUN YAT-SEN UNIVERSITY;Zhejiang University;;Singapore Management University;",
        "aff_domain": "zju.edu.cn;zju.edu.cn;mail2.sysu.edu.cn;zju.edu.cn;;smu.edu.sg;",
        "position": "MS student;MS student;PhD student;PhD student;;Full Professor;",
        "bibtex": "@inproceedings{\nxu2025quantitative,\ntitle={Quantitative Runtime Monitoring of Ethereum Transaction Attacks},\nauthor={Xinyao Xu and Ziyu Mao and Jianzhong Su and Xingwei Lin and David A. Basin and Jun Sun and Jingyi Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=YsnZ4cbwRS}\n}",
        "github": "",
        "project": "",
        "reviewers": "99gy;AJeC;bhwt;AX14;KakU",
        "site": "https://openreview.net/forum?id=YsnZ4cbwRS",
        "pdf_size": 0,
        "novelty": "3;3;4;5;5",
        "technical_quality": "3;3;3;4;5",
        "scope": "2;2;4;4;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            3.6,
            0.8
        ],
        "scope_avg": [
            3.0,
            0.8944271909999159
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "ZANfpN6cYY",
        "title": "Transfer Rule Learning over Large Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Logical rules have been widely used for expressing schema knowledge in various practical applications. It is infeasible to handcraft rules from large knowledge graphs (KGs) and thus many methods have been proposed for learning rules automatically from KGs. However, it is largely ignored how to extract rules in a (target) KG from rules that already exist in some other (source) KGs. In this paper, we propose a framework for KG rule learning based on transfer learning. A major challenge for establishing such a framework is in that a suitable alignment mechanism is required for mapping certain subgraph structures between predicates in the source KG and the target KG. Hence, our framework provides a new method for predicate mapping based on the graph-structural similarity and thus, rules in the source KG can be transferred to the target KG. As not all transferred rules are valid ones in the target KG, methods are developed for further rule evaluation. The proposed framework can be used as a standalone rule learner but more importantly, it paves a new way for enhancing the state-of-the-art rule learners for large KGs. Extensive experiments are conducted to evaluate the new approach to rule learning, which show that rules in smaller KGs can be effectively transferred to a large KG.",
        "keywords": "knowledge graph;transfer learning;rule learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hong Liu;Zhe Wang;Kewen Wang;Xiaowang Zhang;Zhiyong Feng",
        "authorids": "~Hong_Liu16;~Zhe_Wang9;~Kewen_Wang2;~Xiaowang_Zhang2;~Zhiyong_Feng1",
        "gender": "F;M;M;M;M",
        "homepage": "https://www.researchgate.net/profile/Hong_Liu142;https://experts.griffith.edu.au/9818-zhe-wang;https://experts.griffith.edu.au/18814-kewen-wang;http://cic.tju.edu.cn/faculty/zhangxiaowang/index.html;http://cic.tju.edu.cn/faculty/zyfeng/index.html",
        "dblp": ";75/3158-1;52/2483-1;https://dblp.uni-trier.de/pid/54/1153;https://dblp.uni-trier.de/pid/48/195-2",
        "google_scholar": ";https://scholar.google.com.au/citations?user=mIUGVLoAAAAJ;https://scholar.google.com.au/citations?user=NdtjLKoAAAAJ;5pVypA8AAAAJ;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": ";0000-0002-1367-7139;0000-0002-0542-3761;0000-0002-3931-3886;0000-0001-8158-7453",
        "linkedin": ";;;;",
        "or_profile": "~Hong_Liu16;~Zhe_Wang9;~Kewen_Wang2;~Xiaowang_Zhang2;~Zhiyong_Feng1",
        "aff": ";Griffith University;Griffith University;Tianjin University, China;Tianjin University",
        "aff_domain": ";griffith.edu.au;griffith.edu.au;tju.edu.cn;tju.edu.cn",
        "position": ";Lecturer;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025transfer,\ntitle={Transfer Rule Learning over Large Knowledge Graphs},\nauthor={Hong Liu and Zhe Wang and Kewen Wang and Xiaowang Zhang and Zhiyong Feng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ZANfpN6cYY}\n}",
        "github": "",
        "project": "",
        "reviewers": "ifey;PBFM;XykB;qn5f",
        "site": "https://openreview.net/forum?id=ZANfpN6cYY",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "4;5;3;7",
        "scope": "4;4;4;4",
        "confidence": "3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            4.75,
            1.479019945774904
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "ZD9811KEYd",
        "title": "TESA: A Trajectory and Semantic-aware Dynamic Heterogeneous Graph Neural Network",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Dynamic graph neural networks (DGNNs) are designed to capture the dynamic evolution of graph node interactions. However, existing DGNNs mainly consider homogeneous graphs, neglecting the rich heterogeneity in node and edge types, which is prevalent for real-world graphs and essential for modeling complex dynamic interactions.\nIn this work, we propose the **T**raj**E**ctory and **S**emantic-**A**ware dynamic heterogeneous graph neural network (**TeSa**), which integrates *trajectory-based evolution* and *semantic-aware aggregation* to capture both the evolving dynamics and heterogeneous semantics entailed in continuous-time dynamic heterogeneous graphs.\nIn particular, trajectory-based evolution treats the interactions received by each node (called node trajectory) as a sequence and employs  a temporal point process to learn the dynamic evolution in these interactions.\nSemantic-aware aggregation separates edges of different types when aggregating messages for each node from its neighbors. Edges of the same type are processed at first (i.e., intra-semantic aggregation), and then edges of different types are handled (i.e., inter-semantic fusion), to offer a comprehensive view of the heterogeneous semantics.\nWe compare **TeSa** with 7 state-of-the-art DGNN models, and the results show that **TeSa** improves the best-performing baseline by an average of 5.11% and 5.74% in accuracy for transductive and inductive tasks.",
        "keywords": "dynamic graph;heterogeneous graph;graph learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xin Wang;Jiawei Jiang;Xiao Yan;Qiang Huang",
        "authorids": "~Xin_Wang73;~Jiawei_Jiang1;~Xiao_Yan1;~Qiang_Huang5",
        "gender": ";M;M;M",
        "homepage": ";http://bluesjjw.github.io/;https://yanxiaosunny.github.io/;https://orcid.org/0000-0002-6330-9182",
        "dblp": ";185/1521-1;07/2626-2;80/2732-9",
        "google_scholar": ";G_Hg-j0AAAAJ;rzNoyOIAAAAJ;X4DxaFIAAAAJ",
        "orcid": ";0000-0003-0051-0046;0000-0002-2122-915X;0000-0002-6330-9182",
        "linkedin": ";;;",
        "or_profile": "~Xin_Wang73;~Jiawei_Jiang1;~Xiao_Yan1;~Qiang_Huang5",
        "aff": ";Wuhan University;Wuhan University+Centre for Perceptual and Interactive Intelligence;Wuhan University+Wuhan Dameng Database Co., Ltd",
        "aff_domain": ";whu.edu.cn;whu.edu.cn+cpii.hk;whu.edu.cn+dameng.com",
        "position": ";Full Professor;Assistant Professor+Researcher;PhD student+Researcher",
        "bibtex": "@inproceedings{\nwang2025tesa,\ntitle={{TESA}: A Trajectory and Semantic-aware Dynamic Heterogeneous Graph Neural Network},\nauthor={Xin Wang and Jiawei Jiang and Xiao Yan and Qiang Huang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ZD9811KEYd}\n}",
        "github": "",
        "project": "",
        "reviewers": "zLJL;CM5W;anHX;qrXn;Z7y1",
        "site": "https://openreview.net/forum?id=ZD9811KEYd",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "4;5;6;4;6",
        "scope": "4;3;4;3;3",
        "confidence": "4;3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6666666666666667
    },
    {
        "id": "ZKKGHo808F",
        "title": "Autobidding With Interdependent Values",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In this paper, we initiate the study of autobidding where the signals for each bidder can be noisy and correlated. Our first set of results showcases the failure of traditional auctions such as the second-price auction (SPA) and the first-price auction (FPA). In particular, uniform bidding is not an optimal bidding strategy for SPA and both SPA and FPA can have arbitrarily poor efficiency. To circumvent this, we propose the Contextual Second Price Auction (CSPA), a novel mechanism which mitigates the aforementioned adverse effects by leveraging multiple signals to adjust the allocation of SPA. We show that uniform bidding is an optimal bidding strategy in CSPA and we prove a tight bound on the price for anarchy for CSPA of $2$, thus recovering the well-established results in the independent setting. Finally, we show that CSPA always achieves at least half the welfare of SPA; moreover this is also tight.",
        "keywords": "autobidding;mechanism design",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Martino Banchio;Kshipra Bhawalkar;Christopher Liaw;Aranyak Mehta;Andres Perlroth",
        "authorids": "~Martino_Banchio1;~Kshipra_Bhawalkar1;~Christopher_Liaw1;~Aranyak_Mehta1;~Andres_Perlroth1",
        "gender": ";;M;;M",
        "homepage": "https://martinobanchio.github.io;https://cs.stanford.edu/people/kshipra/;;;https://www.linkedin.com/in/andres-perlroth-2044a11a0",
        "dblp": ";46/8419.html;177/8862;23/6337;",
        "google_scholar": "_q3WkT4AAAAJ;ZZesXHYAAAAJ;05WRGRsAAAAJ;;",
        "orcid": ";0009-0000-1375-8054;;;",
        "linkedin": ";;;;",
        "or_profile": "~Martino_Banchio1;~Kshipra_Bhawalkar1;~Christopher_Liaw1;~Aranyak_Mehta1;~Andres_Perlroth1",
        "aff": "Bocconi University+Google Research;Google;Google;Google Research;Google",
        "aff_domain": "unibocconi.it+google.com;google.com;google.com;google.com;google.com",
        "position": "Assistant Professor+Research Scientist;Researcher;Researcher;Researcher;Researcher",
        "bibtex": "@inproceedings{\nbanchio2025autobidding,\ntitle={Autobidding With Interdependent Values},\nauthor={Martino Banchio and Kshipra Bhawalkar and Christopher Liaw and Aranyak Mehta and Andres Perlroth},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ZKKGHo808F}\n}",
        "github": "",
        "project": "",
        "reviewers": "meYd;uEhL;Eca1;tw5L;LqTn",
        "site": "https://openreview.net/forum?id=ZKKGHo808F",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "2;5;5;5;4",
        "scope": "4;4;4;4;3",
        "confidence": "3;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2100420126042015
    },
    {
        "id": "ZsCk4YJTTj",
        "title": "Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Accurate healthcare prediction is essential for improving patient outcomes. Existing research primarily leverages sophisticated frameworks like attention or graph neural networks to capture the intricate collaborative (CO) signals inherent in electronic health records. However, prediction for rare diseases remains challenging due to their insufficient co-occurrence. To address this issue, this paper proposes UDC, a novel method that unveils discrete clues to bridge textual knowledge and CO signals within a unified semantic space, thereby enriching the representation semantics of rare diseases. Specifically, we focus on addressing two key sub-problems: (1) acquiring distinguishable discrete codes for precise disease representation and (2) achieving semantic alignment between textual knowledge and the CO signals at the code level. For the first sub-problem, we refine the standard vector quantized (VQ) process to include condition awareness. Additionally, we develop an advanced contrastive learning approach in the decoding stage, leveraging synthetic and mixed domain targets as hard negatives to enrich the perceptibility of the reconstructed representation for downstream tasks. For the second sub-problem, we introduce a novel codebook update strategy using co-teacher distillation. This approach facilitates bidirectional supervision between textual knowledge and CO signals, thereby aligning semantically equivalent information in a shared discrete latent space. Extensive experimentation across two tasks on three datasets showcases that the proposed UDC significantly improves health prediction performance for both rare and common diseases.",
        "keywords": "Discrete modeling;Healthcare prediction;Rare disease",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chuang Zhao;Hui Tang;Jiheng Zhang;Xiaomeng Li",
        "authorids": "~Chuang_Zhao1;~Hui_Tang3;~Jiheng_Zhang1;~Xiaomeng_Li1",
        "gender": "M;F;;F",
        "homepage": "https://data-designer.github.io/;https://huitangtang.github.io/;https://reijz.github.io;https://xmengli.github.io/",
        "dblp": "29/5452-2;;13/7602;02/9850-1",
        "google_scholar": "YYMcwZAAAAAJ;eqVvhiQAAAAJ;;uVTzPpoAAAAJ",
        "orcid": "0000-0001-6220-0540;0000-0001-8856-9127;;",
        "linkedin": ";;;",
        "or_profile": "~Chuang_Zhao1;~Hui_Tang3;~Jiheng_Zhang1;~Xiaomeng_Li1",
        "aff": "Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology",
        "aff_domain": "ust.hk;ust.hk;ust.hk;ust.hk",
        "position": "PhD student;Postdoc;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nzhao2025unveiling,\ntitle={Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases},\nauthor={Chuang Zhao and Hui Tang and Jiheng Zhang and Xiaomeng Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ZsCk4YJTTj}\n}",
        "github": "",
        "project": "",
        "reviewers": "akHv;rvnx;6yMv;9sRp;NeV4",
        "site": "https://openreview.net/forum?id=ZsCk4YJTTj",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "4;4;5;5;6",
        "scope": "3;3;2;3;4",
        "confidence": "2;2;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "a0XN5HXy4F",
        "title": "SimEdge: A Scalable Transitivity-Aware Graph-Theoretic Similarity Model for Capturing Edge-to-Edge Relationships",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Measuring similarity based on network topology is a crucial task in the realm of web search. While many well-established similarity measures (e.g. SimRank) focus on assessing node-to-node similarity, capturing edge-to-edge relationships is equally important in many applications (e.g. link spam detection). However, existing node-to-node similarity measures from the SimRank family may violate the triangular inequality. When applied directly to assessing edge-to-edge similarity, such measures may fail to capture transitive relationships and misrepresent dissimilarity between nodes. In this paper, we propose a novel similarity measure, SimEdge, which can capture transitive relationships for assessing edge-to-edge similarity. The intuition of SimEdge revolves around a mutual reinforcement co-recursion: ``two edges are assessed as similar if they are linked to similar nodes, and two nodes are assessed as similar if they are linked to similar edges.'' We show that SimEdge guarantees the transitivity of similarity, and enhances the accuracy of the node-to-node SimRank similarity without misrepresenting dissimilarity between nodes. For large-scale graphs, we also propose efficient techniques to compute SimEdge similarities in linear memory with guaranteed accuracy. Our empirical evaluation on various datasets validates that SimEdge is highly effective in capturing transitive edge-to-edge relationships, while offering a more reliable assessment of node-to-node similarity.",
        "keywords": "graph-theoretic similarity model;link-based analysis;search algorithm",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weiren Yu",
        "authorids": "~Weiren_Yu2",
        "gender": "M",
        "homepage": "https://warwick.ac.uk/fac/sci/dcs/people/weiren_yu/",
        "dblp": "",
        "google_scholar": "",
        "orcid": "",
        "linkedin": "",
        "or_profile": "~Weiren_Yu2",
        "aff": "University of Warwick",
        "aff_domain": "warwick.ac.uk",
        "position": "Associate Professor",
        "bibtex": "@inproceedings{\nyu2025simedge,\ntitle={SimEdge: A Scalable Transitivity-Aware Graph-Theoretic Similarity Model for Capturing Edge-to-Edge Relationships},\nauthor={Weiren Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=a0XN5HXy4F}\n}",
        "github": "",
        "project": "",
        "reviewers": "RtNz;XxaP;hPp5;nKuA",
        "site": "https://openreview.net/forum?id=a0XN5HXy4F",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "6;5;6;5",
        "scope": "3;3;4;3",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "aGhk1VNcRJ",
        "title": "Assessing and Post-Processing Black Box Large Language Models for Knowledge Editing",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The rapid evolution of the Web as a key platform for information dissemination has led to the growing integration of large language models (LLMs) in Web-based applications. However, the swift changes in web content present challenges in maintaining these models' relevance and accuracy. The task of Knowledge Editing (KE) is aimed at efficiently and precisely adjusting the behavior of large language models (LLMs) to update specific knowledge while minimizing any adverse effects on other knowledge. Current research predominantly concentrates on editing white-box LLMs, neglecting a significant scenario: editing black-box LLMs, where access is limited to interfaces and only textual output is provided. In this paper, we initially officially introduce KE on black-box LLMs, followed by presenting a thorough evaluation framework. This framework operates without requiring logits and considers pre- and post-edit consistency, addressing the limitations of current evaluations that are inadequate for black-box LLMs editing and lack comprehensiveness. To address privacy leaks of editing data and style over-editing in existing approaches, we propose a new postEdit framework. postEdit incorporates a retrieval mechanism for editing knowledge and a purpose-trained editing plugin called post-editor, ensuring privacy through downstream processing and maintaining textual style consistency via fine-grained editing. Experiments and analysis conducted on two benchmarks show that postEdit surpasses all baselines and exhibits robust generalization, notably enhancing style retention by an average of +20.82\\%. We will release our code after blind review.",
        "keywords": "Knowledge Editing;Retrieval-Augmented Generation;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaoshuai Song;Zhengyang Wang;Keqing He;Guanting Dong;Yutao Mou;Jinxu Zhao;Weiran Xu",
        "authorids": "~Xiaoshuai_Song1;~Zhengyang_Wang4;~Keqing_He1;~Guanting_Dong1;~Yutao_Mou1;~Jinxu_Zhao1;~Weiran_Xu1",
        "gender": "M;;;M;;M;M",
        "homepage": ";;https://helicqin.github.io/about/index.html;https://dongguanting.github.io/;;https://pris-nlp.github.io/author/%E8%B5%B5%E9%87%91%E6%97%AD/;",
        "dblp": "45/9576;;79/2314;;;;41/5448",
        "google_scholar": "https://scholar.google.com/citations?view_op=list_works;;811USNoAAAAJ;amozZDkAAAAJ;;;https://scholar.google.com/citations?view_op=list_works",
        "orcid": ";;;0000-0002-2318-0281;;;0000-0002-9416-7666",
        "linkedin": ";;;;;;",
        "or_profile": "~Xiaoshuai_Song1;~Zhengyang_Wang4;~Keqing_He1;~Guanting_Dong1;~Yutao_Mou1;~Jinxu_Zhao1;~Weiran_Xu1",
        "aff": "Renmin University of China+Beijing University of Posts and Telecommunications;;Meituan Group;Renmin University of China;;Beijing University of Posts and Telecommunications;Beijing University of Post and Telecommunication",
        "aff_domain": "ruc.edu.cn+bupt.edu.cn;;meituan.com;ruc.edu.cn;;bupt.edu;bupt.edu.cn",
        "position": "PhD student+MS student;;Researcher;PhD student;;MS student;Associate Professor",
        "bibtex": "@inproceedings{\nsong2025assessing,\ntitle={Assessing and Post-Processing Black Box Large Language Models for Knowledge Editing},\nauthor={Xiaoshuai Song and Zhengyang Wang and Keqing He and Guanting Dong and Yutao Mou and Jinxu Zhao and Weiran Xu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=aGhk1VNcRJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "7UcN;b1K8;B6AZ;MBkG",
        "site": "https://openreview.net/forum?id=aGhk1VNcRJ",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "4;5;4;6",
        "scope": "3;4;3;4",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.13245323570650439
    },
    {
        "id": "aSfLEeRn4L",
        "title": "Self-Comparison for Dataset-Level Membership Inference in Large (Vision-)Language Model",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Large Language Models (LLMs) and Vision-Language Models (VLMs) have made significant advancements in a wide range of natural language processing and vision-language tasks. Access to large web-scale datasets has been a key factor in their success. However, concerns have been raised about the unauthorized use of copyrighted materials and potential copyright infringement. Existing methods, such as sample-level Membership Inference Attacks (MIA) and distribution-based dataset, inference distinguish member and non-member data by leveraging the common observation that models tend to memorize and show greater confidence in member data. Nevertheless, these methods face challenges when applied to LLMs and VLMs, such as the requirement for ground-truth member data or non-member data that shares the same distribution as the test data. In this paper, we propose a novel dataset-level membership inference method based on Self-Comparison. We find that a member prefix followed by a non-member suffix (paraphrased from a member suffix) can further trigger the model's memorization on training data. Instead of directly comparing member and non-member data, we introduce paraphrasing to the second half of the sequence and evaluate how the likelihood changes before and after paraphrasing. Unlike prior approaches, our method does not require access to ground-truth member data or non-member data in identical distribution, making it more practical. Extensive experiments demonstrate that our proposed method outperforms traditional MIA and dataset inference techniques across various datasets and models, including GPT-4o.",
        "keywords": "Dataset protection;Membership inference;LLM;VLM",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jie Ren;Kangrui Chen;Chen Chen;Vikash Sehwag;Yue Xing;Jiliang Tang;Lingjuan Lyu",
        "authorids": "~Jie_Ren6;~Kangrui_Chen1;~Chen_Chen20;~Vikash_Sehwag1;~Yue_Xing1;~Jiliang_Tang1;~Lingjuan_Lyu1",
        "gender": "M;M;M;M;;M;F",
        "homepage": "https://renjie3.github.io/;https://artanisax.github.io/;https://cc233.github.io/;https://vsehwag.github.io/;https://sites.google.com/site/xingyuecuhk/;https://www.cse.msu.edu/~tangjili/;https://sites.google.com/view/lingjuan-lyu",
        "dblp": "181/2887-19.html;;65/4423-43;187/5613;185/5744-2.html;64/10812;178/9876",
        "google_scholar": ";iJHCqX0AAAAJ;;JAkeEG8AAAAJ;;WtzKMWAAAAAJ;",
        "orcid": ";0009-0005-5946-9967;0000-0001-7359-8515;;;0000-0001-7125-3898;0009-0004-3502-8094",
        "linkedin": ";;;;;;",
        "or_profile": "~Jie_Ren6;~Kangrui_Chen1;~Chen_Chen20;~Vikash_Sehwag1;~Yue_Xing1;~Jiliang_Tang1;~Lingjuan_Lyu1",
        "aff": "Amazon+Michigan State University;Southern University of Science and Technology;Sony AI;Google+Sony AI;Michigan State University;Michigan State University;Sony",
        "aff_domain": "amazon.com+msu.edu;mail.sustech.edu.cn;sony.com;deepmind.com+sony.com;msu.edu;msu.edu;sony.com",
        "position": "Intern+PhD student;Undergrad student;Researcher;Researcher+Researcher;Assistant Professor;Full Professor;Global Team Head",
        "bibtex": "@inproceedings{\nren2025selfcomparison,\ntitle={Self-Comparison for Dataset-Level Membership Inference in Large (Vision-)Language Model},\nauthor={Jie Ren and Kangrui Chen and Chen Chen and Vikash Sehwag and Yue Xing and Jiliang Tang and Lingjuan Lyu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=aSfLEeRn4L}\n}",
        "github": "",
        "project": "",
        "reviewers": "4znB;1S2g;UUh7;2XAc;XPzY",
        "site": "https://openreview.net/forum?id=aSfLEeRn4L",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "3;4;5;6;5",
        "scope": "3;2;3;4;3",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8017837257372731
    },
    {
        "id": "aeP5nmlw5B",
        "title": "WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Automatically generating webpage code from webpage designs can significantly reduce the workload of front-end developers, and\nrecent Multimodal Large Language Models (MLLMs) have shown promising potential in this area. However, our investigation re-\nveals that most existing MLLMs are constrained by the absence of high-quality, large-scale, real-word datasets, resulting in inadequate\nperformance in automated webpage code generation. To fill this gap, this paper introduces WebCode2M, a new dataset comprising 2.56\nmillion instances, each containing a design image along with the corresponding webpage code and layout details. Sourced from real-\nworld web resources, WebCode2M offers a rich and valuable dataset for webpage code generation across a variety of user scenarios. The\ndataset quality is ensured by a highly accurate scoring model that filters out instances with aesthetic deficiencies or other incomplete\nelements. To validate the effectiveness of our proposed dataset, we introduce a baseline model based on the Vision Transformer (ViT),\nnamed WebCoder, and establish a benchmark for fair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure the\nstructural hierarchy recall. The benchmarking results demonstrate that our dataset significantly improves the ability of MLLMs to gen-\nerate code from webpage designs, confirming its effectiveness and usability for future applications in front-end design tools. Finally,\nwe highlight several practical challenges introduced by our dataset, calling for further research. We have hosted the WebCode2M on an\nanonymous webpage: https://webcode2m-anonymous.github.io.",
        "keywords": "Benchmark Dataset;Webpage Generation;Code Generation;TreeBLEU",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yi Gui;Zhen Li;Yao Wan;Yemin Shi;Hongyu Zhang;Yi Su;Bohua Chen;Dongping Chen;Siyuan Wu;Xing Zhou;Wenbin Jiang;Hai Jin;Xiangliang Zhang",
        "authorids": "~Yi_Gui3;~Zhen_Li24;~Yao_Wan2;~Yemin_Shi2;~Hongyu_Zhang1;~Yi_Su8;~Bohua_Chen2;~Dongping_Chen1;~Siyuan_Wu6;~Xing_Zhou5;~Wenbin_Jiang1;~Hai_Jin1;~Xiangliang_Zhang1",
        "gender": "M;M;M;;M;;;M;;M;M;M;F",
        "homepage": "https://github.com/gystar;https://github.com/LZpenguin;http://wanyao.me;;https://sites.google.com/site/hongyujohn;;;https://dongping-chen.github.io;https://github.com/nauyisu022;;http://faculty.hust.edu.cn/jiangwenbin/zh_CN/index.htm;http://www.linkedin.com/in/jinhust;https://sites.nd.edu/xiangliang-zhang/",
        "dblp": "311/5499;74/2397-50;167/0275.html;;29/2726-2;;;151/7051;44/3983-1;;96/5583-1;98/4156;74/1890-1",
        "google_scholar": "https://scholar.google.com.hk/citations?user=zImBrG4AAAAJ;https://scholar.google.cz/citations?user=YGS6-hEAAAAJ;c3MtqtMAAAAJ;;https://scholar.google.com.au/citations?user=zsUN6PkAAAAJ;;;;v8qD1HsAAAAJ;;zImBrG4AAAAJ;;BhRJe4wAAAAJ",
        "orcid": "0009-0006-2841-7942;0009-0007-0873-6126;0000-0001-6937-4180;;0000-0002-3063-9425;;;0009-0009-9848-2557;;0009-0006-4165-7756;0000-0001-5628-8806;0000-0002-3934-7605;0000-0002-3574-5665",
        "linkedin": ";;;;;;;;;;;jinhust;",
        "or_profile": "~Yi_Gui3;~Zhen_Li24;~Yao_Wan2;~Yemin_Shi2;~Hongyu_Zhang1;~Yi_Su8;~Bohua_Chen2;~Dongping_Chen1;~Siyuan_Wu6;~Xing_Zhou5;~Wenbin_Jiang1;~Hai_Jin1;~Xiangliang_Zhang1",
        "aff": "Huazhong University of Science and Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology;;Chongqing University;;;University of Maryland, College Park+University of Washington+Huazhong University of Science and Technology;University of Waterloo;Peking University;Huazhong University of Science and Technology;Huazhong University of Science and Technology;University of Notre Dame",
        "aff_domain": "hust.edu.cn;hust.edu.cn;hust.edu.cn;;cqu.edu.cn;;;umd.edu+uw.edu+hust.edu.cn;uwaterloo.ca;pku.edu;hust.edu.cn;hust.edu.cn;nd.edu",
        "position": "PhD student;MS student;Associate Professor;;Full Professor;;;PhD student+Intern+Undergrad student;Intern;Researcher;Full Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\ngui2025webcodem,\ntitle={WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs},\nauthor={Yi Gui and Zhen Li and Yao Wan and Yemin Shi and Hongyu Zhang and Yi Su and Bohua Chen and Dongping Chen and Siyuan Wu and Xing Zhou and Wenbin Jiang and Hai Jin and Xiangliang Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=aeP5nmlw5B}\n}",
        "github": "",
        "project": "",
        "reviewers": "H4k6;UmeU;osCd;jvBD",
        "site": "https://openreview.net/forum?id=aeP5nmlw5B",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "6;4;5;5",
        "scope": "2;4;4;3",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            13,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5222329678670935
    },
    {
        "id": "aq393AkrKa",
        "title": "Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Community detection is a cornerstone problem in social network analysis (SNA), aimed at identifying cohesive communities with minimal external links. However, the rise of generative AI and the Metaverse introduces new complexities by creating hybrid communities of human users and AI entities. Traditional community detection approaches that overlook the interwoven presence of humans and AIs are inadequate for managing such hybrid networks, known as human-AI social networks (denoted by HASNs), especially when prioritizing human-centric communities. This paper introduces a novel community detection problem in HASNs (denoted by MetaCD), which seeks to enhance human connectivity within communities while reducing the presence of AI nodes. Effective processing of MetaCD poses challenges due to the delicate trade-off between excluding AI nodes and maintaining community structure. To address this, we propose CUSA, an innovative framework incorporating AI-aware clustering techniques that navigate this trade-off by selectively retaining AI nodes that contribute to community integrity. Furthermore, given the scarcity of real-world HASNs, we design four strategies for synthesizing these networks under various hypothetical scenarios. Empirical evaluations on real social networks, reconfigured as HASNs, demonstrate the effectiveness and practicality of our approach compared to traditional non-deep learning and graph neural network (GNN)-based methods.",
        "keywords": "community detection;human-centric;social networks;generative AI;Metaverse",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shih-Hsuan Chiu;Ya-Wen Teng;De-Nian Yang;Ming-syan Chen",
        "authorids": "~Shih-Hsuan_Chiu1;~Ya-Wen_Teng1;~De-Nian_Yang1;~Ming-Syan_Chen2",
        "gender": "M;F;M;M",
        "homepage": ";https://homepage.iis.sinica.edu.tw/pages/ywteng/index_en.html;https://homepage.iis.sinica.edu.tw/pages/dnyang/index_en.html;https://arbor.ee.ntu.edu.tw/~mschen",
        "dblp": "22/4532.html;163/2000;85/318;c/MingSyanChen",
        "google_scholar": "Pb3f8wwAAAAJ;;;KTmCrFkAAAAJ",
        "orcid": ";0009-0009-3563-578X;0000-0002-3765-9293;0000-0002-0711-8197",
        "linkedin": ";;;",
        "or_profile": "~Shih-Hsuan_Chiu1;~Ya-Wen_Teng1;~De-Nian_Yang1;~Ming-Syan_Chen2",
        "aff": "National Taiwan University;Institute of Information Science, Academia Sinica;Academia Sinica;National Taiwan University",
        "aff_domain": "ntu.edu.tw;iis.sinica.edu.tw;iis.sinica.edu.tw;ntu.edu",
        "position": "PhD student;Postdoc;Professor;Full Professor",
        "bibtex": "@inproceedings{\nchiu2025humancentric,\ntitle={Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated {AI} Entities},\nauthor={Shih-Hsuan Chiu and Ya-Wen Teng and De-Nian Yang and Ming-syan Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=aq393AkrKa}\n}",
        "github": "",
        "project": "",
        "reviewers": "Boj9;Fn6c;3Y8U;o3sV;CbT1",
        "site": "https://openreview.net/forum?id=aq393AkrKa",
        "pdf_size": 0,
        "novelty": "3;5;6;6;7",
        "technical_quality": "3;4;5;4;6",
        "scope": "3;3;4;4;3",
        "confidence": "3;3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.22116293423234576
    },
    {
        "id": "b0TEaurFma",
        "title": "Behavioral Homophily in Social Media via Inverse Reinforcement Learning: A Reddit Case Study",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Online communities play a critical role in shaping societal discourse and influencing collective behavior in the real world. The tendency for people to connect with others who share similar characteristics and views, known as homophily, plays a key role in the formation of echo chambers which further amplify polarization and division. Existing works examining homophily in online communities traditionally infer it using content- or adjacency-based approaches, such as constructing explicit interaction networks or performing topic analysis. These methods fall short for platforms where interaction networks cannot be easily constructed and fail to capture the complex nature of user interactions across the platform. This work introduces a novel approach for quantifying user homophily. We first use an Inverse Reinforcement Learning (IRL) framework to infer users' policies, then use these policies as a measure of behavioral homophily. We apply our method to Reddit, conducting a case study across 5.9 million interactions over six years, demonstrating how this approach uncovers distinct behavioral patterns and user roles that vary across different communities. We further validate our behavioral homophily measure against traditional content-based homophily, offering a powerful method for analyzing social media dynamics and their broader societal implications. We find, among others, that users can behave very similarly (high behavioral homophily) when discussing entirely different topics like soccer vs e-sports (low topical homophily), and that there is an entire class of users on Reddit whose purpose seems to be to disagree with others.",
        "keywords": "Homophily;Inverse Reinforcement Learning;Reddit;Social Media",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Lanqin Yuan;Philipp J. Schneider;Marian-Andrei Rizoiu",
        "authorids": "~Lanqin_Yuan1;~Philipp_J._Schneider1;~Marian-Andrei_Rizoiu1",
        "gender": "M;M;",
        "homepage": ";;",
        "dblp": "222/3479.html;;",
        "google_scholar": "TGm6jw8AAAAJ;;",
        "orcid": "0000-0001-6992-7187;0000-0003-0457-9825;",
        "linkedin": ";;",
        "or_profile": "~Lanqin_Yuan1;~Philipp_J._Schneider1;~Marian-Andrei_Rizoiu1",
        "aff": "University of Technology Sydney;EPFL - EPF Lausanne;",
        "aff_domain": "uts.edu.au;epfl.ch;",
        "position": "PhD student;PhD student;",
        "bibtex": "@inproceedings{\nyuan2025behavioral,\ntitle={Behavioral Homophily in Social Media via Inverse Reinforcement Learning: A Reddit Case Study},\nauthor={Lanqin Yuan and Philipp J. Schneider and Marian-Andrei Rizoiu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=b0TEaurFma}\n}",
        "github": "",
        "project": "",
        "reviewers": "833m;31W7;6DeC;8JzY",
        "site": "https://openreview.net/forum?id=b0TEaurFma",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "5;6;5;6",
        "scope": "4;4;4;4",
        "confidence": "2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8703882797784891
    },
    {
        "id": "b2skS0nzFO",
        "title": "Distributionally Robust Graph Out-of-Distribution Recommendation via Diffusion Model",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The distributionally robust optimization (DRO)-based graph neural network methods improve recommendation systems\u2019 out-of-\ndistribution (OOD) generalization by optimizing the model\u2019s worst-case performance. However, these studies fail to consider the impact\nof noisy samples in the training data, which results in diminished generalization capabilities and lower accuracy. Through experimental and theoretical analysis, this paper reveals that current DRO-based graph recommendation methods assign greater weightto noise distribution, leading to model parameter learning being dominated by it. When the model overly focuses on fitting noise samples in the training data, it may learn irrelevant or meaningless features that cannot be generalized to OOD data. To address this challenge, we design a Distributionally Robust Graph model for OOD recommendation (DRGO). Specifically, our method first employs a simple and effective diffusion paradigm to alleviate the noisy effect in the latent space. Additionally, an entropy regularization term is introduced in the DRO objective function to avoid extreme sample weights in the worst-case distribution. Finally, we provide a theoretical proof of the generalization error bound of DRGO as well as a theoretical analysis of how our approach mitigates noisy sample effects, which helps to better understand the proposed framework from a theoretical perspective. We conductextensive experiments on four datasets to evaluate the effectiveness of our framework against three typical distribution shifts, and the results demonstrate its superiority in both independently and identically distributed distributions (IID) and OOD.",
        "keywords": "Graph Recommendation;Out of Distribution;Robust",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chu Zhao;Enneng Yang;Yuliang Liang;Jianzhe Zhao;Guibing Guo;Xingwei Wang",
        "authorids": "~Chu_Zhao2;~Enneng_Yang1;~Yuliang_Liang2;~Jianzhe_Zhao1;~Guibing_Guo2;~Xingwei_Wang3",
        "gender": "M;M;;F;M;M",
        "homepage": "https://anonymous.4open.science/;;;http://faculty.neu.edu.cn/zhaojz/zh_CN/index/110560/list/index.htm;https://guoguibing.github.io/cn/;https://www.neu.edu.cn/info/1012/3221.htm",
        "dblp": ";246/2889;;126/2196;84/10716;99/4694-1",
        "google_scholar": ";;;;YMXJa2EAAAAJ;",
        "orcid": ";0000-0001-5419-5286;0000-0002-2946-7910;0000-0003-4492-5075;;0000-0003-2856-4716",
        "linkedin": ";;;;;",
        "or_profile": "~Chu_Zhao2;~Enneng_Yang1;~Yuliang_Liang2;~Jianzhe_Zhao1;~Guibing_Guo2;~Xingwei_Wang3",
        "aff": "Northeastern University ;SUN YAT-SEN UNIVERSITY+Nanyang Technological University+Northeastern University;Northeastern University;Northeastern University;Northeastern University;Northeastern University",
        "aff_domain": "northeastern.edu;sysu.edu.cn+ntu.edu.sg+neu.edu.cn;neu.edu.cn;neu.edu;neu.edu.cn;neu.edu",
        "position": "PhD student;Postdoc+PhD student+PhD student;PhD student;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhao2025distributionally,\ntitle={Distributionally Robust Graph Out-of-Distribution Recommendation via Diffusion Model},\nauthor={Chu Zhao and Enneng Yang and Yuliang Liang and Jianzhe Zhao and Guibing Guo and Xingwei Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=b2skS0nzFO}\n}",
        "github": "",
        "project": "",
        "reviewers": "Tnbe;VReo;5Lx7;wucE",
        "site": "https://openreview.net/forum?id=b2skS0nzFO",
        "pdf_size": 0,
        "novelty": "3;4;4;5",
        "technical_quality": "3;5;6;4",
        "scope": "3;4;3;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "bElAkCL6zb",
        "title": "UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Polarization and fragmentation in social media amplify user biases, making it increasingly important to understand the evolution of opinions. Opinion dynamics provide interpretability for studying opinion evolution, yet incorporating these insights into predictive models remains challenging. This challenge arises due to the inherent complexity of social interactions, the diversity of opinion fusion rules, and the difficulty in capturing equilibrium states while avoiding over-smoothing. This paper introduces UniGO, a unified framework for modeling opinion evolution on graphs.  By abstracting various opinion dynamics models into a unified graph-based structure, UniGO captures both common features and complex fusion rules. Using a coarsen-refine mechanism, UniGO efficiently models opinion dynamics through a graph neural network, mitigating over-smoothing while preserving equilibrium phenomena. Additionally, UniGO leverages pretraining on synthetic datasets, which enhances its ability to generalize to real-world scenarios, providing a viable paradigm for large-scale applications of opinion dynamics. Experimental results on both synthetic and real-world datasets demonstrate UniGO's effectiveness in capturing complex opinion formation processes and predicting future evolution. The pretrained model also shows strong generalization capability, validating the benefits of using synthetic data to boost real-world performance.",
        "keywords": "Opinion Dynamics;Graph Nerual Networks;Graph Coarse;Social Networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hao Li;Hao Jiang;Yuke Zheng;Hao Sun;Wenying Gong",
        "authorids": "~Hao_Li55;~Hao_Jiang18;~Yuke_Zheng1;~Hao_Sun26;~Wenying_Gong1",
        "gender": "M;M;;;F",
        "homepage": ";http://eis.whu.edu.cn/ryDetail.shtml?rsh=00007828;;;",
        "dblp": ";;267/5287;;388/1389",
        "google_scholar": ";;;;",
        "orcid": "0009-0009-9322-0603;;0009-0008-6338-882X;;0009-0008-7659-4745",
        "linkedin": ";;;;",
        "or_profile": "~Hao_Li55;~Hao_Jiang18;~Yuke_Zheng1;~Hao_Sun26;~Wenying_Gong1",
        "aff": "Wuhan University;Wuhan University;Wuhan University;;Wuhan University",
        "aff_domain": "whu.edu.cn;whu.edu.cn;whu.edu.cn;;whu.edu.cn",
        "position": "PhD student;Full Professor;MS student;;PhD student",
        "bibtex": "@inproceedings{\nli2025unigo,\ntitle={Uni{GO}: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs},\nauthor={Hao Li and Hao Jiang and Yuke Zheng and Hao Sun and Wenying Gong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bElAkCL6zb}\n}",
        "github": "",
        "project": "",
        "reviewers": "C4RP;fWxe;NvnW;qtwL;Au6Y",
        "site": "https://openreview.net/forum?id=bElAkCL6zb",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;4;4;5;4",
        "scope": "4;3;4;4;4",
        "confidence": "4;4;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6428571428571428
    },
    {
        "id": "bROi7lRYbl",
        "title": "Learning Feasible Causal Algorithmic Recourse: A Prior Structural Knowledge Free Approach",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Algorithmic recourse (AR) has made significant progress by identifying small perturbations in input features that can alter predictions, which provide a data-centric approach to understand decisions from diverse black-box models on the Web. Towards the feasibility issue, i.e., whether the recoursed examples provides actionable and reliable recommendations to end-users, causal algorithmic recourse have incorporated structural causal model (SCM) to preserve the realistic constraints among input features. For instance, preserving structural causal knowledge between \"age\" and \"educational level\" can avoid generating samples with decreasing age and increasing educational level. However, previous causal AR methods suffer from the requirement of prior structural causal knowledge, e.g., prior causal graph or the whole SCM, which restricts the realistic application of causal AR methods.\n  \n  To bridge this gap, we aim to develop a novel framework for causal algorithmic recourse that does not rely on neither prior causal graph or prior SCM. Since identifying counterfactuals without causal graph is impossible, we instead propose to approximate and constrain the variation of the perturbed components, i.e., the exogenous noise variables, by formulating the generation of AR as the structure-preserving intervention. With the aid of development in non-linear Independent Component Analysis (ICA), our method can further achieve theoretically guaranteed constraints on such variation of exogeneous variables. Experimental results on synthetic, semi-synthetic, and real-world data demonstrate the effectiveness of our proposed methods without any prior causal graph or SCM knowledge.",
        "keywords": "Algorithmic Recourse; Causality; User Recommendation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Haotian Wang;Hao Zou;Xueguang Zhou;Shangwen Wang;Wenjing Yang;Peng Cui",
        "authorids": "~Haotian_Wang2;~Hao_Zou1;~Xueguang_Zhou2;~Shangwen_Wang1;~Wenjing_Yang1;~Peng_Cui1",
        "gender": "M;M;;M;F;M",
        "homepage": "https://www.researchgate.net/profile/Haotian-Wang-9;https://scholar.google.com/citations?user=f5cbI4cAAAAJ&hl=en;;https://shangwenwang.github.io/;https://www.researchgate.net/scientific-contributions/Wen-Jing-Yang-2056467943;http://pengcui.thumedialab.com/",
        "dblp": "63/11345-1;13/4741-1;;219/1645;48/3396-2;31/891-1",
        "google_scholar": "CbH1UJAAAAAJ;f5cbI4cAAAAJ;;https://scholar.google.com.hk/citations?user=YAezhncAAAAJ;;https://scholar.google.com.tw/citations?user=G8x97ZgAAAAJ",
        "orcid": "0000-0003-2928-5575;0000-0002-6000-6936;;0000-0003-1469-2063;;0000-0003-2957-8511",
        "linkedin": ";;;;;",
        "or_profile": "~Haotian_Wang2;~Hao_Zou1;~Xueguang_Zhou2;~Shangwen_Wang1;~Wenjing_Yang1;~Peng_Cui1",
        "aff": "National University of Defense Technology+Purdue University;Tsinghua University;;National University of Defense Technology;National University of Defense Technology;Tsinghua University",
        "aff_domain": "nudt.edu.cn+purdue.edu;tsinghua.edu.cn;;nudt.edu.cn;nudt.edu.cn;tsinghua.edu.cn",
        "position": "Assistant Professor+Intern;PhD student;;Assistant Professor;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nwang2025learning,\ntitle={Learning Feasible Causal Algorithmic Recourse: A Prior Structural Knowledge Free Approach},\nauthor={Haotian Wang and Hao Zou and Xueguang Zhou and Shangwen Wang and Wenjing Yang and Peng Cui},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bROi7lRYbl}\n}",
        "github": "",
        "project": "",
        "reviewers": "XHwG;qnuq;92T5;HzGz",
        "site": "https://openreview.net/forum?id=bROi7lRYbl",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;4;5;5",
        "scope": "3;3;3;3",
        "confidence": "3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "bb0yNwAc2o",
        "title": "Rumor Detection on Social Media with Reinforcement Learning-based Key Propagation Graph Generator",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The spread of rumors on social media, particularly during significant events like the US elections and the COVID-19 pandemic, poses a serious threat to social stability and public health. Current rumor detection methods primarily rely on propagation graphs to improve the model performance. However, the effectiveness of these methods is often compromised by noisy and irrelevant structures in the propagation process. To tackle this issue, techniques such as weight adjustment and data augmentation have been proposed. However, they depend heavily on rich original propagation structures, limiting their effectiveness in handling rumors that lack sufficient propagation information, especially in the early stages of dissemination. In this work, we introduce Key Propagation Graph Generator (KPG), a novel reinforcement learning-based framework, that generates contextually coherent and informative propagation patterns for events with insufficient topology information and identifies significant substructures in events with redundant and noisy propagation structures. KPG comprises two key components: the Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG learns latent variable distributions from refined propagation patterns to eliminate noise and generate new candidates for ENS, while ENS identifies the most influential substructures in propagation graphs and provides training data for CRG. Furthermore, we develop an end-to-end framework that utilizes rewards derived from a pre-trained graph neural network to guide the training process. The resulting key propagation graphs are then employed in downstream rumor detection tasks. Extensive experiments conducted on four datasets demonstrate that KPG outperforms current state-of-the-art methods.",
        "keywords": "Rumor Detection;Key Propagation Graph;Reinforcement Learning;Graph Neural Networks;Response Generator",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yusong Zhang;Kun XIE;Xingyi Zhang;Xiangyu Dong;Sibo Wang",
        "authorids": "~Yusong_Zhang1;~Kun_XIE2;~Xingyi_Zhang1;~Xiangyu_Dong2;~Sibo_Wang3",
        "gender": "M;F;M;;M",
        "homepage": ";https://kkkkk001.github.io/;http://josiah96zhang.github.io/;https://xydong127.github.io/;https://www1.se.cuhk.edu.hk/~swang/",
        "dblp": ";98/476-10.html;93/1107-3;84/3152-2.html;131/6529-1",
        "google_scholar": ";;j_o_XDkAAAAJ;;b2gLqsgAAAAJ",
        "orcid": "0009-0001-3110-9194;0009-0000-8921-5531;0000-0001-5203-5916;0009-0009-6312-8160;0000-0003-1892-6971",
        "linkedin": ";kun-xie-0714kkkk;xingyi-zhang-769338204/;;sibo-wang-b6a60941/?originalSubdomain=hk",
        "or_profile": "~Yusong_Zhang1;~Kun_XIE2;~Xingyi_Zhang1;~Xiangyu_Dong2;~Sibo_Wang3",
        "aff": "The Chinese University of Hong Kong;The Chinese University of Hong Kong;Mohamed bin Zayed University of Artificial Intelligence;Chinese University of Hong Kong;The Chinese University of Hong Kong",
        "aff_domain": "link.cuhk.edu.hk;se.cuhk.edu.hk;mbzuai.ac.ae;cuhk.hk;cuhk.edu.hk",
        "position": "PhD student;PhD student;Postdoc;PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nzhang2025rumor,\ntitle={Rumor Detection on Social Media with Reinforcement Learning-based Key Propagation Graph Generator},\nauthor={Yusong Zhang and Kun XIE and Xingyi Zhang and Xiangyu Dong and Sibo Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bb0yNwAc2o}\n}",
        "github": "",
        "project": "",
        "reviewers": "64Ft;EJ64;gjsS;guGn;srfC",
        "site": "https://openreview.net/forum?id=bb0yNwAc2o",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;6;5;5;4",
        "scope": "4;4;4;3;3",
        "confidence": "3;2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "bdaJGj9LPc",
        "title": "Exploring Hypergraph Condensation via Variational Hyperedge Generation and Multi-Aspectual Amelioration",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Hypergraph neural networks (HyperGNNs) show promise in modeling online networks with high-order correlations. Despite notable progress, training these models on large-scale raw hypergraphs entails substantial computational and storage costs, thereby increasing the need of hypergraph size reduction. However, existing size reduction methods primarily capture pairwise association pattern within conventional graphs, making them challenging to adapt to hypergraphs with high-order correlations. To fill this gap, we introduce a novel hypergraph condensation framework, HG-Cond, designed to distill large-scale hypergraphs into compact, synthetic versions while maintaining comparable HyperGNN performance. Within this framework, we develop a Neural Hyperedge Linker to capture the high-order connectivity pattern through variational inference, achieving linear complexity with respect to the number of nodes. Moreover, We propose a multi-aspectual amelioration strategy including a Gradient-Parameter Synergistic Matching objective to holistically refine synthetic hypergraphs by coordinating improvements in node attributes, high-order connectivity, and label distributions. Extensive experiments demonstrate the efficacy of HG-Cond in hypergraph condensation, notably outperforming the original test accuracy on the 20News dataset while concurrently reducing the hypergraph size to a mere 5\\% of its initial scale. Furthermore, the condensed hypergraphs demonstrate robust cross-architectural generalizability and potential for expediting neural architecture search. This research represents a significant advancement in hypergraph processing, providing a scalable approach for hypergraph-based learning in resource-limited environments.",
        "keywords": "Hypergraph Condensation;High-order Correlations",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zheng Gong;Shuheng Shen;Changhua Meng;Ying Sun",
        "authorids": "~Zheng_Gong7;~Shuheng_Shen2;~Changhua_Meng1;~Ying_Sun4",
        "gender": "M;;M;F",
        "homepage": "https://scholar.google.com/citations?user=CQuOLaUAAAAJ&hl=zh-CN;;https://www.linkedin.com/in/changhua-meng-04826021/;https://sunyinggilly.github.io",
        "dblp": "85/5448-1.html;205/9070.html;295/9441;10/5415-6.html",
        "google_scholar": "CQuOLaUAAAAJ;tnjYeo4AAAAJ;;",
        "orcid": "0000-0003-1222-4055;;;0000-0002-4763-6060",
        "linkedin": ";;;",
        "or_profile": "~Zheng_Gong7;~Shuheng_Shen2;~Changhua_Meng1;~Ying_Sun4",
        "aff": "The Hong Kong University of Science and Technology (Guangzhou);Ant Group;Ant Group;Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "hkust-gz.edu.cn;antgroup.com;antgroup.com;hkust-gz.edu.cn",
        "position": "PhD student;Researcher;Researcher;Assistant Professor",
        "bibtex": "@inproceedings{\ngong2025exploring,\ntitle={Exploring Hypergraph Condensation via Variational Hyperedge Generation and Multi-Aspectual Amelioration},\nauthor={Zheng Gong and Shuheng Shen and Changhua Meng and Ying Sun},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bdaJGj9LPc}\n}",
        "github": "",
        "project": "",
        "reviewers": "fg2j;RAsA;wu1N;c2yw;Zv5S",
        "site": "https://openreview.net/forum?id=bdaJGj9LPc",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;5;5;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.8,
            0.39999999999999997
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.25000000000000006
    },
    {
        "id": "bgE7OaWkDf",
        "title": "Dynamic Gradient Influencing for Viral Marketing Using Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The problem of maximizing the adoption of a product through viral marketing in social networks is of extreme importance and has been studied heavily through postulated network models. We present a novel data-driven formulation of the problem. We use Graph Neural Networks (GNNs) to model the adoption of products by utilizing both topological and attribute information. The resulting \\emph{Dynamic Viral Marketing (DVM)} problem seeks to find the minimum budget and minimal set of dynamic topological and attribute changes in order to attain a specified adoption goal. We show that DVM is NP-Hard and is related to the existing influence maximization problem. Motivated by this connection, we develop the idea of Dynamic Gradient Influencing (DGI) that uses gradient ranking to find optimal perturbations and targets low-budget and high influence non-adopters in discrete steps. We use an efficient strategy for computing node budgets and develop the ``Meta-Influence'' heuristic for assessing a node\u2019s downstream influence. We evaluate DGI against multiple baselines and demonstrate gains on average of 24\\% on budget and 37\\% on AUC on real-world attributed networks. Our code will be made publicly available.",
        "keywords": "Viral Marketing;Social Network Analysis;Influence Propagation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Saurabh Sharma;Ambuj Singh",
        "authorids": "~Saurabh_Sharma3;~Ambuj_Singh1",
        "gender": "M;",
        "homepage": "https://dynamo.cs.ucsb.edu/people/sharma;",
        "dblp": ";",
        "google_scholar": "https://scholar.google.de/citations?user=SgbYgdsAAAAJ;",
        "orcid": ";",
        "linkedin": "saurabh-sharma-deeptinkerer/;",
        "or_profile": "~Saurabh_Sharma3;~Ambuj_Singh1",
        "aff": ";",
        "aff_domain": ";",
        "position": ";",
        "bibtex": "@inproceedings{\nsharma2025dynamic,\ntitle={Dynamic Gradient Influencing for Viral Marketing Using Graph Neural Networks},\nauthor={Saurabh Sharma and Ambuj Singh},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bgE7OaWkDf}\n}",
        "github": "",
        "project": "",
        "reviewers": "oTUD;cWdQ;33RE;B7fN;hPBW",
        "site": "https://openreview.net/forum?id=bgE7OaWkDf",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "3;3;6;5;2",
        "scope": "3;3;3;4;4",
        "confidence": "2;2;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            3.8,
            1.469693845669907
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.40824829046386296
    },
    {
        "id": "bgfXzR8bBF",
        "title": "A Plug-in Critiquing Approach for Knowledge Graph Recommendation Systems via Representative Sampling.",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Incorporating a critiquing component into recommender applications facilitates the enhancement of user perception. Typically, critique-able recommender systems adapt the model parameters and update the recommendation list in real-time through the analysis of user critiquing keyphrases in the inference phase. The current critiquing methods necessitate the designation of a dedicated recommendation model to estimate user relevance to the critiquing keyphrase during the training phase preceding the recommendations update. This paradigm restricts the applicable scenarios and reduces the potential for keyphrase exploitation. Furthermore, these approaches ignore the issue of catastrophic forgetting caused by continuous modification of model parameters in multi-step critiquing. Thus, we present a general $\\textbf{R}epresentative$ ${\\textbf{I}tems}$ ${\\textbf{S}ampling}$ $Framework$ $for$ $\\textbf{C}ritiquing$ $on$ $Knowledge$ $Graph$ ${Recommendation}$ (RISC) implemented as a plug-in, which offers a new paradigm for critiquing in mainstream recommendation scenarios. RISC leverages the knowledge graph to sample important representative items as a hinge to expand and convey information from user critiquing, indirectly estimating the relevance of the user to the critiquing keyphrase. Consequently, the necessity for specialized user-keyphrase correlation modules is eliminated with respect to a variety of knowledge graph recommendation models. Moreover, we propose a ${\\textbf{W}eight}$ $\\textbf{E}xperience$ $\\textbf{R}eplay$ (WER) approach based on KG to mitigate catastrophic forgetting by reinforcing the user's prior preferences during the inference phase. Our extensive experimental findings on three real-world datasets and three knowledge graph recommendation methods illustrate that RISC with WER can be effectively integrated into knowledge graph recommendation models to efficiently utilize user critiquing for refining recommendations and mitigate catastrophic forgetting. Our codes are shared on https://anonymous.4open.science/r/Critique-44F8.",
        "keywords": "Critiquing;Recommendation;Collaborative Filtering;Knowledge Graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhang Huanyu;Xiaoxuan Shen;Yi BAOLIN;Jianfang Liu;yinao xie",
        "authorids": "~Zhang_Huanyu1;~Xiaoxuan_Shen1;~Yi_BAOLIN1;~Jianfang_Liu2;~yinao_xie1",
        "gender": "M;M;;F;F",
        "homepage": ";http://faculty.ccnu.edu.cn/2023691014;http://faculty.ccnu.edu.cn/2006982663;;https://github.com/Aunnyxieyuzhou",
        "dblp": "163/7342;216/4412.html;;;",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-CN;;;",
        "orcid": "0000-0003-1991-565X;0000-0002-6663-5821;0000-0001-8249-9279;0009-0003-7301-8607;",
        "linkedin": ";;;;",
        "or_profile": "~Zhang_Huanyu1;~Xiaoxuan_Shen1;~Yi_BAOLIN1;~Jianfang_Liu2;~yinao_xie1",
        "aff": "Central China Normal University;Central China Normal University;Central China Normal University;Central China Normal University;Central China Normal University",
        "aff_domain": "ccnu.edu.cn;ccnu.edu.cn;ccnu.edu.cn;ccnu.edu.cn;ccnu.edu",
        "position": "PhD student;Assistant Professor;Full Professor;PhD student;PhD student",
        "bibtex": "@inproceedings{\nhuanyu2025a,\ntitle={A Plug-in Critiquing Approach for Knowledge Graph Recommendation Systems via Representative Sampling.},\nauthor={Zhang Huanyu and Xiaoxuan Shen and Yi BAOLIN and Jianfang Liu and yinao xie},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bgfXzR8bBF}\n}",
        "github": "",
        "project": "",
        "reviewers": "VkWi;CUsk;2qsk;WCXx;AN5f",
        "site": "https://openreview.net/forum?id=bgfXzR8bBF",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "3;4;5;6;6",
        "scope": "4;4;4;4;4",
        "confidence": "2;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5041841733655162
    },
    {
        "id": "bhWngwuo74",
        "title": "Personalized Federated Recommendation for Cold-Start Users via Adaptive Knowledge Fusion",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Federated Recommendation System (FRS) usually offers recommendation services for users while keeping their data locally to ensure privacy. Currently, most FRS literature assumes that fixed users participate in federated training with personal IoT devices (e.g., mobile phones and PC). However, users may come incrementally, and it is unfeasible to retrain the whole FRS with the new participating user due to the expensive training overheads and the negligible global knowledge gain brought by a small number of new users. To guarantee the quality service for these new users, we take a dive into the federated recommendation for cold-start users, a novel scenario where the new participating users can directly achieve a promising recommendation without overall training with all participating users by leveraging both transferred knowledge from the converged warm clients and the knowledge learned from the local data. \n\nNevertheless, how to efficiently transfer knowledge from warm clients remains controversial. On the one hand, cold clients may introduce new sparse items, causing a distribution shift from the item embedding converged on warm clients. On the other hand, the user information from warm clients is required to match cold users for a collaborative recommendation, but directly sharing user information is a violation of privacy and unacceptable. To tackle these challenges, we propose an efficient and privacy-enhanced federated recommendation for cold-start users (FR-CSU) that each client can adaptively transfer both user and item knowledge from warm clients separately and implement recommendations with local and transferred knowledge fusion. Specifically, each cold client will train a mapping function locally to transfer the aligned item embedding. Meanwhile, warm clients will maintain a user prototype network in a FedAvg manner that provides privacy-friendly yet effective user information for cold users. Finally, a linear function system will fuse the transferred and local knowledge to improve the recommendation. Extensive experiments show that FR-CSU achieves superior performance compared to state-of-the-art methods.",
        "keywords": "Federated Learning;Recommendation System;Cold-Start User",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yichen Li;Yijing Shan;YI LIU;Haozhao Wang;wangshi.ww;Yi Wang;Ruixuan Li",
        "authorids": "~Yichen_Li5;~Yijing_Shan1;~YI_LIU51;~Haozhao_Wang1;~wangshi.ww1;~Yi_Wang39;~Ruixuan_Li1",
        "gender": "M;;;M;M;M;M",
        "homepage": "https://github.com/liyichen1234;https://github.com/dandanjiejieya;https://www.myxiaojin.cn/;https://wanghaozhao.mysxl.cn/;https://github.com/cqschtu;https://anqiang1900.blog.163.com/;http://idc.hust.edu.cn/rxli/index.html",
        "dblp": "27/2248-6;353/6423;;224/4500.html;;;60/4429.html",
        "google_scholar": "meEbYo0AAAAJ;4JTScVUAAAAJ;;https://scholar.google.com.hk/citations?user=yFrOuMEAAAAJ;t1nPVXIAAAAJ;;https://scholar.google.com/scholar?q=ruixuan+li",
        "orcid": "0009-0009-8630-2504;;;0000-0002-7591-5315;;;0000-0002-7791-5511",
        "linkedin": ";;;;;;https://www.linkedin.cn/incareer/in/ruixuan-li-b367319",
        "or_profile": "~Yichen_Li5;~Yijing_Shan1;~YI_LIU51;~Haozhao_Wang1;~wangshi.ww1;~Yi_Wang39;~Ruixuan_Li1",
        "aff": "Huazhong University of Science and Technology;Huazhong University of Science and Technology;Chongqing Ant Consumer Finance Co,. Ltd;Huazhong University of Science and Technology;Chongqing Ant Consumer Finance Co,. Ltd;Chongqing Ant Consumer Finance Co,. Ltd;Huazhong University of Science and Technology",
        "aff_domain": "hust.edu.cn;hust.edu.cn;myxiaojin.cn;hust.edu.cn;myxiaojin.cn;myxiaojin.cn;hust.edu.cn",
        "position": "PhD student;MS student;Principal Researcher;Assistant Professor;Researcher;Principal Researcher;Full Professor",
        "bibtex": "@inproceedings{\nli2025personalized,\ntitle={Personalized Federated Recommendation for Cold-Start Users via Adaptive Knowledge Fusion},\nauthor={Yichen Li and Yijing Shan and YI LIU and Haozhao Wang and wangshi.ww and Yi Wang and Ruixuan Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bhWngwuo74}\n}",
        "github": "",
        "project": "",
        "reviewers": "jKqp;X3HN;K28p;3xQy;AgXj",
        "site": "https://openreview.net/forum?id=bhWngwuo74",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;5;5;5;5",
        "scope": "4;3;3;4;4",
        "confidence": "3;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.8,
            0.39999999999999997
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "biMNeZuzYL",
        "title": "Chain-of-Factors Paper-Reviewer Matching",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the rapid increase in paper submissions to academic conferences, the need for automated and accurate paper-reviewer matching is more critical than ever. Previous efforts in this area have considered various factors to assess the relevance of a reviewer's expertise to a paper, such as the semantic similarity, shared topics, and citation connections between the paper and the reviewer's previous works. However, most of these studies focus on only one factor, resulting in an incomplete evaluation of the paper-reviewer relevance. To address this issue, we propose a unified model for paper-reviewer matching that jointly considers semantic, topic, and citation factors. To be specific, during training, we instruction-tune a contextualized language model shared across all factors to capture their commonalities and characteristics; during inference, we chain the three factors to enable step-by-step, coarse-to-fine search for qualified reviewers given a submission. Experiments on four datasets (one of which is newly contributed by us) spanning various fields such as machine learning, computer vision, information retrieval, and data mining consistently demonstrate the effectiveness of our proposed Chain-of-Factors model in comparison with state-of-the-art paper-reviewer matching methods and scientific pre-trained language models.",
        "keywords": "paper-reviewer matching;scientific text mining;instruction tuning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yu Zhang;Yanzhen Shen;SeongKu Kang;Xiusi Chen;Bowen Jin;Jiawei Han",
        "authorids": "~Yu_Zhang26;~Yanzhen_Shen1;~SeongKu_Kang1;~Xiusi_Chen1;~Bowen_Jin1;~Jiawei_Han1",
        "gender": "M;M;M;M;M;M",
        "homepage": "https://yuzhimanhua.github.io/;;https://seongku-kang.github.io/;https://xiusic.github.io/;https://peterjin.me/;http://hanj.cs.illinois.edu/",
        "dblp": "50/671-44;350/0200;251/9613.html;210/1049;235/8066;h/JiaweiHan.html",
        "google_scholar": "N0PrmgIAAAAJ;RKBZ8isAAAAJ;fB0K-fMAAAAJ;JqGAil4AAAAJ;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.tw/citations?user=Kv9AbjMAAAAJ",
        "orcid": "0000-0003-0540-6758;;0000-0001-5528-1426;0000-0002-9713-8000;0000-0003-1295-2829;0000-0002-3629-2696",
        "linkedin": ";yanzhen-shen-890102228/;;xiusi-chen-53180583/;bowen-peter-jin/;",
        "or_profile": "~Yu_Zhang26;~Yanzhen_Shen1;~SeongKu_Kang1;~Xiusi_Chen1;~Bowen_Jin1;~Jiawei_Han1",
        "aff": "Texas A&M University - College Station;Stanford University+University of Illinois Urbana-Champaign;Korea University+University of Illinois Urbana-Champaign;University of Illinois, Urbana Champaign;University of Illinois, Urbana Champaign;University of Illinois at Urbana-Champaign (UIUC)",
        "aff_domain": "tamu.edu;stanford.edu+cs.illinois.edu;korea.ac.kr+cs.illinois.edu;illinois.edu;illinois.edu;illinois.edu",
        "position": "Assistant Professor;MS student+Undergrad student;Assistant Professor+Postdoc;Postdoc;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025chainoffactors,\ntitle={Chain-of-Factors Paper-Reviewer Matching},\nauthor={Yu Zhang and Yanzhen Shen and SeongKu Kang and Xiusi Chen and Bowen Jin and Jiawei Han},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=biMNeZuzYL}\n}",
        "github": "",
        "project": "",
        "reviewers": "CxBr;sGqq;edrz;ZjDk;NQtN",
        "site": "https://openreview.net/forum?id=biMNeZuzYL",
        "pdf_size": 0,
        "novelty": "4;5;5;6;6",
        "technical_quality": "5;6;5;6;5",
        "scope": "3;3;4;4;3",
        "confidence": "3;3;2;1;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.4,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4677071733467426
    },
    {
        "id": "bwnWs4us0x",
        "title": "Traceback of Poisoned Texts in Poisoning Attacks to Retrieval-Augmented Generation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs) integrated with retrieval-augmented generation (RAG) systems enhance accuracy by accessing external knowledge database. However, recent studies have exposed RAG's vulnerability to poisoning attacks, where an attacker inject poisoned texts into the knowledge database, leading to attacker-desired responses. Existing defenses, primarily focused on inference-time mitigation, have proven inadequate against sophisticated attacks. In this paper, we present the first traceback system in RAG, RAGForensics, which traces poisoned texts from the knowledge database. RAGForensics narrows the space of potentially poisoned texts and accurately identifies them without requiring access to model gradients, a common challenge in RAG systems.  Our empirical evaluation on multiple datasets demonstrates RAGForensics's effectiveness against state-of-the-art and adaptive poisoning attacks. This work pioneers the exploration of poisoned texts traceback in RAG systems, offering a practical and promising approach to securing them against poisoning attacks.",
        "keywords": "retrieval-augmented generation;traceback;poisoning attack",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Baolei Zhang;Haoran Xin;Minghong Fang;Zhuqing Liu;Biao Yi;Tong Li;Zheli Liu",
        "authorids": "~Baolei_Zhang1;~Haoran_Xin3;~Minghong_Fang1;~Zhuqing_Liu2;~Biao_Yi1;~Tong_Li17;~Zheli_Liu1",
        "gender": "M;M;M;F;M;M;",
        "homepage": ";;https://minghongfang.com/;https://github.com/Zhuqing-Liu;;https://orcid.org/0000-0003-3678-8402;",
        "dblp": "73/10219;222/7784-2.html;157/0863;195/1161;290/6528;29/3826-11;",
        "google_scholar": "PA61W9QAAAAJ;https://scholar.google.com/citations?hl=zh-CN;L6vkkC8AAAAJ;;qU8fx8IAAAAJ;;https://scholar.google.com.hk/citations?user=PpBb6vUAAAAJ",
        "orcid": ";0009-0001-7290-1583;0000-0002-1365-3911;0000-0003-0146-5101;;0000-0003-3678-8402;",
        "linkedin": ";;;;;;",
        "or_profile": "~Baolei_Zhang1;~Haoran_Xin3;~Minghong_Fang1;~Zhuqing_Liu2;~Biao_Yi1;~Tong_Li17;~Zheli_Liu1",
        "aff": "Nankai University;Nankai University+Nankai University;University of Louisville;University of North Texas;Nankai University;Nankai University;",
        "aff_domain": "nku.nankai.edu.cn;nankai.edu.cn+nankai.edu.cn;louisville.edu;unt.edu;nankai.edu.cn;nankai.edu.cn;",
        "position": "PhD student;MS student+Undergrad student;Assistant Professor;Assistant Professor;PhD student;Associate Professor;",
        "bibtex": "@inproceedings{\nzhang2025traceback,\ntitle={Traceback of Poisoned Texts in Poisoning Attacks to Retrieval-Augmented Generation},\nauthor={Baolei Zhang and Haoran Xin and Minghong Fang and Zhuqing Liu and Biao Yi and Tong Li and Zheli Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=bwnWs4us0x}\n}",
        "github": "",
        "project": "",
        "reviewers": "SpJG;LJkp;bqcR;HmNp",
        "site": "https://openreview.net/forum?id=bwnWs4us0x",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;5;5;6",
        "scope": "3;3;3;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "c9f8LmRgnD",
        "title": "Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The spread of fake news negatively impacts individuals and is regarded as a significant social challenge that needs to be addressed.\nA number of algorithmic and insightful features have been identified for detecting fake news. However, with the recent LLMs and their advanced generation capabilities, many of the detectable features (e.g., style-conversion attacks) can be altered, making it more challenging to distinguish from real news. This study proposes adversarial style augmentation, AdSyle, to train a fake news detector that remains robust against various style-conversion attacks.Our model's key mechanism is the careful use of LLMs to automatically generate a diverse yet coherent range of style-conversion attack prompts.  This improves the generation of prompts that are particularly difficult for the detector to handle. Experiments show that our augmentation strategy improves robustness and detection performance when tested on fake news benchmark datasets.",
        "keywords": "Misinformation;Adversarial Training;Fake News Detection;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sungwon Park;Sungwon Han;Xing Xie;Jae-Gil Lee;Meeyoung Cha",
        "authorids": "~Sungwon_Park1;~Sungwon_Han1;~Xing_Xie3;~Jae-Gil_Lee1;~Meeyoung_Cha2",
        "gender": "M;M;M;M;F",
        "homepage": "https://sites.google.com/view/sungwon-park/;https://sites.google.com/view/sungwon-han/;http://research.microsoft.com/en-us/people/xingx/;https://dm.kaist.ac.kr/jaegil/;https://www.mpi-sp.org/cha",
        "dblp": "13/1835-1;72/5688-1;08/6809-1;28/3904;57/4924",
        "google_scholar": "https://scholar.google.com/citations?hl=ko;8zWgcFgAAAAJ;5EQfAFIAAAAJ;https://scholar.google.com.tw/citations?user=h9mbv9MAAAAJ;iFlnVCoAAAAJ",
        "orcid": "0000-0002-6369-8130;0000-0002-1129-760X;0000-0002-8608-8482;0000-0002-8711-7732;0000-0003-4085-9648",
        "linkedin": ";sungwon-han-1bbb63133/;xingx/;;meeyoungcha/",
        "or_profile": "~Sungwon_Park1;~Sungwon_Han1;~Xing_Xie3;~Jae-Gil_Lee1;~Meeyoung_Cha2",
        "aff": "Korea Advanced Institute of Science & Technology;Meta Facebook+Korea Advanced Institute of Science & Technology;Microsoft Research Asia;Korea Advanced Institute of Science & Technology; Max Planck Institute for Security and Privacy+Korea Advanced Institute of Science & Technology",
        "aff_domain": "kiast.ac.kr;meta.com+kaist.ac.kr;microsoft.com;kaist.ac.kr;mpi-sp.org+kaist.ac.kr",
        "position": "PhD student;Research Scientist+PhD student;Senior Principal Researcher;Full Professor;Director+Full Professor",
        "bibtex": "@inproceedings{\npark2025adversarial,\ntitle={Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection},\nauthor={Sungwon Park and Sungwon Han and Xing Xie and Jae-Gil Lee and Meeyoung Cha},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=c9f8LmRgnD}\n}",
        "github": "",
        "project": "",
        "reviewers": "JJpa;41wU;1tiu;cKCM",
        "site": "https://openreview.net/forum?id=c9f8LmRgnD",
        "pdf_size": 0,
        "novelty": "3;4;4;4",
        "technical_quality": "3;3;4;5",
        "scope": "3;4;3;3",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            3.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            3.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "cGWO8WYpdU",
        "title": "EdgeThemis: Ensuring Model Integrity for Edge Intelligence",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Machine learning (ML) models are widely deployed on edge nodes, such as mobile phones and edge servers, to power a wide range of AI applications over the web. Ensuring the integrity of these edge models is paramount, as they are subject to corruption caused by software/hardware exceptions and malicious tampering, which may undermine model performance, incur economic losses, and pose health risks. Existing data integrity mechanisms designed for files stored on disks cannot properly verify the integrity of models running in GPUs or mitigate the new integrity threats against edge models. This paper proposes EdgeThemis, a novel mechanism for verifying the integrity of edge models through sentinel verification. To enable verifiability for a model $M$, EdgeThemis embeds a sentinel backdoor and a verification module into $M$. Then, a challenger can send verification requests to the edge node hosting $M$ to verify its integrity. Next, the sentinel activates the verification module to generate a unique integrity proof tied to the identity of the edge node for verification. Finally, the challenger can verify the integrity proof to detect model corruption. Theoretical analysis proves that EdgeThemis can properly mitigate potential integrity threats against edge models. Experiments demonstrate that EdgeThemis achieves a verification accuracy of 100.00\\% across various models and different types of model corruption with robustness against replay attacks, theft attacks, and replacement attacks.",
        "keywords": "Model integrity;edge intelligence;edge computing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiyu Yang;Qiang He;Zheyu Zhou;Xiaohai Dai;Feifei Chen;Cong Tian;Yun Yang",
        "authorids": "~Jiyu_Yang1;~Qiang_He2;~Zheyu_Zhou1;~Xiaohai_Dai1;~Feifei_Chen1;~Cong_Tian2;~Yun_Yang1",
        "gender": "F;;M;M;F;F;M",
        "homepage": ";;https://github.com/Newultraman;https://seafooler.github.io/;https://sites.google.com/view/feifeichen/home;https://web.xidian.edu.cn/ctian/en/index.html;https://experts.swinburne.edu.au/368-yun-yang",
        "dblp": ";;;202/6715.html;;00/5365.html;90/3406-1",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;;FU4tiesAAAAJ;https://scholar.google.com.au/citations?user=5Hyav0gAAAAJ;;https://scholar.google.com.hk/citations?user=YTDQzfsAAAAJ",
        "orcid": ";;;;;;0000-0002-7868-5471",
        "linkedin": ";;;;;;",
        "or_profile": "~Jiyu_Yang1;~Qiang_He2;~Zheyu_Zhou1;~Xiaohai_Dai1;~Feifei_Chen1;~Cong_Tian2;~Yun_Yang1",
        "aff": "Swinburne University of Technology;;Huazhong University of Science and Technology;Huazhong University of Science and Technology;Deakin University;;Swinburne University of Technology",
        "aff_domain": "swin.edu.au;;hust.edu.cn;hust.edu.cn;deakin.edu.au;;swin.edu.au",
        "position": "PhD student;;Undergrad student;Postdoc;Lecturer;;Full Professor",
        "bibtex": "@inproceedings{\nyang2025edgethemis,\ntitle={EdgeThemis: Ensuring Model Integrity for Edge Intelligence},\nauthor={Jiyu Yang and Qiang He and Zheyu Zhou and Xiaohai Dai and Feifei Chen and Cong Tian and Yun Yang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=cGWO8WYpdU}\n}",
        "github": "",
        "project": "",
        "reviewers": "ZbQM;MjRs;pS3s;L1r5",
        "site": "https://openreview.net/forum?id=cGWO8WYpdU",
        "pdf_size": 0,
        "novelty": "3;4;6;6",
        "technical_quality": "3;4;6;5",
        "scope": "3;3;4;3",
        "confidence": "3;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.299038105676658
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "cHTWkVH5ft",
        "title": "Collaborative Retrieval for Large Language Model-based Conversational Recommender Systems",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Conversational recommender systems (CRS) aim to provide personalized recommendations via interactive dialogues with users. While large language models (LLMs) enhance CRS with their superior understanding of context-based user preferences, they typically struggle to leverage behavioral data, which has proven to be the key for classical collaborative filtering approaches. For this reason, we propose CRAG\u2014Collaborative Retrieval Augmented Generation for LLM-based CRS. To the best of our knowledge, CRAG is the first approach that combines state-of-the-art LLMs with collaborative filtering for conversational recommendations. Our experiments on two publicly available conversational datasets in the movie domain, i.e., a refined Reddit dataset as well as the Redial dataset, demonstrate the superior item coverage and recommendation performance of CRAG, compared to several CRS baselines. Moreover, we observe that the improvements are mainly due to better recommendation accuracy on recently released movies. The code is anonymously available at: https://anonymous.4open.science/r/CRAG-8CBE.",
        "keywords": "conversational recommender system;large language model;reflection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yaochen Zhu;Chao Wan;Harald Steck;Dawen Liang;Yesu Feng;Nathan Kallus;Jundong Li",
        "authorids": "~Yaochen_Zhu1;~Chao_Wan1;~Harald_Steck1;~Dawen_Liang1;~Yesu_Feng1;~Nathan_Kallus1;~Jundong_Li2",
        "gender": "M;;;M;M;;M",
        "homepage": "http://www.ychzhu.com/;;;https://dawenl.github.io;https://www.linkedin.com/in/yesufeng/;http://nathankallus.com/;https://jundongli.github.io/",
        "dblp": "251/3533;;63/3157;63/10572;;142/2900;144/7997.html",
        "google_scholar": "mNKYtHEAAAAJ;;;4c1ZNm4AAAAJ;;K2WfIlsAAAAJ;uY6ek7sAAAAJ",
        "orcid": ";0009-0004-9562-6328;;;;0000-0003-1672-0507;",
        "linkedin": ";;;;;;",
        "or_profile": "~Yaochen_Zhu1;~Chao_Wan1;~Harald_Steck1;~Dawen_Liang1;~Yesu_Feng1;~Nathan_Kallus1;~Jundong_Li2",
        "aff": "University of Virginia, Charlottesville+NetFlix;Cornell University;NetFlix;Netflix;NetFlix;Netflix+Cornell University;University of Virginia",
        "aff_domain": "virginia.edu+netflix.com;cornell.edu;netflix.com;netflix.com;netflix.com;netflix.com+cornell.edu;virginia.edu",
        "position": "PhD student+Intern;PhD student;Senior Data Scientist;Research Scientist;Researcher;Research Director+Associate Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nzhu2025collaborative,\ntitle={Collaborative Retrieval for Large Language Model-based Conversational Recommender Systems},\nauthor={Yaochen Zhu and Chao Wan and Harald Steck and Dawen Liang and Yesu Feng and Nathan Kallus and Jundong Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=cHTWkVH5ft}\n}",
        "github": "",
        "project": "",
        "reviewers": "NoMF;9ezZ;N4SD;TUSb;KAJq",
        "site": "https://openreview.net/forum?id=cHTWkVH5ft",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "4;5;5;5;6",
        "scope": "3;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "cMn2KCzjaX",
        "title": "TEARS: Text Representations for Scrutable Recommendations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Traditional recommender systems rely on high-dimensional (latent)\nembeddings for modeling user-item interactions, often resulting in\nopaque representations that lack interpretability. Moreover, these\nsystems offer limited control to users over their recommendations.\nInspired by recent work, we introduce TExtuAl Representations for\nScrutable recommendations (TEARS) to address these challenges.\nInstead of representing a user\u2019s interests through latent embed-\ndings, TEARS encodes them in natural text, providing transparency\nand allowing users to edit them. To encode such preferences, we\nuse modern LLMs to generate high-quality user summaries which\nwe find uniquely capture user preferences. Using these summaries\nwe take a hybrid approach where we use an optimal transport\nprocedure to align the summaries\u2019 representations with the repre-\nsentation of a standard VAE for collaborative filtering. We find this\napproach can surpass the performance of the three popular VAE\nmodels while providing user-controllable recommendations. We\nfurther analyze the controllability of TEARS through three simu-\nlated user tasks to evaluate the effectiveness of user edits on their\nsummaries. Our code and all user-summaries can be seen in an\nanonymized repository.",
        "keywords": "Recommender Systems;Large language models;Interpretable AI;Scutable models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Emiliano Penaloza;Olivier Gouvert;Haolun Wu;Laurent Charlin",
        "authorids": "~Emiliano_Penaloza1;~Olivier_Gouvert1;~Haolun_Wu1;~Laurent_Charlin1",
        "gender": ";M;M;M",
        "homepage": "https://emilianopp.com/#/home;;https://haolun-wu.github.io/;http://www.cs.toronto.edu/~lcharlin/",
        "dblp": ";;283/5463;48/5717",
        "google_scholar": ";sTfIWd0AAAAJ;-KcBDLcAAAAJ;Cul0g2YAAAAJ",
        "orcid": ";;0000-0001-6255-1535;0000-0002-6545-9459",
        "linkedin": ";;haolun-wu-23ba08133/;",
        "or_profile": "~Emiliano_Penaloza1;~Olivier_Gouvert1;~Haolun_Wu1;~Laurent_Charlin1",
        "aff": "Montreal Institute for Learning Algorithms, University of Montreal, Universit\u00e9 de Montr\u00e9al;Mila;McGill University+Mila - Quebec AI Institute+Computer Science Department, Stanford University;HEC Montreal+Mila - Quebec Artificial Intelligence Institute",
        "aff_domain": "mila.umontreal.ca;mila.quebec;mcgill.ca+mila.quebec+cs.stanford.edu;hec.ca+mila.quebec",
        "position": "PhD student;Postdoc;PhD student+PhD student+PhD student;Associate Professor+Principal Researcher",
        "bibtex": "@inproceedings{\npenaloza2025tears,\ntitle={{TEARS}: Text Representations for Scrutable Recommendations},\nauthor={Emiliano Penaloza and Olivier Gouvert and Haolun Wu and Laurent Charlin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=cMn2KCzjaX}\n}",
        "github": "",
        "project": "",
        "reviewers": "8NCo;wxyX;cbLX;7cjx;561i",
        "site": "https://openreview.net/forum?id=cMn2KCzjaX",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "5;4;4;5;5",
        "scope": "3;4;4;3;4",
        "confidence": "3;4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "cah0ZYeMz0",
        "title": "Ranking on Dynamic Graphs: An Effective and Robust Band-Pass Disentangled Approach",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Ranking is an essential and practical task on dynamic graphs, which aims to prioritize future interaction candidates for given queries. While existing solutions achieve promising ranking performance, they leverage a single listwise loss to jointly optimize candidate sets, which leads to the gradient vanishing issue; and they employ neural networks to model complex temporal structures within a shared latent space, which fails to accurately capture multi-scale temporal patterns due to the frequency aliasing issue. To address these issues, we propose BandRank, a novel and robust band-pass disentangled ranking approach for dynamic graphs in the frequency domain. Concretely, we propose a band-pass disentangled representation (BPDR) approach, which disentangles complex temporal structures into multiple frequency bands and employs non-shared frequency-enhanced multilayer perceptrons (MLPs) to model each band independently. We prove that our BPDR approach ensures effective multi-scale learning for temporal structures by demonstrating its multi-scale global convolution property. Besides, we design a robust Harmonic Ranking (HR) loss to jointly optimize candidate sets and continuously track comparisons between real and virtual candidates, where we theoretically guarantee its ability to alleviate the gradient vanishing issue. Extensive experimental results show that our BandRank achieves an average improvement of 21.31% against eight baselines while demonstrating superior robustness across different learning scenarios.",
        "keywords": "Dynamic graphs;Ranking;Disentangled representation learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yingxuan Li;Yuanyuan Xu;Xuemin Lin;Wenjie Zhang;Ying Zhang",
        "authorids": "~Yingxuan_Li5;~Yuanyuan_Xu1;~Xuemin_Lin2;~Wenjie_Zhang3;~Ying_Zhang6",
        "gender": "F;F;M;F;M",
        "homepage": ";https://luckygirl-xu.github.io/;https://www.acem.sjtu.edu.cn/en/faculty/linxuemin.html;http://www.cse.unsw.edu.au/~zhangw/;https://profiles.uts.edu.au/Ying.Zhang",
        "dblp": ";87/6559-2;l/LinXuemin;98/5684-1;13/6769-1",
        "google_scholar": ";https://scholar.google.com.au/citations?hl=zh-CN;j6rglkYAAAAJ;https://scholar.google.com.au/citations?user=yHTJo1kAAAAJ;https://scholar.google.com.au/citations?user=9LTwX4cAAAAJ",
        "orcid": ";0000-0001-7147-4498;0000-0003-2396-7225;0000-0001-6572-2600;0000-0002-2674-1638",
        "linkedin": "yingxuanli666;;;;",
        "or_profile": "~Yingxuan_Li5;~Yuanyuan_Xu1;~Xuemin_Lin2;~Wenjie_Zhang3;~Ying_Zhang6",
        "aff": "Shanghai Jiaotong University;University of New South Wales;Shanghai Jiaotong University;the university of new south wales;University of Technology Sydney (UTS)",
        "aff_domain": "sjtu.edu.cn;unsw.edu.au;sjtu.edu.cn;cse.unsw.edu.au;uts.eud.au",
        "position": "PhD student;PhD student;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nli2025ranking,\ntitle={Ranking on Dynamic Graphs: An Effective and Robust Band-Pass Disentangled Approach},\nauthor={Yingxuan Li and Yuanyuan Xu and Xuemin Lin and Wenjie Zhang and Ying Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=cah0ZYeMz0}\n}",
        "github": "",
        "project": "",
        "reviewers": "nGqL;aiPb;MDPv;coBh;Fgh8",
        "site": "https://openreview.net/forum?id=cah0ZYeMz0",
        "pdf_size": 0,
        "novelty": "4;4;4;4;5",
        "technical_quality": "5;3;3;5;5",
        "scope": "4;1;4;4;4",
        "confidence": "3;4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.2,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            1.2000000000000002
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "chxX4KuDDs",
        "title": "SCOOT: SLO-Oriented Performance Tuning for LLM Inference Engines",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "As large language models (LLMs) are gaining increasing popularity across a wide range of web applications, it is of great importance to optimize service-level objectives (SLOs) for LLM inference services to enhance user satisfaction and improve the competitiveness of cloud vendors. In this paper, we observe that adjusting the parameters of LLM inference engines can improve service performance, and the optimal parameter configurations of different services are different. Therefore, we propose SCOOT, an automatic performance tuning system to optimize SLOs for each LLM inference service by tuning the parameters of the inference engine. SCOOT jointly exploits single-objective and multiple-objective Bayesian optimization (BO) techniques to handle various optimization objectives via exploration and exploitation. Moreover, SCOOT prunes the search space with known constraints and adopts a random forest to learn hidden constraints during the tuning process to mitigate invalid exploration. To improve the tuning efficiency, SCOOT utilizes the parallel suggestion to accelerate the tuning process. Extensive experiments demonstrate that SCOOT considerably outperforms existing tuning techniques in SLO optimization while greatly improving the tuning efficiency. SCOOT is universally applicable to various LLM inference engines and is easily expandable to new parameters. Currently, SCOOT has already been implemented in the production environment of a leading international technology company.",
        "keywords": "Service-Level Objective;LLM Inference Engine;Performance Tuning;Bayesian Optimization;Cloud Computing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ke Cheng;Zhi Wang;Wen Hu;Tiannuo Yang;Jianguo Li;Sheng Zhang",
        "authorids": "~Ke_Cheng3;~Zhi_Wang4;~Wen_Hu1;~Tiannuo_Yang1;~Jianguo_Li2;~Sheng_Zhang18",
        "gender": "M;;;M;;M",
        "homepage": "https://ieeexplore.ieee.org/author/37089751952;;;https://tiannuo-yang.github.io/;;http://cs.nju.edu.cn/sheng/",
        "dblp": ";;;356/7972.html;;69/6137-1.html",
        "google_scholar": ";VoB6-2cAAAAJ;0NetjTIAAAAJ;TQFL5r4AAAAJ;;",
        "orcid": "0000-0003-0336-6916;;;0000-0001-5465-9626;;0000-0002-6581-6399",
        "linkedin": ";;;;;",
        "or_profile": "~Ke_Cheng3;~Zhi_Wang4;~Wen_Hu1;~Tiannuo_Yang1;~Jianguo_Li2;~Sheng_Zhang18",
        "aff": "Nanjing University+Ant Group;Ant Group;Antgroup;University of Southern California;;Nanjing University",
        "aff_domain": "nju.edu.cn+antgroup.com;antgroup.com;angroup.com;usc.edu;;nju.edu.cn",
        "position": "PhD student+Intern;Researcher;Senior Algorithm Expert;PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\ncheng2025scoot,\ntitle={{SCOOT}: {SLO}-Oriented Performance Tuning for {LLM} Inference Engines},\nauthor={Ke Cheng and Zhi Wang and Wen Hu and Tiannuo Yang and Jianguo Li and Sheng Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=chxX4KuDDs}\n}",
        "github": "",
        "project": "",
        "reviewers": "F5v3;gHSV;2YMp;DWvM",
        "site": "https://openreview.net/forum?id=chxX4KuDDs",
        "pdf_size": 0,
        "novelty": "4;5;5;7",
        "technical_quality": "3;4;4;7",
        "scope": "3;3;3;4",
        "confidence": "4;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.5,
            1.5
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.20751433915982243
    },
    {
        "id": "d7I9ZgbR0l",
        "title": "BETag: Behavior-enhanced Item Tagging with Finetuned Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Tags play a critical role in enhancing product discoverability, optimizing search results, and enriching recommendation systems on e-commerce platforms.\nDespite the recent advancements in large language models (LLMs), which have shown proficiency in processing and understanding textual information, their application in tag generation remains an under-explored yet complex challenge.\nTo this end, we introduce a novel method for automatic product tagging using LLMs to create behavior-enhanced tags (BETags).\nSpecifically, our approach begins by generating base tags using an LLM. These base tags are then refined into BETags by incorporating user behavior data.\nThis method aligns the tags with users' actual browsing and purchasing behavior, enhancing the accuracy and relevance of tags to user preferences.\nBy personalizing the base tags with user behavior data, BETags are able to capture deeper behavioral insights, which is essential for understanding nuanced user interests and preferences in e-commerce environments.\nMoreover, since BETags are generated offline, they do not impose real-time computational overhead and can be seamlessly integrated into downstream tasks commonly associated with recommendation systems and search optimization.\nOur evaluation of BETag across three datasets--- Amazon (Scientific), MovieLens-1M, and FreshFood---shows that our approach significantly outperforms both human-annotated tags and other automated methods. \nThese results highlight BETag as a scalable and efficient solution for personalized automated tagging, advancing e-commerce platforms by creating more tailored and engaging user experiences.",
        "keywords": "Tagging System;Large Language Models;User Behavior Modeling;Personalization;Recommendation;Information Retrieval",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shao-En Lin;Brian Liu;Miao-Chen Chiang;Ming-Yi Hong;Yu-Shiang Huang;Chuan-Ju Wang;Che Lin",
        "authorids": "~Shao-En_Lin1;~Brian_Liu4;~Miao-Chen_Chiang1;~Ming-Yi_Hong1;~Yu-Shiang_Huang1;~Chuan-Ju_Wang2;~Che_Lin1",
        "gender": "M;M;;M;M;F;M",
        "homepage": "https://google.com;;;https://www.linkedin.com/in/ming-yi-hong/;;https://cfda.citi.sinica.edu.tw/~cjwang/;https://www.idssp.ee.ntu.edu.tw/che-lin",
        "dblp": ";;;264/4105.html;71/10695;03/5904;66/4850",
        "google_scholar": ";;;https://scholar.google.com/citations?view_op=list_works;https://scholar.google.com.tw/citations?user=5w3AhiMAAAAJ;;https://scholar.google.com.tw/citations?user=S63I7jMAAAAJ",
        "orcid": ";;;0000-0001-7101-6454;;;0000-0002-4986-311X",
        "linkedin": ";brian-liu-9a2b2132a/;;ming-yi-hong/;yu-shiang-huang-309108126/;;che-lin-18ab268/",
        "or_profile": "~Shao-En_Lin1;~Brian_Liu4;~Miao-Chen_Chiang1;~Ming-Yi_Hong1;~Yu-Shiang_Huang1;~Chuan-Ju_Wang2;~Che_Lin1",
        "aff": "National Taiwan University;;;National Taiwan University;National Taiwan University;Academia Sinica;National Taiwan University",
        "aff_domain": "ntu.edu.tw;;;ntu.edu.tw;ntu.edu.tw;sinica.edu.tw;ntu.edu.tw",
        "position": "MS student;;;PhD student;PhD student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nlin2025betag,\ntitle={{BET}ag: Behavior-enhanced Item Tagging with Finetuned Large Language Models},\nauthor={Shao-En Lin and Brian Liu and Miao-Chen Chiang and Ming-Yi Hong and Yu-Shiang Huang and Chuan-Ju Wang and Che Lin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=d7I9ZgbR0l}\n}",
        "github": "",
        "project": "",
        "reviewers": "KE8Q;w9zn;vGRD;g2xL;4xw7",
        "site": "https://openreview.net/forum?id=d7I9ZgbR0l",
        "pdf_size": 0,
        "novelty": "4;4;4;5;7",
        "technical_quality": "4;3;3;4;6",
        "scope": "4;4;3;4;4",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.08574929257125444
    },
    {
        "id": "d7spHwemKX",
        "title": "OntoTune: Ontology-Driven Self-training for Aligning Large Language Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using ontology with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called OntoTune, which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compare to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM.",
        "keywords": "Large Language Model;Self-training;Align with Ontology",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhiqiang Liu;Chengtao Gan;Junjie Wang;Yichi Zhang;Zhongpu Bo;Mengshu Sun;Huajun Chen;Wen Zhang",
        "authorids": "~Zhiqiang_Liu7;~Chengtao_Gan1;~Junjie_Wang6;~Yichi_Zhang13;~Zhongpu_Bo1;~Mengshu_Sun2;~Huajun_Chen1;~Wen_Zhang4",
        "gender": "M;;M;M;M;F;M;",
        "homepage": ";;https://github.com/wjj0122;https://zhang-each.github.io/CV/;;;;https://person.zju.edu.cn/en/wenzhang",
        "dblp": ";;;86/7054-9;235/9794.html;;94/5089;43/2368-15",
        "google_scholar": ";;;-ys4Y-EAAAAJ;https://scholar.google.com/citations?view_op=list_works;https://scholar.google.com.hk/citations?view_op=list_works;;Ig9ho4kAAAAJ",
        "orcid": "0009-0009-5656-6859;0009-0008-0228-3477;;0009-0007-4046-1003;;;0000-0001-5496-7442;0000-0001-8429-9326",
        "linkedin": ";;;;;;;",
        "or_profile": "~Zhiqiang_Liu7;~Chengtao_Gan1;~Junjie_Wang6;~Yichi_Zhang13;~Zhongpu_Bo1;~Mengshu_Sun2;~Huajun_Chen1;~Wen_Zhang4",
        "aff": "Zhejiang University;Zhejiang University;Zhejiang University;Zhejiang University;Alibaba Group;antgroup;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;zju.edu.cn;zju.edu.cn;antgroup.com;antgroup.com;zju.edu.cn;zju.edu.cn",
        "position": "MS student;MS student;MS student;MS student;Researcher;Researcher;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nliu2025ontotune,\ntitle={OntoTune: Ontology-Driven Self-training for Aligning Large Language Models},\nauthor={Zhiqiang Liu and Chengtao Gan and Junjie Wang and Yichi Zhang and Zhongpu Bo and Mengshu Sun and Huajun Chen and Wen Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=d7spHwemKX}\n}",
        "github": "",
        "project": "",
        "reviewers": "diXY;vzvQ;s6bC;Mu7N",
        "site": "https://openreview.net/forum?id=d7spHwemKX",
        "pdf_size": 0,
        "novelty": "5;5;5;6",
        "technical_quality": "5;6;6;6",
        "scope": "3;4;3;4",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3333333333333333
    },
    {
        "id": "d9LJBlnCAQ",
        "title": "Passage: Ensuring Completeness and Responsiveness of Public SPARQL Endpoints with SPARQL Continuation Queries",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Being able to query online public knowledge graphs such as Wikidata or DBpedia is extremely valuable. However, these queries can\nbe interrupted due to the fair use policies enforced by SPARQL\nendpoint providers, leading to incomplete results. While these policies help maintain responsiveness for public SPARQL endpoints,\nthey compromise the completeness of query results, limiting the\nfeasibility of various downstream tasks. Ideally, we shouldn\u2019t have\nto choose between completeness and responsiveness. To address\nthis issue, we introduce the concept of SPARQL continuation queries.\nWhen a SPARQL endpoint interrupts a query, it returns partial\nresults along with a SPARQL continuation query to retrieve the\nremaining results. If the continuation query is also interrupted,\nthe process repeats, generating further continuation queries until the complete results are obtained. In our experimention, we\nshow that our continuation server Passage ensures completeness\nand responsiveness with performances in execution time similar to\nBlazeGraph.",
        "keywords": "Semantic web;Public Knowledge Graph;SPARQL endpoint;Responsiveness;Completeness;Performances",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Thi Hoang Thi PHAM;Gabriela Montoya;Brice N\u00e9delec;hala skaf-molli;Pascal Molli",
        "authorids": "~Thi_Hoang_Thi_PHAM1;~Gabriela_Montoya1;~Brice_N\u00e9delec1;~hala_skaf-molli1;~Pascal_Molli1",
        "gender": "Not Specified;F;Not Specified;F;M",
        "homepage": ";;;http://pagesperso.ls2n.fr/~skaf-h/pmwiki/pmwiki.php;https://www.univ-nantes.fr/pascal-molli",
        "dblp": "335/9906;120/5232;134/3210;s/HalaSkaf;34/642",
        "google_scholar": ";qXfMXnYAAAAJ;LciNyd8AAAAJ;https://scholar.google.fr/citations?user=gWlHZ4MAAAAJ;YeWxbVoAAAAJ",
        "orcid": "0000-0003-0176-2245;;0000-0003-4238-5060;0000-0003-1062-6659;0000-0001-8048-273X",
        "linkedin": "thihoangthipham93/;;;;pascalmolli/",
        "or_profile": "~Thi_Hoang_Thi_PHAM1;~Gabriela_Montoya1;~Brice_N\u00e9delec1;~hala_skaf-molli1;~Pascal_Molli1",
        "aff": "Universit\u00e9 de Nantes;Nantes University;Universit\u00e9 de Nantes;University of Nantes;University of Nantes",
        "aff_domain": "univ-nantes.fr;univ-nantes.fr;univ-nantes.fr;univ-nantes.fr;univ-nantes.fr",
        "position": "PhD student;Associate Professor;Postdoc;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\npham2025passage,\ntitle={Passage: Ensuring Completeness and Responsiveness of Public {SPARQL} Endpoints with {SPARQL} Continuation Queries},\nauthor={Thi Hoang Thi PHAM and Gabriela Montoya and Brice N{\\'e}delec and hala skaf-molli and Pascal Molli},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=d9LJBlnCAQ}\n}",
        "github": "",
        "project": "",
        "reviewers": "3jZ7;vaEK;ZT1m;eXJy;x6Sg",
        "site": "https://openreview.net/forum?id=d9LJBlnCAQ",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "6;6;5;7;6",
        "scope": "4;4;4;3;4",
        "confidence": "4;3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            6.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3273268353539886
    },
    {
        "id": "dFapOK8Rhb",
        "title": "Exploiting Language Power for Time Series Forecasting with Exogenous Variables",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The World Wide Web thrives on intelligent services that depend heavily on accurate time series forecasting to navigate dynamic and evolving environments. Due to the partially-observed nature of real world, exclusively focusing on the target of interest, so-called \\textit{endogenous variables}, is insufficient for accurate forecasting, especially in web systems that are susceptible to external influences. \nThus, utilizing \\textit{exogenous variables} to harness external information, i.e., forecasting with exogenous variable (FEV),  is imperative. \nNevertheless, as the external environment is complex and ever-evolving, inadequately capturing  external influences  can even lead to learning spurious correlations and  invalid prediction.  Fortunately, recent studies have demonstrated that large language models (LLMs) exhibit exceptional recognition capabilities across open real-world systems, including a deep understanding of exogenous environments. However, it is difficult to directly apply LLMs for FEV  due to challenges of task activation,  exogenous knowledge extraction, and feature space alignment. In this work, we devise ExoLLM, an \\underline{LLM}-driven method to sufficiently utilize \\underline{Exo}genous variables for time series forecasting. We begin by Meta-task Instruction to activate the knowledge transfer of LLM from natural language processing to FEV. To comprehensively understand the intricate and hierarchical influences of exogenous variables,  we propose Multi-grained Prompts,  encompassing diverse  external influences, including natural attributes, trend correlations, and period relationships between two types of variables. Additionally, a Dual TS-Text Attention  is devised to bridge the feature gap between text and numeric data in LLM. \nEvaluation on real-world datasets demonstrates ExoLLM's superiority in exploiting  exogenous information for forecasting with open-world language knowledge. Code is available at \\url{https://anonymous.4open.science/r/ExoLLM}.",
        "keywords": "Time Series Forecasting; Exogenous Variables",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qihe Huang;Zhengyang Zhou;Kuo Yang;Yang Wang",
        "authorids": "~Qihe_Huang2;~Zhengyang_Zhou1;~Kuo_Yang2;~Yang_Wang32",
        "gender": "M;M;M;M",
        "homepage": ";http://home.ustc.edu.cn/~zzy0929/Home/;;http://staff.ustc.edu.cn/~angyan/",
        "dblp": ";246/8238;;",
        "google_scholar": ";dPElQLUAAAAJ;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0000-0001-8960-6583;0000-0003-4728-7347;0000-0003-3346-5130;0000-0002-6079-7053",
        "linkedin": ";;https://www.linkedin.cn/incareer/in/kuo-yang-440a241b4;",
        "or_profile": "~Qihe_Huang2;~Zhengyang_Zhou1;~Kuo_Yang2;~Yang_Wang32",
        "aff": "University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China",
        "aff_domain": "ustc.edu.cn;ustc.edu.cn;ustc.edu.cn;ustc.edu.cn",
        "position": "PhD student;Researcher;PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nhuang2025exploiting,\ntitle={Exploiting Language Power for Time Series Forecasting with Exogenous Variables},\nauthor={Qihe Huang and Zhengyang Zhou and Kuo Yang and Yang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dFapOK8Rhb}\n}",
        "github": "",
        "project": "",
        "reviewers": "TeS9;ZFCo;b4N9;oWKh;V21a",
        "site": "https://openreview.net/forum?id=dFapOK8Rhb",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "4;4;5;5;5",
        "scope": "3;4;4;3;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "dJQ5vj9ol7",
        "title": "On the Cross-Graph Transferability of Dynamic Link Prediction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Dynamic link prediction aims to predict the future links on dynamic graphs, which can be applied to wide scenarios such as recommender systems and social networks on the World Wide Web. Existing methods mainly (1) focus on the in-graph learning, which cannot generalize to graphs unobserved during training; or (2) achieve the cross-graph predictions in a many-many mechanism by training on multiple graphs across various domains, which results in a large computational cost. In this paper, we propose a cross-graph dynamic link predictor named CrossDyG, which achieves the cross-graph transferability in a one-many mechanism which trains on one single source graph and test on different target graphs. Specifically, we provide causal and empirical analysis on the structural bias caused by the graph-specific structural characteristics in cross-graph predictions. Then, we conduct deconfounded training to learn the universal network evolution pattern from one single source graph during training. Finally, we apply the causal intervention to leverage the graph-specific structural characteristics of each target graph during inference. Extensive experiments conducted on three benchmark data of dynamic graphs demonstrate that CrossDyG outperforms the state-of-the-art baselines by up to 11.01% and 17.02% in terms of AP and AUC, respectively. In addition, the improvements are especially significant when training on small source graphs. The implementation of our approach is available in https://anonymous.4open.science/r/CrossDyG-8B70.",
        "keywords": "Dynamic Link Prediction; Network Science; Graph Learning.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhiqiang Pan;Chen Gao;Fei Cai;Wanyu Chen;Xin Zhang;Honghui Chen;Yong Li",
        "authorids": "~Zhiqiang_Pan2;~Chen_Gao5;~Fei_Cai1;~Wanyu_Chen1;~Xin_Zhang66;~Honghui_Chen2;~Yong_Li7",
        "gender": "M;;M;F;M;M;M",
        "homepage": "https://nudtzpan.github.io/;;;;;https://www.researchgate.net/scientific-contributions/Honghui-Chen-69552857;http://fi.ee.tsinghua.edu.cn/~liyong/",
        "dblp": "https://dblp.uni-trier.de/pid/178/6933;;71/2935;204/0075;;;",
        "google_scholar": "mOUou4sAAAAJ;;;;;;https://scholar.google.com/citations?hl=en",
        "orcid": ";;;;0000-0002-6070-1592;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhiqiang_Pan2;~Chen_Gao5;~Fei_Cai1;~Wanyu_Chen1;~Xin_Zhang66;~Honghui_Chen2;~Yong_Li7",
        "aff": "National University of Defense Technology;;;National University of Defense Technology;National University of Defense Technology;;Tsinghua University",
        "aff_domain": "nudt.edu.cn;;;nudt.edu.cn;nudt.edu.cn;;tsinghua.edu.cn",
        "position": "PhD student;;;Assistant Professor;PhD student;;Full Professor",
        "bibtex": "@inproceedings{\npan2025on,\ntitle={On the Cross-Graph Transferability of Dynamic Link Prediction},\nauthor={Zhiqiang Pan and Chen Gao and Fei Cai and Wanyu Chen and Xin Zhang and Honghui Chen and Yong Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dJQ5vj9ol7}\n}",
        "github": "",
        "project": "",
        "reviewers": "yzf2;QPeF;BduB;PLVY;KZ6x",
        "site": "https://openreview.net/forum?id=dJQ5vj9ol7",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;3;5;4;5",
        "scope": "3;3;4;2;4",
        "confidence": "2;2;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8728715609439693
    },
    {
        "id": "dWo7joMCQL",
        "title": "The Cost of Balanced Training-Data Production in an Online Data Market",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Many ethical issues in machine learning are connected to the training data. Online data markets are an important source of training data, facilitating both production and distribution. Recently, a trend has emerged of for-profit \u201cethical\u201d participants in online data markets. This trend raises a fascinating question: Can online data markets sustainably and efficiently address ethical issues in the broader machine-learning economy?\n\nIn this work, we study this question in a stylized model of an online data market. We investigate the effects of intervening in the data market to achieve balanced training-data production. The model reveals the crucial role of market conditions. Under some conditions, an intervention can drive the data producers out of the market, so that the cost of fairness is maximal. Yet, under other conditions, the cost of fairness can vanish (as a fraction of overall welfare) as the market grows.\n\nOur results suggest that \u201cethical\u201d online data markets can be economically feasible under favorable market conditions, and motivate\nmore work to consider the role of data production and distribution in mediating the impacts of ethical interventions.",
        "keywords": "Economics of fairness;balanced training data;endogenous data production",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Augustin Chaintreau;Roland Maio;Juba Ziani",
        "authorids": "~Augustin_Chaintreau2;~Roland_Maio1;~Juba_Ziani1",
        "gender": "M;;M",
        "homepage": "http://www.cs.columbia.edu/~augustin;https://rolandmaio.github.io/;http://www.juba-ziani.com",
        "dblp": "49/5532;;157/3784",
        "google_scholar": "Hb6J54cAAAAJ;;https://scholar.google.co.in/citations?user=1bwPKXpo97YC",
        "orcid": ";;0000-0002-3324-4349",
        "linkedin": ";;",
        "or_profile": "~Augustin_Chaintreau2;~Roland_Maio1;~Juba_Ziani1",
        "aff": "Columbia University;Columbia University;Georgia Institute of Technology",
        "aff_domain": "columbia.edu;columbia.edu;gatech.edu",
        "position": "Professor;PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nchaintreau2025the,\ntitle={The Cost of Balanced Training-Data Production in an Online Data Market},\nauthor={Augustin Chaintreau and Roland Maio and Juba Ziani},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dWo7joMCQL}\n}",
        "github": "",
        "project": "",
        "reviewers": "sVL6;rmCt;G36R;uuMX;fCQT",
        "site": "https://openreview.net/forum?id=dWo7joMCQL",
        "pdf_size": 0,
        "novelty": "2;4;5;5;6",
        "technical_quality": "2;5;5;5;6",
        "scope": "3;3;4;3;4",
        "confidence": "3;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            4.6,
            1.3564659966250536
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.060192926542884655
    },
    {
        "id": "dYKXU5AGs5",
        "title": "Understanding and Scaling Collaborative Filtering Optimization from the Perspective of Matrix Rank",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Collaborative Filtering (CF) methods dominate real-world recommender systems given their ability to learn high-quality, sparse ID-embedding tables that effectively capture user preferences. These tables scale linearly with the number of users and items, and are trained to ensure high similarity between embeddings of interacted user-item pairs, while maintaining low similarity for non-interacted pairs. Despite their high performance, encouraging dispersion for non-interacted pairs necessitates expensive regularization (e.g., negative sampling), hurting runtime and scalability. Existing research tends to address these challenges by simplifying the learning process, either by reducing model complexity or sampling data, trading performance for runtime. In this work, we move beyond model-level modifications and study the properties of the embedding tables under different learning strategies. Through theoretical analysis, we find that the singular values of the embedding tables are intrinsically linked to different CF loss functions. These findings are empirically validated on real-world datasets, demonstrating the practical benefits of higher stable rank -- a continuous version of matrix rank which encodes the distribution of singular values. Based on these insights, we propose an efficient warm-start strategy that regularizes the stable rank of the user and item embeddings. We show that stable rank regularization during early training phases can promote higher-quality embeddings, resulting in training speed improvements of up to 65.9%. Additionally, stable rank regularization can act as a proxy for negative sampling, allowing for performance gains of up to 21.2% over loss functions with small negative sampling ratios. Overall, our analysis unifies current CF methods under a new perspective -- their optimization of stable rank -- motivating a flexible regularization method that is easy to implement, yet effective at enhancing CF systems.",
        "keywords": "recommendation;efficiency;rank",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Donald Loveland;Xinyi Wu;Tong Zhao;Danai Koutra;Neil Shah;Mingxuan Ju",
        "authorids": "~Donald_Loveland2;~Xinyi_Wu3;~Tong_Zhao3;~Danai_Koutra1;~Neil_Shah2;~Mingxuan_Ju1",
        "gender": "M;F;M;F;M;M",
        "homepage": "https://www.donaldloveland.com;https://xinyiwu98.github.io;https://tzhao.io/;http://web.eecs.umich.edu/~dkoutra/;http://nshah.net;https://jumxglhf.github.io",
        "dblp": ";98/7827;94/6503-3;91/9987;71/7771;234/2715",
        "google_scholar": "mycopgEAAAAJ;;05cRc-MAAAAJ;https://scholar.google.com.tw/citations?user=bDrA1-8AAAAJ;Qut69OgAAAAJ;qNoO67AAAAAJ",
        "orcid": "0009-0004-3257-0128;;0000-0001-7660-1732;0000-0002-3206-8179;0000-0003-3261-8430;0009-0008-9054-3856",
        "linkedin": ";;;;;",
        "or_profile": "~Donald_Loveland2;~Xinyi_Wu3;~Tong_Zhao3;~Danai_Koutra1;~Neil_Shah2;~Mingxuan_Ju1",
        "aff": "University of Michigan;Massachusetts Institute of Technology;Snap Inc.;University of Michigan - Ann Arbor+Amazon;Snap Inc.;Snap Inc.",
        "aff_domain": "umich.edu;mit.edu;snap.com;umich.edu+amazon.com;snap.com;snap.com",
        "position": "PhD student;PhD student;Researcher;Associate Professor+Scholar;Research Scientist;Research Scientist",
        "bibtex": "@inproceedings{\nloveland2025understanding,\ntitle={Understanding and Scaling Collaborative Filtering Optimization from the Perspective of Matrix Rank},\nauthor={Donald Loveland and Xinyi Wu and Tong Zhao and Danai Koutra and Neil Shah and Mingxuan Ju},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dYKXU5AGs5}\n}",
        "github": "",
        "project": "",
        "reviewers": "Mvet;1L3Y;em8j",
        "site": "https://openreview.net/forum?id=dYKXU5AGs5",
        "pdf_size": 0,
        "novelty": "4;5;6",
        "technical_quality": "5;5;6",
        "scope": "4;4;4",
        "confidence": "1;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.816496580927726
        ],
        "technical_quality_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.3333333333333335,
            0.9428090415820634
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8660254037844387
    },
    {
        "id": "ddEkATzwiD",
        "title": "Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent studies have demonstrated the effectiveness of using large language language models (LLMs) in passage ranking. The listwise approaches, such as RankGPT, have become new state-of-the-art in this task. However, the efficiency of RankGPT models is limited by the maximum context length and relatively high latency of LLM inference. To address these issues, in this paper, we propose PE-Rank, leveraging the single passage embedding as a good context compression for efficient listwise passage reranking. By treating each passage as a special token, we can directly input passage embeddings into LLMs, thereby reducing input length. Additionally, we introduce an inference method that dynamically constrains the decoding space to these special tokens, accelerating the decoding process. For adapting the model to reranking, we employ listwise learning to rank loss for training. Evaluation results on multiple benchmarks demonstrate that PE-Rank significantly improves efficiency in both prefilling and decoding, while maintaining competitive ranking effectiveness.",
        "keywords": "Re-ranking;Large Language Models;Efficiency",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qi Liu;Bo Wang;Nan Wang;Jiaxin Mao",
        "authorids": "~Qi_Liu21;~Bo_Wang31;~Nan_Wang15;~Jiaxin_Mao1",
        "gender": ";M;;M",
        "homepage": ";https://bwanglzu.github.io/;;https://sites.google.com/site/maojiaxin/",
        "dblp": ";;;174/8367",
        "google_scholar": ";;;DDXcKKcAAAAJ",
        "orcid": ";;;0000-0002-9257-5498",
        "linkedin": ";;;",
        "or_profile": "~Qi_Liu21;~Bo_Wang31;~Nan_Wang15;~Jiaxin_Mao1",
        "aff": ";;;Renmin University of China, Tsinghua University",
        "aff_domain": ";;;ruc.edu.cn",
        "position": ";;;Assistant Professor",
        "bibtex": "@inproceedings{\nliu2025leveraging,\ntitle={Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models},\nauthor={Qi Liu and Bo Wang and Nan Wang and Jiaxin Mao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ddEkATzwiD}\n}",
        "github": "",
        "project": "",
        "reviewers": "Z2Ty;mVhQ;o38Y;WrjU",
        "site": "https://openreview.net/forum?id=ddEkATzwiD",
        "pdf_size": 0,
        "novelty": "5;5;5;5",
        "technical_quality": "5;5;5;5",
        "scope": "4;4;4;4",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.0
        ],
        "technical_quality_avg": [
            5.0,
            0.0
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "di9gHcxYf3",
        "title": "Damage Analysis via Bidirectional Multi-Task Cascaded Multimodal Fusion",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Damage analysis in social media platforms such as Twitter is a comprehensive problem which involves different subtasks for mining damage-related information from tweets e.g., informativeness, humanitarian categories and severity assessment). The comprehensive information obtained by damage analysis enables to identify breaking events around the world in real-time and hence provides aids in emergency responses. Recently, with the rapid development of web technologies, multimodal damage analysis has received increasing attentions due to users'  preference of posting  multimodal information in social media. Multimodal damage analysis leverages the associated image modality to improve the identification of damage-related information in social media. However,  existing works on multimodal damage analysis address each damage-related subtask individually  and do not consider their joint training mechanism. In this work, we propose the Bidirectional Multi-task Cascaded multimodal Fusion (BiMCF) approach towards joint multimodal damage analysis. To this end, we introduce the cascaded multimodal fusion framework to separately integrate effective visual and text information for each task, considering that different tasks attend to different  information. To exploit the interactions across tasks, bidirectional  propagation of the attended image-text interactive information is implemented between tasks, which can lead to enhanced multimodal fusion. Comprehensive experiments are conducted to validate the effectiveness of the proposed approach.",
        "keywords": "Damage analysis;Social network Analysis;Feature fusion;Multimodal deep learning;Multi-task learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tao Liang;Siying Wu;Junfeng Fang;Guowu Yang;Wenya Wang;Fengmao Lv",
        "authorids": "~Tao_Liang1;~Siying_Wu2;~Junfeng_Fang1;~Guowu_Yang1;~Wenya_Wang1;~Fengmao_Lv1",
        "gender": "M;F;M;;F;",
        "homepage": "https://orcid.org/0000-0003-0488-8900;https://orcid.org/0009-0004-3201-9117;https://scholar.google.com/citations?user=beNNywsAAAAJ&hl=zh-CN;;https://personal.ntu.edu.sg/wangwy/;",
        "dblp": ";;340/7929;38/4538;;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;beNNywsAAAAJ;;https://scholar.google.com.sg/citations?user=eOKISncAAAAJ;",
        "orcid": "0000-0003-0488-8900;0009-0004-3201-9117;0000-0002-3317-2103;;0000-0001-5612-7818;",
        "linkedin": ";;;;;",
        "or_profile": "~Tao_Liang1;~Siying_Wu2;~Junfeng_Fang1;~Guowu_Yang1;~Wenya_Wang1;~Fengmao_Lv1",
        "aff": "University of Electronic Science and Technology of China;Southwest Jiaotong University;National University of Singapore;University of Electronic Science and Technology of China;Nanyang Technological University;",
        "aff_domain": "uestc.edu.cn;swjtu.edu.cn;nus.edu.sg;uestc.edu.cn;ntu.edu.sg;",
        "position": "PhD student;MS student;Postdoc;Full Professor;Assistant Professor;",
        "bibtex": "@inproceedings{\nliang2025damage,\ntitle={Damage Analysis via Bidirectional Multi-Task Cascaded Multimodal Fusion},\nauthor={Tao Liang and Siying Wu and Junfeng Fang and Guowu Yang and Wenya Wang and Fengmao Lv},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=di9gHcxYf3}\n}",
        "github": "",
        "project": "",
        "reviewers": "MWWN;43rs;NAb9;LgdB",
        "site": "https://openreview.net/forum?id=di9gHcxYf3",
        "pdf_size": 0,
        "novelty": "5;5;5;6",
        "technical_quality": "5;5;5;5",
        "scope": "3;4;3;3",
        "confidence": "2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.0,
            0.0
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "diaXdjqLGW",
        "title": "ShapeShifter: Workload-Aware Adaptive Evolving Index Structures Based on Learned Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In applications such as data management and Web search engines, indexes are key to enabling efficient data retrieval. \nWe find that unlike standard benchmarks with uniform data distribution, index operations in real-world tasks often exhibit strong skewness.\nHowever, existing high-performance learned indexes, while proposed to enhance query and update efficiency, often fail to account for the characteristics of skewed workload access, leading to an imbalanced focus on optimizing a single performance metric at the expense of other critical aspects of overall index performance.\nFurthermore, the complete use of learned models in index structures can lead to increased robustness issues, making them highly vulnerable to attacks and resulting in system unavailability.\n\nTo address these challenges, we propose ShapeShifter, an adaptive evolutionary structure based on traditional indexes, capable of dynamically adjusting node structures according to the workload. \nShapeShifter introduces a node evolution strategy, designed with workload-skew-aware policies, to adaptively adjust and optimize the most suitable partial index structure, leveraging a hybrid mechanism that combines traditional and learned structures for robust performance and an optimal time-space trade-off under skewed workloads and extreme data conditions.\nThe evaluation results show that ShapeShifter achieves the optimal trade-off between performance and space efficiency while maintaining robustness.",
        "keywords": "index structure;learned model;evolving strategy;data management;web search engine",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hui Wang;Xin Wang;Jiake Ge;Lei Liang;Peng Yi",
        "authorids": "~Hui_Wang30;~Xin_Wang39;~Jiake_Ge1;~Lei_Liang2;~Peng_Yi6",
        "gender": "F;M;M;M;M",
        "homepage": ";http://www.tjudb.cn/dbgroup/Xin_Wang;;https://github.com/leywar;",
        "dblp": ";10/5630-30;299/9626;24/1476-2;",
        "google_scholar": ";https://scholar.google.com/citations?hl=en;o0uk0b8AAAAJ;9vrGGHwAAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": "0009-0009-0886-8713;0000-0001-9651-0651;0000-0003-4644-0733;0009-0000-9700-5809;",
        "linkedin": ";;;;",
        "or_profile": "~Hui_Wang30;~Xin_Wang39;~Jiake_Ge1;~Lei_Liang2;~Peng_Yi6",
        "aff": "Tianjin University;Tianjin University;Tianjin University;Alibaba Group;Alibaba Group",
        "aff_domain": "tju.edu.cn;tju.edu.cn;tju.edu;antgroup.com;antgroup.com",
        "position": "MS student;Full Professor;Assistant Professor;Researcher;Researcher",
        "bibtex": "@inproceedings{\nwang2025shapeshifter,\ntitle={ShapeShifter: Workload-Aware Adaptive Evolving Index Structures Based on Learned Models},\nauthor={Hui Wang and Xin Wang and Jiake Ge and Lei Liang and Peng Yi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=diaXdjqLGW}\n}",
        "github": "",
        "project": "",
        "reviewers": "2pD5;MAXh;4XkW;Bd8R",
        "site": "https://openreview.net/forum?id=diaXdjqLGW",
        "pdf_size": 0,
        "novelty": "3;4;6;6",
        "technical_quality": "4;5;4;6",
        "scope": "3;4;4;4",
        "confidence": "3;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.299038105676658
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.19245008972987526
    },
    {
        "id": "doyAPsYKf6",
        "title": "Unleashing the Power of Large Language Model for Denoising Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recommender systems are vital for personalizing user experiences, yet they often rely on implicit feedback data that can be noisy and misleading. Existing denoising studies typically involve either incorporating auxiliary information or learning denoising strategies from interaction data. Nonetheless, they face challenges due to the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, which hinder their ability to accurately identify noise. Recently, large language models (LLMs) have garnered significant attention due to their extensive world knowledge and powerful reasoning capabilities. Despite this, the potential of LLMs to enhance the denoising process in recommendations remains largely unexplored. In this paper, we introduce LLaRD, a novel framework that leverages LLMs to improve the denoising process in recommender systems, thereby enhancing overall recommendation performance. Specifically, LLaRD generates denoising-related knowledge by first enriching semantic insights from observational data through LLMs, facilitating a comprehensive inference of user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to uncover relation knowledge pertinent to denoising. Finally, it utilizes the Information Bottleneck (IB) principle to align the denoising knowledge generated by LLMs with the recommendation targets, effectively filtering out both data noise and irrelevant knowledge produced by the LLMs. Empirical results demonstrate the effectiveness of our proposed framework, showcasing its superior performance in denoising and recommendation accuracy.",
        "keywords": "Implicit feedback;LLM",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shuyao Wang;Zhi Zheng;Yongduo Sui;Hui Xiong",
        "authorids": "~Shuyao_Wang1;~Zhi_Zheng3;~Yongduo_Sui1;~Hui_Xiong1",
        "gender": "F;;M;M",
        "homepage": ";https://zhengzhi-1997.github.io/;https://yongduosui.github.io/;https://www.hkust-gz.edu.cn/people/hui-xiong/",
        "dblp": "180/2578.html;30/679-8;277/5175;262/1686-1.html",
        "google_scholar": "wxZLbL0AAAAJ;uoYLG8UAAAAJ;VD9g6ogAAAAJ;cVDF1tkAAAAJ",
        "orcid": "0009-0002-0439-4249;0000-0001-7758-8904;0000-0003-4492-147X;0000-0001-6016-6465",
        "linkedin": ";;yongduosui/;",
        "or_profile": "~Shuyao_Wang1;~Zhi_Zheng3;~Yongduo_Sui1;~Hui_Xiong1",
        "aff": "Alibaba Group+University of Science and Technology of China;University of Science and Technology of China;Tencent;Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "alibaba-inc.com+ustc.edu.cn;ustc.edu.cn;tencent.com;hkust.edu",
        "position": "Intern+PhD student;PhD student;Researcher;Full Professor",
        "bibtex": "@inproceedings{\nwang2025unleashing,\ntitle={Unleashing the Power of Large Language Model for Denoising Recommendation},\nauthor={Shuyao Wang and Zhi Zheng and Yongduo Sui and Hui Xiong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=doyAPsYKf6}\n}",
        "github": "",
        "project": "",
        "reviewers": "D55K;PxuU;dHZn;DSjK;fUHs",
        "site": "https://openreview.net/forum?id=doyAPsYKf6",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "3;5;4;3;6",
        "scope": "4;4;4;3;3",
        "confidence": "3;4;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.49999999999999994
    },
    {
        "id": "dqSiYC8a4p",
        "title": "Instruction Vulnerability Prediction for WebAssembly with Semantic Enhanced Code Property Graph",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "WebAssembly (Wasm) is a universal low-level bytecode designed to build modern web systems. Recent studies have shown that technologies such as voltage scaling and RowHammer attacks are expected to increase the likelihood of bit flips, which may cause unacceptable or catastrophic system failures. This raises concerns about the impact of bit flips on Wasm programs, which run as instructions in web systems, and it is an undeveloped topic since the features of Wasm differ from traditional programs. In this paper, we propose a novel paradigm, namely IVPSEG, to understand the error propagation of bit flips within Wasm programs. Specifically, we first use Large Language Models (LLMs) to automatically extract instruction embeddings containing semantic knowledge of each instruction's context. Then, we exploit these embeddings and program structure (control execution and data transfer) to construct a semantic enhanced code property graph, which implicates the potential path of error propagation. Based on this graph, we utilize graph neural networks and attention diffusion to optimize instruction embeddings by capturing different error propagation patterns for instruction vulnerability prediction. In particular, we build a Wasm compilation and fault generation system to simulate bit flips at Wasm runtime. \nOur experimental results with 14 benchmark programs and test cases show IVPSEG outperforms the state-of-the-art methods in terms of accuracy (average 13.06\\%$\\uparrow$ ), F1-score (average 14.93\\%$\\uparrow$), and model robustness.",
        "keywords": "WebAssembly;Bit flips;Instruction Vulnerability Prediction;Error Propagation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Bao Wen;Jingjing Gu;Hao Han;Pengfei Yu;Yang Liu",
        "authorids": "~Bao_Wen1;~Jingjing_Gu1;~Hao_Han3;~Pengfei_Yu3;~Yang_Liu115",
        "gender": ";;M;M;M",
        "homepage": ";;https://hhannuaa.github.io/;;https://github.com/LiuyAaa",
        "dblp": ";;;;",
        "google_scholar": ";;80_y6KEAAAAJ;https://scholar.google.com.hk/citations?user=vBcLzIAAAAAJ;",
        "orcid": ";;;0000-0002-9926-9442;0009-0001-2596-8419",
        "linkedin": ";;;;",
        "or_profile": "~Bao_Wen1;~Jingjing_Gu1;~Hao_Han3;~Pengfei_Yu3;~Yang_Liu115",
        "aff": ";;Nanjing University of Aeronautics and Astronautics;Nanjing University of Aeronautics and Astronautics;Nanjing University of Aeronautics and Astronautics",
        "aff_domain": ";;nuaa.edu.cn;nuaa.edu;nuaa.edu.cn",
        "position": ";;Full Professor;PhD student;PhD student",
        "bibtex": "@inproceedings{\nwen2025instruction,\ntitle={Instruction Vulnerability Prediction for WebAssembly with Semantic Enhanced Code Property Graph},\nauthor={Bao Wen and Jingjing Gu and Hao Han and Pengfei Yu and Yang Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dqSiYC8a4p}\n}",
        "github": "",
        "project": "",
        "reviewers": "MGnz;ZEhd;iSG9;GtLN",
        "site": "https://openreview.net/forum?id=dqSiYC8a4p",
        "pdf_size": 0,
        "novelty": "4;5;6;7",
        "technical_quality": "4;3;6;5",
        "scope": "3;3;4;4",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7745966692414834
    },
    {
        "id": "dyFPBgMdii",
        "title": "GL2GPU: Accelerating WebGL Applications via Dynamic API Translation to WebGPU",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "WebGL has long been the prevalent API for GPU-accelerated graphics in web browsers, boosting 2D/3D graphical web applications. Despite widespread adoption, WebGL's programming model hinders its rendering performance on modern GPU hardware. To this end, WebGPU has been proposed as the next-generation API of GPU-accelerated processing in web browsers, exhibiting higher performance than WebGL. However, considering the complex logic of WebGL applications and the still-evolving WebGPU specification, statically migrating existing WebGL applications to WebGPU from source code is labor-intensive. To address this issue, we propose GL2GPU, an intermediate layer that dynamically translates WebGL to WebGPU at JavaScript runtime to improve rendering performance. GL2GPU addresses the inconsistencies between the WebGL and WebGPU programming models by emulating WebGL rendering states and leverages performance optimization mechanisms introduced by WebGPU to reduce the overhead of dynamic translation. Evaluation of three representative WebGL benchmarks shows that GL2GPU significantly enhances end-to-end rendering performance while maintaining visual consistency, achieving an average frame time reduction of 45.05\\% across different devices and operating systems.",
        "keywords": "graphics processing;webgl;webgpu;api translation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yudong Han;Weichen Bi;Ruibo An;Deyu Tian;Qi Yang;Yun Ma",
        "authorids": "~Yudong_Han3;~Weichen_Bi1;~Ruibo_An1;~Deyu_Tian2;~Qi_Yang9;~Yun_Ma1",
        "gender": "M;;M;;;M",
        "homepage": ";;;https://tiandeyu-cs.github.io/;;",
        "dblp": ";;;;;75/7811-2",
        "google_scholar": ";;;;;1hnJ3TgAAAAJ",
        "orcid": "0000-0003-4846-5803;;0009-0005-3061-442X;;0000-0003-2057-3861;",
        "linkedin": ";weichen-bi-2688901a3/;;;;",
        "or_profile": "~Yudong_Han3;~Weichen_Bi1;~Ruibo_An1;~Deyu_Tian2;~Qi_Yang9;~Yun_Ma1",
        "aff": "Peking University;Peking University;Peking University;;;Peking University",
        "aff_domain": "pku.edu.cn;pku.edu.cn;stu.pku.edu.cn;;;pku.edu.cn",
        "position": "PhD student;PhD student;Undergrad student;;;Assistant Professor",
        "bibtex": "@inproceedings{\nhan2025glgpu,\ntitle={{GL}2{GPU}: Accelerating Web{GL} Applications via Dynamic {API} Translation to Web{GPU}},\nauthor={Yudong Han and Weichen Bi and Ruibo An and Deyu Tian and Qi Yang and Yun Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=dyFPBgMdii}\n}",
        "github": "",
        "project": "",
        "reviewers": "sBEE;rSwk;GJ2z;zrdM;HctL",
        "site": "https://openreview.net/forum?id=dyFPBgMdii",
        "pdf_size": 0,
        "novelty": "4;5;5;5;7",
        "technical_quality": "4;4;6;6;7",
        "scope": "3;4;4;4;4",
        "confidence": "2;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            5.4,
            1.2
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8728715609439696
    },
    {
        "id": "eAAXCzLeht",
        "title": "Effective Influence Maximization with Priority",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Influence maximization (IM) aims to identify a small set of influential users to maximize the information spread. It has been widely applied in the context of viral marketing, where a company distributes incentives to a few influencers to promote the product. However, in practical scenarios, not all users hold equal importance and certain users need to be prioritized for the specific requirements. Motivated by this, recently, a variant problem of IM, called influence maximization with priority (IMP), has been proposed. Given a graph G=(V,E), a priority set P \u2286 V and a threshold T \u2208 [0, |P|], IMP aims to identify a set of k nodes (termed seeds) to maximize the expected number of activated nodes in G while satisfying that the expected number of activated nodes in P is no less than the given threshold. Nevertheless, we show that existing solutions for IMP are inferior in maximizing the influence spread in G, and can only offer poor approximation ratios in many cases. To address these limitations, in this paper, we first propose a novel framework named SAR with both superior empirical effectiveness and strong theoretical guarantees. In addition, to obtain more practical results, we study the IMP problem under the adaptive setting, where the seed users are iteratively selected after observing the diffusion result of the previous seeds. We design a scalable and effective algorithm AAS that achieves expected approximation guarantees. Comprehensive experiments on 5 real-world datasets are conducted to validate the performance of the proposed techniques. Compared with the state-of-the-art method, SAR achieves up to 22.3% larger spread and AAS achieves up to 42.6% larger spread, with both exhibiting a higher empirical approximation ratio.",
        "keywords": "Influence Maximization;Approximation Algorithms;Adaptive Submodularity",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jinghao Wang;Yanping Wu;Xiaoyang Wang;Chen Chen;Ying Zhang;Lu Qin",
        "authorids": "~Jinghao_Wang4;~Yanping_Wu2;~Xiaoyang_Wang8;~Chen_Chen51;~Ying_Zhang6;~Lu_Qin1",
        "gender": "M;F;M;;M;M",
        "homepage": ";;https://research.unsw.edu.au/people/dr-xiaoyang-wang;https://scholars.uow.edu.au/chen-chen;https://profiles.uts.edu.au/Ying.Zhang;https://profiles.uts.edu.au/Lu.Qin",
        "dblp": ";;81/1832-2;65/4423-17;13/6769-1;51/5585",
        "google_scholar": "e6re2NsAAAAJ;8accqVcAAAAJ;https://scholar.google.com.au/citations?user=TwbvM1oAAAAJ;nGhl9MMAAAAJ;https://scholar.google.com.au/citations?user=9LTwX4cAAAAJ;DQHL47oAAAAJ",
        "orcid": ";;0000-0003-3554-3219;0000-0003-3908-6545;0000-0002-2674-1638;0000-0001-6068-5062",
        "linkedin": ";;;;;",
        "or_profile": "~Jinghao_Wang4;~Yanping_Wu2;~Xiaoyang_Wang8;~Chen_Chen51;~Ying_Zhang6;~Lu_Qin1",
        "aff": "University of Technology Sydney (UTS);University of Technology Sydney;University of New South Wales;University of Wollongong;University of Technology Sydney (UTS);University of Technology Sydney",
        "aff_domain": "uts.eud.au;student.uts.edu.au;unsw.edu.au;uow.edu.au;uts.eud.au;uts.edu.au",
        "position": "PhD student;PhD student;Lecturer;Lecturer;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nwang2025effective,\ntitle={Effective Influence Maximization with Priority},\nauthor={Jinghao Wang and Yanping Wu and Xiaoyang Wang and Chen Chen and Ying Zhang and Lu Qin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eAAXCzLeht}\n}",
        "github": "",
        "project": "",
        "reviewers": "KpXK;JjF7;F3oN;9j3H;64aR",
        "site": "https://openreview.net/forum?id=eAAXCzLeht",
        "pdf_size": 0,
        "novelty": "2;5;5;5;6",
        "technical_quality": "3;6;5;6;7",
        "scope": "2;3;4;4;4",
        "confidence": "4;2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            5.4,
            1.3564659966250536
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8669214468630109
    },
    {
        "id": "eHF4pDRWjT",
        "title": "Efficient Retrieval with Learned Similarities",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Retrieval plays a fundamental role in recommendation systems, search, and natural language processing (NLP) by efficiently finding relevant items from a large corpus given a query. Dot products have been widely used as the similarity function in such retrieval tasks, thanks to Maximum Inner Product Search (MIPS) that enabled efficient retrieval based on dot products. However, state-of-the-art retrieval algorithms have migrated to learned similarities. Such algorithms vary in form; the queries can be represented with multiple embeddings, complex neural networks can be deployed, the item ids can be decoded directly from queries using beam search, and multiple approaches can be combined in hybrid solutions. Unfortunately, we lack efficient solutions for retrieval in these state-of-the-art setups. Our work investigates techniques for efficient retrieval with expressive learned similarity functions. We first prove that Mixture-of-Logits (MoL) is a universal approximator, and can express all learned similarity functions. We then demonstrate how to apply MoL to common retrieval tasks in recommendation systems and NLP. We next propose techniques to retrieve the approximate top $K$ results using MoL with a tight bound. We finally compare our techniques with existing approaches, showing that MoL, with a new mutual information-based load balancing loss we propose, sets new state-of-the-art results across heterogeneous scenarios, including sequential retrieval models in recommendation systems and finetuning language models for question answering; and our approximate top-k retrieval with learned similarities outperforms baselines by up to 105\u00d7 in latency, while achieving > .99 recall rate of exact algorithms.",
        "keywords": "Nearest Neighbor Search;Learned Similarities;Top-K Retrieval;Vector Databases;Recommendation Systems;Question Answering",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Bailu Ding;Jiaqi Zhai",
        "authorids": "~Bailu_Ding1;~Jiaqi_Zhai1",
        "gender": ";",
        "homepage": "http://aka.ms/bailuding;",
        "dblp": "163/0574;95/9726",
        "google_scholar": "NQiXPb0AAAAJ;E9wn7LUAAAAJ",
        "orcid": "0000-0003-4138-6379;0009-0004-7279-3318",
        "linkedin": ";jiaqizhai/",
        "or_profile": "~Bailu_Ding1;~Jiaqi_Zhai1",
        "aff": "Microsoft;Meta Facebook",
        "aff_domain": "microsoft.com;fb.com",
        "position": "Principal Researcher;Distinguished Engineer",
        "bibtex": "@inproceedings{\nding2025efficient,\ntitle={Efficient Retrieval with Learned Similarities},\nauthor={Bailu Ding and Jiaqi Zhai},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eHF4pDRWjT}\n}",
        "github": "",
        "project": "",
        "reviewers": "sztF;Jyq8;2Kha;6C8f",
        "site": "https://openreview.net/forum?id=eHF4pDRWjT",
        "pdf_size": 0,
        "novelty": "6;6;6;7",
        "technical_quality": "6;6;5;5",
        "scope": "4;4;3;4",
        "confidence": "3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            6.25,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "eOp0bcpbt0",
        "title": "Disentangled Condensation for Large-scale Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph condensation has emerged as an intriguing technique to save the expensive training costs of Graph Neural Networks (GNNs) by substituting a condensed small graph with the original graph. Despite the promising results achieved, previous methods usually employ an entangled paradigm of redundant parameters (nodes, edges, GNNs), which incurs complex joint optimization during condensation.\nThis paradigm has considerably impeded the scalability of graph condensation, making it challenging to condense extremely large-scale graphs and generate high-fidelity condensed graphs. Therefore, we propose to disentangle the condensation process into a two-stage GNN-free paradigm, independently condensing nodes and generating edges while eliminating the need to optimize GNNs at the same time. The node condensation module avoids the complexity of GNNs by focusing on node feature alignment with anchors of the original graph, while the edge translation module constructs the edges of the condensed nodes by transferring the original structure knowledge with neighborhood anchors.  This simple yet effective approach achieves at least 10 times faster than state-of-the-art methods with comparable accuracy on medium-scale graphs. Moreover, the proposed DisCo can successfully scale up to the Ogbn-papers100M graph containing over 100 million nodes with flexible reduction rates and improves performance on the second-largest Ogbn-products dataset by over 5\\%. Extensive downstream tasks and ablation study on five common datasets further demonstrate the effectiveness of the proposed DisCo framework. The source code will be made publicly available.",
        "keywords": "Graph Condensation;Large-scale Graph;Graph Neural Networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhenbang Xiao;Yu Wang;Shunyu Liu;Bingde Hu;Huiqiong Wang;Mingli Song;Tongya Zheng",
        "authorids": "~Zhenbang_Xiao1;~Yu_Wang47;~Shunyu_Liu1;~Bingde_Hu1;~Huiqiong_Wang1;~Mingli_Song1;~Tongya_Zheng1",
        "gender": "M;;;M;F;M;M",
        "homepage": ";;https://liushunyu.github.io/;https://www.vipazoo.cn/people/hubingde;;https://person.zju.edu.cn/msong;https://doujiang-zheng.github.io/",
        "dblp": ";;235/0752-1;353/7326;19/1682;71/5333;245/8743",
        "google_scholar": ";;4U-X6d4AAAAJ;;;7oLbhAwAAAAJ;Ko2OtGgAAAAJ",
        "orcid": "0009-0004-8600-2687;;0000-0003-0584-9129;0000-0003-2556-9239;;0000-0003-2621-6048;0000-0003-1190-9773",
        "linkedin": ";;;;;;",
        "or_profile": "~Zhenbang_Xiao1;~Yu_Wang47;~Shunyu_Liu1;~Bingde_Hu1;~Huiqiong_Wang1;~Mingli_Song1;~Tongya_Zheng1",
        "aff": "Zhejiang University;;Nanyang Technological University;Zhejiang University;Zhejiang University;Zhejiang University;Hangzhou City University",
        "aff_domain": "zju.edu.cn;;ntu.edu.sg;zju.edu.cn;zju.edu.cn;zju.edu.cn;hzcu.edu.cn",
        "position": "MS student;;Postdoc;Postdoc;Lecturer;Full Professor;Postdoc",
        "bibtex": "@inproceedings{\nxiao2025disentangled,\ntitle={Disentangled Condensation for Large-scale Graphs},\nauthor={Zhenbang Xiao and Yu Wang and Shunyu Liu and Bingde Hu and Huiqiong Wang and Mingli Song and Tongya Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eOp0bcpbt0}\n}",
        "github": "",
        "project": "",
        "reviewers": "ShCw;BCYU;dP2X;igYF;Sn7R",
        "site": "https://openreview.net/forum?id=eOp0bcpbt0",
        "pdf_size": 0,
        "novelty": "3;3;4;5;5",
        "technical_quality": "5;4;5;6;6",
        "scope": "4;3;3;4;4",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "eQQnco4OmX",
        "title": "Self-Calibrated Listwise Reranking with Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs), with advanced linguistic capabilities, have been employed in reranking tasks through a sequence-to-sequence approach. In this paradigm, multiple passages are reranked in a listwise manner and a textual reranked permutation is generated. However, due to the limited context window of LLMs, this reranking paradigm requires a sliding window strategy to iteratively handle larger candidate sets. This not only increases computational costs but also restricts the LLM from fully capturing all the comparison information for all candidates. To address these challenges, we propose a novel self-calibrated listwise reranking method, which aims to leverage LLMs to produce global relevance scores for ranking. To achieve it, we first propose the relevance-aware listwise reranking framework, which incorporates explicit list-view relevance scores to improve reranking efficiency and enable global comparison across the entire candidate set. Second, to ensure the comparability of the computed scores, we propose self-calibrated training that uses point-view relevance assessments generated internally by the LLM itself to calibrate the list-view relevance assessments. Extensive experiments and comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks demonstrate the effectiveness and efficiency of our proposed method.",
        "keywords": "Text Reranking;Large Language Models;Self-calibration",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ruiyang Ren;Yuhao Wang;Kun Zhou;Xin Zhao;Wenjie Wang;Jing Liu;Ji-Rong Wen;Tat-Seng Chua",
        "authorids": "~Ruiyang_Ren1;~Yuhao_Wang14;~Kun_Zhou2;~Xin_Zhao10;~Wenjie_Wang1;~Jing_Liu7;~Ji-Rong_Wen1;~Tat-Seng_Chua2",
        "gender": "M;;M;M;M;M;M;",
        "homepage": "https://rui-yang.ren;;https://lancelot39.github.io/;https://gsai.ruc.edu.cn/addons/teacher/index/info.html?user_id=5&ruccode=20140041&ln=cn;https://wenjiewwj.github.io/;https://legendarydan.github.io;https://gsai.ruc.edu.cn/english/jrwen;",
        "dblp": "265/6402;54/518-7.html;48/3927-2.html;https://dblp.uni-trier.de/pid/52/8700.html;38/1956-7;72/2590-22;w/JRWen;",
        "google_scholar": "KpIEBYMAAAAJ;https://scholar.google.com.hk/citations?user=aXedzJgAAAAJ;bmRJVjwAAAAJ;JNhNacoAAAAJ;Ma5DtmoAAAAJ;_NtB74oAAAAJ;tbxCHJgAAAAJ;",
        "orcid": ";0009-0001-5760-9285;0000-0003-0650-9521;0000-0002-8333-6196;0000-0002-5199-1428;;0000-0002-9777-9676;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Ruiyang_Ren1;~Yuhao_Wang14;~Kun_Zhou2;~Xin_Zhao10;~Wenjie_Wang1;~Jing_Liu7;~Ji-Rong_Wen1;~Tat-Seng_Chua2",
        "aff": "Renmin University of China;Renmin University of China;University of California, San Diego;Renmin University of China;University of Science and Technology of China;Baidu;Renmin University of China;",
        "aff_domain": "ruc.edu.cn;ruc.edu.cn;ucsd.edu;ruc.edu.cn;ustc.edu.cn;baidu.com;ruc.edu.cn;",
        "position": "PhD student;MS student;Postdoc;Full Professor;Full Professor;Researcher;Full Professor;",
        "bibtex": "@inproceedings{\nren2025selfcalibrated,\ntitle={Self-Calibrated Listwise Reranking with Large Language Models},\nauthor={Ruiyang Ren and Yuhao Wang and Kun Zhou and Xin Zhao and Wenjie Wang and Jing Liu and Ji-Rong Wen and Tat-Seng Chua},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eQQnco4OmX}\n}",
        "github": "",
        "project": "",
        "reviewers": "HW3v;wuRt;xPxo;seJf",
        "site": "https://openreview.net/forum?id=eQQnco4OmX",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "6;4;5;4",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "eRljAllb2e",
        "title": "SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This\nraises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen\ntarget domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage\nlarge language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, very few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT. (Codes and data are available at https://anonymous.4open.science/r/SAMGPT for anonymous review.)",
        "keywords": "Data mining;graph learning;graph foundation model;multi-domain pre-training;prompt learning;few-shot learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xingtong Yu;Zechuan Gong;Chang Zhou;Yuan Fang;Hui Zhang",
        "authorids": "~Xingtong_Yu1;~Zechuan_Gong1;~Chang_Zhou7;~Yuan_Fang1;~Hui_Zhang30",
        "gender": "M;;;M;M",
        "homepage": "https://xingtongyu.netlify.app/;;;http://www.yfang.site;https://cs.ustc.edu.cn/2020/1203/c23239a462605/page.htm",
        "dblp": "339/7128;;;22/981-1;",
        "google_scholar": "VKWhRggAAAAJ;;;XkBJjPUAAAAJ;",
        "orcid": "0000-0002-2884-8578;0009-0001-9387-5070;;0000-0002-4265-5289;",
        "linkedin": ";;;;",
        "or_profile": "~Xingtong_Yu1;~Zechuan_Gong1;~Chang_Zhou7;~Yuan_Fang1;~Hui_Zhang30",
        "aff": "Singapore Management University;University of Science and Technology of China;;Singapore Management University+Singapore Management University;University of Science and Technology of China",
        "aff_domain": "smu.edu.sg;mail.ustc.edu.cn;;smu.edu.sg+smu.edu.sg;ustc.edu.cn",
        "position": "Postdoc;MS student;;Associate Professor+Assistant Professor;Associate Professor",
        "bibtex": "@inproceedings{\nyu2025samgpt,\ntitle={{SAMGPT}: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation},\nauthor={Xingtong Yu and Zechuan Gong and Chang Zhou and Yuan Fang and Hui Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eRljAllb2e}\n}",
        "github": "",
        "project": "",
        "reviewers": "KYij;EWdj;VqC8;cCq8;Un6B",
        "site": "https://openreview.net/forum?id=eRljAllb2e",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "5;3;5;5;5",
        "scope": "4;4;4;4;3",
        "confidence": "3;3;4;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6666666666666665
    },
    {
        "id": "eiKc2SdjSS",
        "title": "Value Function Decomposition in Markov Recommendation Process",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Recent advances in recommender systems have shown that user-system interaction essentially formulates long-term optimization problems, and online reinforcement learning can be adopted to improve recommendation performance. The general solution framework incorporates a value function that estimates the user's expected cumulative rewards in the future and guides the training of the recommendation policy. To avoid local maxima, the policy may explore potential high-quality actions during inference to increase the chance of finding better future rewards. To accommodate the stepwise recommendation process, one widely adopted approach to learning the value function is learning from the difference between the values of two consecutive states of a user. However, we argue that this paradigm involves an incorrect approximation in the stochastic process. Specifically, between the current state and the next state in each training sample, there exist two separate random factors from the stochastic policy and the uncertain user environment. Original TD learning under these mixed random factors may result in a suboptimal estimation of the long-term rewards. As a solution, we show that these two factors can be separately approximated by decomposing the original temporal difference loss. The disentangled learning framework can achieve a more accurate estimation with faster learning and improved robustness against action exploration. As empirical verification of our proposed method, we conduct offline experiments with online simulated environments built based on public datasets.",
        "keywords": "Recommender Systems;Reinforcement Learning;Markov Decision Process",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaobei Wang;Shuchang Liu;Qingpeng Cai;Xiang Li;Lantao Hu;Han Li;Guangming Xie",
        "authorids": "~Xiaobei_Wang1;~Shuchang_Liu1;~Qingpeng_Cai2;~Xiang_Li49;~Lantao_Hu1;~Han_Li11;~Guangming_Xie1",
        "gender": "M;M;M;M;M;M;M",
        "homepage": "https://github.com/wangxiaobei565;;https://qingpengcai.github.io/;;;;",
        "dblp": ";335/1645;183/0940-1;;;07/1429-5;",
        "google_scholar": ";kivnB4QAAAAJ;uU6s1tYAAAAJ;oMB6_gUAAAAJ;P0EK1y8AAAAJ;IJGli9AAAAAJ;http://scholar.google.com.hk/citations?hl=en",
        "orcid": "0009-0006-7628-7257;0000-0002-1440-911X;0000-0001-6451-9299;0009-0000-6958-3388;;0009-0000-9801-9292;",
        "linkedin": ";;;;;;",
        "or_profile": "~Xiaobei_Wang1;~Shuchang_Liu1;~Qingpeng_Cai2;~Xiang_Li49;~Lantao_Hu1;~Han_Li11;~Guangming_Xie1",
        "aff": "Kuaishou- \u5feb\u624b\u79d1\u6280;Kuaishou;Kuaishou Technology;Kuaishou- \u5feb\u624b\u79d1\u6280;;Kuaishou;Peking University, Tsinghua University",
        "aff_domain": "kuaishou.com;kuaishou.com;kuaishou.com;kuaishou.com;;kuaishou.com;pku.edu.cn",
        "position": "Researcher;Researcher;Senior Staff Research Scientist;Engineer;;Researcher;Full Professor",
        "bibtex": "@inproceedings{\nwang2025value,\ntitle={Value Function Decomposition in Markov Recommendation Process},\nauthor={Xiaobei Wang and Shuchang Liu and Qingpeng Cai and Xiang Li and Lantao Hu and Han Li and Guangming Xie},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eiKc2SdjSS}\n}",
        "github": "",
        "project": "",
        "reviewers": "Bcp9;hJXf;Qk45;SQ1E;c3hg;umbn",
        "site": "https://openreview.net/forum?id=eiKc2SdjSS",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5;6",
        "technical_quality": "4;3;5;6;4;5",
        "scope": "4;3;4;4;4;4",
        "confidence": "2;3;3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.833333333333333,
            0.6871842709362768
        ],
        "technical_quality_avg": [
            4.5,
            0.9574271077563381
        ],
        "scope_avg": [
            3.8333333333333335,
            0.3726779962499649
        ],
        "confidence_avg": [
            2.8333333333333335,
            0.6871842709362768
        ],
        "replies_avg": [
            6,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2941176470588235
    },
    {
        "id": "ekpwUuKlB7",
        "title": "From Data Deluge to Data Curation: A Filtering-WoRA Paradigm for Efficient Text-based Person Search",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In text-based person search endeavors, data generation has emerged as a prevailing practice, addressing concerns over privacy preservation and the arduous task of manual annotation. Although the number of synthesized data can be infinite in theory, the scientific conundrum persists that how much generated data optimally fuels subsequent model training. We observe that only a subset of the data in these constructed datasets plays a decisive role. Therefore, we introduce a new Filtering-WoRA paradigm, which contains a filtering algorithm to identify this crucial data subset and WoRA (Weighted Low-Rank Adaptation) learning strategy for light fine-tuning. The filtering algorithm is based on the cross-modality relevance to remove the lots of coarse matching synthesis pairs. As the number of data decreases, we do not need to fine-tune the entire model. Therefore, we propose a WoRA learning strategy to efficiently update a minimal portion of model parameters. WoRA streamlines the learning process, enabling heightened efficiency in extracting knowledge from fewer, yet potent, data instances. Extensive experimentation validates the efficacy of pretraining, where our model achieves advanced and efficient retrieval performance on challenging real-world benchmarks. Notably, on the CUHK-PEDES dataset, we have achieved a competitive mAP of 67.02% while reducing model training time by 19.82%.",
        "keywords": "Retrieval efficiency;Retrieval effectiveness",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jintao Sun;Hao Fei;Gangyi Ding;Zhedong Zheng",
        "authorids": "~Jintao_Sun1;~Hao_Fei1;~Gangyi_Ding1;~Zhedong_Zheng1",
        "gender": "M;M;M;M",
        "homepage": "https://github.com/JT-Sun?tab=repositories;https://haofei.vip/;https://ieeexplore.ieee.org/author/37684756000;http://zdzheng.xyz",
        "dblp": "19/10855-1;81/3569-1;;190/7710",
        "google_scholar": "OhD3pk8AAAAJ;YGDX46AAAAAJ;;XT17oUEAAAAJ",
        "orcid": "0009-0009-3996-4011;0000-0003-3026-6347;;0000-0002-2434-9050",
        "linkedin": ";;;zhedongzheng",
        "or_profile": "~Jintao_Sun1;~Hao_Fei1;~Gangyi_Ding1;~Zhedong_Zheng1",
        "aff": "Beijing Institute of Technology;National University of Singapore;Beijing Institute of Technology;University of Macau",
        "aff_domain": "bit.edu.cn;nus.edu.sg;bit.edu.cn;um.edu.mo",
        "position": "PhD student;Postdoc;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nsun2025from,\ntitle={From Data Deluge to Data Curation: A Filtering-Wo{RA} Paradigm for Efficient Text-based Person Search},\nauthor={Jintao Sun and Hao Fei and Gangyi Ding and Zhedong Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ekpwUuKlB7}\n}",
        "github": "",
        "project": "",
        "reviewers": "Rut4;51Sw;fQWU;z3rp",
        "site": "https://openreview.net/forum?id=ekpwUuKlB7",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;4;6;6",
        "scope": "3;3;4;4",
        "confidence": "4;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.75,
            1.299038105676658
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.40451991747794525
    },
    {
        "id": "eyCzw3pgmq",
        "title": "Counting Cohesive Subgraphs with Hereditary Properties",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The classic clique model has properties of hereditaries  and cohesiveness. Here hereditaries means a subgraph of a clique is still a clique. Counting small cliques in a graph is a fundamental operation of numerous applications. However, the clique model is often too restrictive for practical use, leading to the focus on other relaxed-cliques with properties of hereditaries and cohesiveness. To address this issue, we investigate a new problem of counting general hereditary cohesive subgraphs (\\hcs). All subgraphs with properties of hereditaries  and cohesiveness can be called a kind of \\hcs. To count \\hcs, we propose a general framework called \\hcspivot, which can be applied to count all kinds of \\hcs. \\hcspivot can count most \\hcs combinatorially without explicitly listing them.  Two additional noteworthy features of \\hcspivot are  its ability to (1) simultaneously count \\hcs of any size and (2) simultaneously count \\hcs for each node or each edge. Based on our \\hcspivot framework, we propose two novel algorithms with several  carefully designed pruning techniques to count $s$-defective cliques and $s$-plexes, which are two specific types of \\hcs. We conduct extensive experiments on 8 large real-world graphs, and the results demonstrate the high efficiency and effectiveness of our solutions.",
        "keywords": "Hereditary Cohesive Subgraph Counting;plex counting;deftective clique counting;subgraph scounting",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rong-Hua Li;Xiaowei Ye;Fusheng Jin;Yu-Ping Wang;Ye Yuan;Guoren Wang",
        "authorids": "~Rong-Hua_Li2;~Xiaowei_Ye2;~Fusheng_Jin1;~Yu-Ping_Wang1;~Ye_Yuan15;~Guoren_Wang2",
        "gender": "M;M;M;M;;M",
        "homepage": "https://ronghuali.github.io/;;https://cs.bit.edu.cn/szdw/jsml/fjs/jfs/index.htm;https://cs.bit.edu.cn/szdw/jsml/js/chehy_3265be3a85294b778e46aeb4093b563a/index.htm;;https://guorenwang.github.io/",
        "dblp": "37/548.html;83/1009;76/6638;https://dblp.uni-trier.de/pid/29/3814-1.html;;",
        "google_scholar": "fOKGw-EAAAAJ;L_Gw3uUAAAAJ;;https://scholar.google.com.tw/citations?user=S41MwX0AAAAJ;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0000-0002-3105-5325;0000-0003-0982-341X;;0000-0003-4129-7704;;",
        "linkedin": ";;;;;",
        "or_profile": "~Rong-Hua_Li2;~Xiaowei_Ye2;~Fusheng_Jin1;~Yu-Ping_Wang1;~Ye_Yuan15;~Guoren_Wang2",
        "aff": "Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;;Beijing Institute of Technology",
        "aff_domain": "bit.edu.cn;bit.edu.cn;bit.edu.cn;bit.edu.cn;;bit.edu.cn",
        "position": "Full Professor;PhD student;Full Professor;Associate Professor;;Full Professor",
        "bibtex": "@inproceedings{\nli2025counting,\ntitle={Counting Cohesive Subgraphs with Hereditary Properties},\nauthor={Rong-Hua Li and Xiaowei Ye and Fusheng Jin and Yu-Ping Wang and Ye Yuan and Guoren Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=eyCzw3pgmq}\n}",
        "github": "",
        "project": "",
        "reviewers": "sT4Q;K7x4;Y9Bb;Z5wp",
        "site": "https://openreview.net/forum?id=eyCzw3pgmq",
        "pdf_size": 0,
        "novelty": "2;5;6;6",
        "technical_quality": "2;4;5;6",
        "scope": "3;3;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.6393596310755
        ],
        "technical_quality_avg": [
            4.25,
            1.479019945774904
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "f2HdZweK2Z",
        "title": "MixedSAND: Semantic Annotation of Mixed-unit Numeric Data",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Quantitative information about entities constitutes a significant portion of tabular data in open sources and data lakes. Tuch tables often lack consistent labeling and proper schema, posing significant challenges for querying and integration. This paper studies the problem of numerical column annotation in scenarios where quantitative data may be gathered from different sources and unit consistency is a concern. For instance, weight measurements may vary between entities, expressed in kilograms for some and pounds for others, with no accompanying unit information. We investigate the conditions for effectively annotating mixed-unit numeric data, introduce a benchmark for such an annotation task, and propose an algorithm that reliably detects semantic types (e.g., height) and links them to the corresponding types present in a knowledge graph. Our evaluation on a diverse set of columns with mixed units and varying levels of annotation difficulty shows that our method significantly outperforms strong baselines such as GPT-4o-mini and SAND in terms of accuracy, excelling in both detecting mixed units and annotating them with appropriate semantic labels. All our code and data will be publicly released upon acceptance of the paper.",
        "keywords": "Semantic annotation;tabular data;web data annotation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Amir Behrad Khorram Nazari;Davood Rafiei;Mario A. Nascimento",
        "authorids": "~Amir_Behrad_Khorram_Nazari1;~Davood_Rafiei2;~Mario_A._Nascimento2",
        "gender": "M;M;M",
        "homepage": ";https://webdocs.cs.ualberta.ca/~drafiei/;https://mnascimento.sites.northeastern.edu/",
        "dblp": ";r/DRafiei;n/MarioANascimento.html",
        "google_scholar": ";https://scholar.google.com.tw/citations?user=lNxSDIwAAAAJ;https://scholar.google.ca/citations?hl=en",
        "orcid": "0009-0008-3287-4964;;",
        "linkedin": ";;",
        "or_profile": "~Amir_Behrad_Khorram_Nazari1;~Davood_Rafiei2;~Mario_A._Nascimento2",
        "aff": ";University of Alberta;Northeastern University",
        "aff_domain": ";ualberta.ca;northeastern.edu",
        "position": ";Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nnazari2025mixedsand,\ntitle={Mixed{SAND}: Semantic Annotation of Mixed-unit Numeric Data},\nauthor={Amir Behrad Khorram Nazari and Davood Rafiei and Mario A. Nascimento},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=f2HdZweK2Z}\n}",
        "github": "",
        "project": "",
        "reviewers": "szUT;3bv7;i77f;JxDx",
        "site": "https://openreview.net/forum?id=f2HdZweK2Z",
        "pdf_size": 0,
        "novelty": "4;5;6;6",
        "technical_quality": "5;6;6;5",
        "scope": "3;3;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.5,
            0.5
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "f4Wb88Z6hQ",
        "title": "Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL) queries in a low-dimensional KG space for complex reasoning over incomplete KGs. To enhance the generalization of KGQE models, recent studies integrate various external information (such as entity types and relation context) to better capture the logical semantics of FOL queries. The whole process is commonly referred to as Query Pattern Learning (QPL). However, current QPL methods typically suffer from the pattern-entity alignment bias problem, leading to the learned defective query patterns limiting KGQE models' performance. To address this problem, we propose an effective Query Instruction Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained Language Models (PLMs) to capture latent query patterns from code-like query instructions. Unlike the external information introduced by previous QPL methods, we first propose code-like instructions to express FOL queries in an alternative format. This format utilizes textual variables and nested tuples to convey the logical semantics within FOL queries, serving as raw materials for a PLM-based instruction encoder to obtain complete query patterns. Building on this, we design a query-guided instruction decoder to adapt query patterns to KGQE models. To further enhance QIPP's effectiveness across various KGQE models, we propose a query pattern injection mechanism based on compressed optimization boundaries and an adaptive normalization component, allowing KGQE models to utilize query patterns more efficiently. Extensive experiments demonstrate that our plug-and-play method improves the performance of eight basic KGQE models and outperforms two state-of-the-art QPL methods.",
        "keywords": "Knowledge Graph;Complex Query Answering;Pre-trained Language Model;Query Pattern Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xingrui Zhuo;Jiapu Wang;Gongqing Wu;Shirui Pan;Xindong Wu",
        "authorids": "~Xingrui_Zhuo1;~Jiapu_Wang1;~Gongqing_Wu1;~Shirui_Pan1;~Xindong_Wu4",
        "gender": ";M;M;;M",
        "homepage": "https://github.com/lazyloafer;;;;https://xwu.zhonghuapu.com/",
        "dblp": ";343/7016;;91/8171;59/4107.html",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;k8YPCRgAAAAJ;oMuwo_EAAAAJ;https://scholar.google.com.au/citations?user=frWRJN4AAAAJ;X8sHmqIAAAAJ",
        "orcid": "0000-0002-8349-3597;0000-0001-7639-5289;;0000-0003-0794-527X;0000-0003-2396-1704",
        "linkedin": ";;;;",
        "or_profile": "~Xingrui_Zhuo1;~Jiapu_Wang1;~Gongqing_Wu1;~Shirui_Pan1;~Xindong_Wu4",
        "aff": "Hefei University of Technology;Beijing University of Technology;;Griffith University;Hefei University of Technology",
        "aff_domain": "hfut.edu.cn;bjut.edu;;griffith.edu.au;hfut.edu.cn",
        "position": "PhD student;PhD student;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhuo2025effective,\ntitle={Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs},\nauthor={Xingrui Zhuo and Jiapu Wang and Gongqing Wu and Shirui Pan and Xindong Wu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=f4Wb88Z6hQ}\n}",
        "github": "",
        "project": "",
        "reviewers": "KZrj;JDZk;cwtW;XSSt;Knr5",
        "site": "https://openreview.net/forum?id=f4Wb88Z6hQ",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "3;5;4;5;5",
        "scope": "4;3;4;3;4",
        "confidence": "4;3;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8451542547285165
    },
    {
        "id": "f5FDfChZRS",
        "title": "LoCal: Logical and Causal Fact-Checking with LLM-Based Multi-Agents",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the development of social media, people are exposed to a vast amount of unverified information, making fact-checking particularly important. Existing fact-checking methods primarily encourage breaking down claims into more easily solvable sub-tasks, and deriving final answers through reasoning with external evidence. However, these models face logical issues regarding whether and how the sub-tasks can logically be combined to form the original claims, and encounter causal errors in the reasoning process due to insufficient evidence or hallucinations from LLMs. In addition, they often suffer from a lack of interpretability. In this paper, we propose  $\\textbf{Lo}$gical and $\\textbf{Ca}$usa$\\textbf{l}$ fact-checking (LoCal), a novel fact-checking framework based on multiple LLM-based agents. The usage of multi-agent systems is due to their increasingly demonstrated ability to perform complex tasks in a manner similar to humans. LoCal primarily consists of a decomposing agent, multiple reasoning agents, and two evaluating agents. Specifically, the decomposing agent first utilizes the in-context learning ability of LLMs to break down complex claims into simpler sub-tasks, including fact verification tasks and question answering tasks. Afterwards, two types of reasoning agents are respectively utilized to  retrieve external knowledge to address the fact verification tasks that requires comparative analysis skills, and the question answering tasks that necessitates the ability of  information extraction from evidence. We then combine the sub-tasks and their corresponding responses to generate a solution for evaluation. In order to enhance logical and causal consistency, two evaluating agents are respectively employed to examine whether the generated solution is logically equivalent to the original claim and determine whether the solution still hold when challenged by the counterfactual label. The evaluating agents provide confidence degrees for the solutions based on the evaluation results and iteratively correct the logical and causal errors in the reasoning process. We evaluate LoCal on two challenging datasets, and the results show that LoCal significantly outperforms all the baseline models across different settings of evidence availability. In addition, LoCal  offers better interpretability by providing a structured solution along with detailed evaluating processes. We believe LoCal will provide valuable insights for future agent-based misinformation detection.",
        "keywords": "Fact-Checking;LLM-Based Agents;Logical and Causal Consistency;Interpretability;Confidence Evaluation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiatong Ma;Linmei Hu;Rang Li;Wenbo Fu",
        "authorids": "~Jiatong_Ma1;~Linmei_Hu1;~Rang_Li1;~Wenbo_Fu1",
        "gender": "M;F;M;M",
        "homepage": "https://jiatong-ma.github.io/;;;https://www.linkedin.com/in/%E6%96%87%E5%8B%83-%E4%BB%98-0b99ab331/?trk=public-profile-join-page",
        "dblp": ";141/4440;;",
        "google_scholar": ";;https://scholar.google.com.hk/citations?user=PiaKMIUAAAAJ;",
        "orcid": ";;;",
        "linkedin": ";;;%E6%96%87%E5%8B%83-%E4%BB%98-0b99ab331/?trk=public-profile-join-page",
        "or_profile": "~Jiatong_Ma1;~Linmei_Hu1;~Rang_Li1;~Wenbo_Fu1",
        "aff": "Institute of Automation, Chinese Academy of Sciences+Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology;Beijing Institute of Technology",
        "aff_domain": "ia.ac.cn+bit.edu.cn;bit.edu.cn;bit.edu.cn;bit.edu.cn",
        "position": "PhD student+Undergrad student;Associate Professor;Undergrad student;Intern",
        "bibtex": "@inproceedings{\nma2025local,\ntitle={LoCal: Logical and Causal Fact-Checking with {LLM}-Based Multi-Agents},\nauthor={Jiatong Ma and Linmei Hu and Rang Li and Wenbo Fu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=f5FDfChZRS}\n}",
        "github": "",
        "project": "",
        "reviewers": "roCQ;vG3S;jNgs;cQ5B;1iPd",
        "site": "https://openreview.net/forum?id=f5FDfChZRS",
        "pdf_size": 0,
        "novelty": "4;5;6;6;6",
        "technical_quality": "4;5;5;5;5",
        "scope": "4;4;4;4;3",
        "confidence": "1;2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.8,
            0.39999999999999997
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8685990362153791
    },
    {
        "id": "fLJnGtFpvf",
        "title": "MISE: Meta-knowledge Inheritance for Social Media-Based Stressor Estimation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Stress haunts people in modern society, which may cause severe health issues if left unattended. With social media becoming an integral part of daily life, leveraging social media to detect stress has gained increasing attention. While the majority of the work focuses on classifying stress states and stress categories, this study introduce a new task aimed at estimating more specific stressors (like exam, writing paper, etc.) through users' posts on social media. Unfortunately, the diversity of stressors with many different classes but a few examples per class, combined with the consistent arising of new stressors over time, hinders the machine understanding of stressors. To this end, we cast the stressor estimation problem within a practical scenario few-shot learning setting, and propose a novel meta-learning based stressor estimation framework that is enhanced by a meta-knowledge inheritance mechanism. This model can not only learn generic stressor context through meta-learning, but also has a good generalization ability to estimate new stressors with little labeled data. A fundamental breakthrough in our approach lies in the inclusion of the meta-knowledge inheritance mechanism, which equips our model with the ability to prevent catastrophic forgetting when adapting to new stressors. The experimental results show that our model achieves state-of-the-art performance compared with the baselines. Additionally, we construct a social media-based stressor estimation dataset that can help train web mining models to facilitate human well-being.",
        "keywords": "stressor estimation;social media;meta-knowledge inheritance",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xin Wang;Ling Feng;Huijun Zhang;Lei Cao;Kaisheng Zeng;Qi Li;Yang Ding;Yi Dai;David A. Clifton",
        "authorids": "~Xin_Wang33;~Ling_Feng1;~Huijun_Zhang1;~Lei_Cao7;~Kaisheng_Zeng1;~Qi_Li20;~Yang_Ding4;~Yi_Dai2;~David_A._Clifton1",
        "gender": ";F;F;;M;;M;M;M",
        "homepage": ";https://www.cs.tsinghua.edu.cn/info/1111/3489.htm;;;https://github.com/alpc43;;;;http://www.eng.ox.ac.uk/chi",
        "dblp": ";58/4464;00/3215;;199/8788.html;;;;89/6424",
        "google_scholar": ";https://scholar.google.com.tw/citations?user=sFFYgzkAAAAJ;Y1E8ZzUAAAAJ;;https://scholar.google.com/citations?view_op=list_works;;;Tc6C26sAAAAJ;",
        "orcid": ";;;;0000-0002-8104-9652;0000-0003-0696-5252;0000-0003-2992-6758;0000-0003-1219-2436;",
        "linkedin": ";;;;https://cn.linkedin.com/in/%E5%BC%80%E8%83%9C-%E6%9B%BE-496566107;;;;",
        "or_profile": "~Xin_Wang33;~Ling_Feng1;~Huijun_Zhang1;~Lei_Cao7;~Kaisheng_Zeng1;~Qi_Li20;~Yang_Ding4;~Yi_Dai2;~David_A._Clifton1",
        "aff": ";Tsinghua University;China Huaneng;;Information Support Force Engineering University;Beijing Normal University;Department of Computer Science and Technology, Tsinghua University;Tsinghua University;University of Oxford",
        "aff_domain": ";tsinghua.edu.cn;chng.com.cn;;nudt.edu.cn;bnu.edu.cn;cs.tsinghua.edu.cn;mails.tsinghua.edu.cn;ox.ac.uk",
        "position": ";Full Professor;Researcher;;Researcher;Instructor;PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nwang2025mise,\ntitle={{MISE}: Meta-knowledge Inheritance for Social Media-Based Stressor Estimation},\nauthor={Xin Wang and Ling Feng and Huijun Zhang and Lei Cao and Kaisheng Zeng and Qi Li and Yang Ding and Yi Dai and David A. Clifton},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=fLJnGtFpvf}\n}",
        "github": "",
        "project": "",
        "reviewers": "2C3W;aBzc;pjkW;QALN",
        "site": "https://openreview.net/forum?id=fLJnGtFpvf",
        "pdf_size": 0,
        "novelty": "3;5;6;6",
        "technical_quality": "3;4;4;5",
        "scope": "3;3;4;4",
        "confidence": "3;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.224744871391589
        ],
        "technical_quality_avg": [
            4.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "fX3UjnmtTt",
        "title": "Graph Self-Supervised Learning with Learnable Structural and Positional Encodings",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We propose a novel framework that addresses a critical limitation in Graph Self-Supervised Learning (GSSL) for graph classification: the underestimation of topological information. Traditional GSSL, despite its success in various benchmarks, often fails to fully leverage the expressive power of Graph Neural Networks (GNNs), particularly in capturing complex structural properties. This limitation stems from two main factors: (1) the inadequacy of conventional GNNs in representing sophisticated topological features, and (2) the focus of self-supervised learning solely on final graph representations. To address these issues, we introduce GenHopNet, a GNN framework that integrates a k-hop message-passing scheme, enhancing its ability to capture local structural information without explicit substructure extraction. We theoretically demonstrate that GenHopNet surpasses the expressiveness of the classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore, we propose a structural- and positional-aware GSSL framework that incorporates topological information throughout the learning process. This approach enables the learning of representations that are both sensitive to graph topology and invariant to specific structural and feature augmentations. Comprehensive experiments on graph classification datasets, including those designed to test structural sensitivity, show that our methods consistently outperform most of the existing approaches in accuracy while maintaining computational efficiency. Our work significantly advances GSSL's capability in distinguishing graphs with similar local structures but different global topologies.",
        "keywords": "Graph Self-Supervised Learning;Graph Neural networks;Expressive Power of GNNs;Graph Classification;Graph Regression",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Asiri Wijesinghe;Hao Zhu;Piotr Koniusz",
        "authorids": "~Asiri_Wijesinghe1;~Hao_Zhu2;~Piotr_Koniusz1",
        "gender": "M;;",
        "homepage": "https://cecs.anu.edu.au/people/asiri-wijesinghe;;https://www.koniusz.com",
        "dblp": "251/5617;;25/8616",
        "google_scholar": "dV4kyHYAAAAJ;;https://scholar.google.co.uk/citations?user=wZ7-1tUAAAAJ",
        "orcid": "0000-0003-4392-5348;;0000-0002-6340-5289",
        "linkedin": "asiriwijesinghe/?originalSubdomain=au;;",
        "or_profile": "~Asiri_Wijesinghe1;~Hao_Zhu2;~Piotr_Koniusz1",
        "aff": "CSIRO;;University of New South Wales+Australian National University+Data61, CSIRO",
        "aff_domain": "data61.csiro.au;;unsw.edu.au+anu.edu.au+data61.csiro.au",
        "position": "Researcher;;Associate Professor+Associate Professor+Principal Researcher",
        "bibtex": "@inproceedings{\nwijesinghe2025graph,\ntitle={Graph Self-Supervised Learning with Learnable Structural and Positional Encodings},\nauthor={Asiri Wijesinghe and Hao Zhu and Piotr Koniusz},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=fX3UjnmtTt}\n}",
        "github": "",
        "project": "",
        "reviewers": "VJTo;PJCs;RwQK;qs4w",
        "site": "https://openreview.net/forum?id=fX3UjnmtTt",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "4;3;5;4",
        "scope": "3;3;4;3",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            4.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "faMbH0wkye",
        "title": "UICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Automating the synthesis of User Interface (UI) plays an important role in enhancing productivity, ensuring design consistency, and\nexpediting the development lifecycle. Recently, the rapid development of Multimodal Large Language Model (MLLM) has made it\npossible to generate front-end Hypertext Markup Language (HTML) code directly from webpage designs. However, real-world web-\npages encompass not only a diverse array of HTML tags but also complex stylesheets, resulting in significantly lengthy code. The\nlengthy code challenges the performance and efficiency of MLLMs, especially in capturing UI\u2019s structure information. To address this\nchallenge, we propose UICopilot, a structure-aware HTML code generation framework from webpage designs via hierarchy code\ngeneration. Our framework introduces a structure model and a code agent, decoupling the generation of the HTML code\u2019s hierarchical\nstructure from its fine-grained details, thereby significantly reducing the model\u2019s burden in producing lengthy code. We evaluate our\nframework on real-world test datasets, and the experimental results demonstrate that it significantly outperforms existing baselines in\nboth automatic metrics and human evaluations. Specifically, statistical analysis reveals that the majority of human annotators prefer\nthe webpages generated by our framework over those produced by GPT-4V.",
        "keywords": "UICopilot;Webpage Synthesis;UI Generation;Code Generation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yi Gui;Yao Wan;Zhen Li;Zhongyi Zhang;Dongping Chen;Hongyu Zhang;Yi Su;Bohua Chen;Xing Zhou;Wenbin Jiang;Xiangliang Zhang",
        "authorids": "~Yi_Gui3;~Yao_Wan2;~Zhen_Li24;~Zhongyi_Zhang4;~Dongping_Chen1;~Hongyu_Zhang1;~Yi_Su8;~Bohua_Chen2;~Xing_Zhou5;~Wenbin_Jiang1;~Xiangliang_Zhang1",
        "gender": "M;M;M;M;M;M;;;M;M;F",
        "homepage": "https://github.com/gystar;http://wanyao.me;https://github.com/LZpenguin;https://starry1001.github.io/;https://dongping-chen.github.io;https://sites.google.com/site/hongyujohn;;;;http://faculty.hust.edu.cn/jiangwenbin/zh_CN/index.htm;https://sites.nd.edu/xiangliang-zhang/",
        "dblp": "311/5499;167/0275.html;74/2397-50;;151/7051;29/2726-2;;;;96/5583-1;74/1890-1",
        "google_scholar": "https://scholar.google.com.hk/citations?user=zImBrG4AAAAJ;c3MtqtMAAAAJ;https://scholar.google.cz/citations?user=YGS6-hEAAAAJ;;;https://scholar.google.com.au/citations?user=zsUN6PkAAAAJ;;;;zImBrG4AAAAJ;BhRJe4wAAAAJ",
        "orcid": "0009-0006-2841-7942;0000-0001-6937-4180;0009-0007-0873-6126;0009-0009-9951-3335;0009-0009-9848-2557;0000-0002-3063-9425;;;0009-0006-4165-7756;0000-0001-5628-8806;0000-0002-3574-5665",
        "linkedin": ";;;zhongyi-zhang-7b527031a;;;;;;;",
        "or_profile": "~Yi_Gui3;~Yao_Wan2;~Zhen_Li24;~Zhongyi_Zhang4;~Dongping_Chen1;~Hongyu_Zhang1;~Yi_Su8;~Bohua_Chen2;~Xing_Zhou5;~Wenbin_Jiang1;~Xiangliang_Zhang1",
        "aff": "Huazhong University of Science and Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology;University of Maryland, College Park+University of Washington+Huazhong University of Science and Technology;Chongqing University;;;Peking University;Huazhong University of Science and Technology;University of Notre Dame",
        "aff_domain": "hust.edu.cn;hust.edu.cn;hust.edu.cn;hust.edu.cn;umd.edu+uw.edu+hust.edu.cn;cqu.edu.cn;;;pku.edu;hust.edu.cn;nd.edu",
        "position": "PhD student;Associate Professor;MS student;Undergrad student;PhD student+Intern+Undergrad student;Full Professor;;;Researcher;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\ngui2025uicopilot,\ntitle={{UIC}opilot: Automating {UI} Synthesis via Hierarchical Code Generation from Webpage Designs},\nauthor={Yi Gui and Yao Wan and Zhen Li and Zhongyi Zhang and Dongping Chen and Hongyu Zhang and Yi Su and Bohua Chen and Xing Zhou and Wenbin Jiang and Xiangliang Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=faMbH0wkye}\n}",
        "github": "",
        "project": "",
        "reviewers": "WJLJ;kthb;qWe9;oMnQ",
        "site": "https://openreview.net/forum?id=faMbH0wkye",
        "pdf_size": 0,
        "novelty": "5;5;5;5",
        "technical_quality": "5;5;4;5",
        "scope": "4;3;4;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.0
        ],
        "technical_quality_avg": [
            4.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            11,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "gQD7kGKHhM",
        "title": "On the Abuse and Detection of Polyglot Files",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "A polyglot is a file that is valid in two or more formats. Polyglot files pose a problem for file-upload and generative AI web interfaces that rely on format identification to determine how to securely handle incoming files. In this work we found that existing file-format and embedded-file detection tools, even those developed specifically for polyglot files, fail to reliably detect polyglot files used in the wild. To address this issue, we studied the use of polyglot files by malicious actors in the wild, finding 30 polyglot samples and 15 attack chains that leveraged polyglot files. Using knowledge from our survey of polyglot usage in the wild\u2014the first of its kind\u2014we created a novel data set based on adversary techniques. We then trained a machine learning detection solution, PolyConv, using this data set. PolyConv achieves a precision-recall area-under-curve score of 0.999 with an F1 score of 99.20% for polyglot detection and 99.47% for file-format identification, significantly outperforming all other tools tested. We developed a content disarmament and reconstruction tool, ImSan, that successfully sanitized 100% of the tested image-based polyglots, which were the most common type found via the survey. Our work provides concrete tools and suggestions to enable defenders to better defend themselves against polyglot files, as well as directions for future work to create more robust file specifications and methods of disarmament.",
        "keywords": "File Format Manipulation;Polyglot Files;Machine Learning;File Format Identification;Content Disarmament and Reconstruction;APT Survey",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Luke Koch;Sean Oesch;Amir Sadovnik;Brian Weber;Amul Chaulagain;Matthew Dixson;Jared Dixon;Mike Huettel;Cory Watson;Jacob Hartman;Richard Patulski",
        "authorids": "~Luke_Koch1;~Sean_Oesch1;~Amir_Sadovnik4;~Brian_Weber1;~Amul_Chaulagain1;~Matthew_Dixson1;~Jared_Dixon1;~Mike_Huettel1;~Cory_Watson1;~Jacob_Hartman2;~Richard_Patulski1",
        "gender": "M;M;M;;M;;;;M;M;",
        "homepage": "https://www.ornl.gov/staff-profile/lucas-r-koch;;https://www.ornl.gov/staff-profile/amir-sadovnik;;;;;https://ornl.gov;;https://j2h2.com;",
        "dblp": ";;;;;;;;;;",
        "google_scholar": "yT48AoMAAAAJ;E7AuXnMAAAAJ;;;;;;;;;",
        "orcid": "0000-0003-2869-8589;;;0000-0002-3261-5152;0000-0003-4402-4234;0009-0005-3996-4848;0000-0001-5320-0581;;;;",
        "linkedin": ";;;;;;;;cory-watson-85786116a/;jacob-hartman-b4516251;https://linkedin.com/in/rich-patulski",
        "or_profile": "~Luke_Koch1;~Sean_Oesch1;~Amir_Sadovnik4;~Brian_Weber1;~Amul_Chaulagain1;~Matthew_Dixson1;~Jared_Dixon1;~Mike_Huettel1;~Cory_Watson1;~Jacob_Hartman2;~Richard_Patulski1",
        "aff": "Oak Ridge National Laboratory;;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;University of Tennessee, Knoxville;;;Assured Information Security;",
        "aff_domain": "ornl.gov;;ornl.gov;ornl.gov;ornl.gov;ornl.gov;utk.edu;;;ainfosec.com;",
        "position": "Counter-AI Researcher;;Senior Research Sceintist;Researcher;Researcher;Researcher;Undergrad student;;;Researcher;",
        "bibtex": "@inproceedings{\nkoch2025on,\ntitle={On the Abuse and Detection of Polyglot Files},\nauthor={Luke Koch and Sean Oesch and Amir Sadovnik and Brian Weber and Amul Chaulagain and Matthew Dixson and Jared Dixon and Mike Huettel and Cory Watson and Jacob Hartman and Richard Patulski},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=gQD7kGKHhM}\n}",
        "github": "",
        "project": "",
        "reviewers": "W3Dy;zYc4;ygpJ;uch5;2vWZ",
        "site": "https://openreview.net/forum?id=gQD7kGKHhM",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "4;5;4;4;6",
        "scope": "4;3;3;4;3",
        "confidence": "3;3;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            11,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4082482904638631
    },
    {
        "id": "gfqM0MyzLn",
        "title": "SEHG: Bridging Interpretability and Prediction in Self-Explainable Heterogeneous Graph Neural Networks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are extensively applied in modeling web-based applications that involve heterogeneous graph structures. Explanation models for HGNNs aim to address their \"black box\" nature. Enhancing the interpretability of HGNNs leads to a better understanding and can potentially improve predictive performance. However, existing post-hoc HGNN explanation methods cannot impact the HGNN's predictions. Self-explainable homogeneous models also perform poorly on heterogeneous graphs.\nTo address these challenges, we present a Self-Explainable Heterogeneous Graph Neural Network (SEHG), a novel architecture that integrates explanation generation into the learning process of HGNN through two alternative stages. The first stage focuses on producing high-quality explanations while providing predictions alongside. The second stage enhances prediction accuracy by a contrastive learning strategy. Unlike the current methods that rely on manually defined metapaths for structural explanations, SEHG generates important structure and feature explanations by learnable heterogeneous masks. To ensure high-quality and sparsity explanation, these masks are regulated by a uniquely designed range-based penalty during training.\nMoreover, we introduce HetBA, a collection of synthetic heterogeneous datasets designed to quantify and visualize explanations or heterogeneous graphs.\nExtensive experiments demonstrate the effectiveness of SEHG, which surpasses strong baselines in real-world node classification tasks by notable margins of up to 3.91%. SEHG also achieves state-of-the-art performance on synthetic datasets with improvement of up to 9.44%, and records the highest fidelity scores in explanation tasks, improving by up to 46.57%. To our knowledge, SEHG is a pioneering self-explainable HGNN framework that achieves state-of-the-art performance on both heterogeneous graph explanation and prediction tasks.",
        "keywords": "Heterogeneous Graph Neural Network;Graph Explanation;Self-Explainable;Graph Self-Supervised Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhenhua Huang;Wenhao Zhou;YuFeng Li;Xiuyang Wu;Chengpei Xu;Junfeng Fang;Zhaohong Jia;Linyuan L\u00fc;Feng Xia",
        "authorids": "~Zhenhua_Huang6;~Wenhao_Zhou5;~YuFeng_Li6;~Xiuyang_Wu1;~Chengpei_Xu1;~Junfeng_Fang1;~Zhaohong_Jia1;~Linyuan_L\u00fc1;~Feng_Xia1",
        "gender": ";M;M;M;;M;F;;M",
        "homepage": ";;https://github.com/simsimpleple;https://xiuyangwu.github.io/;;https://scholar.google.com/citations?user=beNNywsAAAAJ&hl=zh-CN;https://cs.ahu.edu.cn/2022/0224/c20806a280040/page.htm;;http://xia.ai",
        "dblp": ";;;402/7464.html;;340/7929;;;62/3147",
        "google_scholar": ";TXCJ9GQAAAAJ;;https://scholar.google.com.hk/citations?user=i3MNfwsAAAAJ;;beNNywsAAAAJ;;;HDFA2VYAAAAJ",
        "orcid": ";0009-0000-0413-4282;;0009-0009-6687-568X;;0000-0002-3317-2103;;;0000-0002-8324-1859",
        "linkedin": ";;;;;;;;fxia61",
        "or_profile": "~Zhenhua_Huang6;~Wenhao_Zhou5;~YuFeng_Li6;~Xiuyang_Wu1;~Chengpei_Xu1;~Junfeng_Fang1;~Zhaohong_Jia1;~Linyuan_L\u00fc1;~Feng_Xia1",
        "aff": ";Royal Melbourne Institute of Technology;Guangdong University of Technology;Anhui University;;National University of Singapore;Anhui University;;Royal Melbourne Institute of Technology",
        "aff_domain": ";rmit.edu.au;gdut.edu.cn;ahu.edu.cn;;nus.edu.sg;ahu.edu.cn;;rmit.edu.au",
        "position": ";PhD student;Undergrad student;Undergrad student;;Postdoc;Full Professor;;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025sehg,\ntitle={{SEHG}: Bridging Interpretability and Prediction in Self-Explainable Heterogeneous Graph Neural Networks},\nauthor={Zhenhua Huang and Wenhao Zhou and YuFeng Li and Xiuyang Wu and Chengpei Xu and Junfeng Fang and Zhaohong Jia and Linyuan L{\\\"u} and Feng Xia},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=gfqM0MyzLn}\n}",
        "github": "",
        "project": "",
        "reviewers": "Y7bd;ok3g;n9BN;c8t7;bLaz",
        "site": "https://openreview.net/forum?id=gfqM0MyzLn",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "3;4;6;6;5",
        "scope": "4;4;4;3;4",
        "confidence": "4;3;4;1;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.21004201260420147
    },
    {
        "id": "h9fxznhUe3",
        "title": "Dr. Docker: A Large-Scale Security Measurement of Docker Image Ecosystem",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Docker has transformed modern software development, enabling the widespread reuse of containerized applications. Currently, Docker images are primarily distributed through centralized registries, among which Docker Hub is the largest, allowing developers to share and reuse images easily. The threats within these images also spread through the supply chain via dependency relationships, posing risks to anyone using the image and all images built based on it. However, it is unclear to what extent the threats within Docker images are distributed and propagated. \n\nIn this paper, we investigate five potential security risks in three dimensions of Docker image information, including sensitive command parameters, secret leakage, software vulnerabilities, misconfigurations, and malicious files. We propose a security analysis framework DITECTOR based on these security issues. We utilize it to conduct a large-scale security measurement of the Docker image ecosystem. We collect descriptions of over 12 million image repositories from Docker Hub and construct an image dependency graph based on the layer information of the images. We select two sets of influential images for the Docker image ecosystem: high-pull-count images and high-dependency-weight images, totaling 33,952 images for inspection. Our findings are alarming: 93.7% of analyzed images contain known vulnerabilities, 4,437 images have secret leaks, 50 images contain misconfigurations, and 31 images execute malicious files. Furthermore, we identify 334 downstream images affected by malicious images based on the image dependency graph and uncover patterns of attack propagation within the supply chain. We have discussed the measures to mitigate these issues, reported our findings to the relevant parties, and received positive responses.",
        "keywords": "Docker Security;Supply Chain Security;Malware Detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hequan Shi;Lingyun Ying;Libo Chen;Hai-Xin Duan;Ming Liu;Zhi Xue",
        "authorids": "~Hequan_Shi1;~Lingyun_Ying1;~Libo_Chen1;~Hai-Xin_Duan1;~Ming_Liu24;~Zhi_Xue1",
        "gender": "M;M;;;M;",
        "homepage": ";;;;;",
        "dblp": ";18/7667;;;;44/3322",
        "google_scholar": ";;7ikP578AAAAJ;;;",
        "orcid": ";0000-0001-7445-9103;0000-0003-3236-4805;;0009-0006-2658-5678;",
        "linkedin": "%E5%92%8C%E6%9D%83-%E5%8F%B2-313392260/;;;;;",
        "or_profile": "~Hequan_Shi1;~Lingyun_Ying1;~Libo_Chen1;~Hai-Xin_Duan1;~Ming_Liu24;~Zhi_Xue1",
        "aff": "Shanghai Jiaotong University;QI-ANXIN Technology Research Institute;Shanghai Jiaotong University;;;Shanghai  Jiao Tong University",
        "aff_domain": "sjtu.edu.cn;qianxin.com;sjtu.edu.cn;;;sjtu.edu.cn",
        "position": "MS student;Researcher;Associate Professor;;;Full Professor",
        "bibtex": "@inproceedings{\nshi2025dr,\ntitle={Dr. Docker: A Large-Scale Security Measurement of Docker Image Ecosystem},\nauthor={Hequan Shi and Lingyun Ying and Libo Chen and Hai-Xin Duan and Ming Liu and Zhi Xue},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=h9fxznhUe3}\n}",
        "github": "",
        "project": "",
        "reviewers": "BHdC;Jv8d;3ejN;pkob;QfKU",
        "site": "https://openreview.net/forum?id=h9fxznhUe3",
        "pdf_size": 0,
        "novelty": "3;4;4;4;6",
        "technical_quality": "2;6;3;5;6",
        "scope": "3;2;3;4;4",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.4,
            1.624807680927192
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.10206207261596577
    },
    {
        "id": "hGdbYi3hnB",
        "title": "Achieving Personalized Privacy-Preserving Graph Neural Network via Topology Awareness",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph neural networks (GNNs) with differential privacy (DP) offer a reliable solution for safeguarding sensitive information within graph data. Nonetheless, existing DP-based privacy-preserving GNN learning frameworks generally overlook the local topological heterogeneity of graph nodes and tailor the same privacy budget for all nodes, which may lead to either overprotection or underprotection of some nodes, potentially diminishing model utility or posing privacy leakage risks. To address this issue, we propose a Topology-aware Differential Privacy Graph Neural Network learning framework (TDP-GNN), which can achieve personalized privacy protection for each node with improved privacy-utility guarantees. Specifically, TDP-GNN first identifies the topological importance of each node via an adjacency information entropy method. Then, the personalized topology-aware privacy budget is designed to quantify the privacy sensitivity of each node and adaptively allocate the privacy protection strength. Besides, a weighted neighborhood aggregation mechanism is proposed during the message-passing process of GNN training, which can eliminate the impact of the introduced differentiated DP noise on the utility of the GNN model. Since TDP-GNN is based on node-level local DP, it can be seamlessly integrated into any GNN architecture in a plug-and-play manner while ensuring formal privacy guarantees. Theoretical analysis indicates that TDP-GNN achieves $\\epsilon$-differential privacy over the entire graph nodes while providing personalized privacy protection. Extensive experiments demonstrate that TDP-GNN consistently yields better utilities when applied to various GNN architectures (e.g., GCN and GraphSAGE) across a diverse set of benchmarks.",
        "keywords": "Graph Neural Networks; Privacy-Preserving; Differential Privacy; Topology Awareness;",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Dian Lei;Zijun Song;Yanli Yuan;Chunhai Li;Liehuang Zhu",
        "authorids": "~Dian_Lei2;~Zijun_Song1;~Yanli_Yuan3;~Chunhai_Li1;~Liehuang_Zhu1",
        "gender": "M;M;F;M;",
        "homepage": ";https://github.com/e5dese;;https://xueshu.baidu.com/scholarID/CN-BWG9ID6K;",
        "dblp": ";;;;",
        "google_scholar": ";;;;",
        "orcid": "0009-0009-7381-7007;;0000-0003-4592-5333;;",
        "linkedin": ";;;;",
        "or_profile": "~Dian_Lei2;~Zijun_Song1;~Yanli_Yuan3;~Chunhai_Li1;~Liehuang_Zhu1",
        "aff": "Beijing Institute of Technology;Beijing Institute of Technology;;Guilin University Of Electronic Technology;",
        "aff_domain": "bit.edu.cn;bit.edu.cn;;guet.edu.cn;",
        "position": "MS student;MS student;;Researcher;",
        "bibtex": "@inproceedings{\nlei2025achieving,\ntitle={Achieving Personalized Privacy-Preserving Graph Neural Network via Topology Awareness},\nauthor={Dian Lei and Zijun Song and Yanli Yuan and Chunhai Li and Liehuang Zhu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hGdbYi3hnB}\n}",
        "github": "",
        "project": "",
        "reviewers": "K27A;APYS;neFf;Hpos;ULsk",
        "site": "https://openreview.net/forum?id=hGdbYi3hnB",
        "pdf_size": 0,
        "novelty": "3;4;4;4;6",
        "technical_quality": "4;4;5;4;6",
        "scope": "4;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "hI3ZNOyjqk",
        "title": "ESANS: Effective and Semantic-Aware Negative Sampling for Large-Scale Retrieval Systems",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Industrial recommendation systems typically involve a two-stage process: retrieval and ranking, which aims to match users with millions of items. In the retrieval stage, classic embedding-based retrieval (EBR) methods depend on effective negative sampling techniques to enhance both performance and efficiency. However, existing techniques often suffer from false negatives, high cost for sampling quality and semantic information deficiency. To address these limitations, we propose Effective and Semantic-Aware Negative Sampling (ESANS), which integrates two key components: Effective Dense Interpolation Strategy (EDIS) and Multimodal Semantic-Aware Clustering (MSAC). EDIS generates virtual samples within the low-dimensional embedding space to improve the diversity and density of the sampling distribution while minimizing computational costs. MSAC refines the negative sampling distribution by hierarchically clustering item representations based on multimodal information (visual, textual, behavioral), ensuring semantic consistency and reducing false negatives. Extensive offline and online experiments demonstrate the superior efficiency and performance of ESANS.",
        "keywords": "Recommendation systems;Embedding-based retrieval;Negative sampling",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Haibo Xing;MATSUYAMA KANEFUMI;Hao Deng;Jinxin Hu;zhang yu;Xiaoyi Zeng",
        "authorids": "~Haibo_Xing1;~MATSUYAMA_KANEFUMI1;~Hao_Deng7;~Jinxin_Hu1;~zhang_yu6;~Xiaoyi_Zeng1",
        "gender": "M;M;M;;;M",
        "homepage": "https://github.com/GHbetter980;https://github.com/CraKane;;;;http://zengxiaoyi.cn",
        "dblp": ";;;;;",
        "google_scholar": ";;8yDQVG8AAAAJ;;;",
        "orcid": ";0009-0002-1365-5375;;;;0000-0002-3742-4910",
        "linkedin": ";;;hu-jinxin-b1971151/;;",
        "or_profile": "~Haibo_Xing1;~MATSUYAMA_KANEFUMI1;~Hao_Deng7;~Jinxin_Hu1;~zhang_yu6;~Xiaoyi_Zeng1",
        "aff": "Alibaba Group;Alibaba Group;;;;Alibaba Group",
        "aff_domain": "alibaba-inc.com;alibaba-inc.com;;;;alibaba-inc.com",
        "position": "Researcher;Researcher;;;;Principal Researcher",
        "bibtex": "@inproceedings{\nxing2025esans,\ntitle={{ESANS}: Effective and Semantic-Aware Negative Sampling for Large-Scale Retrieval Systems},\nauthor={Haibo Xing and MATSUYAMA KANEFUMI and Hao Deng and Jinxin Hu and zhang yu and Xiaoyi Zeng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hI3ZNOyjqk}\n}",
        "github": "",
        "project": "",
        "reviewers": "EYiv;LSqZ;Gya8;zan8;ao2u",
        "site": "https://openreview.net/forum?id=hI3ZNOyjqk",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "5;4;4;5;5",
        "scope": "4;3;4;4;4",
        "confidence": "2;2;4;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6666666666666665
    },
    {
        "id": "hKxi3KoSO2",
        "title": "Multimodal Knowledge Graph Error Detection with Disentanglement VAE and Multi-Grained Triplet Confidence",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multimodal knowledge graphs inevitably contain numerous errors due to the absence of human supervision in their automated construction and updating processes. These errors can significantly degrade the performance of downstream applications that rely on them. Existing researches on knowledge graph error detection primarily focus on leveraging graph structural and textual information to identify triplet errors in unimodal knowledge graphs. However, unlike unimodal knowledge graphs, multimodal knowledge graphs also suffer from mismatches between images and their corresponding entities, referred to as modality errors. These modality errors not only hinder the performance of downstream applications but also impede our effective utilization of the abundant complementary information provided by the visual modality for detecting triplet errors. To this end, we introduce a novel task of multimodal knowledge graph error detection (MKGED) in this paper, aiming at simultaneously identifying both modality errors and triplet errors. Given the lack of datasets for evaluating this task, we first establish two comprehensive MKGED datasets. Furthermore, we propose a novel framework, KGDMC, to address the MKGED task. Within KGDMC, we devise a disentanglement modality reconstruction (DMR) module for modality error detection. This module disentangles each original modality representation into two disjoint components: modality-specific representations and modality-invariant representations, leveraging the cross-modality reconstruction process to detect mismatched visual modalities. Additionally, for the triplet error detection, we propose a multi-grained triplet confidence (MTC) module, incorporating local triplet confidence, global structure confidence, and global path confidence, to collaboratively detect mismatched triplets. Extensive experiments on our constructed two datasets demonstrate the superiority of our proposed framework.",
        "keywords": "knowledge graph;multimodal information;error detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xuhui Sui;Ying Zhang;Yu Zhao;Baohang Zhou;Xiaojie Yuan",
        "authorids": "~Xuhui_Sui1;~Ying_Zhang7;~Yu_Zhao14;~Baohang_Zhou1;~Xiaojie_Yuan1",
        "gender": ";F;F;M;",
        "homepage": "https://www.linkedin.com/in/%E6%97%AD%E8%BE%89-%E9%9A%8B-0305b334b/;https://dbis.nankai.edu.cn/2023/0322/c12139a506904/page.htm;https://scholar.google.com/citations?user=47fMA2QAAAAJ&hl=en;https://scholar.google.com/citations?user=U_-raXAAAAAJ;https://dbis.nankai.edu.cn/2023/0322/c12139a506919/page.htm",
        "dblp": "321/6900.html;13/6769-15;57/2056-43;284/1471.html;79/2280",
        "google_scholar": ";;47fMA2QAAAAJ;U_-raXAAAAAJ;",
        "orcid": "0000-0001-5386-9912;0000-0003-4906-5828;0000-0002-0326-7152;0000-0002-7577-6204;0000-0002-5876-6856",
        "linkedin": ";;;;",
        "or_profile": "~Xuhui_Sui1;~Ying_Zhang7;~Yu_Zhao14;~Baohang_Zhou1;~Xiaojie_Yuan1",
        "aff": "Nankai University;Nankai University;Nankai University;Tiangong University+Nankai University;Nankai University",
        "aff_domain": "nankai.edu.cn;nankai.edu.cn;nankai.edu.cn;tiangong.edu.cn+nankai.edu.cn;nankai.edu.cn",
        "position": "PhD student;Full Professor;PhD student;Lecturer+PhD student;Full Professor",
        "bibtex": "@inproceedings{\nsui2025multimodal,\ntitle={Multimodal Knowledge Graph Error Detection with Disentanglement {VAE} and Multi-Grained Triplet Confidence},\nauthor={Xuhui Sui and Ying Zhang and Yu Zhao and Baohang Zhou and Xiaojie Yuan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hKxi3KoSO2}\n}",
        "github": "",
        "project": "",
        "reviewers": "w4EQ;eKkb;JEu2;HvNE;yx1Z",
        "site": "https://openreview.net/forum?id=hKxi3KoSO2",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;3;6;6;4",
        "scope": "3;4;4;3;4",
        "confidence": "4;2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            1.2
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.07142857142857142
    },
    {
        "id": "hX5E5nDboC",
        "title": "PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Federated learning (FL) has gained widespread attention for its privacy-preserving and collaborative learning capabilities. Due to significant statistical heterogeneity, traditional FL struggles to generalize a shared model across diverse data domains. Personalized federated learning addresses this issue by dividing the model into a globally shared part and a locally private part, with the local model correcting representation biases introduced by the global model. Nevertheless, locally converged parameters more accurately capture domain-specific knowledge, and current methods overlook the potential benefits of these parameters. To address these limitations, we propose PM-MoE architecture. This architecture integrates a mixture of personalized modules and an energy-based personalized modules denoising, enabling each client to select beneficial personalized parameters from other clients. We applied the PM-MoE architecture to nine recent model-split-based personalized federated learning algorithms, achieving performance improvements with minimal additional training. Extensive experiments on six widely adopted datasets and two heterogeneity settings validate the effectiveness of our approach. The source code is available at \\url{https://anonymous.4open.science/r/PM-MOE-8315}.",
        "keywords": "Personalized Federated Learning; Mixture of Experts; Energy-based denoising",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yu Feng;Yangliao Geng;Yifan Zhu;Zongfu Han;Xie Yu;Kaiwen Xue;Haoran Luo;Mengyang Sun;Guangwei Zhang;Meina Song",
        "authorids": "~Yu_Feng9;~Yangliao_Geng1;~Yifan_Zhu1;~Zongfu_Han1;~Xie_Yu2;~Kaiwen_Xue3;~Haoran_Luo1;~Mengyang_Sun3;~Guangwei_Zhang1;~Meina_Song1",
        "gender": "M;M;M;M;M;M;M;M;M;F",
        "homepage": "https://github.com/dannis97500;;https://zhuyf8899.github.io/;https://github.com/michan325?tab=repositories;https://github.com/BEIJINGOPRA;;https://lhrlab.github.io/;https://dl.acm.org/profile/99659588159;;http://teacher.bupt.edu.cn/songmeina/",
        "dblp": ";190/7083.html;94/1593-1;;323/7908;;227/5902-1.html;;;95/4440",
        "google_scholar": "xSjdDz0AAAAJ;https://scholar.google.com.hk/citations?user=gA0xam0AAAAJ;https://scholar.google.com.hk/citations?user=pAfNfScAAAAJ;;https://scholar.google.com/citations?view_op=list_works;KZtJaE4AAAAJ;MnNISsEAAAAJ;;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0009-0004-2887-9317;0000-0002-0084-5164;0000-0002-7695-1633;;0009-0009-0755-8078;0009-0004-8371-6975;0000-0003-2727-0361;;0000-0003-3164-9921;0000-0001-6626-9932",
        "linkedin": "yu-feng-fy666;;;;;;haoran-luo-88a96b255/;;;",
        "or_profile": "~Yu_Feng9;~Yangliao_Geng1;~Yifan_Zhu1;~Zongfu_Han1;~Xie_Yu2;~Kaiwen_Xue3;~Haoran_Luo1;~Mengyang_Sun3;~Guangwei_Zhang1;~Meina_Song1",
        "aff": "China Mobile Research Institute+Beijing University of Posts and Telecommunications;Beijing Jiaotong University;Beijing University of Posts and Telecommunications;Beijing University of Posts and Telecommunications;Beihang University;Beijing University of Posts and Telecommunications;Beijing University of Posts and Telecommunications+Nanyang Technological University;Tsinghua University;Beijing University of Posts and Telecommunications;Beijing University of Posts and Telecommunications",
        "aff_domain": "chinamobile.com+bupt.edu.cn;bjtu.edu.cn;bupt.edu.cn;bupt.edu.cn;buaa.edu.cn;bupt.edu.cn;bupt.edu.cn+ntu.edu.sg;tsinghua.edu.cn;bupt.edu.cn;bupt.edu.cn",
        "position": "Researcher+PhD student;Assistant Professor;Assistant Professor;Undergrad student;PhD student;PhD student;PhD student+Intern;PhD student;Lecturer;Full Professor",
        "bibtex": "@inproceedings{\nfeng2025pmmoe,\ntitle={{PM}-{MOE}: Mixture of Experts on Private Model Parameters for Personalized Federated Learning},\nauthor={Yu Feng and Yangliao Geng and Yifan Zhu and Zongfu Han and Xie Yu and Kaiwen Xue and Haoran Luo and Mengyang Sun and Guangwei Zhang and Meina Song},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hX5E5nDboC}\n}",
        "github": "",
        "project": "",
        "reviewers": "nBfy;SQcs;BZk8;cdmC;FsrH",
        "site": "https://openreview.net/forum?id=hX5E5nDboC",
        "pdf_size": 0,
        "novelty": "4;5;6;6;6",
        "technical_quality": "4;3;6;6;5",
        "scope": "4;4;1;4;3",
        "confidence": "3;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.2,
            1.16619037896906
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.10206207261596578
    },
    {
        "id": "hcXmL63aOJ",
        "title": "Facing Anomalies Head-On: Network Traffic Anomaly Detection via Uncertainty-Inspired Inter-Sample Differences",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Network traffic anomaly detection is pivotal in cybersecurity, especially as data volume grows and security requirement intensifies. This study addresses critical limitations in existing reconstruction-based methods, which quantify anomalies relying on intra-sample differences and struggle to detect drifted anomalies. In response, we propose a novel approach, the Uncertainty-Inspired Inter-Sample Differences method (UnDiff), which leverages model uncertainty to enhance anomaly detection capabilities, particularly in scenarios involving anomaly drift. By employing evidential learning, the UnDiff model gathers evidence to minimize uncertainty in normal network traffic, enhancing its ability to differentiate between normal and anomalous traffic. To overcome the limitations of intra-sample difference quantification in reconstruction-based methods, we propose a novel anomaly score based on inter-sample uncertainty deviation that directly quantifies the anomaly degree. Benefiting from a concise model design and parameterized uncertainty quantification, UnDiff achieves high efficiency. Extensive experiments on three benchmarks demonstrate UnDiff's superior performance in detecting both undrifted and drifted anomalies with minimal computational overhead. This research contributes to the field of network security by introducing a new uncertainty-based modeling paradigm and a novel uncertainty-inspired anomaly score.",
        "keywords": "Network Traffic Anomaly Detection;Uncertainty Quantification;Drifted Anomaly Detection;Zero-Positive Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinglin Lian;Chengtai Cao;Yan Liu;Xovee Xu;YU ZHENG;Fan Zhou",
        "authorids": "~Xinglin_Lian1;~Chengtai_Cao1;~Yan_Liu39;~Xovee_Xu1;~YU_ZHENG14;~Fan_Zhou11",
        "gender": "M;M;F;M;;M",
        "homepage": ";https://chengtaicao.github.io;;https://www.xoveexu.com;;https://sise.uestc.edu.cn/info/1035/9375.htm",
        "dblp": ";241/6970.html;;261/9309;87/1585-6;63/3122-2",
        "google_scholar": "EHc-tZIAAAAJ;BbsnLQYAAAAJ;;ra0qyRQAAAAJ;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.hk/citations?hl=zh-CN",
        "orcid": "0009-0000-0627-8933;0000-0003-3944-8358;0009-0007-2441-2375;0000-0001-6415-7558;;0000-0002-8038-8150",
        "linkedin": ";;;xovee/;;",
        "or_profile": "~Xinglin_Lian1;~Chengtai_Cao1;~Yan_Liu39;~Xovee_Xu1;~YU_ZHENG14;~Fan_Zhou11",
        "aff": "University of Electronic Science and Technology of China+Xidian University;City University of Hong Kong;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Xidian University;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu+xdu.edu;cityu.edu.hk;uestc.edu.cn;uestc.edu.cn;xidian.edu.cn;uestc.edu.cn",
        "position": "PhD student+MS student;PhD student;PhD student;PhD student;Lecturer;Full Professor",
        "bibtex": "@inproceedings{\nlian2025facing,\ntitle={Facing Anomalies Head-On: Network Traffic Anomaly Detection via Uncertainty-Inspired Inter-Sample Differences},\nauthor={Xinglin Lian and Chengtai Cao and Yan Liu and Xovee Xu and YU ZHENG and Fan Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hcXmL63aOJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "CB41;MaDh;pgwW;D9zS;t3kv",
        "site": "https://openreview.net/forum?id=hcXmL63aOJ",
        "pdf_size": 0,
        "novelty": "4;4;5;6;7",
        "technical_quality": "3;3;5;4;6",
        "scope": "4;3;3;4;3",
        "confidence": "3;3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.560112033611204
    },
    {
        "id": "hdpDCTCOLB",
        "title": "Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction for Large-Scale Matching",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Two-tower models are widely adopted in the industrial-scale matching stage across a broad range of application domains, such as content recommendations, advertisement systems, and search engines. This model efficiently handles large-scale candidate item screening by separating user and item representations. However, the decoupling network also leads to a neglect of potential information interaction between the user and item representations. Current state-of-the-art (SOTA) approaches include adding a shallow fully connected layer(i.e., COLD), which is limited by performance and can only be used in the ranking stage. For performance considerations, another approach attempts to capture historical positive interaction information from the other tower by regarding them as the input features(i.e., DAT). Later research showed that the gains achieved by this method are still limited because of lacking the guidance on the next user intent. To address the aforementioned challenges, we propose a \"cross-interaction decoupling architecture\" within our matching paradigm. This user-tower architecture leverages a diffusion module to reconstruct the next positive intention representation and employs a mixed-attention module to facilitate comprehensive cross-interaction. During the next positive intention generation, we further enhance the accuracy of its reconstruction by explicitly extracting the temporal drift within user behavior sequences. Experiments on two real-world datasets and one industrial dataset demonstrate that our method outperforms the SOTA two-tower models significantly, and our diffusion approach outperforms other generative models in reconstructing item representations. Please find our open-source code repository at the following link: https://anonymous.4open.science/r/T2Diff_ID296/README.md.",
        "keywords": "Candidate Matching;Diffusion Models;Embedding-based Retrieval",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yihan Wang;Fei Xiong;Zhexin Han;Qi Song;Kaiqiao Zhan;Ben Wang",
        "authorids": "~Yihan_Wang6;~Fei_Xiong6;~Zhexin_Han2;~Qi_Song7;~Kaiqiao_Zhan1;~Ben_Wang4",
        "gender": "M;F;M;;;M",
        "homepage": ";;https://github.com/goodstudy255;https://maimai.cn/profile/detail?dstu=533317;;https://cn.linkedin.com/in/%E7%8A%87-%E7%8E%8B-26315566",
        "dblp": ";;;;;",
        "google_scholar": ";U3sId58AAAAJ;;;7phrAWgAAAAJ;",
        "orcid": "0009-0001-2462-7831;;;;;",
        "linkedin": "yihan-wang-030427190/;;;;;",
        "or_profile": "~Yihan_Wang6;~Fei_Xiong6;~Zhexin_Han2;~Qi_Song7;~Kaiqiao_Zhan1;~Ben_Wang4",
        "aff": "Kuaishou;Meituan;Kuaishou- \u5feb\u624b\u79d1\u6280;kwai inc.;kwai inc.;",
        "aff_domain": "kwai.com;meituan.com;kuaishou.com;kwai.com;kwai.com;",
        "position": "Researcher;Algorithm Engineer;Researcher;Researcher;Researcher;",
        "bibtex": "@inproceedings{\nwang2025unleashing,\ntitle={Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction for Large-Scale Matching},\nauthor={Yihan Wang and Fei Xiong and Zhexin Han and Qi Song and Kaiqiao Zhan and Ben Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hdpDCTCOLB}\n}",
        "github": "",
        "project": "",
        "reviewers": "xuBn;k7LF;Fk75;ByJk;LXC6",
        "site": "https://openreview.net/forum?id=hdpDCTCOLB",
        "pdf_size": 0,
        "novelty": "3;4;6;6;6",
        "technical_quality": "3;4;6;6;6",
        "scope": "3;4;4;4;4",
        "confidence": "3;4;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.2649110640673518
        ],
        "technical_quality_avg": [
            5.0,
            1.2649110640673518
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "hfRLxZuy2c",
        "title": "PerSRV: Personalized Sticker Retrieval with Vision-Language Model",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Instant Messaging is a popular mean for daily communication, allowing users to send text and stickers. As the saying goes, \"a picture is worth a thousand words\", so developing an effective sticker retrieval technique is crucial for enhancing user experience. However, existing sticker retrieval methods rely on labeled data to interpret stickers, and general-purpose Vision-Language Models (VLMs) often struggle to capture the unique semantics of stickers. Additionally, relevant-based sticker retrieval methods lack personalization, creating a gap between diverse user expectations and retrieval results. To address these, we propose the Personalized Sticker Retrieval with Vision-Language Model framework, namely PerSRV, structured into offline calculations and online processing modules. The online retrieval part follows the paradigm of relevant recall and personalized ranking, supported by the offline pre-calculation parts, which are sticker semantic understanding, utility evaluation and personalization modules. Firstly, for sticker-level semantic understanding, we supervised fine-tuned LLaVA-1.5-7B to generate human-like sticker semantics, complemented by textual content extracted from figures and historical interaction queries. Secondly, we investigate three crowd-sourcing metrics for sticker utility evaluation. Thirdly, we cluster style centroids based on users\u2019 historical interactions to achieve personal preference modeling. Finally, we evaluate our proposed PerSRV method on a public sticker retrieval dataset from WeChat, containing 543,098 candidates and 12,568 interactions. Experimental results show that PerSRV significantly outperforms existing methods in multi-modal sticker retrieval. Additionally, our fine-tuned VLM delivers notable improvements in sticker semantic understandings. The code is annoymously available.",
        "keywords": "personalized sticker retrieval;sticker search;vision language model;multi modal;sticker recommendation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chee Heng Er Metilda;Jiayin Wang;Zhiqiang Guo;Weizhi Ma;Min Zhang",
        "authorids": "~Chee_Heng_Er_Metilda1;~Jiayin_Wang2;~Zhiqiang_Guo2;~Weizhi_Ma1;~Min_Zhang15",
        "gender": ";F;;M;F",
        "homepage": ";https://alice1998.github.io;;http://mawz12.github.io;http://www.thuir.cn/group/~mzhang",
        "dblp": ";;;169/1390;83/5342-6",
        "google_scholar": ";;;FO3lHi4AAAAJ;0HtCYQEAAAAJ",
        "orcid": ";0000-0001-8875-1850;;0000-0001-5604-7527;0000-0003-3158-1920",
        "linkedin": "metildachee;;;;",
        "or_profile": "~Chee_Heng_Er_Metilda1;~Jiayin_Wang2;~Zhiqiang_Guo2;~Weizhi_Ma1;~Min_Zhang15",
        "aff": "Tsinghua University;Tsinghua University;;Tsinghua University;Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;mail.tsinghua.edu.cn;;tsinghua.edu.cn;tsinghua.edu.cn",
        "position": "MS student;PhD student;;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nmetilda2025persrv,\ntitle={Per{SRV}: Personalized Sticker Retrieval with Vision-Language Model},\nauthor={Chee Heng Er Metilda and Jiayin Wang and Zhiqiang Guo and Weizhi Ma and Min Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hfRLxZuy2c}\n}",
        "github": "",
        "project": "",
        "reviewers": "jYWt;6R1H;2CG2;9UeM",
        "site": "https://openreview.net/forum?id=hfRLxZuy2c",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "6;3;5;6",
        "scope": "4;3;3;3",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            5.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "hhYYo249sE",
        "title": "Subgraph Federated Unlearning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Subgraph federated learning addresses the challenge of federated learning involving subgraphs stored separately in multiple local systems due to strict privacy regulations. This scenario is prevalent in practical applications such as healthcare, recommendation systems, and financial crime detection, especially in cross-silo scenarios. With the adoption of the \"right to be forgotten,\" the issue of machine unlearning for subgraph federated learning methods has gained significant importance. However, existing studies primarily concentrate on non-structural data scenarios, often ignoring the impact of cross-client nodes and overlooking erasing graph knowledge specific to the target clients. To this end, in this paper, we propose a subgraph federated unlearning framework, ReGEnUnlearn, to erase multiple target clients's contributions. Specifically, we introduce the \\textit{Reinforced Federated Policy Sampler} (RFPS) module, aiming to learn an optimal sampling strategy to for unlearning datasets. By modeling the federated graph sampling environment, the agent can derive an optimal graph sampling strategy to unlearn target clients while preserving model utility selectively. To comprehensively unlearn the target client's graph knowledge, we introduce a tailored \\textit{Parameter-free Graph Prompt Knowledge Distillation} (PGPKD) module, which distills specific graph knowledge from the target clients. The target clients then optimize the designed unlearning loss on the distilled graph, effectively mitigating their contributions. We conduct extensive experiments under diverse federated settings to demonstrate the superiority of the proposed framework over state-of-the-art federated unlearning approaches. Furthermore, the framework exhibits a noteworthy speedup ranging from $3.6\\times$ to $9\\times$ compared to retraining from scratch, while maintaining model utility within the approximate range of 100\\%-102\\%.",
        "keywords": "federated graph learning;machine unleanring",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Fan Liu;Hao Liu",
        "authorids": "~Fan_Liu5;~Hao_Liu17",
        "gender": ";",
        "homepage": "https://luckyfan-cs.github.io/;https://raymondhliu.github.io/",
        "dblp": ";09/3214-26",
        "google_scholar": "https://scholar.google.com/citations?hl=en;",
        "orcid": ";0000-0003-4271-1567",
        "linkedin": ";",
        "or_profile": "~Fan_Liu5;~Hao_Liu17",
        "aff": "Hong Kong University of Science and Technology (Guangzhou);The Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "ust.hk;hkust-gz.edu.cn",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nliu2025subgraph,\ntitle={Subgraph Federated Unlearning},\nauthor={Fan Liu and Hao Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hhYYo249sE}\n}",
        "github": "",
        "project": "",
        "reviewers": "eGe7;CKeP;tCkT;UZa1",
        "site": "https://openreview.net/forum?id=hhYYo249sE",
        "pdf_size": 0,
        "novelty": "3;4;4;5",
        "technical_quality": "2;4;4;5",
        "scope": "3;3;4;4",
        "confidence": "4;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            3.75,
            1.0897247358851685
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4264014327112209
    },
    {
        "id": "hvgN6AeeXt",
        "title": "CROWN: A Novel Approach to Comprehending Users' Preferences for Accurate Personalized News Recommendation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Personalized news recommendation aims to assist users in finding news articles that align with their interests, which plays a pivotal role in mitigating users\u2019 information overload problem. Despite the breakthrough in personalized news recommendation, the following challenges have been rarely explored: (C1) Comprehending manifold intents coupled within a news article, (C2) Differentiating varying post-read preferences of news articles, and (C3) Addressing the cold-start user problem. To tackle these challenges together, we propose a novel personalized news recommendation framework (CROWN) that employs (1) category-guided intent disentanglement for (C1), (2) consistency-based news representation for (C2), and (3) GNN-enhanced hybrid user representation for (C3). Furthermore, we incorporate a category prediction into the training process of CROWN as an auxiliary task for enhancing intent disentanglement. Extensive experiments on two real-world datasets reveal that (1) CROWN outperforms twelve state-of-the-art news recommendation methods and (2) the proposed strategies significantly improve the accuracy of CROWN.",
        "keywords": "Personalized news recommendation;news representation;user modeling;cold-start user problem",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yunyong Ko;Seongeun Ryu;Sang-Wook Kim",
        "authorids": "~Yunyong_Ko1;~Seongeun_Ryu1;~Sang-Wook_Kim1",
        "gender": "M;M;M",
        "homepage": "https://yy-ko.github.io;https://bigdas.hanyang.ac.kr/;https://bigdas.hanyang.ac.kr/",
        "dblp": "178/3557;341/1425;64/5810",
        "google_scholar": "https://scholar.google.co.kr/citations?user=njeSUnIAAAAJ;https://scholar.google.co.kr/citations?user=NNPy-gEAAAAJ;https://scholar.google.co.kr/citations?user=ed2vz_oAAAAJ",
        "orcid": "0000-0003-1283-4697;0000-0003-3618-8896;0000-0002-6345-9084",
        "linkedin": ";;",
        "or_profile": "~Yunyong_Ko1;~Seongeun_Ryu1;~Sang-Wook_Kim1",
        "aff": "Chung-Ang University;;",
        "aff_domain": "cau.ac.kr;;",
        "position": "Assistant Professor;;",
        "bibtex": "@inproceedings{\nko2025crown,\ntitle={{CROWN}: A Novel Approach to Comprehending Users' Preferences for Accurate Personalized News Recommendation},\nauthor={Yunyong Ko and Seongeun Ryu and Sang-Wook Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=hvgN6AeeXt}\n}",
        "github": "",
        "project": "",
        "reviewers": "US8C;nuqt;WxPx;FyTJ;evDx",
        "site": "https://openreview.net/forum?id=hvgN6AeeXt",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "5;5;5;7;5",
        "scope": "4;4;4;4;3",
        "confidence": "3;3;2;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.42257712736425823
    },
    {
        "id": "iAn7rlIfgc",
        "title": "Explainable and Efficient Editing for Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large Language Models (LLMs) possess remarkable capabilities in storing and retrieving vast factual knowledge but often retain outdated or incorrect information from web corpora. While full retraining is costly, locate-and-edit model editing methods offer an feasible alternative. Current methods typically follow a two-stage paradigm: (1) identifying critical layers for knowledge storage and (2) updating their parameters to store new knowledge. However, both of these two phases have their inherent limitations. In stage 1, layers identification is independent of the to-be-updated knowledge, ignoring the varying storage patterns of different knowledge types. Meanwhile, Stage 2 suffers from high computational overhead due to independent gradient descent for each piece of knowledge. To solve these, we propose an Explainable and effiCient model Editing method, termed ECE. Specifically, in Stage 1, ECE integrates the concept of LLMs explainability into the editing process, enabling the adaptive identification of the crucial neurons based on the input knowledge. In Stage 2, ECE clusters similar knowledge based on the explanation results, allowing batch optimization in a single gradient step, significantly reducing time consumption without sacrificing effectiveness. Extensive experiments demonstrate that ECE can achieve superior performance while delivering a 3.27\u00d7 speedup in editing efficiency, showcasing the potential of explainability-driven editing methods for LLMs.",
        "keywords": "Large Language Models;Knowledge Editing;Model Explainability;Question Answering",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tianyu Zhang;Junfeng Fang;Houcheng Jiang;Baolong Bi;Xiang Wang;Xiangnan He",
        "authorids": "~Tianyu_Zhang13;~Junfeng_Fang1;~Houcheng_Jiang1;~Baolong_Bi1;~Xiang_Wang6;~Xiangnan_He1",
        "gender": "M;M;;M;M;M",
        "homepage": "https://github.com/tianyuzhangterry;https://scholar.google.com/citations?user=beNNywsAAAAJ&hl=zh-CN;;https://byronbbl.github.io/;https://github.com/xiangwang1223;http://staff.ustc.edu.cn/~hexn",
        "dblp": ";340/7929;;367/3982;31/2864-10;59/1007",
        "google_scholar": ";beNNywsAAAAJ;;Pdu35PIAAAAJ;https://scholar.google.com.sg/citations?user=HdhaQB0AAAAJ;https://scholar.google.com.sg/citations?user=X45Go24AAAAJ",
        "orcid": ";0000-0002-3317-2103;;0009-0003-4027-1366;0000-0002-6148-6329;0000-0001-8472-7992",
        "linkedin": ";;;;;",
        "or_profile": "~Tianyu_Zhang13;~Junfeng_Fang1;~Houcheng_Jiang1;~Baolong_Bi1;~Xiang_Wang6;~Xiangnan_He1",
        "aff": "University of Science and Technology of China;National University of Singapore;;University of Chinese Academy of Sciences;University of Science and Technology of China;University of Science and Technology of China",
        "aff_domain": "ustc.edu.cn;nus.edu.sg;;ict.ac.cn;ustc.edu.cn;ustc.edu.cn",
        "position": "PhD student;Postdoc;;PhD student;Full Professor;Professor",
        "bibtex": "@inproceedings{\nzhang2025explainable,\ntitle={Explainable and Efficient Editing for Large Language Models},\nauthor={Tianyu Zhang and Junfeng Fang and Houcheng Jiang and Baolong Bi and Xiang Wang and Xiangnan He},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iAn7rlIfgc}\n}",
        "github": "",
        "project": "",
        "reviewers": "GhdP;TS8i;dcSB;MPFq",
        "site": "https://openreview.net/forum?id=iAn7rlIfgc",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "3;2;6;6",
        "scope": "3;3;3;3",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            4.25,
            1.7853571071357126
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "iHaHRqQmN4",
        "title": "Semi-supervised Node Importance Estimation with Informative Distribution Modeling for Uncertainty Regularization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph node importance estimation, a classical problem in network analysis, underpins various web applications. To improve estimation accuracy, previous methods either exploit intrinsic topological characteristics, e.g., graph centrality, or leverage additional information, e.g., data heterogeneity, for node feature enhancement. However, these methods follow the supervised learning setting, overlooking the fact that ground-truth node-importance data are usually partially labeled in practice. In this work, we propose the first semi-supervised node importance estimation framework, i.e., EASING, to improve learning quality for unlabeled data in heterogeneous graphs. Different from previous approaches, EASING explicitly captures uncertainty to reflect the confidence of model predictions. To jointly estimate the importance values and uncertainties, EASING incorporates DJE, a deep encoder-decoder neural architecture. DJE introduces distribution modeling for graph nodes, where the distribution representations are decoded to derive both importance and uncertainty estimates, after encoding the rich heterogeneous graph information. Additionally, DJE facilitates effective pseudo-label generation for the unlabeled data to enrich the training samples. Then based on both labeled and pseudo-labeled data, EASING develops effective semi-supervised heteroscedastic learning with the varying node uncertainty regularization. Extensive experiments on three real-world datasets highlight the superior performance of EASING compared to competing methods and demonstrate the effectiveness of each individual module. Codes are available via https://anonymous.4open.science/r/EASING-2F70/.",
        "keywords": "Node Importance Estimation;Semi-supervised Learning;Heterogeneous Graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yankai Chen;Taotao Wang;Yixiang Fang;Yunyu Xiao",
        "authorids": "~Yankai_Chen2;~Taotao_Wang1;~Yixiang_Fang1;~Yunyu_Xiao1",
        "gender": "M;M;;F",
        "homepage": "https://yankai-chen.github.io/;;;https://vivo.weill.cornell.edu/display/cwid-yux4008",
        "dblp": "96/5327-1;;;",
        "google_scholar": "https://scholar.google.com.hk/citations?user=5ZOi7UAAAAAJ;;;",
        "orcid": "0000-0001-5741-2047;0009-0006-8675-7558;;",
        "linkedin": ";;;",
        "or_profile": "~Yankai_Chen2;~Taotao_Wang1;~Yixiang_Fang1;~Yunyu_Xiao1",
        "aff": "Cornell University;The Chinese University of Hong Kong, Shenzhen;;Weill Cornell Medicine, Cornell University",
        "aff_domain": "cornell.edu;cuhk.edu.cn;;med.cornell.edu",
        "position": "Postdoc;MS student;;Assistant Professor",
        "bibtex": "@inproceedings{\nchen2025semisupervised,\ntitle={Semi-supervised Node Importance Estimation with Informative Distribution Modeling for Uncertainty Regularization},\nauthor={Yankai Chen and Taotao Wang and Yixiang Fang and Yunyu Xiao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iHaHRqQmN4}\n}",
        "github": "",
        "project": "",
        "reviewers": "j1GP;pgDs;DZpe;aYxh",
        "site": "https://openreview.net/forum?id=iHaHRqQmN4",
        "pdf_size": 0,
        "novelty": "5;5;5;5",
        "technical_quality": "4;6;4;5",
        "scope": "4;4;4;3",
        "confidence": "2;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.0
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "iOtb6NpEJW",
        "title": "Efficient and practical approximation algorithms for advertising in content feeds",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Information feeds provided by platforms such as X (formerly Twitter) and TikTok are consumed by users on a daily basis.\nIn this paper, we revisit the native advertising problem in feed, initiated by Ieong et al.\nGiven a sequence of organic items (e.g., videos or posts) relevant to a user's interests or information search,\nthe goal is to design an algorithm that maximizes the reward (e.g., clicks) by placing advertisements\ninterleaved with the organic content under two considerations:\n(1) an advertisement can only be inserted after a relevant content item; (2) the users' attention decays after consuming content or advertisements.\nThese considerations provide a natural model for capturing both the advertisement effectiveness and the user experience.\nIn this paper, we design fast and practical 2-approximation greedy algorithms for the associated optimization problem,\nin contrast to the best-known practical algorithm that only achieves an approximation factor of 4. \nOur algorithms exploit a counter-intuitive structure about the problem, that is, \nwhile top items are seemingly more important due to the decaying attention of the user, \ntaking good care of the bottom items is\nkey for obtaining improved approximation guarantees.\nWe then provide the first comprehensive empirical evaluation on the studied problem, showing the strong empirical performance of our algorithms.",
        "keywords": "Newsfeed Advertising;Ad Allocation;Approximation Algorithms;Matching;Externalities",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Guangyi Zhang;Ilie Sarpe;Aristides Gionis",
        "authorids": "~Guangyi_Zhang1;~Ilie_Sarpe1;~Aristides_Gionis1",
        "gender": "M;M;Not Specified",
        "homepage": "https://www.scholat.com/guangyizhang;https://iliesarpe.github.io/;https://www.kth.se/profile/argioni",
        "dblp": "37/5580-1;283/5567;g/AristidesGionis",
        "google_scholar": "https://scholar.google.fi/citations?user=b91NWS8AAAAJ;qxTMYwwAAAAJ;https://scholar.google.com.tw/citations?user=11JgipcAAAAJ",
        "orcid": "0000-0002-1252-7489;0009-0007-5894-0774;",
        "linkedin": ";;",
        "or_profile": "~Guangyi_Zhang1;~Ilie_Sarpe1;~Aristides_Gionis1",
        "aff": "Shenzhen Technology University;KTH Royal Institute of Technology;KTH Royal Institute of Technology, Stockholm, Sweden",
        "aff_domain": "sztu.edu.cn;kth.se;kth.se",
        "position": "Assistant Professor;Postdoc;Professor",
        "bibtex": "@inproceedings{\nzhang2025efficient,\ntitle={Efficient and practical approximation algorithms for advertising in content feeds},\nauthor={Guangyi Zhang and Ilie Sarpe and Aristides Gionis},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iOtb6NpEJW}\n}",
        "github": "",
        "project": "",
        "reviewers": "KaFD;7oMC;9yBL;msts",
        "site": "https://openreview.net/forum?id=iOtb6NpEJW",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;7;5;6",
        "scope": "3;4;4;4",
        "confidence": "4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            5.25,
            1.479019945774904
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7745966692414834
    },
    {
        "id": "iQEcCo2Mn8",
        "title": "Miresga: Accelerating Layer-7 Load Balancing with Programmable Switches",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As online cloud services expand rapidly, layer-7 load balancing has become indispensable for maintaining service availability and performance. The emergence of programmable switches with both high performance and a certain degree of flexibility has made it possible to apply programmable switches to load balancing. Nevertheless, the meager memory capacity and the relatively sluggish speed of table entry insertion and deletion of programmable switches have severely constrained their performance. \n  \n  To this end, we introduce Miresga, a hybrid and high-performance layer-7 load balancing system by co-designing hardware and software. \n  The core idea of Miresga is to maximize the utilization of hardware and software resources by rationally partitioning the layer-7 load balancing task, thereby improving performance. To achieve this, Miresga offloads the elephant flows, which account for the majority of traffic, to programmable switches that excel at packet processing, and Miresga utilizes general-purpose servers with stronger computational capabilities to parse application layer protocols and apply load balancing rules. To alleviate memory pressure on the programmable switch, Miresga employs a back-end agent to handle memory-intensive tasks, working in conjunction with the programmable switch to complete the offloaded tasks. This design leverages the performance advantages of the programmable switch while avoiding bottlenecks caused by its limited memory and table insertion speed.\n  We implement the Miresga prototype with a 3.2 Tbps Intel Tofino switch and general-purpose servers. The evaluation results show that Miresga achieves $3.9\\times$ throughput and $0.4\\times$ latency compared to software load balancing solutions. Compared to state-of-the-art design employing programmable switches, Miresga achieves almost the same throughput and latency for delivering large objects and $5.0\\times$ throughput and $0.2\\times$ latency when transmitting small objects.",
        "keywords": "Load Balancing;Programmable switches",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaoyi Shi;Lin He;Jiasheng Zhou;Yifan Yang;Ying Liu",
        "authorids": "~Xiaoyi_Shi2;~Lin_He4;~Jiasheng_Zhou2;~Yifan_Yang27;~Ying_Liu6",
        "gender": "M;M;M;M;",
        "homepage": "https://sirius-sxy.github.io/;https://helinhl.github.io/;;;http://insc.tsinghua.edu.cn",
        "dblp": ";;;;91/112-9",
        "google_scholar": ";;;;",
        "orcid": "0009-0007-1799-0820;;0009-0009-5310-3920;0009-0002-6868-1220;",
        "linkedin": ";;;;",
        "or_profile": "~Xiaoyi_Shi2;~Lin_He4;~Jiasheng_Zhou2;~Yifan_Yang27;~Ying_Liu6",
        "aff": "Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University",
        "aff_domain": "mails.tsinghua.edu.cn;tsinghua.edu.cn;mails.tsinghua.edu.cn;tsinghua.edu.cn;mail.tsinghua.edu.cn",
        "position": "PhD student;Assistant Professor;MS student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nshi2025miresga,\ntitle={Miresga: Accelerating Layer-7 Load Balancing with Programmable Switches},\nauthor={Xiaoyi Shi and Lin He and Jiasheng Zhou and Yifan Yang and Ying Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iQEcCo2Mn8}\n}",
        "github": "",
        "project": "",
        "reviewers": "gSwr;6Yj5;Guwd;d542;GKSb",
        "site": "https://openreview.net/forum?id=iQEcCo2Mn8",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "3;4;6;5;5",
        "scope": "3;4;4;4;4",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.1961161351381841
    },
    {
        "id": "iRQkdpfW02",
        "title": "MatriXSSed: A New Taxonomy for XSS in the Modern Web",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Cross-site scripting (XSS) constantly remains one of the most prevalent attacks on the Web. In this work, we question its current taxonomy, i.e., the client- or server-side reflected (non-persistent) or stored (persistent) matrix. The Web has extensively changed. Consequently, considering XSS with the lenses of this famous matrix has become at least imprecise, at most impossible for many code injection scenarios where (i) a service worker or an edge worker generates HTTP responses and can reflect or persist XSS payloads infecting not only JavaScript in web pages but also Web assembly, web workers and affecting one or many users automatically; (ii) an attacker sends a web push message directly to a browser push service to trigger code execution in a dormant service worker; or (iii) a cross-origin adversary tampers with code stored by a vulnerable website on the user\u2019s physical/permanent file system, etc. Our proposal \u2013to get out of the matrix and not enter another rigid one\u2013 expresses the essence of XSS as code infection and affection attack, and allows for clearly specifying the different actors and components involved, their environments, contexts and storages, as well as their recurrence and persistence seen as a continuum rather than a binary marker. From a defensive perspective, we showcase the challenges and limitations of current mechanisms at mitigating XSS targetting the entire attack surface of modern websites. Finally, we demonstrate an abuse of the Service-Worker-Allowed header (SWA) to control entire domains with malicious service workers.",
        "keywords": "Cross-site scripting;XSS;security;taxonomy;service workers;edge workers",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Doli\u00e8re Francis Som\u00e9",
        "authorids": "~Doli\u00e8re_Francis_Som\u00e91",
        "gender": "M",
        "homepage": "",
        "dblp": "190/7601",
        "google_scholar": "WP-DnjMAAAAJ",
        "orcid": "0009-0005-3757-2779",
        "linkedin": "",
        "or_profile": "~Doli\u00e8re_Francis_Som\u00e91",
        "aff": "CISPA Helmholtz Center for Information Security",
        "aff_domain": "cispa.de",
        "position": "Researcher",
        "bibtex": "@inproceedings{\nsome2025matrixssed,\ntitle={Matri{XSS}ed: A New Taxonomy for {XSS} in the Modern Web},\nauthor={Doli{\\`e}re Francis Som{\\'e}},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iRQkdpfW02}\n}",
        "github": "",
        "project": "",
        "reviewers": "naxi;xbXc;LHXz;GLPB;56Mz",
        "site": "https://openreview.net/forum?id=iRQkdpfW02",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "5;4;4;4;4",
        "scope": "4;4;4;4;4",
        "confidence": "3;2;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            4.2,
            0.39999999999999997
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6875000000000001
    },
    {
        "id": "iY8y25ognv",
        "title": "FedRIR: Rethinking Information Representation in Federated Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Mobile and Web-of-Things (WoT) devices at the network edge generate vast amounts of data for machine learning applications, yet privacy concerns hinder centralized model training. Federated Learning (FL) allows clients (devices) to collaboratively train a shared model coordinated by a central server without transfer private data, but inherent statistical heterogeneity among clients presents challenges, often leading to a dilemma between clients' needs for personalized local models and the server's goal of building a generalized global model. Existing FL methods typically prioritize either global generalization or local personalization, resulting in a trade-off between these two objectives and limiting the full potential of diverse client data. To address this challenge, we propose a novel framework that simultaneously enhances global generalization and local personalization by Rethinking Information Representation in the Federated learning process (FedRIR). Specifically, we introduce Masked Client-Specific Learning (MCSL), which isolates and extracts fine-grained client-specific features tailored to each client's unique data characteristics, thereby enhancing personalization. Concurrently, the Information Distillation Module (IDM) refines the global shared features by filtering out redundant client-specific information, resulting in a purer and more robust global representation that enhances generalization. By integrating the refined global features with the isolated client-specific features, we construct enriched representations that effectively capture both global patterns and local nuances, thereby improving the performance of downstream tasks on the client. Extensive experiments across diverse datasets demonstrate that FedRIR significantly outperforms state-of-the-art FL methods, achieving up to a 3.93% improvement in accuracy while ensuring robustness and stability in heterogeneous environments.",
        "keywords": "Federated Learning;Information Representation;Information Distillation;Masked Representation Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongqiang Huang;Zerui Shao;Ziyuan Yang;Zexin Lu;Yi Zhang",
        "authorids": "~Yongqiang_Huang2;~Zerui_Shao1;~Ziyuan_Yang1;~Zexin_Lu2;~Yi_Zhang46",
        "gender": "M;M;M;;",
        "homepage": "https://tsmotlp.github.io/;;https://zi-yuanyang.github.io/;;http://deepimaging.group/",
        "dblp": "28/5912-3;267/5563;160/1058-1.html;https://dblp.uni-trier.de/pid/00/5607.html;64/6544-18",
        "google_scholar": "VmxnkI8AAAAJ;;2vZsJskAAAAJ;;kCtQkrkAAAAJ",
        "orcid": "0009-0008-2799-4726;0000-0002-4936-031X;0000-0002-0275-4098;0000-0001-5307-145X;",
        "linkedin": ";;;;",
        "or_profile": "~Yongqiang_Huang2;~Zerui_Shao1;~Ziyuan_Yang1;~Zexin_Lu2;~Yi_Zhang46",
        "aff": "Sichuan University;Sichuan University;Sichuan University;Sichuan University;Sichuan University",
        "aff_domain": "scu.edu.cn;scu.edu.cn;scu.edu.cn;scu.edu.cn;scu.edu.cn",
        "position": "PhD student;PhD student;PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025fedrir,\ntitle={Fed{RIR}: Rethinking Information Representation in Federated Learning},\nauthor={Yongqiang Huang and Zerui Shao and Ziyuan Yang and Zexin Lu and Yi Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=iY8y25ognv}\n}",
        "github": "",
        "project": "",
        "reviewers": "gkFz;9MX8;kdp7;MZMK;dAZ6",
        "site": "https://openreview.net/forum?id=iY8y25ognv",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;2;5;5;6",
        "scope": "2;3;2;4;4",
        "confidence": "2;4;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.4,
            1.3564659966250536
        ],
        "scope_avg": [
            3.0,
            0.8944271909999159
        ],
        "confidence_avg": [
            3.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7905694150420947
    },
    {
        "id": "ihhjUvs8Yu",
        "title": "Differentially Private Bayesian Persuasion",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The tension between persuasion and privacy preservation is common in real-world settings. Online platforms should protect the privacy of web users whose data they collect, even as they seek to disclose information about these data (e.g., to  advertisers). Similarly, hospitals may share patient data to attract research investments with the obligation to preserve patients' privacy. To address these issues, we study Bayesian persuasion under differential privacy constraints, where the sender must design an optimal signaling scheme for persuasion while guaranteeing the privacy of each agent's private information in the database. To understand how privacy constraints affect information disclosure, we explore two perspectives within Bayesian persuasion: one views the mechanism as releasing a posterior about the private data, while the other views it as sending an action recommendation. \n\nThe posterior-based formulation leads to privacy-utility tradeoffs, quantifying how the tightness of privacy constraints impacts the sender's optimal utility. For any instance in a common utility function family and a wide range of privacy levels, a significant constant gap in the sender's optimal utility can be found between any two of the three conditions: $\\epsilon$-differential privacy constraint, relaxation $(\\epsilon,\\delta)$-differential privacy constraint, and no privacy constraint. We further geometrically characterize optimal signaling schemes under popular privacy constraints ($\\epsilon$-differential privacy, $(\\epsilon,\\delta)$-differential privacy and R\u00e9nyi differential privacy), which turns out to be equivalent to finding concave hulls in constrained posterior regions. Finally, we develop polynomial-time algorithms for computing optimal differentially private signaling schemes.",
        "keywords": "Bayesian persuasion;Differential privacy;Information design",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuqi Pan;Steven Wu;Haifeng Xu;SHURAN ZHENG",
        "authorids": "~Yuqi_Pan1;~Steven_Wu1;~Haifeng_Xu1;~SHURAN_ZHENG2",
        "gender": "F;;M;",
        "homepage": ";;http://www.haifeng-xu.com/;",
        "dblp": "52/4131.html;;04/1895;",
        "google_scholar": "Kg3H9PsAAAAJ;;nLgg388AAAAJ;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Yuqi_Pan1;~Steven_Wu1;~Haifeng_Xu1;~SHURAN_ZHENG2",
        "aff": "Harvard University;;University of Chicago;",
        "aff_domain": "harvard.edu;;cs.uchicago.edu;",
        "position": "PhD student;;Assistant Professor;",
        "bibtex": "@inproceedings{\npan2025differentially,\ntitle={Differentially Private Bayesian Persuasion},\nauthor={Yuqi Pan and Steven Wu and Haifeng Xu and SHURAN ZHENG},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ihhjUvs8Yu}\n}",
        "github": "",
        "project": "",
        "reviewers": "44SX;icSi;ef3v;KWBa;tM1U",
        "site": "https://openreview.net/forum?id=ihhjUvs8Yu",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "4;7;5;7;6",
        "scope": "3;3;2;3;3",
        "confidence": "2;2;1;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            5.8,
            1.16619037896906
        ],
        "scope_avg": [
            2.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.31008683647302115
    },
    {
        "id": "j7B1HkhSox",
        "title": "P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Network",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In recent years, graph neural networks (GNNs) have been commonly utilized for social recommendation systems. However, real-world scenarios often present challenges related to user privacy and business constraints, inhibiting direct access to valuable social information from other platforms. While many existing methods have tackled matrix factorization-based social recommendations without direct social data access, developing GNN-based federated social recommendation models under similar conditions remains largely unexplored.\nTo address this issue, we propose a novel vertical federated social recommendation method leveraging privacy-preserving two-party graph convolution networks (P4GCN) to enhance recommendation accuracy without requiring direct access to sensitive social information. First, we introduce a Sandwich-Encryption module to ensure comprehensive data privacy during the collaborative computing process. Second, we provide a thorough theoretical analysis of the privacy guarantees, considering the participation of both curious and honest parties. Extensive experiments on four real-world datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy.",
        "keywords": "social recommendation;privacy-preserving;graph neural network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zheng Wang;Wanwan Wang;Yimin Huang;Zhaopeng Peng;Ziqi Yang;Ming Yao;Cheng Wang;Xiaoliang Fan",
        "authorids": "~Zheng_Wang25;~Wanwan_Wang1;~Yimin_Huang3;~Zhaopeng_Peng1;~Ziqi_Yang4;~Ming_Yao2;~Cheng_Wang2;~Xiaoliang_Fan1",
        "gender": "M;F;M;M;;M;M;M",
        "homepage": "https://www.researchgate.net/profile/Zheng_Wang216;;;http://github.com/pzp-dzd;;;https://chwang.xmu.edu.cn/index_en.htm;",
        "dblp": ";217/0197;53/4143;;;13/5350;54/2062-3;06/209",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;;;;;https://scholar.google.com/citations?hl=en;gR7VT-4AAAAJ",
        "orcid": ";;;;;;0000-0001-6075-796X;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Zheng_Wang25;~Wanwan_Wang1;~Yimin_Huang3;~Zhaopeng_Peng1;~Ziqi_Yang4;~Ming_Yao2;~Cheng_Wang2;~Xiaoliang_Fan1",
        "aff": "Xiamen University;InsightOne Tech Co., Ltd.;;Xiamen University;;InsightOne Tech Co., Ltd.;Xiamen University;Xiamen University",
        "aff_domain": "xmu.edu.cn;insightone.cn;;stu.xmu.edu.cn;;insightone.cn;xmu.edu.cn;xmu.edu.cn",
        "position": "PhD student;Researcher;;MS student;;Lecturer;Full Professor;Researcher",
        "bibtex": "@inproceedings{\nwang2025pgcn,\ntitle={P4{GCN}: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Network},\nauthor={Zheng Wang and Wanwan Wang and Yimin Huang and Zhaopeng Peng and Ziqi Yang and Ming Yao and Cheng Wang and Xiaoliang Fan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=j7B1HkhSox}\n}",
        "github": "",
        "project": "",
        "reviewers": "uP2G;P9zZ;5cWb;qn1W;Dd76",
        "site": "https://openreview.net/forum?id=j7B1HkhSox",
        "pdf_size": 0,
        "novelty": "3;3;5;5;5",
        "technical_quality": "3;3;5;3;5",
        "scope": "3;3;4;4;3",
        "confidence": "3;2;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            3.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.16666666666666669
    },
    {
        "id": "jBXq5UIov4",
        "title": "Mask-based Membership Inference Attacks for Retrieval-Augmented Generation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Retrieval-Augmented Generation (RAG) has been an effective approach to mitigate hallucinations in large language models (LLMs) by incorporating up-to-date and domain-specific knowledge. Recently, there has been a trend of storing up-to-date or copyrighted data in RAG knowledge databases instead of using it for LLM training. This practice has raised concerns about Membership Inference Attacks (MIAs), which aim to detect if a specific target document is stored in the RAG system's knowledge database so as to protect the rights of data producers. While research has focused on enhancing the trustworthiness of RAG systems, existing MIAs for RAG systems remain largely insufficient. Previous work either relies solely on the RAG system's judgment or is easily influenced by other documents or the LLM's internal knowledge, which is unreliable and lacks explainability. To address these limitations, we propose a **M**ask-**B**ased Membership Inference **A**ttacks (MBA) framework. Our framework first employs a masking algorithm that effectively masks a certain number of words in the target document. The masked text is then used to prompt the RAG system, and the RAG system is required to predict the mask values. If the target document appears in the knowledge database, the masked text will retrieve the complete target document as context, allowing for accurate mask prediction. Finally, we adopt a simple yet effective threshold-based method to infer the membership of target document by analyzing the accuracy of mask prediction. Our mask-based approach is more document-specific, making the RAG system's generation less susceptible to distractions from other documents or the LLM's internal knowledge. Extensive experiments demonstrate the effectiveness of our approach compared to existing baseline models.",
        "keywords": "Retrieval-Augmented Generation;trustworthy;Membership Inference Attacks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Liu Mingrui;Sixiao Zhang;Cheng Long",
        "authorids": "~Liu_Mingrui1;~Sixiao_Zhang1;~Cheng_Long1",
        "gender": "M;M;M",
        "homepage": "https://mingrui001.github.io/;https://scholar.google.com/citations?user=CaZg72cAAAAJ&hl=en;https://personal.ntu.edu.sg/c.long/index.html",
        "dblp": ";293/6716;58/10813",
        "google_scholar": ";CaZg72cAAAAJ;LybJ7ksAAAAJ",
        "orcid": ";0000-0002-8072-4230;0000-0001-6806-8405",
        "linkedin": ";;",
        "or_profile": "~Liu_Mingrui1;~Sixiao_Zhang1;~Cheng_Long1",
        "aff": "Nanyang Technological University;Nanyang Technological University;",
        "aff_domain": "e.ntu.edu.sg;ntu.edu.sg;",
        "position": "PhD student;PhD student;",
        "bibtex": "@inproceedings{\nmingrui2025maskbased,\ntitle={Mask-based Membership Inference Attacks for Retrieval-Augmented Generation},\nauthor={Liu Mingrui and Sixiao Zhang and Cheng Long},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jBXq5UIov4}\n}",
        "github": "",
        "project": "",
        "reviewers": "LbNY;jkdz;MAdz;gjj5;1YFY",
        "site": "https://openreview.net/forum?id=jBXq5UIov4",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "3;3;5;5;4",
        "scope": "3;2;2;4;3",
        "confidence": "3;3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.0,
            0.8944271909999159
        ],
        "scope_avg": [
            2.8,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "jK6e4DIYah",
        "title": "Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Code Summarization Model (CSM) has been widely used in code production, such as online and web programming for PHP and Javascript. CSMs are essential tools in code production, enhancing software development efficiency and driving innovation in automated code analysis. However, CSMs face risks of exploitation by unauthorized users, particularly in an online environment where CSMs can be easily shared and disseminated. To address these risks, digital watermarks offer a promising solution by embedding imperceptible signatures within the models to assert copyright ownership and track unauthorized usage. Traditional watermarking for CSM copyright protection faces two main challenges: 1) dataset watermarking methods require separate design of triggers and watermark features based on the characteristics of different programming languages, which not only increases the computation complexity but also leads to a lack of generalization, 2) existing watermarks based on code style transformation are easily identifiable by automated detection, demonstrating poor concealment. To tackle these issues, we propose ModMark, a novel model-level digital watermark embedding method. Specifically, by fine-tuning the tokenizer, ModMark achieves cross-language generalization while reducing the complexity of watermark design. Moreover, we employ code noise injection techniques to effectively prevent trigger detection. Experimental results show that our method can achieve 100% watermark verification rate across various programming languages' CSMs, and the concealment and effectiveness of ModMark can also be guaranteed. Our codes and datasets are available at https://anonymous.4open.science/r/ModMark.",
        "keywords": "Backdoor Watermark;Code Summarization Model;Copyright Protection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiale Zhang;Haoxuan Li;Di Wu;Xiaobing Sun;Qinghua Lu;Guodong Long",
        "authorids": "~Jiale_Zhang4;~Haoxuan_Li9;~Di_Wu39;~Xiaobing_Sun3;~Qinghua_Lu1;~Guodong_Long2",
        "gender": "M;;M;;F;M",
        "homepage": ";;https://diwu.work/;https://risame.github.io/sun/;https://people.csiro.au/L/Q/Qinghua-Lu;https://www.uts.edu.au/staff/guodong.long",
        "dblp": ";;52/328-50;;19/9978;34/10089",
        "google_scholar": "kgDmOAUAAAAJ;;https://scholar.google.com.au/citations?user=p-L_yWgAAAAJ;8yYA6FEAAAAJ;;https://scholar.google.com.au/citations?user=Pl8m7hMAAAAJ",
        "orcid": "0000-0002-2143-5666;0009-0003-2950-0666;0000-0002-4753-8161;;;0000-0003-3740-9515",
        "linkedin": ";;di-wu-1a273a22/;;;",
        "or_profile": "~Jiale_Zhang4;~Haoxuan_Li9;~Di_Wu39;~Xiaobing_Sun3;~Qinghua_Lu1;~Guodong_Long2",
        "aff": "Yangzhou University;Yangzhou University;University of Southern Queensland;Yangzhou University;CSIRO+CSIRO+China University of Petroleum;University of Technology Sydney",
        "aff_domain": "yzu.edu.cn;yzu.edu.cn;unisq.edu.au;yzu.edu.cn;csiro.au+csiro.au+upc.edu.cn;uts.edu.au",
        "position": "Associate Professor;MS student;Senior Lecturer;Full Professor;Principal Researcher+Researcher+Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nzhang2025beyond,\ntitle={Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models},\nauthor={Jiale Zhang and Haoxuan Li and Di Wu and Xiaobing Sun and Qinghua Lu and Guodong Long},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jK6e4DIYah}\n}",
        "github": "",
        "project": "",
        "reviewers": "h3Gv;ePdM;KWUu;mNvi;1peD",
        "site": "https://openreview.net/forum?id=jK6e4DIYah",
        "pdf_size": 0,
        "novelty": "4;5;5;6;7",
        "technical_quality": "5;5;5;5;6",
        "scope": "3;3;4;3;3",
        "confidence": "2;2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            5.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.48038446141526137
    },
    {
        "id": "jXPMvjlzyH",
        "title": "MSTI-Plus: Introducing Non-Sarcasm Reference Materials to Enhance Multimodal Sarcasm Target Identification",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Sarcasm is a subtle expression that indicates the incongruity between literal meanings and factual opinions. For multimodal posts in social medias which consist of both images and texts, sarcasm expressions are even more widespread. Recent works have paid attentions to Multimodal Sarcasm Target Identification (MSTI), which focuses on detecting aspect terms of mockery or ridicule as sarcasm targets. However, the current MSTI benchmark only contains annotations on fine-grained sarcasm targets within sarcastic samples. In practice, it will be featured by two major limitations. First, there lack annotations on non-sarcasm aspects to inform deep models to perceive the semantic difference between sarcasm targets and non-sarcasm aspects. As a result, deep models will tend to incorrectly recognize non-sarcasm aspects as sarcasm targets. Second, there lack non-sarcasm samples to inform deep models to  perceive the inherent semantics of sarcasm intentions. Due to the subtle characteristic of sarcasm expressions, models trained with only fine-grained supervision signals cannot thoroughly understand the sarcasm semantics, making the fine-grained task of sarcasm target identification restricted. Motivated by these limitations, this work reconstructs a more comprehensive MSTI benchmark by introducing both fine-grained non-sarcasm aspect annotations for existing sarcasm samples and non-sarcastic samples as non-sarcasm references to enable deep models to clearly perceive the mentioned information during training. Based on the multi-granularity (i.e., both aspect-level and sample-level) non-sarcasm information  introduced into this new benchmark, this work further proposes a pluggable Semantics-aware Sarcasm Target Identification mechanism to enhance sarcasm target identification by modeling the overall semantics of sarcasm intentions via an auxiliary sample-level sarcasm recognition task. By modeling the overall semantics of sarcasm intention, deep models can obtain a more comprehensive understanding on sarcasm semantics, leading to improved performance on fine-grained sarcasm target identification. Extensive experiments are conducted to validate our contribution. Both the dataset and implementation code will be released once the paper is accepted.",
        "keywords": "Multimodal sarcasm target identification;social media analysis;sentiment analysis;multimodal deep learning.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Fengmao Lv;Mengting Xiong;Junlin Fang;Lingli Zhang;Tianze Luo;Weichao Liang;Tianrui Li",
        "authorids": "~Fengmao_Lv1;~Mengting_Xiong1;~Junlin_Fang1;~Lingli_Zhang1;~Tianze_Luo1;~Weichao_Liang1;~Tianrui_Li1",
        "gender": ";;M;F;Not Specified;;M",
        "homepage": ";;https://dblp.org/pid/389/2572;https://orcid.org/0009-0003-7148-353X;https://ltz0120.github.io/;;https://faculty.swjtu.edu.cn/litianrui/en/index.htm",
        "dblp": ";;389/2572;;297/4000;;47/3003",
        "google_scholar": ";;;;XROXNIMAAAAJ;;eLsZxC4AAAAJ",
        "orcid": ";0009-0008-5923-4828;0009-0002-8162-3201;0009-0003-7148-353X;;;0000-0001-7780-104X",
        "linkedin": ";;;;;;",
        "or_profile": "~Fengmao_Lv1;~Mengting_Xiong1;~Junlin_Fang1;~Lingli_Zhang1;~Tianze_Luo1;~Weichao_Liang1;~Tianrui_Li1",
        "aff": ";Southwest Jiaotong University;Southwest Jiaotong University;Southwest Jiaotong University;Nanyang Technological University;;Southwest Jiaotong University",
        "aff_domain": ";swjtu.edu.cn;swjtu.edu.cn;swjtu.edu;ntu.edu.sg;;swjtu.edu.cn",
        "position": ";MS student;MS student;PhD student;PhD student;;Full Professor",
        "bibtex": "@inproceedings{\nlv2025mstiplus,\ntitle={{MSTI}-Plus: Introducing Non-Sarcasm Reference Materials to Enhance Multimodal Sarcasm Target Identification},\nauthor={Fengmao Lv and Mengting Xiong and Junlin Fang and Lingli Zhang and Tianze Luo and Weichao Liang and Tianrui Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jXPMvjlzyH}\n}",
        "github": "",
        "project": "",
        "reviewers": "NMPV;ViRo;Ae8f;ap97",
        "site": "https://openreview.net/forum?id=jXPMvjlzyH",
        "pdf_size": 0,
        "novelty": "3;4;4;6",
        "technical_quality": "3;3;5;6",
        "scope": "3;4;3;3",
        "confidence": "2;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.25,
            1.299038105676658
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3244428422615251
    },
    {
        "id": "jZ3fyP7But",
        "title": "Multi-Platform Autobidding with and without Predictions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the problem of finding the optimal bidding strategy for an advertiser in a multi-platform auction setting. The competition on a platform is captured by a value and a cost function, mapping bidding strategies to value and cost respectively. We assume a diminishing returns property, whereby the marginal cost is increasing in value. The advertiser uses an autobidder that selects a bidding strategy for each platform, aiming to maximize total value subject to budget and return-on-spend constraint. The advertiser\nhas no prior information and learns about the value and cost functions by querying a platform with a specific bidding strategy. Our goal is to design an algorithm that finds the optimal bidding strategy with a small number of queries.\n\nWe first present an algorithm that requires \\(O(m \\log (mn) \\log n)\\) queries, where $m$ is the number of platforms and $n$ is \nthe number of possible bidding strategies in each platform. \nMoreover, we adopt the learning-augmented framework and propose an algorithm that utilizes a (possibly erroneous) prediction of the optimal bidding strategy. We provide a $O(m \\log (m\\eta) \\log \\eta)$ query-complexity bound on our algorithm as a function of the prediction error $\\eta$. This guarantee gracefully degrades to \\(O(m \\log (mn) \\log n)\\). This achieves a ``best-of-both-worlds'' scenario: \\(O(m)\\) queries when given a correct prediction, and \\(O(m \\log (mn) \\log n)\\) even for an arbitrary incorrect prediction.",
        "keywords": "Autobidding;Multi-channel bidding;Algorithm with predictions",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Gagan Aggarwal;Anupam Gupta;Xizhi Tan;Mingfei Zhao",
        "authorids": "~Gagan_Aggarwal1;~Anupam_Gupta2;~Xizhi_Tan1;~Mingfei_Zhao1",
        "gender": "F;M;F;M",
        "homepage": ";https://cs.nyu.edu/~anupamg/;https://xizhitan.github.io/;https://www.cs.yale.edu/homes/zhao-mingfei/",
        "dblp": "75/3847;27/2931;275/3566.html;175/1739",
        "google_scholar": ";QuwaU-8AAAAJ;XcmsNHEAAAAJ;OFxBCzIAAAAJ",
        "orcid": "0009-0003-3296-4891;;;",
        "linkedin": ";;;",
        "or_profile": "~Gagan_Aggarwal1;~Anupam_Gupta2;~Xizhi_Tan1;~Mingfei_Zhao1",
        "aff": "Google Research;New York University;Drexel University;",
        "aff_domain": "research.google.com;cs.nyu.edu;drexel.edu;",
        "position": "Researcher;Full Professor;PhD student;",
        "bibtex": "@inproceedings{\naggarwal2025multiplatform,\ntitle={Multi-Platform Autobidding with and without Predictions},\nauthor={Gagan Aggarwal and Anupam Gupta and Xizhi Tan and Mingfei Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jZ3fyP7But}\n}",
        "github": "",
        "project": "",
        "reviewers": "FGMc;FSzY;zije;9s56;2Ye4",
        "site": "https://openreview.net/forum?id=jZ3fyP7But",
        "pdf_size": 0,
        "novelty": "3;3;3;5;6",
        "technical_quality": "4;3;3;5;6",
        "scope": "3;3;3;3;4",
        "confidence": "2;1;1;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.2649110640673518
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            1.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6454972243679028
    },
    {
        "id": "jiv0Gl6sto",
        "title": "Thematic-LM: a LLM-based Multi-agent System for Large-scale Thematic Analysis",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Thematic analysis (TA) is a widely used qualitative method for identifying underlying meanings within unstructured text. However, TA requires manual processes, which become increasingly labour-intensive and time-consuming as datasets grow. While large language models (LLMs) have been introduced to assist with TA on small-scale datasets, three key limitations hinder their effectiveness on larger datasets. First, current approaches often depend on interactions between an LLM agent and a human coder, a process that becomes challenging with larger datasets. Second, with feedback from the human coder, the LLM tends to mirror the human coder, which provides a narrower viewpoint of the data. Third, existing methods follow a sequential process, where codes are generated for individual samples without recalling or adapting previous codes and associated data, reducing the ability to analyse data holistically. To address these limitations, we propose Thematic-LM, an LLM-based multi-agent system for large-scale computational thematic analysis. Thematic-LM assigns specialised tasks to each agent, such as coding, aggregating codes, and maintaining and updating the codebook. We assign coder agents different identity perspectives to simulate the subjective nature of TA, fostering a more diverse interpretation of the data. We applied Thematic-LM to the Dreaddit dataset and the Reddit climate change dataset to analyse themes related to social media stress and online opinions on climate change. We evaluate the resulting themes based on trustworthiness principles in qualitative research. Our study reveals significant insights, such as assigning different identities to coder agents promotes divergence in codes and themes.",
        "keywords": "Computational Social Science;Thematic Analysis;Large Language Model;Multi-agent System",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Tingrui Qiao;Caroline Walker;Chris W Cunningham;Yun Sing Koh",
        "authorids": "~Tingrui_Qiao1;~Caroline_Walker1;~Chris_W_Cunningham1;~Yun_Sing_Koh2",
        "gender": ";F;M;",
        "homepage": "https://profiles.auckland.ac.nz/ricky-qiao;https://profiles.auckland.ac.nz/caroline-walker;;https://profiles.auckland.ac.nz/y-koh",
        "dblp": ";;;23/1879.html",
        "google_scholar": ";;;0L38IrAAAAAJ",
        "orcid": "0009-0000-8396-673X;0000-0002-9210-7651;0000-0001-7083-9088;0000-0001-7256-4049",
        "linkedin": ";;;yun-sing-koh-a7ba358/",
        "or_profile": "~Tingrui_Qiao1;~Caroline_Walker1;~Chris_W_Cunningham1;~Yun_Sing_Koh2",
        "aff": "University of Auckland;University of Auckland;Massey University;University of Auckland",
        "aff_domain": "aucklanduni.ac.nz;auckland.ac.nz;massey.ac.nz;auckland.ac.nz",
        "position": "PhD student;Researcher;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nqiao2025thematiclm,\ntitle={Thematic-{LM}: a {LLM}-based Multi-agent System for Large-scale Thematic Analysis},\nauthor={Tingrui Qiao and Caroline Walker and Chris W Cunningham and Yun Sing Koh},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jiv0Gl6sto}\n}",
        "github": "",
        "project": "",
        "reviewers": "3Dxs;zUZp;sgn8;Cf24;LU6o",
        "site": "https://openreview.net/forum?id=jiv0Gl6sto",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "3;5;5;4;3",
        "scope": "3;4;4;4;4",
        "confidence": "3;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5345224838248487
    },
    {
        "id": "juwGL2d37N",
        "title": "ETS-MM: A Multi-Modal Social Bot Detection Model Based on Enhanced Textual Semantic Representation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Social bots are becoming increasingly common in social networks, and their activities affect the security and authenticity of social media platforms. Current state-of-the-art social bot detection methods leverage multimodal approaches that analyze various modalities, such as user metadata, text, and social network relationships. However, these methods may not always extract additional dimensions of semantic feature information that could offer a deeper understanding of users' social patterns. To address this issue, we propose ETS-MM, a multimodal detection framework designed to augment multidimensional information from text and extract the semantic feature representation of user text information. We first analyze the user's tweeting behavior based on topic preference and emotion tendency, integrating them into the textual data. Then, we try to extract enhanced semantic representations that reveal the latent relationship between tweeting behavior and tweet content while identifying potential contextual associations and emotional changes. Additionally, to capture the complex interaction between users, we integrate the user's multimodal information, including metadata, textual features, enhanced semantic features, and social network relationships to propagate and aggregate information across various modalities. Experimental results demonstrate that ETS-MM significantly outperforms existing methods across two widely used social bot detection benchmark datasets, validating its effectiveness and superiority.",
        "keywords": "Twitter Bot Detection;Language Model;Large Language Model;Graph Neural Network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wei Li;Jiawen Deng;Jiali You;Yuanyuan He;Yan Zhuang;Fuji Ren",
        "authorids": "~Wei_Li115;~Jiawen_Deng1;~Jiali_You1;~Yuanyuan_He2;~Yan_Zhuang10;~Fuji_Ren2",
        "gender": "F;F;;F;M;M",
        "homepage": ";;https://www.researchgate.net/profile/You-Jiali;;;",
        "dblp": ";;136/5160-2;01/4775-5;;",
        "google_scholar": ";fseN_08AAAAJ;;;DtOl0DkAAAAJ;eyLJ0fMAAAAJ",
        "orcid": "0009-0002-3460-1712;0000-0003-0602-8250;0000-0002-4621-3496;0009-0000-1040-631X;0000-0001-7444-3275;",
        "linkedin": ";;;;;",
        "or_profile": "~Wei_Li115;~Jiawen_Deng1;~Jiali_You1;~Yuanyuan_He2;~Yan_Zhuang10;~Fuji_Ren2",
        "aff": "University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu;uestc.edu;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "position": "PhD student;Lecturer;PhD student;PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nli2025etsmm,\ntitle={{ETS}-{MM}: A Multi-Modal Social Bot Detection Model Based on Enhanced Textual Semantic Representation},\nauthor={Wei Li and Jiawen Deng and Jiali You and Yuanyuan He and Yan Zhuang and Fuji Ren},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=juwGL2d37N}\n}",
        "github": "",
        "project": "",
        "reviewers": "oiMi;6BEr;cZ5y;bHcL",
        "site": "https://openreview.net/forum?id=juwGL2d37N",
        "pdf_size": 0,
        "novelty": "3;4;4;6",
        "technical_quality": "3;5;4;6",
        "scope": "4;4;4;4",
        "confidence": "3;2;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.48420012470625223
    },
    {
        "id": "jvTGwsd5tU",
        "title": "Domain-Informed Negative Sampling Strategies for Dynamic Graph Embedding in Meme Stock-Related Social Networks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Social network platforms like Reddit are increasingly impacting real-world economics. Meme stocks are a recent phenomena where price movements are driven by retail investors organising themselves via social networks. To study the impact of social networks on meme stocks, the first step is to analyse these networks. Going forward, predicting meme stocks' returns would require to predict dynamic interactions first. This is different from conventional link prediction, frequently applied in e.g. recommendation systems. For this task, it is essential to predict more complex interaction dynamics, such as the exact timing and interaction types like loops. These are crucial for linking the network to meme stock price movements. Dynamic graph embedding (DGE) has recently emerged as a promising approach for modeling dynamic graph-structured data. However, current negative sampling strategies, an important component of DGE, are designed for conventional dynamic link prediction and do not capture the specific patterns present in meme stock-related social networks. This limits the training and evaluation of DGE models in analysing such social networks. To overcome this drawback, we propose novel negative sampling strategies based on the analysis of real meme stock-related social networks and financial knowledge. \nOur experiments show that the proposed negative sampling strategy can better evaluate and train DGE models targeted at meme stock-related social networks compared to existing baselines.",
        "keywords": "Dynamic Graph Embedding;Negative Sampling Strategies;Social Network Analysis;Reddit;Wallstreetbets",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yunming Hui;Inez Maria Zwetsloot;Simon Trimborn;Stevan Rudinac",
        "authorids": "~Yunming_Hui1;~Inez_Maria_Zwetsloot1;~Simon_Trimborn1;~Stevan_Rudinac1",
        "gender": "M;F;M;M",
        "homepage": "https://www.uva.nl/en/profile/h/u/y.hui/y.hui.html;https://inezzwetsloot.nl/;https://www.simontrimborn.de/;https://stevanrudinac.com/",
        "dblp": "347/2785;169/7754;;92/7629",
        "google_scholar": ";XlQsiSkAAAAJ;9ddGlWkAAAAJ;https://scholar.google.nl/citations?user=9o9fZfcAAAAJ",
        "orcid": "0009-0004-2908-9042;0000-0002-6144-4188;0000-0003-3745-4164;0000-0003-1904-8736",
        "linkedin": ";;simon-trimborn;",
        "or_profile": "~Yunming_Hui1;~Inez_Maria_Zwetsloot1;~Simon_Trimborn1;~Stevan_Rudinac1",
        "aff": "University of Amsterdam;University of Amsterdam;University of Amsterdam+City University of Hong Kong;University of Amsterdam",
        "aff_domain": "uva.nl;uva.nl;uva.nl+cityu.edu.hk;uva.nl",
        "position": "PhD student;Associate Professor;Assistant Professor+Assistant Professor;Associate Professor",
        "bibtex": "@inproceedings{\nhui2025domaininformed,\ntitle={Domain-Informed Negative Sampling Strategies for Dynamic Graph Embedding in Meme Stock-Related Social Networks},\nauthor={Yunming Hui and Inez Maria Zwetsloot and Simon Trimborn and Stevan Rudinac},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=jvTGwsd5tU}\n}",
        "github": "",
        "project": "",
        "reviewers": "q3ph;T9tF;W7s4;AoU9;MeeD",
        "site": "https://openreview.net/forum?id=jvTGwsd5tU",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;3;6;5;5",
        "scope": "3;4;4;4;4",
        "confidence": "2;3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.49999999999999994
    },
    {
        "id": "k03hiubX3F",
        "title": "On-device Content-based Recommendation with Single-shot Embedding Pruning: A Cooperative Game Perspective",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Content-based Recommender Systems (CRSs) play a crucial role in shaping user experiences in e-commerce, online advertising, and personalized recommendations. However, due to the large amount of categorical features, the embedding tables used in CRS models pose a significant storage bottleneck for real-world deployment, especially on resource-constrained devices. To address this problem, various embedding pruning methods have been proposed, but most existing ones require expensive retraining steps for each target parameter budget, leading to large computational costs. In reality, this computation cost is a major hurdle in real-world applications with diverse storage requirements, such as federated learning and streaming settings. In this paper, we propose SHApley Value-guided Embedding Reduction (Shaver) as our response. With Shaver, we view the problem from a cooperative game perspective, and quantify each embedding parameter's contribution with Shapley values to facilitate contribution-based parameter pruning. To address the inheriently high computation costs of Shapley values, we propose an efficient and unbiased method to estimate Shapley values of a CRS's embedding parameters. Moreover, in the pruning stage, we put forward a field-aware codebook to mitigate the information loss in the traditional zero-out treatment. Through extensive experiments on three real-world datasets, Shaver has demonstrated competitive performance with lightweight recommendation models across various parameter budgets. The source code is available at https://anonymous.4open.science/r/shaver-E808.",
        "keywords": "On-device Recommender Systems;Single-shot Model Compression;Click-through Rate Prediction",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hung Vinh Tran;Tong Chen;Guanhua Ye;Quoc Viet Hung Nguyen;Kai Zheng;Hongzhi Yin",
        "authorids": "~Hung_Vinh_Tran1;~Tong_Chen8;~Guanhua_Ye2;~Quoc_Viet_Hung_Nguyen1;~Kai_Zheng5;~Hongzhi_Yin2",
        "gender": ";M;M;M;M;M",
        "homepage": ";https://itee.uq.edu.au/profile/1253/rocky-chen;https://teacher.bupt.edu.cn/yeguanhua/en/index.htm;https://experts.griffith.edu.au/9203-henry-nguyen/;http://zheng-kai.com/#;https://sites.google.com/view/hongzhi-yin/home",
        "dblp": ";22/1512-5;43/6374;88/302.html;73/3928-1;04/10606.html",
        "google_scholar": ";07cqSMsAAAAJ;-4Sr-CwAAAAJ;ntkO_bEAAAAJ;EM-l50cAAAAJ;JJsBmhYAAAAJ",
        "orcid": ";0000-0001-7269-146X;0000-0002-1683-1875;0000-0002-9687-1315;0000-0002-0217-3998;0000-0003-1395-261X",
        "linkedin": ";;;quoc-viet-hung-nguyen-9304b348/;;",
        "or_profile": "~Hung_Vinh_Tran1;~Tong_Chen8;~Guanhua_Ye2;~Quoc_Viet_Hung_Nguyen1;~Kai_Zheng5;~Hongzhi_Yin2",
        "aff": ";The University of Queensland;Beijing University of Posts and Telecommunications;Griffith University;University of Electronic Science and Technology of China;University of Queensland",
        "aff_domain": ";uq.edu.au;bupt.edu.cn;griffith.edu.au;uestc.edu.cn;uq.edu.au",
        "position": ";Assistant Professor;Associate Professor;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ntran2025ondevice,\ntitle={On-device Content-based Recommendation with Single-shot Embedding Pruning: A Cooperative Game Perspective},\nauthor={Hung Vinh Tran and Tong Chen and Guanhua Ye and Quoc Viet Hung Nguyen and Kai Zheng and Hongzhi Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k03hiubX3F}\n}",
        "github": "",
        "project": "",
        "reviewers": "aGp7;54mF;Sx1Z;73LH",
        "site": "https://openreview.net/forum?id=k03hiubX3F",
        "pdf_size": 0,
        "novelty": "3;6;6;6",
        "technical_quality": "2;6;6;6",
        "scope": "2;3;4;4",
        "confidence": "4;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.25,
            1.299038105676658
        ],
        "technical_quality_avg": [
            5.0,
            1.7320508075688772
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            3.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "k1khdfmYNp",
        "title": "Beyond Single Tabs: A Transformative Few-Shot Approach to Multi-Tab Website Fingerprinting Attacks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Website Fingerprinting (WF) attacks allow passive eavesdroppers to deduce the websites a user visits by analyzing encrypted traffic, threatening user privacy. While current WF attacks achieve high accuracy, they typically assume single-tab browsing, which is unrealistic as users often open multiple tabs, creating mixed traffic. Existing multi-tab WF approaches require large datasets and frequent retraining due to evolving website content, limiting their practicality. In this paper, we introduce Few-shot Multi-tab Website Fingerprinting (FMWF), a novel approach designed to address the limitations of existing multi-tab WF attacks. FMWF directly tackles the challenges of mixed, overlapping traffic traces generated from multi-tab browsing, leveraging two key innovations: (1) an advanced data augmentation technique that synthesizes realistic multi-tab traffic sequences from easily collected single-tab traces, thereby dramatically reducing the need for large-scale real-world traffic data; and (2) a powerful fine-tuning algorithm based on transfer learning that adapts pre-trained models to new, multi-tab environments with minimal additional data. This two-stage framework enables FMWF to capture the complex effectively, overlapping traffic patterns inherent in multi-tab browsing while maintaining a high level of flexibility and significantly lowering computational and data collection burdens. Our experiments, conducted using real traffic traces collected from three widely-used browsers\u2014Microsoft Edge, Google Chrome, and Tor Browser\u2014highlight the superior performance of FMWF in both closed-world and open-world scenarios. Notably, FMWF achieves a minimum 12.3% improvement in accuracy compared to ARES (SP'23), TMWF (CCS'23), and BAPM (ACSAC'21) in the open-world scenario. The code with related datasets is available at https://anonymous.4open.science/r/FMWF-D164.",
        "keywords": "Tor;Multi-tab Website fingerprinting;Few-shot learning;Deep learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenwen Meng;Chuan Ma;Ming Ding;Chunpeng Ge;Yuwen Qian;Tao Xiang",
        "authorids": "~Wenwen_Meng1;~Chuan_Ma1;~Ming_Ding2;~Chunpeng_Ge1;~Yuwen_Qian1;~Tao_Xiang2",
        "gender": ";M;M;M;M;M",
        "homepage": ";https://faculty.cqu.edu.cn/machuan1/zh_CN/index.htm;https://people.csiro.au/D/M/Ming-Ding;;;",
        "dblp": ";87/5241-1.html;48/3462-1;;133/5246;22/4460-1.html",
        "google_scholar": "DUZbedsAAAAJ;tOWxY5sAAAAJ;QuUuw70AAAAJ;RgN3FagAAAAJ;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0001-7819-4544;0000-0002-3690-0321;;;0000-0002-9439-4623",
        "linkedin": ";;drmingding;;;",
        "or_profile": "~Wenwen_Meng1;~Chuan_Ma1;~Ming_Ding2;~Chunpeng_Ge1;~Yuwen_Qian1;~Tao_Xiang2",
        "aff": "Nanjing University of Science and Technology;Chongqing University;University of Technology Sydney+Swinburne University of Technology+CSIRO+CSIRO;Shandong University;Nanjing University of Science and Technology;Chongqing University",
        "aff_domain": "njust.edu;cqu.edu.cn;uts.edu.au+swin.edu.au+csiro.au+csiro.au;sdu.edu.cn;njust.edu.cn;cqu.edu.cn",
        "position": "MS student;Associate Professor;Adjunct Professor+Adjunct Professor+Group Science Lead+Principal Research Scientist;Full Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nmeng2025beyond,\ntitle={Beyond Single Tabs: A Transformative Few-Shot Approach to Multi-Tab Website Fingerprinting Attacks},\nauthor={Wenwen Meng and Chuan Ma and Ming Ding and Chunpeng Ge and Yuwen Qian and Tao Xiang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k1khdfmYNp}\n}",
        "github": "",
        "project": "",
        "reviewers": "SL7b;Dawe;iD8D;fL63",
        "site": "https://openreview.net/forum?id=k1khdfmYNp",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;4;4;3",
        "scope": "3;4;4;4",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            3.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "k4e3Dh2icw",
        "title": "DVIB: Towards Robust Multimodal Recommender Systems via Variational Information Bottleneck Distillation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In multimodal recommender systems (MRS), integrating various modalities helps to model user preferences and item characteristics more accurately, thereby assisting users in discovering items that match their interests. \n Although the introduction of multimodal information offers opportunities for performance improvement, it will increase the risks of inherent noise and information redundancy, posing challenges to the robustness of MRS. \n Many existing methods typically address these two issues separately either by introducing perturbations at the model input for robust training to handle noise or by designing complex network structures to filter out redundant information. In contrast, we propose the DVIB framework to simultaneously address both issues in a simple manner. We found that moving the perturbations from the input layer to the hidden layer, combined with feature self-distillation, can mitigate noise and handle information redundancy without altering the original network architecture. Additionally, we also provide theoretical evidence for the effectiveness of DVIB, demonstrating that the framework not only explicitly enhances the robustness of model training but also implicitly exhibits an information bottleneck effect,  which effectively reduces redundant information during multimodal fusion and improves feature extraction quality. Extensive experiments show that DVIB consistently improves the performance of MRS across different datasets and model settings, and it can complement existing robust training methods, representing a promising new paradigm in MRS. The code and all models will be released online.",
        "keywords": "Multimodal Recommender System;Robust Training;Variational Information Bottleneck;Feature Distillation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenkuan Zhao;Shanshan Zhong;Yifan Liu;Wushao Wen;Jinghui Qin;Mingfu Liang;Zhongzhan Huang",
        "authorids": "~Wenkuan_Zhao1;~Shanshan_Zhong1;~Yifan_Liu39;~Wushao_Wen3;~Jinghui_Qin1;~Mingfu_Liang1;~Zhongzhan_Huang1",
        "gender": "F;;M;M;M;M;M",
        "homepage": ";;;http://sdcs.sysu.edu.cn/content/2524;;https://wuyujack.github.io/;https://dedekinds.github.io/",
        "dblp": ";;;58/5626;228/6607;241/9790;241/9753",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;https://scholar.google.com/citations?hl=en;FSnLWy4AAAAJ;HIQBxXAAAAAJ;_uUUvt4AAAAJ;R-b68CEAAAAJ",
        "orcid": ";;;;0000-0003-0663-199X;0000-0001-6779-2418;",
        "linkedin": ";;;;;;",
        "or_profile": "~Wenkuan_Zhao1;~Shanshan_Zhong1;~Yifan_Liu39;~Wushao_Wen3;~Jinghui_Qin1;~Mingfu_Liang1;~Zhongzhan_Huang1",
        "aff": "SUN YAT-SEN UNIVERSITY;;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Guangdong University of Technology+Guangdong University of Technology;Meta;Bosch+Sun Yat-Sen University",
        "aff_domain": "mail2.sysu.edu.cn;;mail2.sysu.edu.cn;sysu.edu.cn;gdut.edu.cn+gdut.edu.cn;meta.com;bosch.com+sysu.edu.cn",
        "position": "Undergrad student;;Undergrad student;Full Professor;Associate Professor+Lecturer;Research Scientist;Researcher+PhD student",
        "bibtex": "@inproceedings{\nzhao2025dvib,\ntitle={{DVIB}: Towards Robust Multimodal Recommender Systems via Variational Information Bottleneck Distillation},\nauthor={Wenkuan Zhao and Shanshan Zhong and Yifan Liu and Wushao Wen and Jinghui Qin and Mingfu Liang and Zhongzhan Huang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k4e3Dh2icw}\n}",
        "github": "",
        "project": "",
        "reviewers": "Pn1Y;Dahk;Zk5J;2PWX;t5WE",
        "site": "https://openreview.net/forum?id=k4e3Dh2icw",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "4;4;4;4;4",
        "scope": "4;3;4;4;3",
        "confidence": "2;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.0,
            0.0
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.16666666666666663
    },
    {
        "id": "k7CeyvR0dd",
        "title": "Epidemiology-informed Network for Robust Rumor Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The rapid spread of rumors on social media has posed significant challenges to maintaining public trust and information integrity. Since an information cascade process is essentially a propagation tree, recent rumor detection models leverage graph neural networks to additionally capture information propagation patterns, thus outperforming text-only solutions. Given the variations in topics and social impact of the root node, different source information naturally has distinct outreach capabilities, resulting in different heights of propagation trees. This variation, however, impedes the data-driven design of existing graph-based rumor detectors. Given a shallow propagation tree with limited interactions, it is unlikely for graph-based approaches to capture sufficient cascading patterns, questioning their ability to handle less popular news or early detection needs. In contrast, a deep propagation tree is prone to noisy user responses, and this can in turn obfuscate the predictions. In this paper, we propose a novel Epidemiology-informed Network (EIN) that integrates epidemiological knowledge to enhance performance by overcoming data-driven methods\u2019 sensitivity to data quality. Meanwhile, to adapt epidemiology theory to rumor detection, it is expected that each user\u2019s stance toward the source information will be annotated. To bypass the costly and time-consuming human labeling process, we take advantage of large language models to generate stance labels, facilitating optimization objectives for learning epidemiology-informed representations. Our experimental results demonstrate that the proposed EIN not only outperforms state-of-the-art methods on real-world datasets but also exhibits enhanced robustness across varying tree depths.",
        "keywords": "First Principle-guided Machine Learning;Rumor Detection;Graph Representation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wei Jiang;Tong Chen;Xinyi Gao;Wentao Zhang;Lizhen Cui;Hongzhi Yin",
        "authorids": "~Wei_Jiang16;~Tong_Chen8;~Xinyi_Gao1;~Wentao_Zhang1;~Lizhen_Cui1;~Hongzhi_Yin2",
        "gender": "M;M;M;;M;M",
        "homepage": "https://jwwweee.github.io/;https://itee.uq.edu.au/profile/1253/rocky-chen;https://www.researchgate.net/profile/Xinyi-Gao-14;;https://faculty.sdu.edu.cn/cuilizhen/zh_CN/index.htm;https://sites.google.com/view/hongzhi-yin/home",
        "dblp": "21/3839-6.html;22/1512-5;176/6793-1;;;04/10606.html",
        "google_scholar": ";07cqSMsAAAAJ;zCgaJWEAAAAJ;;;JJsBmhYAAAAJ",
        "orcid": "0000-0002-9821-2276;0000-0001-7269-146X;0009-0004-1146-8925;;;0000-0003-1395-261X",
        "linkedin": ";;;;;",
        "or_profile": "~Wei_Jiang16;~Tong_Chen8;~Xinyi_Gao1;~Wentao_Zhang1;~Lizhen_Cui1;~Hongzhi_Yin2",
        "aff": "The University of Queensland;The University of Queensland;The University of Queensland;;Shandong University;University of Queensland",
        "aff_domain": "uq.edu.au;uq.edu.au;uq.edu.au;;sdu.edu.cn;uq.edu.au",
        "position": "PhD student;Assistant Professor;PhD student;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\njiang2025epidemiologyinformed,\ntitle={Epidemiology-informed Network for Robust Rumor Detection},\nauthor={Wei Jiang and Tong Chen and Xinyi Gao and Wentao Zhang and Lizhen Cui and Hongzhi Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k7CeyvR0dd}\n}",
        "github": "",
        "project": "",
        "reviewers": "rr7D;oiNg;tWSs;hRro;BXVP",
        "site": "https://openreview.net/forum?id=k7CeyvR0dd",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;4;6;5;6",
        "scope": "3;4;3;3;4",
        "confidence": "4;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5345224838248488
    },
    {
        "id": "k7G42gLuab",
        "title": "Understanding and Detecting File Knowledge Leakage in GPT App Ecosystem",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "ChatGPT has rapidly evolved from basic natural language processing to handling more complex and specialized tasks. Inspired by the\nsuccess of the mobile app ecosystems, OpenAI enables third-party developers to build applications around ChatGPT, known as GPTs,\nto further expand ChatGPT\u2019s capabilities. A crucial aspect to endow the GPTs with domain-specific capabilities is through developers\nuploading documents containing domain knowledge or application context. These documents, known as file knowledge, often involve\nsensitive information such as business logic that constitutes the developer\u2019s confidential or intellectual property. Nonetheless, the security of file knowledge management and access control mechanisms with GPTs remains an underexplored area.\nIn this work, we present the first comprehensive study on file knowledge leakage within GPTs. We develop GPTs-Filtor, leveraging the unique characteristics of GPTs\u2019 deployment, to conduct in-depth analysis and detection of file knowledge leakage at both user interaction (i.e., prompt) and network transmission levels. Our analysis is featured by automatically driving the interactions with GPTs and dynamically examining network traffic packets in real-time during the process. To evaluate GPTs-Filtor, we built a GPTs dataset by crawling 8,000 of the most popular GPTs across 8 different categories. Our findings in the evaluation reveal that the currently GPTs development and deployment model is largely vulnerable to data leakage. From 1,331 GPTs that involve uploaded file knowledge, GPTs-Filtor detects 618 GPTs with file knowledge leakage, leading to exfiltration of 3,645 file contents that include highly-sensitive data like internal bank audit transaction records. Our work underscores the pressing need for improved security practices in GPTs development and deployment, providing crucial insights for the secure development of this young but rapidly evolving ecosystem.",
        "keywords": "File leakage;testing;web",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chuan Yan;Bowei Guan;Yazhi Li;Mark Huasong Meng;Liuhuo Wan;Guangdong Bai",
        "authorids": "~Chuan_Yan1;~Bowei_Guan1;~Yazhi_Li1;~Mark_Huasong_Meng1;~Liuhuo_Wan1;~Guangdong_Bai1",
        "gender": "M;F;;M;F;",
        "homepage": ";;;https://mark-h-meng.github.io/;;",
        "dblp": ";;;218/5770;;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;;https://scholar.google.com.sg/citations?user=Lcjd0zwAAAAJ;https://scholar.google.com.au/citations?user=4nWdmS4AAAAJ;",
        "orcid": ";0009-0007-1414-8523;;0000-0003-1039-2151;;",
        "linkedin": ";;;;;",
        "or_profile": "~Chuan_Yan1;~Bowei_Guan1;~Yazhi_Li1;~Mark_Huasong_Meng1;~Liuhuo_Wan1;~Guangdong_Bai1",
        "aff": "University of Queensland;The University of Queensland+The University of Queensland;;Technische Universit\u00e4t M\u00fcnchen;University of Queensland;",
        "aff_domain": "uq.edu.au;uq.edu.au+uq.edu.au;;tum.de;uq.edu.au;",
        "position": "PhD student;PhD student+MS student;;Postdoc;PhD student;",
        "bibtex": "@inproceedings{\nyan2025understanding,\ntitle={Understanding and Detecting File Knowledge Leakage in {GPT} App Ecosystem},\nauthor={Chuan Yan and Bowei Guan and Yazhi Li and Mark Huasong Meng and Liuhuo Wan and Guangdong Bai},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k7G42gLuab}\n}",
        "github": "",
        "project": "",
        "reviewers": "xahj;MEA3;3ZHE;PNmg;nxiM",
        "site": "https://openreview.net/forum?id=k7G42gLuab",
        "pdf_size": 0,
        "novelty": "4;4;4;4;6",
        "technical_quality": "3;3;5;4;6",
        "scope": "3;3;4;4;4",
        "confidence": "3;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4082482904638631
    },
    {
        "id": "k9mEkaTKGf",
        "title": "WavePulse: Real-time Content Analytics of Radio Livestreams",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Radio remains a pervasive medium for mass information dissemination, with AM/FM stations reaching more Americans than either smartphone-based social networking or live television. Increasingly, radio broadcasts are also streamed online and accessed over the Internet. We present WavePulse, a framework that records, documents, and analyzes radio content in real-time. While our framework is generally applicable, we showcase the efficacy of WavePulse in a collaborative project with a team of political scientists focusing on the 2024 Presidential Elections. We use WavePulse to monitor livestreams of 396 news radio stations over a period of three months, processing close to 500,000 hours of audio streams. These streams were converted into time-stamped, diarized transcripts and analyzed to track answer key political science questions at both the national and state levels. Our analysis revealed how local issues interacted with national trends, providing insights into information flow. Our results demonstrate WavePulse's efficacy in capturing and analyzing content from radio livestreams sourced from the Web.",
        "keywords": "Web content analytics;Radio Livestreams;Large Language Models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Govind Mittal;Sarthak Gupta;Shruti Wagle;Chirag Chopra;Anthony J DeMattee;Nasir Memon;Mustaque Ahamad;Chinmay Hegde",
        "authorids": "~Govind_Mittal1;~Sarthak_Gupta4;~Shruti_Wagle1;~Chirag_Chopra1;~Anthony_J_DeMattee1;~Nasir_Memon1;~Mustaque_Ahamad1;~Chinmay_Hegde1",
        "gender": "M;M;F;M;M;M;;M",
        "homepage": "https://govindm.me;;https://github.com/shrutz510;;https://www.demattee.com;http://engineering.nyu.edu/people/nasir-memon;;https://chinmayhegde.github.io/",
        "dblp": "242/0556;;;;;89/6419;73/3162.html;39/2056",
        "google_scholar": "JR1C0tcAAAAJ;;bytZdLwAAAAJ;;;https://scholar.google.com.tw/citations?user=Pz0YttAAAAAJ;;eJAV17IAAAAJ",
        "orcid": ";;0000-0002-2700-3725;;0000-0001-7946-7831;;;",
        "linkedin": "https://linkedin.com/in/govindmittal;https://linkedin.com/in/sarthak99;shruti-wagle-3488ab186/;chiragchopra7/;;;;",
        "or_profile": "~Govind_Mittal1;~Sarthak_Gupta4;~Shruti_Wagle1;~Chirag_Chopra1;~Anthony_J_DeMattee1;~Nasir_Memon1;~Mustaque_Ahamad1;~Chinmay_Hegde1",
        "aff": "New York University;New York University;New York University;New York University;The Carter Center;New York University;Georgia Institute of Technology;New York University",
        "aff_domain": "nyu.edu;nyu.edu;nyu.edu;nyu.edu;cartercenter.org;nyu.edu;gatech.edu;nyu.edu",
        "position": "PhD student;MS student;Researcher;MS student;Data Scientist;Full Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nmittal2025wavepulse,\ntitle={WavePulse: Real-time Content Analytics of Radio Livestreams},\nauthor={Govind Mittal and Sarthak Gupta and Shruti Wagle and Chirag Chopra and Anthony J DeMattee and Nasir Memon and Mustaque Ahamad and Chinmay Hegde},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=k9mEkaTKGf}\n}",
        "github": "",
        "project": "",
        "reviewers": "iy1e;6yVa;Jc55;Y9nW;TRMu",
        "site": "https://openreview.net/forum?id=k9mEkaTKGf",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "4;5;4;5;5",
        "scope": "3;3;4;4;3",
        "confidence": "4;3;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2857142857142857
    },
    {
        "id": "kAzqfqsCC5",
        "title": "Large Language Models Empowered Personalized Web Agents",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. \nDespite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g. user profiles and historical Web behaviors) in assisting the understanding of users' personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. \nMoreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. \nBased on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. \nExtensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB. \nWe release code and data at https://anonymous.4open.science/r/PersonalWAB-CDBF/.",
        "keywords": "Personalized Web Agents;Personalization;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hongru Cai;Yongqi Li;Wenjie Wang;Fengbin ZHU;Xiaoyu Shen;Wenjie Li;Tat-Seng Chua",
        "authorids": "~Hongru_Cai1;~Yongqi_Li1;~Wenjie_Wang1;~Fengbin_ZHU1;~Xiaoyu_Shen1;~Wenjie_Li1;~Tat-Seng_Chua2",
        "gender": "M;;M;M;M;F;",
        "homepage": "https://hongrucai.github.io/;;https://wenjiewwj.github.io/;https://fengbinzhu.github.io/;https://eit-nlp.github.io/;https://web.comp.polyu.edu.hk/cswjli/;",
        "dblp": ";;38/1956-7;283/4845.html;;33/3999-2.html;",
        "google_scholar": "Ql8ITXsAAAAJ;;Ma5DtmoAAAAJ;-rxzvfcAAAAJ;BWfPrE4AAAAJ;Rx5swD4AAAAJ;",
        "orcid": ";;0000-0002-5199-1428;0000-0001-6776-2040;0000-0002-0217-2469;0000-0002-7360-8864;",
        "linkedin": "henry-hongrucai;;;fengbin-zhu/;;;",
        "or_profile": "~Hongru_Cai1;~Yongqi_Li1;~Wenjie_Wang1;~Fengbin_ZHU1;~Xiaoyu_Shen1;~Wenjie_Li1;~Tat-Seng_Chua2",
        "aff": "National University of Singapore;;University of Science and Technology of China;National University of Singapore;Amazon;The Hong Kong Polytechnic University;",
        "aff_domain": "u.nus.edu;;ustc.edu.cn;u.nus.edu;amazon.com;comp.polyu.edu.hk;",
        "position": "MS student;;Full Professor;Postdoc;machine learning scientist;Full Professor;",
        "bibtex": "@inproceedings{\ncai2025large,\ntitle={Large Language Models Empowered Personalized Web Agents},\nauthor={Hongru Cai and Yongqi Li and Wenjie Wang and Fengbin ZHU and Xiaoyu Shen and Wenjie Li and Tat-Seng Chua},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=kAzqfqsCC5}\n}",
        "github": "",
        "project": "",
        "reviewers": "wHd3;kao7;ftMS;YhyA;fZDJ",
        "site": "https://openreview.net/forum?id=kAzqfqsCC5",
        "pdf_size": 0,
        "novelty": "3;4;5;6;6",
        "technical_quality": "4;4;5;5;4",
        "scope": "3;3;3;4;4",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.4,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5144957554275266
    },
    {
        "id": "kFO0vRKweC",
        "title": "Reducing Symbiosis Bias Through Better A/B Tests of Recommendation Algorithms",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "It is increasingly common in digital environments to use A/B tests to compare the performance of recommendation algorithms. However, such experiments often violate the stable unit treatment value assumption (SUTVA), particularly SUTVA's \"no hidden treatments\" assumption, due to the shared data between algorithms being compared. This results in a novel form of bias, which we term \"symbiosis bias,\" where the performance of each algorithm is influenced by the training data generated by its competitor. In this paper, we investigate three experimental designs--cluster-randomized, data-diverted, and user-corpus co-diverted experiments--aimed at mitigating symbiosis bias. We present a theoretical model of symbiosis bias and simulate the impact of each design in dynamic recommendation environments. Our results show that while each design reduces symbiosis bias to some extent, they also introduce new challenges, such as reduced training data in data-diverted experiments. We further validate the existence of symbiosis bias using data from a large-scale A/B test conducted on a global recommender system, demonstrating that symbiosis bias affects treatment effect estimates in the field. Our findings provide actionable insights for researchers and practitioners seeking to design experiments that accurately capture algorithmic performance without bias in treatment effect estimates introduced by shared data.",
        "keywords": "Randomized Experiments;SUTVA;Simulations;Experiment Design;Symbiosis Bias;Interference;A/B testing;Recommendation Algorithms",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jennifer Rogers Brennan;Yahu Cong;Yiwei Yu;Lina Lin;Yajun Peng;Changping Meng;Ningren Han;Jean Pouget-Abadie;David Holtz",
        "authorids": "~Jennifer_Rogers_Brennan1;~Yahu_Cong1;~Yiwei_Yu1;~Lina_Lin1;~Yajun_Peng1;~Changping_Meng1;~Ningren_Han2;~Jean_Pouget-Abadie1;~David_Holtz1",
        "gender": "F;M;F;F;M;M;M;;M",
        "homepage": "https://homes.cs.washington.edu/~jrb/;;;;;;https://www.linkedin.com/in/ningrenhan/;https://jean.pouget-abadie.com;https://www.daveholtz.net",
        "dblp": "259/3055;;;;;162/8996;;https://dblp.uni-trier.de/pers/hd/p/Pouget=Abadie:Jean;",
        "google_scholar": ";;;;5HutTpQAAAAJ;;https://scholar.google.com/citations?hl=en;6F3ZIeEAAAAJ;",
        "orcid": ";;;;;;;;",
        "linkedin": ";yahu-cong-b52285297/;yiwei-ivy-yu/;linlina/;;;;;",
        "or_profile": "~Jennifer_Rogers_Brennan1;~Yahu_Cong1;~Yiwei_Yu1;~Lina_Lin1;~Yajun_Peng1;~Changping_Meng1;~Ningren_Han2;~Jean_Pouget-Abadie1;~David_Holtz1",
        "aff": "Google;University of California, Berkeley;University of California, Berkeley;Google;Google;;Google;Harvard University;University of California, Berkeley",
        "aff_domain": "google.com;berkeley.edu;berkeley.edu;google.com;google.com;;google.com;harvard.edu;berkeley.edu",
        "position": "Researcher;PhD student;Undergrad student;Researcher;Researcher;;Researcher;PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nbrennan2025reducing,\ntitle={Reducing Symbiosis Bias Through Better A/B Tests of Recommendation Algorithms},\nauthor={Jennifer Rogers Brennan and Yahu Cong and Yiwei Yu and Lina Lin and Yajun Peng and Changping Meng and Ningren Han and Jean Pouget-Abadie and David Holtz},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=kFO0vRKweC}\n}",
        "github": "",
        "project": "",
        "reviewers": "ojuP;qjbA;g7UN;HbG1",
        "site": "https://openreview.net/forum?id=kFO0vRKweC",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "2;4;5;6",
        "scope": "3;4;4;3",
        "confidence": "3;1;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.25,
            1.479019945774904
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2581988897471611
    },
    {
        "id": "kPj1Touziw",
        "title": "Fully Anonymous Decentralized Identity Supporting Threshold Traceability with Practical Blockchain",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Decentralized identity (DID) holds significant potential for applications in the Web3, such as digital markets and financial systems. Traditional DID paradigms offer a degree of privacy but struggle to prevent the link analysis on user behaviours and repeated public key usage. Anonymity is not fully achieved, as users' real identities or public keys are exposed to the issuing authority, while introducing high public key management complexity. Besides, existing anonymous credential schemes lack effective mechanisms for threshold traceability, not meeting the Web3's distributed governance requirements. In this paper, we propose FADID-TT, a $\\textbf{F}$ully $\\textbf{A}$nonymous $\\textbf{DID}$ system supporting $\\textbf{T}$hreshold $\\textbf{T}$racing with practical blockchain, to tackle the above challenges. Firstly, we propose a distributed identity registration scheme based on secret sharing. A committee composed of distributed issuing authorities is responsible for issuing user's secret key shares and no single entity in the system can obtain a user\u2019s real identity or public key, achieving anonymity to authority. Moreover, we design a $\\textit{fully anonymous}$ DID system combined with anonymous signatures and decentralized anonymous credentials (DAC). A service provider can only use the committee public key to verify a user identity, eliminating the need for user public keys, fully resisting link attacks, and reducing the user public key management complexity from $O(n)$ to $O(1)$. Furthermore, we design a public verifiable $\\textit{threshold tracing}$ mechanism that enables committee members to collaboratively trace the identity of a malicious user without compromising privacy guarantees. FADID-TT realizes publicly verifiable tracing via zero-knowledge proofs. Finally, we give comprehensive security analysis and concrete performance evaluation. In addition to evaluate each part of proposal, we also deploy FADID-TT on two well-known blockchain platforms including Hyperledger Fabric (permissioned) and Ethereum (permissionless) to demonstrate the practical feasibility of FADID-TT.",
        "keywords": "decentralized identity;full anonymity;threshold traceability;blockchain",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yizhong Liu;Zedan Zhao;boyu zhao;Feiang Ran;Xun Lin;Dawei Li;Zhenyu Guan",
        "authorids": "~Yizhong_Liu1;~Zedan_Zhao1;~boyu_zhao2;~Feiang_Ran1;~Xun_Lin1;~Dawei_Li6;~Zhenyu_Guan1",
        "gender": "M;F;M;M;M;M;",
        "homepage": ";https://zdzhao.github.io/;;;;http://cst.buaa.edu.cn/info/1208/3027.htm;",
        "dblp": ";;;;57/88;;121/1665",
        "google_scholar": "8PXwE_MAAAAJ;;;;nHrEsbcAAAAJ;;https://scholar.google.com/citations?hl=zh-TW",
        "orcid": ";0009-0005-9861-301X;0000-0001-9443-7147;0009-0004-7803-008X;0000-0001-8387-4245;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Yizhong_Liu1;~Zedan_Zhao1;~boyu_zhao2;~Feiang_Ran1;~Xun_Lin1;~Dawei_Li6;~Zhenyu_Guan1",
        "aff": "Beihang University;Beihang University;Beihang University;Beihang University;The Chinese University of Hong Kong+Beihang University;Beihang University;Beihang University",
        "aff_domain": "buaa.edu.cn;buaa.edu.cn;buaa.edu.cn;buaa.edu;cuhk.edu.hk+buaa.edu.cn;buaa.edu.cn;buaa.edu.cn",
        "position": "Assistant Professor;MS student;PhD student;Undergrad student;Postdoc+PhD student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025fully,\ntitle={Fully Anonymous Decentralized Identity Supporting Threshold Traceability with Practical Blockchain},\nauthor={Yizhong Liu and Zedan Zhao and boyu zhao and Feiang Ran and Xun Lin and Dawei Li and Zhenyu Guan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=kPj1Touziw}\n}",
        "github": "",
        "project": "",
        "reviewers": "G34r;eRxc;hrfq;dJC2;kxKn",
        "site": "https://openreview.net/forum?id=kPj1Touziw",
        "pdf_size": 0,
        "novelty": "4;4;5;6;6",
        "technical_quality": "4;3;5;6;6",
        "scope": "4;3;3;4;1",
        "confidence": "1;3;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.8944271909999159
        ],
        "technical_quality_avg": [
            4.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.0,
            1.0954451150103321
        ],
        "confidence_avg": [
            2.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "kYTdzHP6Bq",
        "title": "ORFA: Exploring WebAssembly as a Turing Complete Query Language for Web APIs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Web APIs are the primary communication form for Web services, with RESTful design being the predominant paradigm. However, RESTful APIs are typically fixed once defined, causing data under- or over-fetching as they can't meet clients' varying Web service needs. While semantic enriched API query languages like GraphQL mitigates this problem, they still face expressiveness limitations for logical operations such as indirect queries and loop traversals. To address this, we propose ORFA (One Request For All), the first in literature that employs WebAssembly (Wasm) as a Web API query language to achieve complete expressiveness of client requests.\nORFA's key advantage lies in its use of Wasm's Turing completeness to allow clients to compose arbitrary operations within a single request, thus significantly eliminating redundant data transmission and boosting communication efficiency. Technically, ORFA provides a runtime for executing Wasm query programs and incorporates new module splitting strategies and a caching mechanism customized for integrating Wasm into Web API services, which can enable lightweight code transfer and fast request responses. Experimental results on a realistic testbed and popular Web applications show that ORFA effectively reduces latency by 18.4% and network traffic by 24.5% on average, compared to the state-of-the-art GraphQL.",
        "keywords": "WebAssembly;Web API;Query Language;Expressiveness;Runtime",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuhao Gu;Chunyu Chen;Jiangsu Du;Xiaoxi Zhang;Xianwei Zhang",
        "authorids": "~Yuhao_Gu1;~Chunyu_Chen5;~Jiangsu_Du1;~Xiaoxi_Zhang1;~Xianwei_Zhang1",
        "gender": "M;M;M;;M",
        "homepage": "https://yhgu2000.github.io/resume_en/;https://junyussh.github.io;https://dujiangsu.github.io/;;https://xianweiz.github.io",
        "dblp": ";;250/0536;62/5337;",
        "google_scholar": ";;GayKRzEAAAAJ;nyLg3KMAAAAJ;",
        "orcid": "0009-0009-8761-1237;0009-0003-7925-2920;0000-0003-4707-9492;;0000-0003-3507-4299",
        "linkedin": ";;;;",
        "or_profile": "~Yuhao_Gu1;~Chunyu_Chen5;~Jiangsu_Du1;~Xiaoxi_Zhang1;~Xianwei_Zhang1",
        "aff": "SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY;Sun Yat-Sen University;SUN YAT-SEN UNIVERSITY;SUN YAT-SEN UNIVERSITY",
        "aff_domain": "mail2.sysu.edu.cn;sysu.edu.cn;mail.sysu.edu.cn;sysu.edu.cn;sysu.edu.cn",
        "position": "PhD student;MS student;Postdoc;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\ngu2025orfa,\ntitle={{ORFA}: Exploring WebAssembly as a Turing Complete Query Language for Web {API}s},\nauthor={Yuhao Gu and Chunyu Chen and Jiangsu Du and Xiaoxi Zhang and Xianwei Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=kYTdzHP6Bq}\n}",
        "github": "",
        "project": "",
        "reviewers": "TafT;SAau;B3ek;zpe6;yxsX",
        "site": "https://openreview.net/forum?id=kYTdzHP6Bq",
        "pdf_size": 0,
        "novelty": "3;5;5;6;6",
        "technical_quality": "3;4;4;6;3",
        "scope": "4;4;3;3;4",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4564354645876385
    },
    {
        "id": "ktZoMTTF3x",
        "title": "In-Group Love, Out-Group Hate: A Framework to Measure Affective Polarization via Contentious Online Discussions",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Affective polarization, the emotional divide between ideological groups marked by in-group love and out-group hate, has intensified in the United States, driving contentious issues like masking and lockdowns during the COVID-19 pandemic. Despite its societal impact, existing models of opinion change fail to account for emotional dynamics nor offer methods to quantify affective polarization robustly and in real-time. In this paper, we introduce a discrete choice model that captures decision-making within affectively polarized social networks and propose a statistical inference method  estimate key parameters---in-group love and out-group hate---from social media data. Through empirical validation from online discussions about the  COVID-19 pandemic, we demonstrate that our approach accurately captures real-world polarization dynamics and explains the rapid emergence of a partisan gap in attitudes towards masking and lockdowns. This framework allows for tracking affective polarization across  contentious issues has broad implications for fostering constructive online dialogues in digital spaces.",
        "keywords": "Polarization;Twitter;COVID-19;Social Networks;Exposure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Buddhika Nettasinghe;Ashwin Rao;Bohan Jiang;Allon Percus;Kristina Lerman",
        "authorids": "~Buddhika_Nettasinghe1;~Ashwin_Rao2;~Bohan_Jiang2;~Allon_Percus1;~Kristina_Lerman1",
        "gender": ";;M;M;F",
        "homepage": "https://tippie.uiowa.edu/people/buddhika-nettasinghe;;https://jiangbohan.github.io/;https://scholar.cgu.edu/allon-percus/;http://www.isi.edu/~lerman/",
        "dblp": ";;240/6257.html;55/1416;99/433",
        "google_scholar": ";QovGNgYAAAAJ;Wu6doL0AAAAJ;;",
        "orcid": ";;0000-0001-8552-2681;0000-0002-0847-5284;0000-0002-5071-0575",
        "linkedin": ";;;;",
        "or_profile": "~Buddhika_Nettasinghe1;~Ashwin_Rao2;~Bohan_Jiang2;~Allon_Percus1;~Kristina_Lerman1",
        "aff": ";University of Southern California;Arizona State University;Claremont Graduate University;University of Southern California+USC Information Sciences Institute",
        "aff_domain": ";usc.edu;asu.edu;cgu.edu;usc.edu+isi.edu",
        "position": ";PhD student;PhD student;Full Professor;Full Professor+Principal Researcher",
        "bibtex": "@inproceedings{\nnettasinghe2025ingroup,\ntitle={In-Group Love, Out-Group Hate: A Framework to Measure Affective Polarization via Contentious Online Discussions},\nauthor={Buddhika Nettasinghe and Ashwin Rao and Bohan Jiang and Allon Percus and Kristina Lerman},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ktZoMTTF3x}\n}",
        "github": "",
        "project": "",
        "reviewers": "Sh3Q;UBiz;61JV;996o;zecR",
        "site": "https://openreview.net/forum?id=ktZoMTTF3x",
        "pdf_size": 0,
        "novelty": "3;3;3;4;5",
        "technical_quality": "4;3;4;5;6",
        "scope": "4;4;4;2;4",
        "confidence": "3;3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            3.6,
            0.8
        ],
        "technical_quality_avg": [
            4.4,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.8
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.875
    },
    {
        "id": "l4kbDCMWKX",
        "title": "GraphCSR: A Space and Time-Efficient Sparse Matrix Representation for Web-scale Graph Processing",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph data processing is essential for web-scale applications, including social networks, recommendation systems, and web of things\n(WoT) systems, where large, sparsely connected graphs dominate. Traditional sparse matrix storage formats like compressed sparse\nrow (CSR) face significant memory and performance bottlenecks in distributed, federated, and edge-based computing environments,\nwhich are increasingly central to the web. To address this challenge, we propose GraphCSR, a novel storage format that clusters ver-\ntices with identical edge degrees and stores only the starting index of each group. This approach minimizes memory overhead and\nfacilitates batch memory access while enhancing overall performance, making it particularly suitable for federated systems and\nresource-constrained edge nodes. Our experiments across various graph operations and large datasets show that GraphCSR achieves\nconsiderable memory savings and performance gains of large-scale, distributed graph processing. When deployed GraphCSR on a\nproduction-grade supercomputer with 79,024 computing nodes, it outperforms the top-ranked system on the Graph 500 list, demon-\nstrating its potential for scaling web and WoT graph processing in large-scale distributed computing systems.",
        "keywords": "Graph representation; CSR;Sorted graph;Graph processing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinbiao Gan;Tiejun Li;Qiang Zhang;Liyang Wu;Bo Yang;Chunye Gong;Jie Liu;KAI LU",
        "authorids": "~Xinbiao_Gan1;~Tiejun_Li1;~Qiang_Zhang21;~Liyang_Wu1;~Bo_Yang26;~Chunye_Gong2;~Jie_Liu41;~KAI_LU8",
        "gender": "M;M;M;F;M;M;M;M",
        "homepage": "http://www.tianhegraph.top/homepage;https://xueshu.baidu.com/scholarID/CN-BU74ZJ7J;https://gitee.com/zhang-yuyuyuyu;;https://www.researchgate.net/profile/Bo-Yang-77;https://xueshu.baidu.com/scholarID/CN-B473T3CJ;https://xueshu.baidu.com/scholarID/CN-BYG71YLK;https://www.ccf.org.cn/Chapters/Chapters/Changsha/zzjg/zxwy/2017-05-11/594599.shtml",
        "dblp": "36/4875;;;;;;;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;;;;;;",
        "orcid": "0000-0003-3622-1772;;0009-0001-5234-1937;0009-0006-5727-7678;;;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Xinbiao_Gan1;~Tiejun_Li1;~Qiang_Zhang21;~Liyang_Wu1;~Bo_Yang26;~Chunye_Gong2;~Jie_Liu41;~KAI_LU8",
        "aff": "National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology;National University of Defense Technology",
        "aff_domain": "nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "position": "Associate Professor;Full Professor;MS student;MS student;Assistant Professor;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\ngan2025graphcsr,\ntitle={Graph{CSR}: A Space and Time-Efficient Sparse Matrix Representation for Web-scale Graph Processing},\nauthor={Xinbiao Gan and Tiejun Li and Qiang Zhang and Liyang Wu and Bo Yang and Chunye Gong and Jie Liu and KAI LU},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=l4kbDCMWKX}\n}",
        "github": "",
        "project": "",
        "reviewers": "vdVf;3qiM;dXM8;kioU;WcBw",
        "site": "https://openreview.net/forum?id=l4kbDCMWKX",
        "pdf_size": 0,
        "novelty": "4;4;6;6;7",
        "technical_quality": "4;5;6;6;7",
        "scope": "3;3;3;4;4",
        "confidence": "2;2;4;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            1.2
        ],
        "technical_quality_avg": [
            5.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9525793444156803
    },
    {
        "id": "l5aPuFYNBH",
        "title": "Mining User Preferences from Online Reviews with the Genre-aware Personalized neural Topic Model",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Customer-generated reviews on e-commerce websites often contain valuable insights into users' interests in product genres and provide a rich source for mining user preferences. However, most existing neural topic models tend to generate meaningless topics that have low correlations with product genres. Furthermore, they often fail to mine user preferences and discover personalized topic profiles due to the absence of explicit user modeling. To address these limitations, we propose a novel Genre-aware Personalized neural Topic Model (GPTM), which incorporates product genre information into the topic modeling process to ensure the relevance between mined topics and product genres. Moreover, it could produce a personalized topic profile for each user by performing user preference modeling. Extensive experimental results on three publicly available Amazon review corpora validate the effectiveness of the proposed GPTM in genre-aware topic modeling. Furthermore, GPTM surpasses state-of-the-art baselines in user preference mining and generating high-quality personalized topic profiles.",
        "keywords": "Neural Topic Modeling;User Preferences Discovery;Text Mining",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rui Wang;Jiahao Lu;Xincheng Lv;Shuyu Chang;Yansheng Wu;Yuanzhi Yao;Haiping Huang;Guozi Sun",
        "authorids": "~Rui_Wang44;~Jiahao_Lu7;~Xincheng_Lv1;~Shuyu_Chang1;~Yansheng_Wu1;~Yuanzhi_Yao1;~Haiping_Huang1;~Guozi_Sun1",
        "gender": "M;M;M;;M;M;;M",
        "homepage": "https://www.researchgate.net/profile/Rui-Wang-63;https://www.researchgate.net/profile/Jiahao-Lu-15;https://www.researchgate.net/profile/Xincheng-Lv-2;;;https://faculty.hfut.edu.cn/yaoyz/en/;;",
        "dblp": "06/2293-43;;;;207/7455.html;121/1222;;",
        "google_scholar": "vzjqZzsAAAAJ;;;;https://scholar.google.com/citations?hl=zh-CN;FHNibMIAAAAJ;;c6NqHEQAAAAJ",
        "orcid": "0000-0001-9350-3667;;;;;0000-0003-1965-7670;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Rui_Wang44;~Jiahao_Lu7;~Xincheng_Lv1;~Shuyu_Chang1;~Yansheng_Wu1;~Yuanzhi_Yao1;~Haiping_Huang1;~Guozi_Sun1",
        "aff": "Nanjing University of Posts and Telecommunications;Nanjing University of Posts and Telecommunications;Nanjing University of Posts and Telecommunications;;Nanjing University of Posts and Telecommunications;Hefei University of Technology;;",
        "aff_domain": "njupt.edu.cn;njupt.edu.cn;njupt.edu.cn;;njupt.edu.cn;hfut.edu.cn;;",
        "position": "Lecturer;MS student;MS student;;Associate Professor;Associate Professor;;",
        "bibtex": "@inproceedings{\nwang2025mining,\ntitle={Mining User Preferences from Online Reviews with the Genre-aware Personalized neural Topic Model},\nauthor={Rui Wang and Jiahao Lu and Xincheng Lv and Shuyu Chang and Yansheng Wu and Yuanzhi Yao and Haiping Huang and Guozi Sun},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=l5aPuFYNBH}\n}",
        "github": "",
        "project": "",
        "reviewers": "t4kn;Gp9V;o7j7;fGCV",
        "site": "https://openreview.net/forum?id=l5aPuFYNBH",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "5;4;4;6",
        "scope": "4;3;3;4",
        "confidence": "4;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4264014327112209
    },
    {
        "id": "l5zRaRSBn0",
        "title": "X-ClusterLink: An Efficient Cross-Cluster Communication Framework in Multi-Kubernetes Clusters",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Kubernetes is widely adopted by enterprises to enhance service availability for applications such as web services and large-scale model training, due to its advantages in managing containerized applications. As service demands increase, a single Kubernetes cluster often becomes insufficient, leading to the trend of using multiple clusters to improve service scalability. However, achieving efficient cross-cluster communication poses significant challenges due to the need for low latency, high throughput, and strong robustness. Existing methods for cross-cluster communication either employ a centralized control plane, which becomes a communication bottleneck, or use numerous service-bound proxies, leading to increased management complexity and possibly compromised robustness in cross-cluster communication.\n\nTo address the above challenges, we introduce X-ClusterLink, a framework designed for efficient cross-cluster communication in multi-Kubernetes clusters. X-ClusterLink first employs broker clusters to ensure low-latency cross-cluster synchronization. Then, it aggregates multiple containerized gateways to enhance throughput and leverages eXpress Data Path (XDP) for advanced packet processing, thereby accelerating traffic forwarding. Finally, it incorporates Bucket-Based Consistent ECMP to facilitate seamless failover and enhance robustness. Experimental results demonstrate that X-ClusterLink significantly improves cross-cluster communication efficiency, increasing cross-cluster forwarding bandwidth by 3.1 $\\times$ compared to existing solutions.",
        "keywords": "Virtualization;Resource Management;Kubernetes;Traffic Forwarding;Web Infrastructure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Pengbo Wang;Gongming Zhao;Yuantao Wu;Hongli Xu;Haibo Wang",
        "authorids": "~Pengbo_Wang3;~Gongming_Zhao1;~Yuantao_Wu2;~Hongli_Xu1;~Haibo_Wang9",
        "gender": ";;M;M;M",
        "homepage": ";https://gmzhao-ustc.github.io/;http://home.ustc.edu.cn/~tgkyrie/;https://int-ustc.github.io/index.html;http://www.haibo.pro",
        "dblp": ";;;;71/3583-4",
        "google_scholar": ";;;zGmKnqMAAAAJ;FUNoAkEAAAAJ",
        "orcid": ";;;0000-0003-3831-4577;0000-0003-4809-4897",
        "linkedin": ";;;;",
        "or_profile": "~Pengbo_Wang3;~Gongming_Zhao1;~Yuantao_Wu2;~Hongli_Xu1;~Haibo_Wang9",
        "aff": ";;University of Science and Technology of China;University of Science and Technology of China;University of Kentucky",
        "aff_domain": ";;mail.ustc.edu.cn;ustc.edu.cn;uky.edu",
        "position": ";;MS student;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025xclusterlink,\ntitle={X-ClusterLink: An Efficient Cross-Cluster Communication Framework in Multi-Kubernetes Clusters},\nauthor={Pengbo Wang and Gongming Zhao and Yuantao Wu and Hongli Xu and Haibo Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=l5zRaRSBn0}\n}",
        "github": "",
        "project": "",
        "reviewers": "867S;SZfc;AX6Q;rEZu;YqFo",
        "site": "https://openreview.net/forum?id=l5zRaRSBn0",
        "pdf_size": 0,
        "novelty": "4;4;5;5;5",
        "technical_quality": "5;6;6;5;6",
        "scope": "2;3;4;4;4",
        "confidence": "2;3;3;1;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.8
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.10206207261596574
    },
    {
        "id": "lEQEKUpXt6",
        "title": "UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Existing foundation models, such as CLIP, aim to learn a unified embedding space for multimodal data, enabling a wide range of downstream web-based applications like search, recommendation, and content classification. However, these models often overlook the inherent graph structures in multimodal datasets, where entities and their relationships are crucial. For example, in social networks, users are connected through friendships, follows, or interactions, and share content in various modalities like text and images. Multimodal graphs (MMGs) represent such graphs where each node is associated with features from different modalities, while the edges capture the relationships between these entities. On the other hand, existing graph foundation models primarily focus on text-attributed graphs (TAGs) and are not designed to handle the complexities of MMGs. To address these limitations, we propose UniGraph2, a novel cross-domain graph foundation model that enables general representation learning on MMGs, providing a unified embedding space. UniGraph2 employs modality-specific encoders alongside a graph neural network (GNN) to learn a unified low-dimensional embedding space that captures both the multimodal information and the underlying graph structure. We propose a new cross-domain multi-graph pre-training algorithm at scale to ensure effective transfer learning across diverse graph domains and modalities. Additionally, we introduce a new Mixture of Experts (MoE) component to align features from different domains and modalities, ensuring coherent and robust embeddings that unify the information across modalities. Extensive experiments on a variety of multimodal graph tasks demonstrate that UniGraph2 significantly outperforms state-of-the-art models in tasks such as representation learning, transfer learning, and multimodal generative tasks, offering a scalable and flexible solution for learning on MMGs.",
        "keywords": "Graph Pre-Training;Graph Foundation Models;Web Mining;Multimodal Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yufei He;Yuan Sui;Xiaoxin He;Yue Liu;Yifei Sun;Bryan Hooi",
        "authorids": "~Yufei_He1;~Yuan_Sui1;~Xiaoxin_He1;~Yue_Liu10;~Yifei_Sun1;~Bryan_Hooi1",
        "gender": "M;M;F;M;M;",
        "homepage": "https://github.com/yf-he;https://www.yuan-sui.com/;https://xiaoxinhe.github.io/;https://yueliu1999.github.io/;https://sunefei.github.io/;http://bhooi.github.io",
        "dblp": ";;72/5872;74/1932-8;27/3389-2;169/9975",
        "google_scholar": "https://scholar.google.com/citations?hl=en;DHuHxJAAAAAJ;icT6GMsAAAAJ;5tfpu3MAAAAJ;9mxdFawAAAAJ;",
        "orcid": "0000-0001-8918-6734;0000-0001-8559-831X;;;0000-0002-6814-5527;0000-0002-5645-1754",
        "linkedin": ";;he-xiaoxin-a130601b4/;;yifeis;",
        "or_profile": "~Yufei_He1;~Yuan_Sui1;~Xiaoxin_He1;~Yue_Liu10;~Yifei_Sun1;~Bryan_Hooi1",
        "aff": "National University of Singapore;National University of Singapore+Tencent AI;National University of Singapore;National University of Singapore;Zhejiang University;National University of Singapore",
        "aff_domain": "u.nus.edu;u.nus.edu+tencent.com;nus.edu;u.nus.edu;zju.edu.cn;nus.edu.sg",
        "position": "PhD student;PhD student+Intern;PhD student;PhD student;PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nhe2025unigraph,\ntitle={UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs},\nauthor={Yufei He and Yuan Sui and Xiaoxin He and Yue Liu and Yifei Sun and Bryan Hooi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lEQEKUpXt6}\n}",
        "github": "",
        "project": "",
        "reviewers": "nzEj;PebM;BpYj;ghGf;DTL2",
        "site": "https://openreview.net/forum?id=lEQEKUpXt6",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "6;6;4;5;5",
        "scope": "4;4;3;4;3",
        "confidence": "3;2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.4082482904638631
    },
    {
        "id": "lOSomJvrc5",
        "title": "AI Model Modulation with Logits Redistribution",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The substantial data and resource consumption of training deep neural networks has rendered the large-scale training accessible only to organizations with necessary infrastructure and massive datasets. \nOnce these models are developed, they are typically adapted to meet the diverse requirements of model owners and users through techniques like early exiting and fine-tuning. \nHowever, maintaining multiple specialized versions of the established model is inefficient and unsustainable in the long run.\nIn response to this challenge, we propose AIM, a novel model modulation paradigm that enables a single model to exhibit diverse behaviors meeting the specific needs of stakeholders. \nAIM enables two key modulation modes: utility and focus modulation. \nThe former provides model owners with dynamic control over output quality to deliver varying utility levels from the same model, the latter offers users precise control to shift model's focused features of inputs. \n\nAIM introduces a logits redistribution strategy for modulating model behaviors. It operates in a training data-agnostic and retraining-free manner by directly manipulating off-the-shelf pre-trained networks, facilitating AIM's seamless integration across diverse neural network architectures. To mathematically guarantee that our modulation achieves a precise regulation of model behavior, we establish a formal foundation grounded in the statistical properties of logits ordering via joint probability distributions. Our evaluation spans across diverse applications, including image classification, semantic segmentation, and text generation, utilizing prevalent architectures such as ResNet, SegFormer, and Llama. Experimental results confirm the efficacy of our approach, demonstrating the practicality and versatility of AIM in realizing AI model modulation. AIM provides both theoretical and system-level tools to empower a single model to meet diverse needs of both model owners and users, paving the way for scalable, accessible, and efficient AI deployment.",
        "keywords": "Model Modulation;Neural Networks;Personalization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zihan Wang;Zhongkui Ma;Xinguo Feng;Zhiyang Mei;Ethan Ma;Derui Wang;Jason Xue;Guangdong Bai",
        "authorids": "~Zihan_Wang6;~Zhongkui_Ma1;~Xinguo_Feng1;~Zhiyang_Mei2;~Ethan_Ma1;~Derui_Wang1;~Jason_Xue1;~Guangdong_Bai1",
        "gender": "M;M;M;M;M;;;",
        "homepage": "https://www.zihan.com.au;https://zhongkuima.github.io;;https://www.magicyoung.online/;https://www.zhiyong.space/;;;",
        "dblp": ";;;;;;;",
        "google_scholar": ";https://scholar.google.com.au/citations?user=r2Z7bCMAAAAJ;;;;;;",
        "orcid": ";0000-0002-2392-3751;0000-0003-2307-2771;;;;;",
        "linkedin": ";zhongkui-ma-3276442a8/;;;;;;",
        "or_profile": "~Zihan_Wang6;~Zhongkui_Ma1;~Xinguo_Feng1;~Zhiyang_Mei2;~Ethan_Ma1;~Derui_Wang1;~Jason_Xue1;~Guangdong_Bai1",
        "aff": "The University of Queensland;The University of Queensland;The University of Queensland;The University of Queensland;The University of Queensland;;;",
        "aff_domain": "uq.edu.au;uq.edu.au;uq.edu.au;uqconnect.edu.au;uq.edu.au;;;",
        "position": "PhD student;PhD student;PhD student;MS student;Undergrad student;;;",
        "bibtex": "@inproceedings{\nwang2025ai,\ntitle={{AI} Model Modulation with Logits Redistribution},\nauthor={Zihan Wang and Zhongkui Ma and Xinguo Feng and Zhiyang Mei and Ethan Ma and Derui Wang and Jason Xue and Guangdong Bai},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lOSomJvrc5}\n}",
        "github": "",
        "project": "",
        "reviewers": "ygzy;FFJK;bug7;d2zV;PKFn",
        "site": "https://openreview.net/forum?id=lOSomJvrc5",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "4;5;4;5;4",
        "scope": "2;3;3;2;3",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.4,
            0.48989794855663565
        ],
        "scope_avg": [
            2.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.10206207261596574
    },
    {
        "id": "lSJ8VjjimZ",
        "title": "HOLMES & WATSON: A Robust and Lightweight HTTPS Website Fingerprinting through HTTP Version Parallelism",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Website Fingerprinting (WF) is a traffic analysis technique that aims to identify websites visited by users through the analysis of encrypted traffic patterns. Existing approaches often exhibit limited robustness against network variability and concept drift, resulting in significant performance degradation under real-world HTTPS conditions. Moreover, these methods typically require large-scale training datasets and substantial computational resources, which further increases the complexity of deployment. In this paper, we propose HOLMES, a novel approach that exploits HTTP version parallelism to extract enhanced application-layer features. These features, including the number of web resources transmitting in various HTTP versions, expose up to 4.28 bits of information\u2014surpassing 98\\% of previously reported features and demonstrate increased stability across varying network conditions. Complementary to this, we introduce WATSON, a lightweight classification method based on lazy learning, which substantially reduces the dependency on large training datasets. To further enhance the identification accuracy, we incorporate two fingerprint-specific distance metrics that ensure high intra-class similarity. Our experimental evaluation demonstrates that HOLMES \\& WATSON significantly enhance both robustness and efficiency, achieving an average accuracy of 87.7\\% with only a single sample per website, marking an improvement of over 15\\% compared to state-of-the-art methods.",
        "keywords": "Website fingerprinting;HTTP version parallelism;Protocol analysis;Lazy learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yifei Cheng;Yujia Zhu;Baiyang Li;peishuai sun;Yong Ding;Xinhao Deng;Qingyun Liu",
        "authorids": "~Yifei_Cheng2;~Yujia_Zhu1;~Baiyang_Li1;~peishuai_sun1;~Yong_Ding4;~Xinhao_Deng3;~Qingyun_Liu2",
        "gender": "M;F;;M;M;M;M",
        "homepage": ";https://people.ucas.ac.cn/~zhuyujia;;;https://mesalab.cn/;https://xinhao-deng.github.io/;https://people.ucas.edu.cn/~liuqingyun",
        "dblp": ";;;;;247/1165;",
        "google_scholar": "bXNTgsgAAAAJ;Fz7gyFsAAAAJ;;;;https://scholar.google.com/citations?hl=zh-CN;",
        "orcid": ";0009-0002-4365-7339;;0000-0003-1135-8297;;0000-0002-4366-4777;",
        "linkedin": ";;;;;;",
        "or_profile": "~Yifei_Cheng2;~Yujia_Zhu1;~Baiyang_Li1;~peishuai_sun1;~Yong_Ding4;~Xinhao_Deng3;~Qingyun_Liu2",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;;University of Chinese Academy of Sciences;University of Chinese Academy of Sciences;Tsinghua University;",
        "aff_domain": "iie.ac.cn;iie.ac.cn;;ucas.edu;ucas.ac.cn;mails.tsinghua.edu.cn;",
        "position": "PhD student;Associate Professor;;Undergrad student;PhD student;PhD student;",
        "bibtex": "@inproceedings{\ncheng2025holmes,\ntitle={{HOLMES} \\& {WATSON}: A Robust and Lightweight {HTTPS} Website Fingerprinting through {HTTP} Version Parallelism},\nauthor={Yifei Cheng and Yujia Zhu and Baiyang Li and peishuai sun and Yong Ding and Xinhao Deng and Qingyun Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lSJ8VjjimZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "98Pd;VpBG;u11L;sQ4q;vXBP",
        "site": "https://openreview.net/forum?id=lSJ8VjjimZ",
        "pdf_size": 0,
        "novelty": "3;6;6;6;7",
        "technical_quality": "4;5;6;6;5",
        "scope": "3;4;4;3;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.6,
            1.3564659966250536
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "lTiW2VXME1",
        "title": "Beast in the Cage: A Fine-grained and Object-oriented Permission System to Confine JavaScript Operations on the Web",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "JavaScript plays a crucial role on web. However, the inclusion of unknown, vulnerable, or malicious scripts on websites and in browser extensions and the use of browsers' developer tools often leads to undesired web content manipulations and data acquisitions. To restrict JavaScript operations on web content and data, we introduce a fine-grained, mandatory access control-based, and object-oriented permission system for browsers. With our system, web developers can define policies for sensitive web elements on their web pages to allow or deny scripts' operations on web content and data within browsers. The system substantially thwarts many web threats and attacks, and offers benefits to personal data governance. We developed a tool for automatic policy generation and demonstrated the usability and compatibility of the system in a three-month study. Our system is a reasonable and practical solution, bolstering the security and trustworthiness on the internet.",
        "keywords": "HTML;JavaScript;permission",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rui Zhao",
        "authorids": "~Rui_Zhao5",
        "gender": "M",
        "homepage": "https://rzhao-sec.github.io/",
        "dblp": "26/2578-5",
        "google_scholar": "pECklRAAAAAJ",
        "orcid": "0000-0001-8292-8483",
        "linkedin": "",
        "or_profile": "~Rui_Zhao5",
        "aff": "University of Nebraska, Omaha",
        "aff_domain": "unomaha.edu",
        "position": "Assistant Professor",
        "bibtex": "@inproceedings{\nzhao2025beast,\ntitle={Beast in the Cage: A Fine-grained and Object-oriented Permission System to Confine JavaScript Operations on the Web},\nauthor={Rui Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lTiW2VXME1}\n}",
        "github": "",
        "project": "",
        "reviewers": "BWCK;tVJ6;6pyB;Qc6W",
        "site": "https://openreview.net/forum?id=lTiW2VXME1",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "3;4;5;4",
        "scope": "3;4;4;4",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "lZ3jDGOR2Y",
        "title": "Synergizing Large Language Models and Knowledge-based Reasoning for Interpretable Feature Engineering",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Feature engineering stands as a pivotal step in enhancing the performance of machine learning models, particularly with tabular data. However, traditional feature engineering methods are often time-consuming and require case-by-case domain knowledge. In addition, as machine learning systems become more common, interpretability becomes increasingly important, especially among domain experts. To this end, we propose ReaGen, an automated feature engineering (AutoFE) approach that combines the use of knowledge graphs (KGs) with large language models (LLMs) to generate interpretable features. ReaGen begins by symbolic reasoning over a knowledge graph to extract relevant information based on datasets description. Then, it uses several LLMs to iteratively generate meaningful features based on the retrieved information and the datasets description. Finally, to overcome challenges such as hallucinations and handling long contexts typical in LLMs, our model performs logical reasoning on the knowledge graph to ensure that the generated features maintain interpretability. ReaGen provides Python code for automatic feature generation and detailed explanations of feature utility. It leverages both LLM's internal knowledge and retrieved information from knowledge graphs. Extensive experiments on public datasets demonstrate that ReaGen significantly improves prediction accuracy while ensuring high interpretability through human-like explanations for each feature. This work highlights the potential of integrating large language models and knowledge graphs in feature engineering, paving the way for interpretable machine learning models.",
        "keywords": "Automated Feature Engineering;Large Language Models;Knowledge Graphs;Semantic Web Reasoning;Interpretable Machine learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Mohamed Bouadi;Arta Alavi;Salima BENBERNOU;Mourad OUZIRI",
        "authorids": "~Mohamed_Bouadi1;~Arta_Alavi2;~Salima_BENBERNOU1;~Mourad_OUZIRI1",
        "gender": ";;;M",
        "homepage": ";;;https://helios2.mi.parisdescartes.fr/~ouziri/",
        "dblp": ";;;37/5056",
        "google_scholar": ";;;xtjW798AAAAJ",
        "orcid": ";;;0000-0003-1682-2781",
        "linkedin": ";;;mourad-ouziri-40710280",
        "or_profile": "~Mohamed_Bouadi1;~Arta_Alavi2;~Salima_BENBERNOU1;~Mourad_OUZIRI1",
        "aff": ";;;Universit\u00e9 Paris Cit\u00e9",
        "aff_domain": ";;;u-paris.fr",
        "position": ";;;Associate Professor",
        "bibtex": "@inproceedings{\nbouadi2025synergizing,\ntitle={Synergizing Large Language Models and Knowledge-based Reasoning for Interpretable Feature Engineering},\nauthor={Mohamed Bouadi and Arta Alavi and Salima BENBERNOU and Mourad OUZIRI},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lZ3jDGOR2Y}\n}",
        "github": "",
        "project": "",
        "reviewers": "XNrV;VyuX;MVhL;W2VS",
        "site": "https://openreview.net/forum?id=lZ3jDGOR2Y",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "3;5;4;6",
        "scope": "4;4;4;4",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8703882797784891
    },
    {
        "id": "lZQp7s69ls",
        "title": "Bridging Fairness and Uncertainty: Theoretical Insights and Practical Strategies for Equalized Coverage in GNNs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs) have become indispensable tools in many domains, such as social network analysis, financial fraud detection, and drug discovery. Prior research primarily concentrated on improving prediction accuracy while overlooking how reliable the model predictions are. Conformal prediction on graphs emerges as a promising solution, offering statistically sound uncertainty estimates with a pre-defined coverage level. Despite the promising progress, existing works only focus on achieving model coverage guarantees without considering fairness in the coverage within different demographic groups. To bridge the gap between conformal prediction and fair coverage across different groups, we pose the fundamental question: Can fair GNNs enable the uncertainty estimates to be fairly applied across demographic groups? To answer this question, we provide a comprehensive analysis of the uncertainty estimation in fair GNNs employing various strategies. We prove theoretically that fair GNNs can enforce consistent uncertainty bounds across different demographic groups, thereby minimizing bias in uncertainty estimates. Furthermore, we conduct extensive experiments on five commonly used datasets across seven state-of-the-art fair GNN models to validate our theoretical findings. Additionally, based on the theoretical and empirical insights, we identify and analyze the key strategies from various fair GNN models that contribute to ensuring equalized uncertainty estimates. Our work estimates a solid foundation for future exploration of the practical implications and potential adjustments needed to enhance fairness in GNN applications across various domains.  For reproducibility, we publish our data and code at https://anonymous.4open.science/r/EqualizedCoverage_CP-9CF8.",
        "keywords": "Conditional conformal prediction;fairness;graph neural networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Longfeng Wu;Yao Zhou;Jian Kang;Dawei Zhou",
        "authorids": "~Longfeng_Wu1;~Yao_Zhou3;~Jian_Kang1;~Dawei_Zhou1",
        "gender": "F;M;M;M",
        "homepage": ";https://publish.illinois.edu/yaozhou3/;https://jiank2.github.io/;https://sites.google.com/view/dawei-zhou/home?authuser=0",
        "dblp": "256/5049;19/8104.html;56/6072-8;39/3130-3.html",
        "google_scholar": "Y5RFAzUAAAAJ;-SEKavEAAAAJ;U_jFlOQAAAAJ;8dakqOgAAAAJ",
        "orcid": "0000-0001-7422-4398;0000-0002-9575-2832;0000-0003-3902-7131;0000-0002-7065-2990",
        "linkedin": "longfeng-wu-a50249207/;;jiank2/;dawei-zhou-31035668/",
        "or_profile": "~Longfeng_Wu1;~Yao_Zhou3;~Jian_Kang1;~Dawei_Zhou1",
        "aff": ", Virginia Polytechnic Institute and State University;;Mohamed bin Zayed University of Artificial Intelligence+University of Rochester;Virginia Polytechnic Institute and State University",
        "aff_domain": "cs.vt.edu;;mbzuai.ac.ae+cs.rochester.edu;vt.edu",
        "position": "PhD student;;Assistant Professor+Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwu2025bridging,\ntitle={Bridging Fairness and Uncertainty: Theoretical Insights and Practical Strategies for Equalized Coverage in {GNN}s},\nauthor={Longfeng Wu and Yao Zhou and Jian Kang and Dawei Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lZQp7s69ls}\n}",
        "github": "",
        "project": "",
        "reviewers": "g15o;WBBd;TR3m;zYQM;8ChT",
        "site": "https://openreview.net/forum?id=lZQp7s69ls",
        "pdf_size": 0,
        "novelty": "4;5;5;6;6",
        "technical_quality": "3;5;6;5;6",
        "scope": "3;4;3;3;4",
        "confidence": "3;3;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3273268353539886
    },
    {
        "id": "lbFQ2QJHNY",
        "title": "Boosting Graph Convolution with Disparity-induced Structural Refinement",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs) have expressed remarkable capability in processing graph-structured data. Recent studies have found that most GNNs rely on the homophily assumption of graphs, leading to unsatisfactory performance on heterophilous graphs. While certain methods have been developed to address heterophilous links,they lack more precise estimation of high-order relationships between nodes. This could result in the aggregation of excessive interference information during message propagation, thus degrading the representation ability of learned features. In this work, we propose a {D}isparity-induced {S}tructural {R}efinement (DSR) method that enables adaptive and selective message propagation in GNN, to enhance representation learning in heterophilous graphs. We theoretically analyze the necessity of structural refinement during message passing grounded in the derivation of error bound for node classification. To this end, we design a disparity score that combines both features and structural information at the node level, reflecting the connectivity degree of hopping neighbor nodes. Based on the disparity score, we can adjust the aggregation of neighbor nodes, thereby mitigating the impact  of irrelevant information during message passing. Experimental results demonstrate that our method achieves competitive performance, mostly outperforming advanced methods on both homophilous and heterophilous datasets.",
        "keywords": "Graph neural network;homophily and heterophily;structural learning;message passing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sujia Huang;Yueyang Pi;Tong Zhang;Wenzhe Liu;Zhen Cui",
        "authorids": "~Sujia_Huang1;~Yueyang_Pi1;~Tong_Zhang8;~Wenzhe_Liu2;~Zhen_Cui4",
        "gender": "F;M;M;F;M",
        "homepage": ";;https://vgg-ai.cn/teachers/ZhangTong/;https://github.com/jlhushi;http://aip.seu.edu.cn/zcui/",
        "dblp": "312/7888;377/4982;07/4227-21;;59/8491-1",
        "google_scholar": "bYy7jlAAAAAJ;https://scholar.google.com/citations?hl=zh-CN;;;ChRyl3kAAAAJ",
        "orcid": "0000-0002-4745-2157;;0000-0001-6212-4891;;",
        "linkedin": ";;;;",
        "or_profile": "~Sujia_Huang1;~Yueyang_Pi1;~Tong_Zhang8;~Wenzhe_Liu2;~Zhen_Cui4",
        "aff": "Nanjing University of Science and Technology;Fuzhou University;Nanjing University of Science and Technology;Huzhou University;Nanjing University of Science and Technology",
        "aff_domain": "njust.edu.cn;fzu.edu.cn;njust.edu.cn;zjhu.edu.cn;njust.edu.cn",
        "position": "PhD student;PhD student;Associate Professor;Lecturer;Full Professor",
        "bibtex": "@inproceedings{\nhuang2025boosting,\ntitle={Boosting Graph Convolution with Disparity-induced Structural Refinement},\nauthor={Sujia Huang and Yueyang Pi and Tong Zhang and Wenzhe Liu and Zhen Cui},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lbFQ2QJHNY}\n}",
        "github": "",
        "project": "",
        "reviewers": "cjt8;izth;8o4t;5Bgw;vvDd",
        "site": "https://openreview.net/forum?id=lbFQ2QJHNY",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "4;5;4;4;6",
        "scope": "4;4;3;3;3",
        "confidence": "3;4;1;2;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.140028008402801
    },
    {
        "id": "lhFcbb5q48",
        "title": "Uncertainty Quantification and Decomposition for LLM-based Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations.\nTo ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs.\nWe start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations.\nWe further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty.\nThrough extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation.\nOur source code and model weights are available at https://anonymous.4open.science/r/UNC_LLM_REC",
        "keywords": "Recommendation;Large Language Models;Uncertainty",
        "primary_area": "",
        "supplementary_material": "",
        "author": "WONBIN KWEON;Sanghwan Jang;SeongKu Kang;Hwanjo Yu",
        "authorids": "~WONBIN_KWEON1;~Sanghwan_Jang1;~SeongKu_Kang1;~Hwanjo_Yu2",
        "gender": "M;;M;",
        "homepage": "https://wonbinkweon.github.io/;https://scholar.google.com/citations?user=iuvgvowAAAAJ;https://seongku-kang.github.io/;",
        "dblp": "264/2604;336/3880;251/9613.html;",
        "google_scholar": "u-zOiMUAAAAJ;iuvgvowAAAAJ;fB0K-fMAAAAJ;",
        "orcid": "0000-0002-8813-3179;0009-0000-9856-491X;0000-0001-5528-1426;",
        "linkedin": ";;;",
        "or_profile": "~WONBIN_KWEON1;~Sanghwan_Jang1;~SeongKu_Kang1;~Hwanjo_Yu2",
        "aff": "University of Illinois Urbana-Champaign;POSTECH;Korea University+University of Illinois Urbana-Champaign;",
        "aff_domain": "illinois.edu;postech.ac.kr;korea.ac.kr+cs.illinois.edu;",
        "position": "Postdoc;PhD student;Assistant Professor+Postdoc;",
        "bibtex": "@inproceedings{\nkweon2025uncertainty,\ntitle={Uncertainty Quantification and Decomposition for {LLM}-based Recommendation},\nauthor={WONBIN KWEON and Sanghwan Jang and SeongKu Kang and Hwanjo Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lhFcbb5q48}\n}",
        "github": "",
        "project": "",
        "reviewers": "2vsU;QuqH;Gfxo;KQyE;LrA8",
        "site": "https://openreview.net/forum?id=lhFcbb5q48",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "3;3;4;4;5",
        "scope": "4;4;3;4;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            3.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "lq2jDWv3w0",
        "title": "Following Clues, Approaching the Truth: Explainable Micro-Video Rumor Detection via Chain-of-Thought Reasoning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The rapid spread of rumor content on online micro-video platforms poses significant threats to public health and safety. However, existing Micro-Video Rumor Detection (MVRD) methods are generally black-box, which lacks transparency and makes it difficult to understand the reasoning behind classification decisions. In this work, we introduce ExMRD, a novel Explainable Micro-video Rumor Detection framework designed to generate detailed and coherent explanations for enhancing MVRD. Inspired by the powerful reasoning capacity of Chain-of-Thought (CoT), we introduce a novel inference mechanism called R^3CoT-- consisting of Refining, Retrieving, and Reasoning on MVRD.  This mechanism enables Multimodal Large Language Models (MLLMs) to reorganize the original video content, retrieve domain knowledge related to rumors, and generate explainable conclusions regarding whether the micro-video contains rumor information. Instead of directly fine-tuning MLLMs for MVRD, which is computationally expensive, we propose a Small Language Reviewer (SLReviewer), which distills the outputs of R^3CoT guided MLLMs to ensure efficient and reliable predictions. Extensive experiments on three real-world benchmarks demonstrate that ExMRD significantly outperforms competitive baselines while providing high-quality rationales.",
        "keywords": "Micro-video rumor detection;explainability;chain-of-thought;multimodal large language models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Rongpei Hong;Jian Lang;Jin Xu;Zhangtao Cheng;Ting Zhong;Fan Zhou",
        "authorids": "~Rongpei_Hong1;~Jian_Lang1;~Jin_Xu19;~Zhangtao_Cheng1;~Ting_Zhong2;~Fan_Zhou11",
        "gender": ";M;M;M;F;M",
        "homepage": "https://rongpei.org;https://jian-lang.github.io/;https://www.maynoothuniversity.ie/people/jin-xu;https://ieeexplore.ieee.org/author/37089549978;;https://sise.uestc.edu.cn/info/1035/9375.htm",
        "dblp": "358/7838.html;380/2006;;324/1807.html;73/9481.html;63/3122-2",
        "google_scholar": "mS-iMV4AAAAJ;https://scholar.google.com.hk/citations?user=tEVL8eUAAAAJ;UKXjf5UAAAAJ;CU28LO0AAAAJ;Mdr0XDkAAAAJ;https://scholar.google.com.hk/citations?hl=zh-CN",
        "orcid": "0009-0007-4977-1657;0009-0009-0876-0497;0000-0002-6644-8217;0000-0002-0097-3617;0000-0002-8163-3146;0000-0002-8038-8150",
        "linkedin": ";;xu-jin-engineer/;;;",
        "or_profile": "~Rongpei_Hong1;~Jian_Lang1;~Jin_Xu19;~Zhangtao_Cheng1;~Ting_Zhong2;~Fan_Zhou11",
        "aff": "University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;Maynooth University;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;mu.ie;uestc.edu.cn;uestc.edu.cn;uestc.edu.cn",
        "position": "MS student;MS student;Assistant Professor;PhD student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nhong2025following,\ntitle={Following Clues, Approaching the Truth: Explainable Micro-Video Rumor Detection via Chain-of-Thought Reasoning},\nauthor={Rongpei Hong and Jian Lang and Jin Xu and Zhangtao Cheng and Ting Zhong and Fan Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=lq2jDWv3w0}\n}",
        "github": "",
        "project": "",
        "reviewers": "wdZ1;YXhj;rpHC;yepA",
        "site": "https://openreview.net/forum?id=lq2jDWv3w0",
        "pdf_size": 0,
        "novelty": "4;4;4;6",
        "technical_quality": "3;5;4;6",
        "scope": "3;4;3;4",
        "confidence": "3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -1.0
    },
    {
        "id": "m0iCbfjGQk",
        "title": "Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the emergence of edge AI application scenarios such as on-device web search assistants, enhancing the reasoning performance of large language models (LLMs) on edge devices has become an increasingly important topic. Due to the memory and computation limitations of edge devices, edge-cloud collaboration presents a promising solution, which involves deploying smaller LLMs locally while invoking larger-scale LLMs in the cloud. However, how to coordinate these two to balance cost and performance is a challenge.\nWe propose a new collaborative reasoning framework called Division-of-Thoughts (DoT) to fully harness the synergy between locally deployed SLMs and cloud-based LLMs. DOT leverages a Task Decomposer to elicit the inherent planning abilities in language models to decompose user queries into smaller sub-tasks. DoT also employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks and create a dependency graph, facilitating parallel reasoning of sub-tasks and the identification of key steps. To allocate the appropriate model based on the difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an additional task head attached to the SLM that does not alter the SLM's parameters. To boost the allocation of the adapter, We also design a self-reinforced tree search algorithm to create a high-qualiy sub-task allocation dataset. Extensive experiments on various benchmarks demonstrate that our DoT significantly reduces LLM costs while maintaining reasoning accuracy. Comparable to the best baseline methods, we reduce the average reasoning time and API costs by 66.12% and 83.57%, respectively. \nOur code can be accessed via the following link: https://anonymous.4open.science/status/DoT-F17C",
        "keywords": "LLM;LLM Agent;Hybrid Language Model Synergy;On-Device Agent",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chenyang Shao;Xinyuan Hu;Yutang Lin;Fengli Xu",
        "authorids": "~Chenyang_Shao1;~Xinyuan_Hu3;~Yutang_Lin1;~Fengli_Xu1",
        "gender": "M;M;M;",
        "homepage": "https://github.com/PLUTO-SCY/PLUTO-SCY;;https://github.com/Miyanaga-nonoka/Miyanaga-nonoka;",
        "dblp": ";;;",
        "google_scholar": ";;;",
        "orcid": ";0009-0004-6139-192X;;",
        "linkedin": ";xinyuanhu03204/;;",
        "or_profile": "~Chenyang_Shao1;~Xinyuan_Hu3;~Yutang_Lin1;~Fengli_Xu1",
        "aff": "Tsinghua University;Emory University;Tsinghua University;",
        "aff_domain": "mails.tsinghua.edu.cn;emory.edu;mails.tsinghua.edu.cn;",
        "position": "PhD student;Undergrad student;Undergrad student;",
        "bibtex": "@inproceedings{\nshao2025divisionofthoughts,\ntitle={Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents},\nauthor={Chenyang Shao and Xinyuan Hu and Yutang Lin and Fengli Xu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=m0iCbfjGQk}\n}",
        "github": "",
        "project": "",
        "reviewers": "J64y;Am9u;jcWL;h31F",
        "site": "https://openreview.net/forum?id=m0iCbfjGQk",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;5;5;4",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.3333333333333333
    },
    {
        "id": "m7SmS3Rkr5",
        "title": "Joint Similarity Item Exploration and Overlapped User Guidance for Multi-Modal Cross-Domain Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Cross-Domain Recommendation (CDR) has been widely investi-\ngated for solving long-standing data sparsity problem via knowl-\nedge sharing across domains. In this paper, we focus on the Multi-\nModal Cross-Domain Recommendation (MMCDR) problem where\ndifferent items have multi-modal information while few users are\noverlapped across domains. MMCDR is particularly challenging\nin two aspects: fully exploiting diverse multi-modal information\nwithin each domain and leveraging useful knowledge transfer\nacross domains. However, previous methods fail to cluster items\nwith similar characteristics while filtering out inherit noises within\ndifferent modalities, hurdling the model performance. What is\nworse, conventional CDR models primarily rely on overlapped\nusers for domain adaptation, making them ill-equipped to handle\nscenarios where the majority of users are non-overlapped. To fill\nthis gap, we propose Joint Similarity Item Exploration and Over-\nlapped User Guidance (SIEOUG) for solving the MMCDR problem.\nSIEOUG first proposes similarity item exploration module, which\nnot only obtains pair-wise and group-wise item-item graph knowl-\nedge, but also reduces irrelevant noise for multi-modal modeling.\nThen SIEOUG proposes user-item collaborative filtering module\nto aggregate user/item embeddings with the attention mechanism\nfor collaborative filtering. Finally SIEOUG proposes overlapped\nuser guidance module with optimal user matching for knowledge\nsharing across domains. Our empirical study on Amazon dataset\nwith several different tasks demonstrates that SIEOUG significantly\noutperforms the state-of-the-art models under the MMCDR setting",
        "keywords": "Recommendation;Cross-domain recommendation;Multi-modal cross-domain recommendation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weiming Liu;Chaochao Chen;Jiahe Xu;Xinting Liao;Fan Wang;Xiaolin Zheng;Zhihui Fu;Ruiguang Pei;Jun Wang",
        "authorids": "~Weiming_Liu2;~Chaochao_Chen3;~Jiahe_Xu1;~Xinting_Liao1;~Fan_Wang14;~Xiaolin_Zheng1;~Zhihui_Fu1;~Ruiguang_Pei1;~Jun_Wang38",
        "gender": ";;F;F;;M;M;M;M",
        "homepage": ";https://sites.google.com/site/ccchomepage/;https://github.com/Che-Xu;;;https://person.zju.edu.cn/xlzheng;https://www.linkedin.com/in/fuzhihui/?locale=en_US;https://ruiguangpei.com;https://dblp.org/pid/w/JunWang20.html",
        "dblp": ";26/1492-1;72/7143-3.html;331/1544;;09/5763;158/9419.html;;w/JunWang20",
        "google_scholar": ";qZTMyzwAAAAJ;;FoMerO8AAAAJ;;MY23M60AAAAJ;;;8alC56MAAAAJ",
        "orcid": ";0000-0003-1419-964X;0009-0009-0680-1806;0000-0002-8257-2381;;0000-0001-5483-0366;0009-0003-3512-9656;;0000-0002-0481-5341",
        "linkedin": ";ccchomepage/;;;;;fuzhihui/?locale=en_US;;",
        "or_profile": "~Weiming_Liu2;~Chaochao_Chen3;~Jiahe_Xu1;~Xinting_Liao1;~Fan_Wang14;~Xiaolin_Zheng1;~Zhihui_Fu1;~Ruiguang_Pei1;~Jun_Wang38",
        "aff": ";Zhejiang University;Zhejiang University;Zhejiang University;;Zhejiang University;Guangdong OPPO Mobile Telecommunications Corp.,Ltd.;;OPPO Research Institute ",
        "aff_domain": ";zju.edu.cn;zju.edu.cn;zju.edu.cn;;zju.edu.cn;oppo.com;;oppo.com",
        "position": ";Distinguished Research Fellow;MS student;PhD student;;Full Professor;Researcher;;Principal Researcher",
        "bibtex": "@inproceedings{\nliu2025joint,\ntitle={Joint Similarity Item Exploration and Overlapped User Guidance for Multi-Modal Cross-Domain Recommendation},\nauthor={Weiming Liu and Chaochao Chen and Jiahe Xu and Xinting Liao and Fan Wang and Xiaolin Zheng and Zhihui Fu and Ruiguang Pei and Jun Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=m7SmS3Rkr5}\n}",
        "github": "",
        "project": "",
        "reviewers": "KJMH;MEmh;S1A5;a9w6",
        "site": "https://openreview.net/forum?id=m7SmS3Rkr5",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "4;3;5;5",
        "scope": "4;3;4;4",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.25,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5222329678670935
    },
    {
        "id": "mJdbe2zFR7",
        "title": "Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The increasing prevalence of large-scale graphs poses a significant challenge for graph neural network training, attributed to their substantial computational requirements. In response, graph condensation (GC) emerges as a promising data-centric solution aiming to substitute the large graph with a small yet informative condensed graph to facilitate data-efficient GNN training. However, existing GC methods suffer from intricate optimization processes, necessitating excessive computing resources and training time. In this paper, we revisit existing GC optimization strategies and identify two pervasive issues therein: (1) various GC optimization strategies converge to coarse-grained class-level node feature matching between the original and condensed graphs; (2) existing GC methods rely on a Siamese graph network architecture that requires time-consuming bi-level optimization with iterative gradient computations. To overcome these issues, we propose a training-free GC framework termed Class-partitioned Graph Condensation (CGC), which refines the node distribution matching from the class-to-class paradigm into a novel class-to-node paradigm, transforming the GC optimization into a class partition problem which can be efficiently solved by any clustering methods. Moreover, CGC incorporates a pre-defined graph structure to enable a closed-form solution for condensed node features, eliminating the need for back-and-forth gradient descent in existing GC approaches. Extensive experiments demonstrate that CGC achieves an exceedingly efficient condensation process with advanced accuracy. Compared with the state-of-the-art GC methods, CGC condenses the Ogbn-products graph within 30 seconds, achieving a speedup ranging from $10^2 \\times$ to $10^4 \\times$ and increasing accuracy by up to 4.2\\%.",
        "keywords": "Graph condensation;Graph neural network;Graph representation learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xinyi Gao;Guanhua Ye;Tong Chen;Wentao Zhang;Junliang Yu;Hongzhi Yin",
        "authorids": "~Xinyi_Gao1;~Guanhua_Ye2;~Tong_Chen8;~Wentao_Zhang1;~Junliang_Yu1;~Hongzhi_Yin2",
        "gender": "M;M;M;;M;M",
        "homepage": "https://www.researchgate.net/profile/Xinyi-Gao-14;https://teacher.bupt.edu.cn/yeguanhua/en/index.htm;https://itee.uq.edu.au/profile/1253/rocky-chen;;https://junliang-yu.github.io/;https://sites.google.com/view/hongzhi-yin/home",
        "dblp": "176/6793-1;43/6374;22/1512-5;;204/2362;04/10606.html",
        "google_scholar": "zCgaJWEAAAAJ;-4Sr-CwAAAAJ;07cqSMsAAAAJ;;JGuWOUIAAAAJ;JJsBmhYAAAAJ",
        "orcid": "0009-0004-1146-8925;0000-0002-1683-1875;0000-0001-7269-146X;;0000-0003-3401-9829;0000-0003-1395-261X",
        "linkedin": ";;;;;",
        "or_profile": "~Xinyi_Gao1;~Guanhua_Ye2;~Tong_Chen8;~Wentao_Zhang1;~Junliang_Yu1;~Hongzhi_Yin2",
        "aff": "The University of Queensland;Beijing University of Posts and Telecommunications;The University of Queensland;;University of Queensland;University of Queensland",
        "aff_domain": "uq.edu.au;bupt.edu.cn;uq.edu.au;;uq.edu.au;uq.edu.au",
        "position": "PhD student;Associate Professor;Assistant Professor;;Postdoc;Full Professor",
        "bibtex": "@inproceedings{\ngao2025rethinking,\ntitle={Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition},\nauthor={Xinyi Gao and Guanhua Ye and Tong Chen and Wentao Zhang and Junliang Yu and Hongzhi Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=mJdbe2zFR7}\n}",
        "github": "",
        "project": "",
        "reviewers": "Aa8e;KT8N;T2fK;B9Pr",
        "site": "https://openreview.net/forum?id=mJdbe2zFR7",
        "pdf_size": 0,
        "novelty": "3;4;5;6",
        "technical_quality": "3;4;5;7",
        "scope": "3;4;3;4",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.118033988749895
        ],
        "technical_quality_avg": [
            4.75,
            1.479019945774904
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.2581988897471611
    },
    {
        "id": "mfWGm5FeQw",
        "title": "LUSTER: Link Prediction Utilizing Shared-Latent Space Representation in Multi-Layer Networks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Link prediction in multi-layer networks is a longstanding issue that predicts missing links based on the observed structures across all layers. Existing link prediction methods in multi-layer network typically merge the multi-layer network into a single-layer network and/or perform explicit calculations using intra-layer and inter-layer similarity metrics. However, these approaches often overlook the role of coupling in multi-layer networks, specifically the shared information and latent relationships between layers, which in turn limits prediction performance. This calls the need for methods that can extract representations in a shared-latent space to enhance inter-layer information sharing and prediction performance. In this paper, we propose a novel end-to-end framework namely: Link prediction Utilizing Shared-laTent spacE Representation (LUSTER) in multi-layer networks. LUSTER consists of four key modules: the representation extractor, the latent space learner, the complementary enhancer, and the link predictor. The representation extractor focuses on learning the intra-layer representations of each layer, capturing the data characteristics within the layer. The latent space learner {extracts representations from the shared-latent space across different network layers} through adversarial training. The complementary enhancer combines the intra-layer representations and the shared-latent space representations through orthogonal fusion, providing comprehensive information. Finally, the link predictor uses the enhanced representations to predict missing links. Extensive experimental analyses demonstrate that LUSTER outperforms state-of-the-art methods for link prediction in multi-layer networks, improving the AUC metric by up to 15.87%.",
        "keywords": "link prediction;multi-layer networks;shared-latent space;adversarial training;orthogonal fusion",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ruohan Yang;Muhammad Asif Ali;Huan Wang;Junyang Chen;Di Wang",
        "authorids": "~Ruohan_Yang1;~Muhammad_Asif_Ali1;~Huan_Wang13;~Junyang_Chen1;~Di_Wang1",
        "gender": "F;M;M;M;",
        "homepage": "https://blog.csdn.net/m0_51732188;;https://faculty.hzau.edu.cn/wanghuan/en/index.htm;https://csse.szu.edu.cn/pages/user/index?id=1101;",
        "dblp": ";130/2551;70/6155-5;196/7893.html;",
        "google_scholar": "https://scholar.google.com.hk/citations?user=oAomxrAAAAAJ;https://scholar.google.com.au/citations?user=Kj0S5aYAAAAJ;https://scholar.google.com/citations?hl=zh-CN;Q0u3dRQAAAAJ;",
        "orcid": "0009-0005-8862-8664;;0000-0002-3162-2350;0000-0002-1139-8654;",
        "linkedin": ";;;;",
        "or_profile": "~Ruohan_Yang1;~Muhammad_Asif_Ali1;~Huan_Wang13;~Junyang_Chen1;~Di_Wang1",
        "aff": "Huazhong Agricultural University;King Abdullah University of Science and Technology;Huazhong Agricultural University+Huazhong Agricultural University;Shenzhen University;",
        "aff_domain": "hzau.edu.cn;kaust.edu.sa;hzau.edu.cn+hzau.edu.cn;szu.edu;",
        "position": "MS student;Postdoc;Full Professor+Associate Professor;Associate Professor;",
        "bibtex": "@inproceedings{\nyang2025luster,\ntitle={{LUSTER}: Link Prediction Utilizing Shared-Latent Space Representation in Multi-Layer Networks},\nauthor={Ruohan Yang and Muhammad Asif Ali and Huan Wang and Junyang Chen and Di Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=mfWGm5FeQw}\n}",
        "github": "",
        "project": "",
        "reviewers": "HvXS;myNQ;zsbY;xZdo",
        "site": "https://openreview.net/forum?id=mfWGm5FeQw",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "4;5;4;5",
        "scope": "3;4;4;3",
        "confidence": "1;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8703882797784891
    },
    {
        "id": "mjzss9Xg76",
        "title": "GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recently, research on Text-Attributed Graphs (TAGs) has gained significant attention due to the prevalence of free-text node features in real-world applications and the advancements in Large Language Models (LLMs) that bolster TAG methodologies. However, current TAG approaches face two primary challenges: (i) Heavy reliance on label information and (ii) Limited cross-domain zero/few-shot transferability. These issues constrain the scaling of both data and model size, owing to high labor costs and scaling laws, complicating the development of graph foundation models with strong transferability. In this work, we propose the GraphCLIP framework to address these challenges by learning graph foundation models with strong cross-domain zero/few-shot transferability through a self-supervised contrastive graph-summary pretraining method. Specifically, we generate and curate large-scale graph-summary pair data with the assistance of LLMs, and introduce a novel graph-summary pretraining method, combined with invariant learning, to enhance graph foundation models with strong cross-domain zero-shot transferability. For few-shot learning, we propose a novel graph prompt tuning technique aligned with our pretraining objective to mitigate catastrophic forgetting and minimize learning costs. Extensive experiments show the superiority of GraphCLIP in both zero-shot and few-shot settings, while evaluations across various downstream tasks confirm the versatility of GraphCLIP. Our code is available at: https://anonymous.4open.science/r/GraphCLIP",
        "keywords": "GNNs;LLMs;Graph Foundation Models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yun Zhu;Haizhou Shi;Xiaotang Wang;Yongchao Liu;Yaoke Wang;Boci Peng;Chuntao Hong;Siliang Tang",
        "authorids": "~Yun_Zhu4;~Haizhou_Shi1;~Xiaotang_Wang1;~Yongchao_Liu2;~Yaoke_Wang1;~Boci_Peng1;~Chuntao_Hong1;~Siliang_Tang1",
        "gender": "M;M;M;M;M;M;;M",
        "homepage": "https://zhuyun97.github.io/;https://haizhou-shi.github.io;https://github.com/wangxiaotang0906;https://yongchao-liu.github.io;;;;https://person.zju.edu.cn/en/siliang",
        "dblp": ";245/0213;333/3734;29/3462;;303/6556;62/6933.html;44/5693",
        "google_scholar": "60HqQsQAAAAJ;JKwP43sAAAAJ;https://scholar.google.com.hk/citations?view_op=list_works;qYQHl4sAAAAJ;https://scholar.google.com/citations?hl=zh-CN;IPIZUVAAAAAJ;;8e7H3PcAAAAJ",
        "orcid": "0000-0002-8950-383X;0000-0002-8431-3703;0009-0001-6804-542X;0000-0003-3440-9675;;0000-0002-0984-8740;;0000-0002-7356-9711",
        "linkedin": ";haizhou-shi-229206180/;;yongchaoliu;;boci-peng-4b357b226/;;siliang-tang-4734272a/",
        "or_profile": "~Yun_Zhu4;~Haizhou_Shi1;~Xiaotang_Wang1;~Yongchao_Liu2;~Yaoke_Wang1;~Boci_Peng1;~Chuntao_Hong1;~Siliang_Tang1",
        "aff": "Shanghai AI Laboratory+Zhejiang University;Rutgers University, New Brunswick;The Hong Kong University of Science and Technology (Guangzhou)+Huazhong University of Science and Technology;Ant Group;Zhejiang University;Peking University;Alibaba Group;Zhejiang University",
        "aff_domain": "pjlab.org.cn+zju.edu.cn;rutgers.edu;hkust-gz.edu.cn+hust.edu.cn;antgroup.com;zju.edu.cn;pku.edu.cn;antgroup.com;zju.edu.cn",
        "position": "Researcher+PhD student;PhD student;PhD student+MS student;Researcher;MS student;PhD student;Researcher;Full Professor",
        "bibtex": "@inproceedings{\nzhu2025graphclip,\ntitle={Graph{CLIP}: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs},\nauthor={Yun Zhu and Haizhou Shi and Xiaotang Wang and Yongchao Liu and Yaoke Wang and Boci Peng and Chuntao Hong and Siliang Tang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=mjzss9Xg76}\n}",
        "github": "",
        "project": "",
        "reviewers": "RT5s;ExV2;LDqL;2A8e",
        "site": "https://openreview.net/forum?id=mjzss9Xg76",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "3;5;5;6",
        "scope": "4;3;4;4",
        "confidence": "3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.75,
            1.0897247358851685
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.13245323570650439
    },
    {
        "id": "mxIGQ0bIum",
        "title": "Does weighting improve matrix factorization for recommender systems?",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Matrix factorization is a widely used approach for top-N recommendations and collaborative filtering. When it is implemented on implicit feedback data (such as clicks), a common heuristic is to upweight the observed interactions. This strategy has been shown to improve the performance of certain algorithms. In this paper, we conduct a systematic study of various weighting schemes and matrix factorization algorithms. Somewhat surprisingly, we find that the best performing methods, as measured by the standard (unweighted) ranking accuracy on publicly available datasets, are trained using unweighted data. This observation challenges the conventional wisdom in the literature. Nevertheless, we identify cases where weighting can be beneficial, particularly for models with lower capacity and certain regularization schemes. We also derive efficient algorithms for minimizing a number of weighted objectives which were previously unexplored due to the lack of efficient optimization techniques. Our work provides a comprehensive analysis of the interplay between weighting, regularization, and model capacity in matrix factorization for recommender systems.",
        "keywords": "Recommender System; Collaborative Filtering; Autoencoder; Neighborhood Approach; Weighted Linear Regression; Matrix Factorization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Alex Ayoub;Samuel Robertson;Dawen Liang;Harald Steck;Nathan Kallus",
        "authorids": "~Alex_Ayoub1;~Samuel_Robertson1;~Dawen_Liang1;~Harald_Steck1;~Nathan_Kallus1",
        "gender": "M;;M;;",
        "homepage": ";http://www.openreview.net;https://dawenl.github.io;;http://nathankallus.com/",
        "dblp": "266/8071;;63/10572;63/3157;142/2900",
        "google_scholar": "eh0TSgYAAAAJ;;4c1ZNm4AAAAJ;;K2WfIlsAAAAJ",
        "orcid": ";;;;0000-0003-1672-0507",
        "linkedin": ";;;;",
        "or_profile": "~Alex_Ayoub1;~Samuel_Robertson1;~Dawen_Liang1;~Harald_Steck1;~Nathan_Kallus1",
        "aff": "University of Alberta;University of Alberta;Netflix;NetFlix;Netflix+Cornell University",
        "aff_domain": "ualberta.ca;ualberta.ca;netflix.com;netflix.com;netflix.com+cornell.edu",
        "position": "PhD student;MS student;Research Scientist;Senior Data Scientist;Research Director+Associate Professor",
        "bibtex": "@inproceedings{\nayoub2025does,\ntitle={Does weighting improve matrix factorization for recommender systems?},\nauthor={Alex Ayoub and Samuel Robertson and Dawen Liang and Harald Steck and Nathan Kallus},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=mxIGQ0bIum}\n}",
        "github": "",
        "project": "",
        "reviewers": "Tayd;kCin;hGmx;vTbr;v7Lr",
        "site": "https://openreview.net/forum?id=mxIGQ0bIum",
        "pdf_size": 0,
        "novelty": "3;4;4;5;6",
        "technical_quality": "4;6;5;6;6",
        "scope": "4;3;4;3;4",
        "confidence": "4;4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6289709020331511
    },
    {
        "id": "n1HoTshiz5",
        "title": "UNIDEC : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Extreme Multi-label Classification (XMC) involves predicting a subset of relevant labels from an extremely large label space, given an input query and labels with textual features. Models developed for this problem have conventionally made use of dual encoder (DE) to embed the queries and label texts and one-vs-all (OvA) classifiers to rerank the shortlisted labels by the DE. While such methods have shown empirical success, a major drawback is their computational cost, often requiring upto 16 GPUs to train on the largest public dataset. Such a high cost is a consequence of calculating the loss over the entire label space. While shortlisting strategies have been proposed for classifiers, we aim to study such methods for the DE framework. In this work, we develop UniDEC, a loss-independent, end-to-end trainable framework which trains the DE and classifier together in a unified manner with a multi-class loss, while reducing the computational cost by 4-16x. This is done via the proposed pick-some-label (PSL) reduction, which aims to compute the loss on only a subset of positive and negative labels. These labels are carefully chosen in-batch so as to maximise their supervisory signals. Not only does the proposed framework achieve state-of-the-art results on datasets with labels in the order of millions, it is also computationally and resource efficient in achieving this performance on a single GPU. Code is provided with the submission and will be open-sourced upon acceptance.",
        "keywords": "Extreme Classification;Retrieval",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Siddhant Kharbanda;Devaansh Gupta;Gururaj K;Pankaj Malhotra;Amit S;Cho-Jui Hsieh;Rohit Babbar",
        "authorids": "~Siddhant_Kharbanda1;~Devaansh_Gupta1;~Gururaj_K1;~Pankaj_Malhotra2;~Amit_S1;~Cho-Jui_Hsieh1;~Rohit_Babbar1",
        "gender": "M;M;M;M;M;M;",
        "homepage": ";https://devaansh100.github.io;;;;http://web.cs.ucla.edu/~chohsieh/index.html;",
        "dblp": "302/0835;351/9786;;42/811;;14/2770;",
        "google_scholar": "4lVrfloAAAAJ;lSBqiz4AAAAJ;;HP4M0MkAAAAJ;;Wy89g4IAAAAJ;",
        "orcid": "0009-0000-6847-5836;;0000-0001-9235-4815;;0000-0002-0669-5283;;",
        "linkedin": "siddhant-kharbanda-32782b18a/;devaanshgupta/;;;https://in.linkedin.com/in/amitoengg;;",
        "or_profile": "~Siddhant_Kharbanda1;~Devaansh_Gupta1;~Gururaj_K1;~Pankaj_Malhotra2;~Amit_S1;~Cho-Jui_Hsieh1;~Rohit_Babbar1",
        "aff": "Inception AI;University of California, Los Angeles;Microsoft;Microsoft;Microsoft;Google+University of California, Los Angeles;",
        "aff_domain": "inceptionai.xyz;ucla.edu;microsoft.com;microsoft.com;microsoft.com;google.com+ucla.edu;",
        "position": "Researcher;MS student;Researcher;Principal Researcher;Applied Research;Researcher+Associate Professor;",
        "bibtex": "@inproceedings{\nkharbanda2025unidec,\ntitle={{UNIDEC} : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification},\nauthor={Siddhant Kharbanda and Devaansh Gupta and Gururaj K and Pankaj Malhotra and Amit S and Cho-Jui Hsieh and Rohit Babbar},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=n1HoTshiz5}\n}",
        "github": "",
        "project": "",
        "reviewers": "eAi9;W8ag;BDjw;z536",
        "site": "https://openreview.net/forum?id=n1HoTshiz5",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "3;5;5;5",
        "scope": "1;3;3;4",
        "confidence": "1;2;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            4.5,
            0.8660254037844386
        ],
        "scope_avg": [
            2.75,
            1.0897247358851685
        ],
        "confidence_avg": [
            2.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7071067811865475
    },
    {
        "id": "n6mjapwzQd",
        "title": "Ranking Items by the Current-Preferences and Profits: A List-wise Learning-to-Rank Approach to Profit Maximization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In e-commerce platforms, profit-aware recommender systems aim to improve the platform's profits while maintaining high overall accuracy by recommending items with high profits as top-ranked items. We explore two issues faced by existing model-based profit-aware approaches (i.e., MBAs) when training recommendation models for profit enhancement. First, current MBAs tend to inaccurately infer the item ranking by the profit-based weighting scheme; the ranking of observed (i.e., purchased) items by a user is inferred without considering the user preference for each item, while all unobserved items are assumed to have an equally low ranking. Second, current MBAs train the model without employing the item ranking as ground truth; during training, the model is optimized for the preference score for each item independently rather than being directly optimized for the overall ranking of items. To tackle these issues, we propose a novel MBA that involves three key steps: (S1) defining the Current Preference incorporated with Profit (i.e., CPP) for items; (S2) classifying items through CPP; and (S3) training the model by list-wise learning-to-rank (LTR) based on CPP. Extensive experimental results using real-world platform datasets demonstrate that our approach improves accuracy by approximately 4% and profits by about 24% compared to the best-competing method.",
        "keywords": "Collaborative filtering;List-wise learning-to-rank;Profit maximization;Recommender systems",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hong-Kyun Bae;Hae-Ri Jang;Won-Yong Shin;Sang-Wook Kim",
        "authorids": "~Hong-Kyun_Bae1;~Hae-Ri_Jang1;~Won-Yong_Shin1;~Sang-Wook_Kim1",
        "gender": "M;F;M;M",
        "homepage": "https://hongkyun-bae.github.io/;https://bigdas.hanyang.ac.kr/alumni/haeri%20jang/;https://sites.google.com/site/midasyonsei/faculty?authuser=0;https://bigdas.hanyang.ac.kr/",
        "dblp": "308/6469;374/9836;05/2819;64/5810",
        "google_scholar": "pmX6O10AAAAJ;EmpT7mYAAAAJ;PwOjMLEAAAAJ;https://scholar.google.co.kr/citations?user=ed2vz_oAAAAJ",
        "orcid": "0009-0009-4104-9111;0009-0002-0592-6155;0000-0002-6533-3469;0000-0002-6345-9084",
        "linkedin": ";;;",
        "or_profile": "~Hong-Kyun_Bae1;~Hae-Ri_Jang1;~Won-Yong_Shin1;~Sang-Wook_Kim1",
        "aff": "Kookmin University+Hanyang University;;Yonsei University;",
        "aff_domain": "kookmin.ac.kr+hanyang.ac.kr;;yonsei.ac.kr;",
        "position": "Assistant Professor+Postdoc;;Full Professor;",
        "bibtex": "@inproceedings{\nbae2025ranking,\ntitle={Ranking Items by the Current-Preferences and Profits: A List-wise Learning-to-Rank Approach to Profit Maximization},\nauthor={Hong-Kyun Bae and Hae-Ri Jang and Won-Yong Shin and Sang-Wook Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=n6mjapwzQd}\n}",
        "github": "",
        "project": "",
        "reviewers": "37G5;xxiS;NrEs;P7Gf;Bwrd",
        "site": "https://openreview.net/forum?id=n6mjapwzQd",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "3;3;5;6;6",
        "scope": "3;4;3;3;4",
        "confidence": "3;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            1.3564659966250536
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.375
    },
    {
        "id": "nB1Apc36yp",
        "title": "Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The rapid development of large language models (LLMs), like ChatGPT, has resulted in the widespread presence of LLM-generated content on social media platforms, raising concerns about misinformation, data biases, and privacy violations, which can undermine trust in online discourse. While detecting LLM-generated content is crucial for mitigating these risks, current methods often focus on binary classification, failing to address the complexities of real-world scenarios like human-AI collaboration. To move beyond binary classification and address these challenges, we propose a new paradigm for detecting LLM-generated content. This approach introduces two novel tasks: LLM Role Recognition (LLM-RR), a multi-class classification task that identifies specific roles of LLM in content generation, and LLM Influence Measurement (LLM-IM), a regression task that quantifies the extent of LLM involvement in content creation. To support these tasks, we propose LLMDetect, a benchmark designed to evaluate detectors' performance on these new tasks. LLMDetect includes the Hybrid News Detection Corpus (HNDC) for training detectors, as well as DetectEval, a comprehensive evaluation suite that considers five distinct cross-context variations and multi-intensity variations within the same LLM role. This allows for a thorough assessment of detectors' generalization and robustness across diverse contexts. Our empirical validation of 10 baseline detection methods demonstrates that fine-tuned Pre-trained Language Model (PLM)-based models consistently outperform others on both tasks, while advanced LLMs face challenges in accurately detecting their own generated content. Our experimental results and analysis offer insights for developing more effective detection models for LLM-generated content. This research enhances the understanding of LLM-generated content and establishes a foundation for more nuanced detection methodologies.",
        "keywords": "Social Media;Large Language Models;LLM-generated Text Detection;AI-assisted News Detection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zihao Cheng;Li Zhou;Feng Jiang;Benyou Wang;Haizhou Li",
        "authorids": "~Zihao_Cheng1;~Li_Zhou4;~Feng_Jiang4;~Benyou_Wang2;~Haizhou_Li3",
        "gender": "M;F;M;M;M",
        "homepage": "https://github.com/ZihaoCheng123;https://lizhou21.github.io/;;https://wabyking.github.io/old.html;https://colips.org/~eleliha/",
        "dblp": ";;75/1693-7;169/1793;36/4118",
        "google_scholar": ";https://scholar.google.com.hk/citations?user=BLWhoYcAAAAJ;zrxpiWYAAAAJ;Jk4vJU8AAAAJ;https://scholar.google.com.sg/citations?user=z8_x7C8AAAAJ",
        "orcid": ";;0000-0002-3465-311X;0000-0002-1501-9914;0000-0001-9158-9401",
        "linkedin": ";;;;haizhou-li-4ba74b6/",
        "or_profile": "~Zihao_Cheng1;~Li_Zhou4;~Feng_Jiang4;~Benyou_Wang2;~Haizhou_Li3",
        "aff": "The Chinese University of Hong Kong;The Chinese University of Hong Kong, Shenzhen;Shenzhen University of Advanced Technology+The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong, Shenzhen;The Chinese University of Hong Kong (Shenzhen); National University of Singapore+National University of Singapore",
        "aff_domain": "cuhk.edu.cn;cuhk.edu.cn;suat-sz.edu.cn+cuhk.edu.cn;cuhk.edu.cn;cuhk.edu.cn+nus.edu.sg",
        "position": "MS student;Postdoc;Associate Researcher+Postdoc;Assistant Professor;Full Professor+Full Professor",
        "bibtex": "@inproceedings{\ncheng2025beyond,\ntitle={Beyond Binary: Towards Fine-Grained {LLM}-Generated Text Detection via Role Recognition and Involvement Measurement},\nauthor={Zihao Cheng and Li Zhou and Feng Jiang and Benyou Wang and Haizhou Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=nB1Apc36yp}\n}",
        "github": "",
        "project": "",
        "reviewers": "h9C1;PAY3;bcB8;RQLA;Cc53",
        "site": "https://openreview.net/forum?id=nB1Apc36yp",
        "pdf_size": 0,
        "novelty": "4;5;5;6;7",
        "technical_quality": "5;4;5;6;7",
        "scope": "3;3;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            5.4,
            1.0198039027185568
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "nV86gaEqfW",
        "title": "ExpressPQDelivery : Toward Efficient and Immediately Deployable Post-Quantum Key Delivery for Web-of-Things",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Post-quantum cryptography (PQC) aims to develop quantum-safe algorithms against attacks by a quantum computer. As quantum-safe algorithms require much larger keys in their operation compared to the current RSA/ECC practice, the networking latency significantly increases when executing the protocols with sending such large keys. This problem gets more challenging in the era of Web-of-Things (WoTs) with low-memory devices. To tackle the problem, we propose ExpressPQDelivery, which is, to the best of our knowledge, the first immediately deployable protocol to efficiently transport large keys. It leverages the DNS infrastructure, as DNS is close to clients, guaranteeing express key delivery with a short round-trip time (RTT). We split a large PQ key along with a server's signature and feed them into several DNS records. To show the feasibility of ExpressPQDelivery, we instantiate it with TLS 1.3 and demonstrate that it reduces 27\\% of network latency between a server and a client on average compared to the standard TLS 1.3. We deploy ExpressPQDelivery on a low-capability board with 256 KB RAM, showing a significant high gain (34\\%).",
        "keywords": "transport layer security;post-quantum cryptography",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jane kim;Jung-Hun Kang;Hyunwoo Lee;Seung-hyun seo",
        "authorids": "~Jane_kim1;~Jung-Hun_Kang1;~Hyunwoo_Lee5;~Seung-hyun_seo1",
        "gender": "F;M;M;F",
        "homepage": ";;https://hw5773.github.io;https://sites.google.com/view/esplab/home",
        "dblp": ";;55/8846-1.html;",
        "google_scholar": ";;https://scholar.google.com/citations?hl=ko;https://scholar.google.co.kr/citations?hl=ko",
        "orcid": ";0009-0002-3075-9440;0000-0001-7490-9936;",
        "linkedin": "%EC%A0%9C%EC%9D%B8-%EA%B9%80-3827121b9/;;hw5773/;",
        "or_profile": "~Jane_kim1;~Jung-Hun_Kang1;~Hyunwoo_Lee5;~Seung-hyun_seo1",
        "aff": "Hanyang University;Hanyang University;Korean Institute of Energy Technology;Hanyang University",
        "aff_domain": "hanyang.ac.kr;hanyang.ac.kr;kentech.ac.kr;hanyang.ac.kr",
        "position": "PhD student;MS student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nkim2025expresspqdelivery,\ntitle={Express{PQD}elivery : Toward Efficient and Immediately Deployable Post-Quantum Key Delivery for Web-of-Things},\nauthor={Jane kim and Jung-Hun Kang and Hyunwoo Lee and Seung-hyun seo},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=nV86gaEqfW}\n}",
        "github": "",
        "project": "",
        "reviewers": "oQoM;Q5Jq;mjis;SV2e;2jU6",
        "site": "https://openreview.net/forum?id=nV86gaEqfW",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "3;5;5;5;5",
        "scope": "2;4;3;3;3",
        "confidence": "3;3;1;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5624999999999999
    },
    {
        "id": "nvd2unLfbI",
        "title": "MCNet: Monotonic Calibration Networks for Expressive Uncertainty Calibration in Online Advertising",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In online advertising, uncertainty calibration aims to adjust a ranking model's probability predictions to better approximate the true likelihood of an event, e.g., a click or a conversion. However, existing calibration approaches may lack the ability to effectively model complex nonlinear relations, consider context features, and achieve balanced performance across different data subsets. To tackle these challenges, we introduce a novel model called Monotonic Calibration Networks, featuring three key designs: a monotonic calibration function (MCF), an order-preserving regularizer, and a field-balance regularizer. The nonlinear MCF is capable of naturally modeling and universally approximating the intricate relations between uncalibrated predictions and the posterior probabilities, thus being much more expressive than existing methods. MCF can also integrate context features using a flexible model architecture, thereby achieving context awareness. The order-preserving and field-balance regularizers promote the monotonic relationship between adjacent bins and the balanced calibration performance on data subsets, respectively. Experimental results on both public and industrial datasets demonstrate the superior performance of our method in generating well-calibrated probability predictions.",
        "keywords": "Uncertainty Calibration;Online Advertising;Monotonic Neural Networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Quanyu Dai;Jiaren Xiao;Zhaocheng Du;Jieming Zhu;Chengxiao Luo;Xiao-Ming Wu;Zhenhua Dong",
        "authorids": "~Quanyu_Dai1;~Jiaren_Xiao1;~Zhaocheng_Du1;~Jieming_Zhu2;~Chengxiao_Luo1;~Xiao-Ming_Wu1;~Zhenhua_Dong1",
        "gender": "M;;M;M;;F;",
        "homepage": ";;;https://jiemingzhu.github.io/;;http://www4.comp.polyu.edu.hk/~csxmwu/;",
        "dblp": "210/1089;;351/9561.html;10/2717;;98/2898-3;",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;YYnrPzEAAAAJ;oNKerP8AAAAJ;p_1uVLQAAAAJ;3KbaUFkAAAAJ;",
        "orcid": "0000-0001-7578-2738;;0000-0002-1811-129X;0000-0002-5666-8320;;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Quanyu_Dai1;~Jiaren_Xiao1;~Zhaocheng_Du1;~Jieming_Zhu2;~Chengxiao_Luo1;~Xiao-Ming_Wu1;~Zhenhua_Dong1",
        "aff": "Huawei Technologies Ltd.;;Huawei Technologies Ltd.;Huawei Noah's Ark Lab;Tsinghua University;Hong Kong Polytechnic University;",
        "aff_domain": "huawei.com;;huawei.com;huawei.com;tsinghua.edu.cn;polyu.edu.hk;",
        "position": "Researcher;;Researcher;Researcher;MS student;Associate Professor;",
        "bibtex": "@inproceedings{\ndai2025mcnet,\ntitle={{MCN}et: Monotonic Calibration Networks for Expressive Uncertainty Calibration in Online Advertising},\nauthor={Quanyu Dai and Jiaren Xiao and Zhaocheng Du and Jieming Zhu and Chengxiao Luo and Xiao-Ming Wu and Zhenhua Dong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=nvd2unLfbI}\n}",
        "github": "",
        "project": "",
        "reviewers": "dLT4;R7ze;WcM8;9snk",
        "site": "https://openreview.net/forum?id=nvd2unLfbI",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "3;5;5;6",
        "scope": "3;4;4;3",
        "confidence": "3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.75,
            1.0897247358851685
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "oHka3683Cb",
        "title": "Enabling Real-Time Inference in Online Continual Learning via Device-Cloud Collaboration",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Online continual learning (CL) is becoming a mainstream paradigm to learn incrementally from task streams without forgetting previously learned knowledge. However, current online CL primarily focuses on the learning performance, such as avoiding catastrophic forgetting, neglecting the critical demands of real-time inference. As a result, the performance of real-time inference in online CL degrades significantly due to frequent data distribution variations and time-consuming incremental model adaptation. In this work, we propose ELITE, an online CL framework with device-cloud collaboration, to realize on-device real-time inference on time-varying task streams with performance guarantee. To realize on-device real-time inference in online CL, ELITE features a new design of the model zoo comprising various pre-trained models with the assistance of the cloud, and proposes a task-oriented on-device model selection to quickly retrieve the best-fit models instead of performing time-consuming model retraining. To prevent performance degradation on new tasks not available in the cloud, we introduces a latency-aware on-device model fine-tuning strategy to adapt to new tasks with accuracy-latency trade-off, and dynamically updates the model zoo in the cloud to enhance ELITE. Extensive evaluations on five real-world datasets have been conducted, and the results demonstrate that ELITE consistently outperforms the state-of-art solutions, improving the accuracy by 16.3\\% on average and reducing the response latency by up to 1.98 times.",
        "keywords": "Online Continual Learning; Real-Time Inference; Device-Cloud Collaboration.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Haibo Liu;Chen Gong;Zhenzhe Zheng;Shengzhong Liu;Fan Wu",
        "authorids": "~Haibo_Liu2;~Chen_Gong6;~Zhenzhe_Zheng1;~Shengzhong_Liu1;~Fan_Wu10",
        "gender": ";M;M;M;M",
        "homepage": "https://www.linkedin.com/in/haibo-liu-279a75321/;https://gongchenooo.github.io/;https://zhengzhenzhe220.github.io/;https://liushengzhong1023.github.io/;https://www.cs.sjtu.edu.cn/~fwu/",
        "dblp": "83/1694;21/8587-6;132/8083;166/5424;07/6378-15.html",
        "google_scholar": "thYLaZgAAAAJ;HmEvi20AAAAJ;kx_5xxEAAAAJ;REzrIucAAAAJ;NwoNqygAAAAJ",
        "orcid": "0000-0002-6411-3448;0000-0003-0333-6418;0000-0002-5094-5331;;0000-0003-0965-9058",
        "linkedin": "haibo-liu-279a75321/;;;;",
        "or_profile": "~Haibo_Liu2;~Chen_Gong6;~Zhenzhe_Zheng1;~Shengzhong_Liu1;~Fan_Wu10",
        "aff": "Shanghai Jiaotong University;Shanghai Jiaotong University;Shanghai Jiaotong University;Shanghai Jiaotong University;Shanghai Jiaotong University",
        "aff_domain": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "position": "PhD student;PhD student;Full Professor;Associate Professor;Professor",
        "bibtex": "@inproceedings{\nliu2025enabling,\ntitle={Enabling Real-Time Inference in Online Continual Learning via Device-Cloud Collaboration},\nauthor={Haibo Liu and Chen Gong and Zhenzhe Zheng and Shengzhong Liu and Fan Wu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=oHka3683Cb}\n}",
        "github": "",
        "project": "",
        "reviewers": "8sQq;4DGH;DriV;ZSRt",
        "site": "https://openreview.net/forum?id=oHka3683Cb",
        "pdf_size": 0,
        "novelty": "2;4;6;6",
        "technical_quality": "3;4;6;6",
        "scope": "3;3;4;4",
        "confidence": "3;3;1;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            1.6583123951777
        ],
        "technical_quality_avg": [
            4.75,
            1.299038105676658
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5222329678670935
    },
    {
        "id": "oQU1OrqNl7",
        "title": "Hyperbolic Diffusion Recommender Model",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Diffusion models (DMs) have emerged as the new state-of-the-art family of deep generative models. To gain deeper insights into the limitations of diffusion models in recommender systems, we investigate the fundamental structural disparities between images and items. Consequently, items often exhibit distinct anisotropic and directional structures that are less prevalent in images. However, the traditional forward diffusion process continuously adds isotropic Gaussian noise, causing anisotropic signals to degrade into noise, which impairs the semantically meaningful representations in recommender systems.\n\nInspired by the advancements in hyperbolic spaces, we propose a novel \\textbf{H}yperbolic \\textbf{D}iffusion \\textbf{R}ecommender \\textbf{M}odel (named HDRM). Unlike existing directional diffusion methods based on Euclidean space, the intrinsic non-Euclidean structure of hyperbolic space makes it particularly well-adapted for handling anisotropic diffusion processes. In particular, we begin by constructing a geometrically latent space grounded in hyperbolic geometry, incorporating interpretability measures to define the latent anisotropic diffusion processes. Subsequently, we propose a novel hyperbolic latent diffusion process specifically tailored for users and items. Drawing upon the natural geometric attributes of hyperbolic spaces, we restrict both radial and angular components to facilitate directional diffusion propagation, thereby ensuring the preservation of the original topological structure in user-item interaction graphs. Extensive experiments on three benchmark datasets demonstrate the effectiveness of HDRM. Our code is available at\n\\url{https://anonymous.4open.science/status/HDRM-ECFA}.",
        "keywords": "recommender system;hyperbolic spaces;diffusion models.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Meng Yuan;Yutian Xiao;Wei Chen;Chu Zhao;deqing wang;Fuzhen Zhuang",
        "authorids": "~Meng_Yuan1;~Yutian_Xiao2;~Wei_Chen39;~Chu_Zhao1;~deqing_wang2;~Fuzhen_Zhuang1",
        "gender": "M;;;;M;M",
        "homepage": "https://orcid.org/0000-0003-4016-5048;https://github.com/nqxytttt;;;https://ktl.buaa.edu.cn/;https://fuzhenzhuang.github.io/index.html",
        "dblp": ";263/2001.html;;;;48/5638",
        "google_scholar": ";;;;NrYqxY4AAAAJ;https://scholar.google.com/citations?hl=en",
        "orcid": ";0000-0002-8276-7920;;;0000-0001-6441-4390;0000-0001-9170-7009",
        "linkedin": ";;;;;",
        "or_profile": "~Meng_Yuan1;~Yutian_Xiao2;~Wei_Chen39;~Chu_Zhao1;~deqing_wang2;~Fuzhen_Zhuang1",
        "aff": "Beihang University;Beihang University;;;Beihang University;School of Artificial Intelligence, Beihang University+Institute of Computing Technology, Chinese Academy of Sciences",
        "aff_domain": "buaa.edu.cn;buaa.edu.cn;;;buaa.edu.cn;buaa.edu.cn+ict.ac.cn",
        "position": "PhD student;PhD student;;;Full Professor;Professor+Associate Professor",
        "bibtex": "@inproceedings{\nyuan2025hyperbolic,\ntitle={Hyperbolic Diffusion Recommender Model},\nauthor={Meng Yuan and Yutian Xiao and Wei Chen and Chu Zhao and deqing wang and Fuzhen Zhuang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=oQU1OrqNl7}\n}",
        "github": "",
        "project": "",
        "reviewers": "YF9h;2YKE;LteD;eztn;dsQa",
        "site": "https://openreview.net/forum?id=oQU1OrqNl7",
        "pdf_size": 0,
        "novelty": "3;4;4;6;6",
        "technical_quality": "4;4;5;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "4;4;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.2
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.801783725737273
    },
    {
        "id": "oW1XWv6Oll",
        "title": "Empowering Federated Graph Rationale Learning with Latent Environments",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The success of Graph Neural Networks (GNNs) in graph classification has heightened interest in explainable GNNs, particularly through graph rationalization. This method aims to enhance GNNs explainability by identifying subgraph structures (i.e., rationales) that support model predictions. However, existing methods often rely on centralized datasets, posing challenges in scenarios where data privacy is crucial, such as in molecular property prediction. Federated Learning (FL) offers a solution by enabling collaborative model training without sharing raw data. In this context, Federated Graph Rationalization emerges as a promising research direction. However, in each client, the rationalization methods often rely on client-specific shortcuts to compose rationales and make task predictions.  Data heterogeneity, characterized by non-IID data across clients, exacerbates this problem, leading to poor prediction performance. To address these challenges, we propose the Environment-aware Data Augmentation (EaDA) method for Federated Graph Rationalization. EaDA comprises two main components: the Environment-aware Rationale Extraction (ERE) module and the Local-Global Alignment (LGA) module. The ERE module employs prototype learning to infer and share abstract environment information across clients, which are then aggregated to form a global environment. This information is used to generate counterfactual samples for local clients, enhancing the robustness of task predictions. The LGA module uses contrastive learning methods to align local and global rationale representations, mitigating performance degradation due to data heterogeneity. Comprehensive experiments on benchmark datasets demonstrate the effectiveness of our approaches.",
        "keywords": "Federated Learning;Graph Rationalization;Explainability",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Linan Yue;Qi Liu;Yawen Li;Fangzhou Yao;Weibo Gao;Junping Du",
        "authorids": "~Linan_Yue1;~Qi_Liu3;~Yawen_Li3;~Fangzhou_Yao1;~Weibo_Gao1;~Junping_Du1",
        "gender": "M;M;F;;;F",
        "homepage": "https://yuelinan.github.io/;http://staff.ustc.edu.cn/~qiliuql/;https://teacher.bupt.edu.cn/liyawen/en/index.htm;;;https://teacher.bupt.edu.cn/dujunping/en/index.htm",
        "dblp": "297/1080;95/2446-3;30/4774-1;;;13/1151-1",
        "google_scholar": "https://scholar.google.com.hk/citations?user=XDaNgG4AAAAJ;5EoHAFwAAAAJ;;;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0000-0002-5980-6098;0000-0001-6956-5550;0000-0003-2662-3444;;;0000-0002-9402-3806",
        "linkedin": ";;;;;",
        "or_profile": "~Linan_Yue1;~Qi_Liu3;~Yawen_Li3;~Fangzhou_Yao1;~Weibo_Gao1;~Junping_Du1",
        "aff": "Southeast University;University of Science and Technology of China;Beijing University of Posts and Telecommunications;;;Beijing University of Posts and Telecommunications",
        "aff_domain": "seu.edu.cn;ustc.edu.cn;bupt.edu.cn;;;bupt.edu.cn",
        "position": "Associate Professor;Full Professor;Associate Professor;;;Full Professor",
        "bibtex": "@inproceedings{\nyue2025empowering,\ntitle={Empowering Federated Graph Rationale Learning with Latent Environments},\nauthor={Linan Yue and Qi Liu and Yawen Li and Fangzhou Yao and Weibo Gao and Junping Du},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=oW1XWv6Oll}\n}",
        "github": "",
        "project": "",
        "reviewers": "8TX1;vsAj;T3dP;1FTL",
        "site": "https://openreview.net/forum?id=oW1XWv6Oll",
        "pdf_size": 0,
        "novelty": "3;4;4;6",
        "technical_quality": "3;3;5;7",
        "scope": "3;4;3;4",
        "confidence": "2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.5,
            1.6583123951777
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9733285267845754
    },
    {
        "id": "oYJ4ih7DBl",
        "title": "Tackling Sparse Facts for Temporal Knowledge Graph Completion",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Temporal knowledge graph completion (TKGC) seeks to develop more comprehensive knowledge representations by addressing missing relationships and entities within temporal knowledge graphs (TKGs), thereby enhancing reasoning and predictive capabilities in downstream tasks. Nonetheless, real-world knowledge\u2014such as the progression of social network interactions and the unfolding of news events\u2014is inherently dynamic, resulting in substantial sparsity issues in TKGs that profoundly impair the performance of TKGC models. To overcome this challenge, we introduce the Adaptive Neighborhood Enhancement Layer (ANEL), a novel module that can be effortlessly integrated into existing TKGC models to substantially elevate the representation quality of sparse entities. ANEL first derives initial entity embeddings through a base model and then uncovers concealed semantic relationships between entities via a latent relation module, enriching the explicit relationships within the knowledge graph. Furthermore, ANEL incorporates an adaptive latent information adjustment component, which dynamically calibrates the influence of latent information based on the entity's relational structure: entities with fewer connections derive greater benefit from latent information, while entities with denser connections become less dependent on latent augmentation, ensuring precise and resilient representations. We conducted comprehensive experiments on four prominent benchmark datasets, and the results underscore the effectiveness and superiority of ANEL in TKGC tasks. The code is available at: https://anonymous.4open.science/r/ANEL-177F.",
        "keywords": "Knowledge Representation;Temporal Knowledge Graph Completion;Fact Sparsity",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuchao Zhang;Xiangjie Kong;Kailun Ye;Guojiang Shen;Shangfei Zheng",
        "authorids": "~Yuchao_Zhang5;~Xiangjie_Kong1;~Kailun_Ye1;~Guojiang_Shen1;~Shangfei_Zheng1",
        "gender": "M;M;M;M;M",
        "homepage": ";http://www.cssclab.cn/xjkong/;https://github.com/swiderrrr;https://homepage.zjut.edu.cn//sgj/;",
        "dblp": ";74/8773;;;",
        "google_scholar": "https://scholar.google.com.hk/citations?view_op=list_works;Z0dStKsAAAAJ;;;",
        "orcid": ";0000-0003-2698-3319;;;0000-0002-7286-5631",
        "linkedin": ";;;;",
        "or_profile": "~Yuchao_Zhang5;~Xiangjie_Kong1;~Kailun_Ye1;~Guojiang_Shen1;~Shangfei_Zheng1",
        "aff": "Zhejiang University of Technology;Zhejiang University of Technology;Zhejiang University of Technology;Zhejiang University of Technology;Zhejiang Sci-Tech University",
        "aff_domain": "zjut.edu.cn;zjut.edu.cn;zjut.edu.cn;zjut.edu.cn;zstu.edu.cn",
        "position": "PhD student;Full Professor;MS student;Full Professor;Lecturer",
        "bibtex": "@inproceedings{\nzhang2025tackling,\ntitle={Tackling Sparse Facts for Temporal Knowledge Graph Completion},\nauthor={Yuchao Zhang and Xiangjie Kong and Kailun Ye and Guojiang Shen and Shangfei Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=oYJ4ih7DBl}\n}",
        "github": "",
        "project": "",
        "reviewers": "PC6m;PgUc;KZ1o;rVmN;r3cp",
        "site": "https://openreview.net/forum?id=oYJ4ih7DBl",
        "pdf_size": 0,
        "novelty": "2;4;5;5;5",
        "technical_quality": "5;4;5;4;5",
        "scope": "2;3;4;4;3",
        "confidence": "3;2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.21004201260420152
    },
    {
        "id": "pGNc9zxcOq",
        "title": "Surprisingly Popular Voting with Concentric Rank-Order Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "An important problem on social information sites is the recovery of ground truth from individual reports when the experts are in the minority. The wisdom of the crowd, i.e. the collective opinion of a group of individuals fails in such a scenario. However, the surprisingly popular (SP) algorithm~\\cite{prelec2017solution} can recover the ground truth even when the experts are in the minority, by asking the individuals to report additional prediction reports -- their beliefs about the reports of others. Several recent works have extended the surprisingly popular algorithm to an equivalent voting rule (SP-voting) to recover the ground truth ranking over a set of $m$ alternatives. However, we are yet to fully understand when SP-voting can recover the ground truth ranking, and if so, how many samples (votes and predictions) it needs. We answer this question by proposing two rank-order models and analyzing the sample complexity of SP-voting under these models. In particular, we propose concentric mixtures of Mallows and Plackett-Luce models with $G (\\ge 2)$ groups. Our models generalize previously proposed concentric mixtures of Mallows models with $2$ groups, and we highlight the importance of $G > 2$ groups by identifying three distinct groups (expert, intermediate, and non-expert) from existing datasets. Next, we provide conditions on the parameters of the underlying models so that SP-voting can recover ground-truth rankings with high probability, and also derive sample complexities under the same. We complement the theoretical results by evaluating SP-voting on simulated and real datasets.",
        "keywords": "Surprisingly Popular Voting;Mixture Models;Preference Aggregation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hadi Hosseini;Debmalya Mandal;Amrit Puhan",
        "authorids": "~Hadi_Hosseini4;~Debmalya_Mandal2;~Amrit_Puhan1",
        "gender": ";M;M",
        "homepage": "https://faculty.ist.psu.edu/hadi/;https://debmandal.github.io;https://www.amritpuhan.com",
        "dblp": "10/8187.html;151/3685;325/6917",
        "google_scholar": "https://scholar.google.com/citations?hl=en;OquWQpEAAAAJ;G1U8jiIAAAAJ",
        "orcid": "0000-0001-5468-6798;;",
        "linkedin": "hadihosseini;;amritpuhan/",
        "or_profile": "~Hadi_Hosseini4;~Debmalya_Mandal2;~Amrit_Puhan1",
        "aff": "Pennsylvania State University;University of Warwick;Pennsylvania State University",
        "aff_domain": "psu.edu;warwick.ac.uk;psu.edu",
        "position": "Associate Professor;Assistant Professor;MS student",
        "bibtex": "@inproceedings{\nhosseini2025surprisingly,\ntitle={Surprisingly Popular Voting with Concentric Rank-Order Models},\nauthor={Hadi Hosseini and Debmalya Mandal and Amrit Puhan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pGNc9zxcOq}\n}",
        "github": "",
        "project": "",
        "reviewers": "W6QH;QFCV;RQhV;T7rd;oo6U",
        "site": "https://openreview.net/forum?id=pGNc9zxcOq",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "5;4;6;4;5",
        "scope": "3;3;3;4;3",
        "confidence": "3;2;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7905694150420949
    },
    {
        "id": "pICsIg90kE",
        "title": "NFTs as a Data-Rich Test Bed: Conspicuous Consumption and its Determinants",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We show that the market for non-fungible tokens (NFTs), much like the luxury fashion market, exhibits conspicuous consumption dynamics: an NFT's value depends substantially on its social meaning as a signal of wealth, taste, and community affiliation. More specifically, we introduce a novel dataset of NFT transaction data combined with embeddings of the corresponding NFT images computed using an off-the-shelf vision transformer architecture. We use our dataset to identify evidence for two phenomena that prior work has identified as the primary determinants of conspicuous consumption: the \\emph{bandwagon effect} and the \\emph{snob effect}. For each determinant, we identify characteristics of the NFTs themselves and of the communities surrounding them that drive the effect.",
        "keywords": "NFT;blockchain;conspicuous consumption;empirical economics;digital goods",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Taylor Lundy;Narun Krishnamurthi Raman;Scott Kominers;Kevin Leyton-Brown",
        "authorids": "~Taylor_Lundy1;~Narun_Krishnamurthi_Raman1;~Scott_Kominers1;~Kevin_Leyton-Brown1",
        "gender": "M;M;M;Not Specified",
        "homepage": "https://cs.ubc.ca/~tlundy;https://narunraman.com;http://scottkom.com/;http://cs.ubc.ca/~kevinlb",
        "dblp": "243/2600;;52/7071;81/1149",
        "google_scholar": ";SEWbKagAAAAJ;YHSRCCsAAAAJ;_4dnp0IAAAAJ",
        "orcid": ";;;0000-0002-7644-5327",
        "linkedin": "taylor-lundy-8b915418b/;;scott-kominers/;kevinleytonbrown/",
        "or_profile": "~Taylor_Lundy1;~Narun_Krishnamurthi_Raman1;~Scott_Kominers1;~Kevin_Leyton-Brown1",
        "aff": "University of British Columbia;University of British Columbia;Harvard University, Harvard Business School+Quora+Meta Facebook;University of British Columbia",
        "aff_domain": "ubc.ca;ubc.ca;harvard.edu+quora.com+facebook.com;ubc.ca",
        "position": "PhD student;PhD student;Full Professor+Advisor+Advisor;Full Professor",
        "bibtex": "@inproceedings{\nlundy2025nfts,\ntitle={{NFT}s as a Data-Rich Test Bed: Conspicuous Consumption and its Determinants},\nauthor={Taylor Lundy and Narun Krishnamurthi Raman and Scott Kominers and Kevin Leyton-Brown},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pICsIg90kE}\n}",
        "github": "",
        "project": "",
        "reviewers": "5Jn7;vTgm;xUu5;w5gd;Nv3B",
        "site": "https://openreview.net/forum?id=pICsIg90kE",
        "pdf_size": 0,
        "novelty": "1;2;3;3;5",
        "technical_quality": "2;4;6;5;6",
        "scope": "3;3;3;3;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            2.8,
            1.32664991614216
        ],
        "technical_quality_avg": [
            4.6,
            1.4966629547095764
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "pKOJrwqXLh",
        "title": "TD3: Tucker Decomposition Based Dataset Distillation Method for Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In the era of data-centric AI, the focus of recommender systems has shifted from model-centric innovations to data-centric approaches. The success of modern AI models is built on large-scale datasets, but this also results in significant training costs. Dataset distillation has emerged as a key solution, condensing large datasets to accelerate model training while preserving model performance. However, condensing discrete and sequentially correlated user-item interactions, particularly with extensive item sets, presents considerable challenges. This paper introduces \\textbf{TD3}, a novel \\textbf{T}ucker \\textbf{D}ecomposition based \\textbf{D}ataset \\textbf{D}istillation method within a meta-learning framework, designed for sequential recommendation. TD3 distills a fully expressive \\emph{synthetic sequence summary} from original data. To efficiently reduce computational complexity and extract refined latent patterns, Tucker decomposition decouples the summary into four factors: \\emph{synthetic user latent factor}, \\emph{temporal dynamics latent factor}, \\emph{shared item latent factor}, and a \\emph{relation core} that models their interconnections. Additionally, a surrogate objective in bi-level optimization is proposed to align feature spaces extracted from models trained on both original data and synthetic sequence summary beyond the na\\\"ive performance matching approach. In the \\emph{inner-loop}, an augmentation technique allows the learner to closely fit the synthetic summary, ensuring an accurate update of it in the \\emph{outer-loop}. To accelerate the optimization process and address long dependencies, RaT-BPTT is employed for bi-level optimization. Experiments and analyses on multiple public datasets have confirmed the superiority and cross-architecture generalizability of the proposed designs. Codes are released at \\textcolor{blue}{\\url{https://anonymous.4open.science/r/TD3}}.",
        "keywords": "Sequential Recommendation; Dataset Distillation; Bi-level Optimization",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiaqing Zhang;Mingjia Yin;Hao Wang;Yawen Li;Yuyang Ye;Xingyu Lou;Junping Du;Enhong Chen",
        "authorids": "~Jiaqing_Zhang2;~Mingjia_Yin1;~Hao_Wang32;~Yawen_Li3;~Yuyang_Ye1;~Xingyu_Lou2;~Junping_Du1;~Enhong_Chen1",
        "gender": "M;;M;F;M;M;F;M",
        "homepage": ";https://shadowtinker.github.io/;http://staff.ustc.edu.cn/~wanghao3/;https://teacher.bupt.edu.cn/liyawen/en/index.htm;;;https://teacher.bupt.edu.cn/dujunping/en/index.htm;http://staff.ustc.edu.cn/~cheneh",
        "dblp": ";288/3952;181/2812-76;30/4774-1;194/4226-2;242/3345.html;13/1151-1;07/258",
        "google_scholar": "3kNE7u8AAAAJ;mI5RlZcAAAAJ;ou4Miu4AAAAJ;;q6Xx2FcAAAAJ;;https://scholar.google.com/citations?hl=zh-CN;Q9h02J0AAAAJ",
        "orcid": "0009-0001-1039-9735;0009-0005-0853-1089;0000-0001-9921-2078;0000-0003-2662-3444;0000-0002-1513-7814;;0000-0002-9402-3806;0000-0002-4835-4102",
        "linkedin": ";;;;yuyang-ye-298b23135/;;;",
        "or_profile": "~Jiaqing_Zhang2;~Mingjia_Yin1;~Hao_Wang32;~Yawen_Li3;~Yuyang_Ye1;~Xingyu_Lou2;~Junping_Du1;~Enhong_Chen1",
        "aff": "University of Science and Technology of China;University of Science and Technology of China;University of Science and Technology of China+University of Science and Technology of China;Beijing University of Posts and Telecommunications;ByteDance Inc.+Rutgers University;SUN YAT-SEN UNIVERSITY;Beijing University of Posts and Telecommunications;University of Science and Technology of China",
        "aff_domain": "ustc.edu.cn;ustc.edu.cn;ustc.edu.cn+ustc.edu.cn;bupt.edu.cn;bytedance.com+rutgers.edu;sysu.edu.cn;bupt.edu.cn;ustc.edu.cn",
        "position": "MS student;PhD student;Associate Professor+Associate Researcher;Associate Professor;Researcher+PhD student;Researcher;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025td,\ntitle={{TD}3: Tucker Decomposition Based Dataset Distillation Method for Sequential Recommendation},\nauthor={Jiaqing Zhang and Mingjia Yin and Hao Wang and Yawen Li and Yuyang Ye and Xingyu Lou and Junping Du and Enhong Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pKOJrwqXLh}\n}",
        "github": "",
        "project": "",
        "reviewers": "e1xT;wJ4H;FDEr;aWTe",
        "site": "https://openreview.net/forum?id=pKOJrwqXLh",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "4;5;4;6",
        "scope": "4;4;3;4",
        "confidence": "3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            2.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "pR4ieD44tM",
        "title": "Hidden Impact of Hardware Technologies on Throughput: a Case Study on a Brazilian Mobile Web Network",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The Web has shifted towards a mobile-first ecosystem with tools, frameworks, and forums explicitly discussing and catering for the mobile users, both mobile apps and mobile web-pages. Unfortunately much of the studies and designs are often based on analysis and findings from developed regions (e.g., N. America and Europe) or based on user-generated data (introducing  bias). In this paper, we present one of the first studies to understand the interplay between hardware characteristics (e.g., cellular and mobile) on expected network and application level performance in Brazil (the largest developing region in S. America). We analyze more than 170 million measurement sessions collected from within the network of one of the largest Mobile Network Operators in Brazil. Our findings (1) illustrate limitations of existing crowdsourced measurements and inaccuracies in assumptions about adoption patterns and performance in the global south, (2) highlight the differences between recommendations made by standardization bodies and real world performance, (3) disclose a significant change pre- and post-pandemic, and (4) quantify the benefits of using both client side and network data for analysis.",
        "keywords": "measurements;5G;celllular;correlation;MNO",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eduardo C. Paim;Roberto Iraja Tavares da Costa Filho;Valter Roesler;Theophilus A Benson;Alberto Egon Schaeffer-Filho",
        "authorids": "~Eduardo_C._Paim1;~Roberto_Iraja_Tavares_da_Costa_Filho1;~Valter_Roesler1;~Theophilus_A_Benson1;~Alberto_Egon_Schaeffer-Filho1",
        "gender": "M;M;M;;M",
        "homepage": ";;https://www.inf.ufrgs.br/~roesler/site/;;https://www.inf.ufrgs.br/~alberto/",
        "dblp": ";79/1538;;;89/1649.html",
        "google_scholar": ";VFtZ3_oAAAAJ;https://scholar.google.com/cit;;https://scholar.google.com.br/citations?user=y6oOiqYAAAAJ",
        "orcid": ";0000-0003-4804-8954;0000-0003-2290-197X;;0000-0003-1780-9060",
        "linkedin": "eduardo-chaves-paim-b2586a1a2/;robertocostafilho/;https://linkedin.com/in/valter-roesler-87a693123;;aschaeff/",
        "or_profile": "~Eduardo_C._Paim1;~Roberto_Iraja_Tavares_da_Costa_Filho1;~Valter_Roesler1;~Theophilus_A_Benson1;~Alberto_Egon_Schaeffer-Filho1",
        "aff": ";Instituto Federal Sul-rio-grandense;;;Universidade Federal do Rio Grande do Sul",
        "aff_domain": ";ifsul.edu.br;;;ufrgs.br",
        "position": ";Associate Professor;;;Associate Professor",
        "bibtex": "@inproceedings{\npaim2025hidden,\ntitle={Hidden Impact of Hardware Technologies on Throughput: a Case Study on a Brazilian Mobile Web Network},\nauthor={Eduardo C. Paim and Roberto Iraja Tavares da Costa Filho and Valter Roesler and Theophilus A Benson and Alberto Egon Schaeffer-Filho},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pR4ieD44tM}\n}",
        "github": "",
        "project": "",
        "reviewers": "9BEu;XDKd;cefH;YPNo",
        "site": "https://openreview.net/forum?id=pR4ieD44tM",
        "pdf_size": 0,
        "novelty": "1;4;5;6",
        "technical_quality": "1;4;5;6",
        "scope": "1;3;3;4",
        "confidence": "1;2;2;1",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.8708286933869707
        ],
        "technical_quality_avg": [
            4.0,
            1.8708286933869707
        ],
        "scope_avg": [
            2.75,
            1.0897247358851685
        ],
        "confidence_avg": [
            1.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2672612419124244
    },
    {
        "id": "pdxEXGnw5l",
        "title": "Fitting Into Any Shape: A Flexible LLM-Based Re-Ranker With Configurable Depth and Width",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs) provide powerful foundations to\nperform fine-grained text re-ranking. However, they are often pro-\nhibitive in reality due to constraints on computation bandwidth. In\nthis work, we propose a flexible architecture called Matroyshka\nRe-Ranker, which is designed to facilitate runtime customiza-\ntion of model layers and sequence lengths at each layer based on\nusers\u2019 configurations. Consequently, the LLM-based re-rankers can\nbe made applicable across various real-world situations.\nThe increased flexibility may come at the cost of precision loss. To\naddress this problem, we introduce a suite of techniques to optimize\nthe performance. First, we propose cascaded self-distillation,\nwhere each sub-architecture learns to preserve a precise re-ranking\nperformance from its super components, whose predictions can be\nexploited as smooth and informative teacher signals. Second, we\ndesign a factorized compensation mechanism, where two col-\nlaborative Low-Rank Adaptation modules, vertical and horizontal,\nare jointly employed to compensate for the precision loss resulted\nfrom arbitrary combinations of layer and sequence compression.\nWe perform comprehensive experiments based on the passage\nand document retrieval datasets from MSMARCO, along with all\npublic datasets from BEIR benchmark. In our experiments, Ma-\ntryoshka Re-Ranker substantially outperforms the existing meth-\nods, while effectively preserving its superior performance across\nvarious forms of compression and different application scenarios.\nOur source code has been uploaded to this anonymous repository",
        "keywords": "Text Retrieval;Re-Ranking;Lightweighting;Flexibility",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zheng Liu;Chaofan Li;Shitao Xiao;Chaozhuo Li;Chen Jason Zhang;Hao Liao;Defu Lian;Yingxia Shao",
        "authorids": "~Zheng_Liu4;~Chaofan_Li2;~Shitao_Xiao1;~Chaozhuo_Li3;~Chen_Jason_Zhang1;~Hao_Liao1;~Defu_Lian1;~Yingxia_Shao1",
        "gender": ";M;M;;M;M;M;",
        "homepage": "https://www.microsoft.com/en-us/research/people/zhengliu/;https://scholar.google.com.hk/citations?view_op=list_works&hl=zh-CN&user=RxPRsnUAAAAJ&gmla=AETOMgHfUaIods-R0hoCrqPJlj6N1ZJ3vwcbW5O7nSL4TGTeUCtcGYXMg6NZ8G_iPXzVw4aHL4hjQcM1mHUlfzG1OJM8AJnHGo_G7va9iA;;;https://www.zhangchen.info/;https://csse.szu.edu.cn/pages/user/index?id=542;https://faculty.ustc.edu.cn/liandefu/en/index.htm;",
        "dblp": "06/3580-11;https://dblp.org/search?q=Chaofan+Li;286/1495;;133/9850;74/1078;87/10734;",
        "google_scholar": "https://scholar.google.com.hk/citations?user=k2SF4M0AAAAJ;https://scholar.google.com.hk/citations?view_op=list_works;https://scholar.google.com.hk/citations?hl=zh-CN;;;Tu5ZuREAAAAJ;QW0ad4sAAAAJ;",
        "orcid": "0000-0001-7765-8466;0009-0005-6189-9456;;;0000-0002-3306-9317;;0000-0002-3507-9607;",
        "linkedin": ";;;;;hao-liao-30635127;;",
        "or_profile": "~Zheng_Liu4;~Chaofan_Li2;~Shitao_Xiao1;~Chaozhuo_Li3;~Chen_Jason_Zhang1;~Hao_Liao1;~Defu_Lian1;~Yingxia_Shao1",
        "aff": "Microsoft Research;Beijing University of Posts and Telecommunications;Beijing Academy of Artificial Intelligence;;Hong Kong Polytechnic University;Shenzhen University;University of Science and Technology of China;",
        "aff_domain": "research.microsoft.com;bupt.edu.cn;baai.ac.cn;;polyu.edu.hk;szu.edu.cn;ustc.edu.cn;",
        "position": "Researcher;MS student;Researcher;;Assistant Professor;Associate Professor;Full Professor;",
        "bibtex": "@inproceedings{\nliu2025fitting,\ntitle={Fitting Into Any Shape: A Flexible {LLM}-Based Re-Ranker With Configurable Depth and Width},\nauthor={Zheng Liu and Chaofan Li and Shitao Xiao and Chaozhuo Li and Chen Jason Zhang and Hao Liao and Defu Lian and Yingxia Shao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pdxEXGnw5l}\n}",
        "github": "",
        "project": "",
        "reviewers": "Vs6G;2h5u;Lqrv;ffcp;w3nx",
        "site": "https://openreview.net/forum?id=pdxEXGnw5l",
        "pdf_size": 0,
        "novelty": "2;5;5;5;5",
        "technical_quality": "2;4;4;5;4",
        "scope": "3;3;3;4;4",
        "confidence": "4;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.2
        ],
        "technical_quality_avg": [
            3.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -1.0
    },
    {
        "id": "pje11KNgT6",
        "title": "Cluster Aware Graph Anomaly Detection",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph anomaly detection has gained significant attention across various domains, particularly in critical applications like fraud detection in e-commerce platforms and insider threat detection in cybersecurity. Usually, these data are composed of multiple types (e.g.,  user information and transaction records for financial data), thus exhibiting view heterogeneity. However, in the era of big data, the heterogeneity of views and the lack of label information pose substantial challenges to traditional approaches. Existing unsupervised graph anomaly detection methods often struggle with high-dimensionality issues, rely on strong assumptions about graph structures or fail to handle complex multi-view graphs. To address these challenges, we propose a cluster aware multi-view graph anomaly detection method, called CARE. Our approach captures both local and global node affinities by augmenting the graph's adjacency matrix with the pseudo-label (i.e., soft membership assignments) without any strong assumption about the graph. To mitigate potential biases from the pseudo-label, we introduce a similarity-guided loss. Theoretically, we show that the proposed similarity-guided loss is a variant of contrastive learning loss, and we present how this loss alleviates the bias introduced by pseudo-label with the connection to graph spectral clustering. Experimental results on several datasets demonstrate the effectiveness and efficiency of our proposed framework. Specifically, CARE outperforms the second-best competitors by more than 39% on the Amazon dataset with respect to AUPRC and 18.7% on the YelpChi dataset with respect to AUROC. The code of our method is available at the anonymous GitHub link: https://anonymous.4open.science/r/CARE-demo-1C7F.",
        "keywords": "Anomaly detection;Contrastive Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Lecheng Zheng;John Birge;Haiyue Wu;Yifang Zhang;Jingrui He",
        "authorids": "~Lecheng_Zheng1;~John_Birge1;~Haiyue_Wu1;~Yifang_Zhang1;~Jingrui_He1",
        "gender": ";M;F;M;F",
        "homepage": "https://sites.google.com/view/lecheng-zheng/home;https://www.chicagobooth.edu/faculty/directory/b/john-r-birge;;https://experts.illinois.edu/en/persons/yifang-zhang;https://www.hejingrui.org",
        "dblp": "234/8652;;;;34/2685",
        "google_scholar": "Lp09wUoAAAAJ;jRY_V1gAAAAJ;;;hXpZynkAAAAJ",
        "orcid": "0000-0002-6869-3320;0000-0002-7446-0953;;;0000-0002-6429-6272",
        "linkedin": ";;https://linkedin.com/in/haiyue-wu;yifang-zhang-9b9b3329/;",
        "or_profile": "~Lecheng_Zheng1;~John_Birge1;~Haiyue_Wu1;~Yifang_Zhang1;~Jingrui_He1",
        "aff": "Virginia Polytechnic Institute and State University+University of Illinois Urbana-Champaign;University of Chicago;University of Illinois, Urbana Champaign;;University of Illinois, Urbana Champaign",
        "aff_domain": "vt.edu+illinois.edu;uchicago.edu;uiuc.edu;;illinois.edu",
        "position": "Postdoc+PhD student;Full Professor;Undergrad student;;Full Professor",
        "bibtex": "@inproceedings{\nzheng2025cluster,\ntitle={Cluster Aware Graph Anomaly Detection},\nauthor={Lecheng Zheng and John Birge and Haiyue Wu and Yifang Zhang and Jingrui He},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pje11KNgT6}\n}",
        "github": "",
        "project": "",
        "reviewers": "1dp9;AT93;nSeK",
        "site": "https://openreview.net/forum?id=pje11KNgT6",
        "pdf_size": 0,
        "novelty": "5;5;6",
        "technical_quality": "5;4;6",
        "scope": "4;3;4",
        "confidence": "2;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5000000000000001
    },
    {
        "id": "ppMEwffPZl",
        "title": "DAGPrompT: Pushing the Limits of Graph Prompting with a Distribution-aware Graph Prompt Tuning Approach",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The \"pre-training then fine-tuning\" paradigm has advanced Graph Neural Networks (GNNs) by enabling the capture of general knowledge without task-specific labels. However, a significant objective gap between pre-training and downstream tasks limits their effectiveness. Recent graph prompting methods aim to bridge this gap by task reformulations and learnable prompts. Yet, they struggle with complex graphs like heterophily graphs\u2014freezing the GNN encoder may diminish prompting effectiveness, and simple prompts fail to capture diverse hop-level distributions. This paper identifies two key challenges in adapting graph prompting methods for complex graphs: (i) adapting the model to new distributions in downstream tasks to mitigate pre-training and fine-tuning discrepancies from heterophily and (ii) customizing prompts for hop-specific node requirements. To overcome these challenges, we propose Distribution-aware Graph Prompt Tuning (DAGPrompT), which integrates a GLoRA module for optimizing the GNN encoder\u2019s projection matrix and message-passing schema through low-rank adaptation. DAGPrompT also incorporates hop-specific prompts accounting for varying graph structures and distributions among hops. Evaluations on 10 datasets and 14 baselines demonstrate that DAGPrompT improves accuracy by up to 7.55\\% in node and graph classification tasks, setting a new state-of-the-art while preserving efficiency. We\nprovide our code and data via AnonymousGithub.",
        "keywords": "graph neural networks;graph prompting;few-shot learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Qin Chen;Liang Wang;Bo Zheng;Guojie Song",
        "authorids": "~Qin_Chen3;~Liang_Wang15;~Bo_Zheng5;~Guojie_Song1",
        "gender": ";M;M;M",
        "homepage": ";;;http://sai.pku.edu.cn/info/1022/2212.htm",
        "dblp": ";;33/1610-7;37/2900",
        "google_scholar": "FjeRoMsAAAAJ;3hcLUEAAAAAJ;3gHhO9QAAAAJ;https://scholar.google.com.tw/citations?user=a832IIMAAAAJ",
        "orcid": "0000-0003-1808-1585;0000-0001-5353-7803;0000-0002-4037-6315;0000-0001-8295-2520",
        "linkedin": ";;bo-zheng-0315254/;",
        "or_profile": "~Qin_Chen3;~Liang_Wang15;~Bo_Zheng5;~Guojie_Song1",
        "aff": "Peking University;Alibaba Group;Alibaba Group;Peking University",
        "aff_domain": "pku.edu.cn;alibaba-inc.com;alibaba-inc.com;pku.edu.cn",
        "position": "MS student;Senior Tech Expert;Principal Researcher;Associate Professor",
        "bibtex": "@inproceedings{\nchen2025dagprompt,\ntitle={{DAGP}rompT: Pushing the Limits of Graph Prompting with a Distribution-aware Graph Prompt Tuning Approach},\nauthor={Qin Chen and Liang Wang and Bo Zheng and Guojie Song},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ppMEwffPZl}\n}",
        "github": "",
        "project": "",
        "reviewers": "Jz67;URyD;RSvb;CyyA;YYMb",
        "site": "https://openreview.net/forum?id=ppMEwffPZl",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;5;5;4;6",
        "scope": "4;4;4;3;4",
        "confidence": "4;4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9185586535436918
    },
    {
        "id": "pwdRhjHrEx",
        "title": "Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Adversarial evasion attacks pose significant threats to graph learning, with lines of studies that have made progress in improving the robustness of Graph Neural Networks (GNNs) for real-world applications. However, existing works overly rely on priors of clean graphs or attacking strategies, which are often heuristic and not universally consistent. To achieve robust graph learning over different types of evasion attacks and diverse datasets, we investigate this non-trivial problem from a prior-free structure purification perspective. Specifically, we propose a novel **Diff**usion-based **S**tructure **P**urification framework named **DiffSP**, which creatively incorporates the graph diffusion model to learn intrinsic latent distributions of clean graphs and purify the perturbed structures by removing adversaries under the direction of the captured predictive patterns without relying on any pre-defined priors. DiffSP is divided into the forward diffusion process and the reverse denoising process, during which structure purification is achieved. To avoid valuable information loss during the forward process, we propose an LID-driven non-isotropic diffusion mechanism to selectively inject controllable noise anisotropically. To promote semantic alignment between the clean graph and the purified graph generated during the reverse process, we reduce the generation uncertainty by the proposed graph transfer entropy guided denoising mechanism. Extensive experiments on both graph and node classification tasks demonstrate the superior robustness of DiffSP against evasion attacks.",
        "keywords": "robust graph learning;adversarial evasion attack;graph structure purification;graph diffuison",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiayi Luo;Qingyun Sun;Haonan Yuan;Xingcheng Fu;Jianxin Li",
        "authorids": "~Jiayi_Luo1;~Qingyun_Sun2;~Haonan_Yuan2;~Xingcheng_Fu1;~Jianxin_Li3",
        "gender": "M;F;M;M;M",
        "homepage": ";https://sunqysunqy.github.io/;;https://fuxingcheng.github.io/;http://myjianxin.github.io",
        "dblp": ";;258/2050;236/7003;l/JianxinLi-2.html",
        "google_scholar": "IXVSkOQAAAAJ;e2oYBzUAAAAJ;4UL1RIsAAAAJ;gN4tbgMAAAAJ;EY2lqD0AAAAJ",
        "orcid": "0009-0004-5742-3589;;0000-0001-9205-8610;0000-0002-4643-8126;0000-0001-5152-0055",
        "linkedin": ";;;;",
        "or_profile": "~Jiayi_Luo1;~Qingyun_Sun2;~Haonan_Yuan2;~Xingcheng_Fu1;~Jianxin_Li3",
        "aff": "Beihang University;Beihang University;Beihang University;Guangxi Normal University;Beihang University ",
        "aff_domain": "buaa.edu.cn;buaa.edu.cn;buaa.edu.cn;gxnu.edu.cn;buaa.edu.cn",
        "position": "PhD student;Assistant Professor;PhD student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nluo2025robust,\ntitle={Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification},\nauthor={Jiayi Luo and Qingyun Sun and Haonan Yuan and Xingcheng Fu and Jianxin Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pwdRhjHrEx}\n}",
        "github": "",
        "project": "",
        "reviewers": "UVEh;SJeU;6RjP;iod5",
        "site": "https://openreview.net/forum?id=pwdRhjHrEx",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "4;6;6;6",
        "scope": "3;4;4;4",
        "confidence": "4;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            5.5,
            0.8660254037844386
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.75,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "pyZ0Jmo5PI",
        "title": "FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The Web of Things (WoT) facilitates interoperability across web-based mobile and ubiquitous computing platforms and application domains, aiming to complement and preserve existing IoT standards and solutions. In this context, the multimodal federated learning (FL) paradigm has been introduced to enhance WoT by enabling the fusion of multi-source mobile sensing data while preserving privacy.\nHowever, a critical challenge in web-based mobile sensing systems employing multimodal FL is modality incompleteness, where certain modalities may be unavailable or partially captured, which can adversely impact the performance and reliability of these systems.\nCurrent multimodal FL frameworks typically train multiple unimodal FL subsystems or apply interpolation techniques on the node side to approximate missing modalities. However, these approaches overlook the shared latent feature space among incomplete modalities across different nodes and fail to discriminate against low quality nodes. To address this gap, we present FedMobile, a new knowledge contribution-aware multimodal FL framework designed for robust learning despite missing modalities. FedMobile prioritizes local-to-global knowledge transfer, leveraging cross-node multimodal feature information to reconstruct missing features.\nIt also enhances system performance and resilience to modality heterogeneity through rigorous node contribution assessments and knowledge contribution-aware aggregation rules. Empirical evaluations on five widely recognized multimodal benchmark datasets demonstrate that FedMobile maintains robust learning even when up to 90% of modality information is missing or when data from two modalities is randomly missing, outperforming state-of-the-art baselines. Our datasets and code are available at the link.",
        "keywords": "Multi-modal Federated Learning;Incomplete Modalities;Web-based Mobile;Knowledge Distillation;Model Aggregation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yi Liu;Cong Wang;Xingliang YUAN",
        "authorids": "~Yi_Liu15;~Cong_Wang10;~Xingliang_YUAN2",
        "gender": "M;;",
        "homepage": "https://yiliucs.github.io/;;http://xyuancs.github.io",
        "dblp": "97/4626-57;;21/8884",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;https://scholar.google.com.hk/citations?user=81yWaCoAAAAJ",
        "orcid": "0000-0002-0811-6150;;0000-0002-3701-4946",
        "linkedin": ";;",
        "or_profile": "~Yi_Liu15;~Cong_Wang10;~Xingliang_YUAN2",
        "aff": "City University of Hong Kong;;University of Melbourne",
        "aff_domain": "cityu.edu.hk;;unimelb.edu.au",
        "position": "PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\nliu2025fedmobile,\ntitle={FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities},\nauthor={Yi Liu and Cong Wang and Xingliang YUAN},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=pyZ0Jmo5PI}\n}",
        "github": "",
        "project": "",
        "reviewers": "2aXN;VYQU;u9gC;WwBc",
        "site": "https://openreview.net/forum?id=pyZ0Jmo5PI",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "5;4;5;5",
        "scope": "3;3;4;3",
        "confidence": "3;2;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            4.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9045340337332909
    },
    {
        "id": "q5T7whUuGa",
        "title": "FLock: Robust and Privacy-Preserving Federated Learning based on Practical Blockchain State Channels",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "\\textit{Federated Learning} (FL) is a distributed machine learning paradigm that allows multiple clients to train models collaboratively without sharing local data. Numerous works have explored security and privacy protection in FL, as well as its integration with blockchain technology. However, existing FL works still face critical issues. \\romannumeral1) It is difficult to achieving \\textit{poisoning robustness} and \\textit{data privacy} while ensuring high \\textit{model accuracy}. Malicious clients can launch \\textit{poisoning attacks} that degrade the global model. Besides, aggregators can infer private data from the gradients, causing \\textit{privacy leakages}. Existing privacy-preserving poisoning defense FL solutions suffer from decreased model accuracy and high computational overhead. \\romannumeral2) Blockchain-assisted FL records iterative gradient updates on-chain to prevent model tampering, yet existing schemes are not compatible with practical blockchains and incur high costs for maintaining the gradients on-chain. Besides, incentives are overlooked, where unfair reward distribution hinders the sustainable development of the FL community. In this work, we propose FLock, a robust and privacy-preserving FL scheme based on practical blockchain state channels. First, we propose a lightweight secure \\textit{Multi-party Computation} (MPC)-friendly robust aggregation method through quantization, median, and Hamming distance, which could resist poisoning attacks against up to $<50\\%$ malicious clients. Besides, we propose communication-efficient Shamir's secret sharing-based MPC protocols to protect data privacy with high model accuracy. Second, we utilize blockchain off-chain state channels to achieve immutable model records and incentive distribution. FLock achieves cost-effective compatibility with practical cryptocurrency platforms, e.g. Ethereum, along with fair incentives, by merging the secure aggregation into a multi-party state channel. In addition, a pipelined \\textit{Byzantine Fault-Tolerant} (BFT) consensus is integrated where each aggregator can reconstruct the final aggregated results. Lastly, we implement FLock and the evaluation results demonstrate that FLock enhances robustness and privacy, while maintaining efficiency and high model accuracy. Even with 25 aggregators and 100 clients, FLock can complete one secure aggregation for ResNet in $2$ minutes over a WAN. FLock successfully implements secure aggregation with such a large number of aggregators, thereby enhancing the fault tolerance of the aggregation.",
        "keywords": "Federated learning;Privacy;Robust;Blockchain;Fair incentives",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ruonan Chen;Ye Dong;Yizhong Liu;Tingyu Fan;Dawei Li;Zhenyu Guan;Jianwei Liu;Jianying Zhou",
        "authorids": "~Ruonan_Chen1;~Ye_Dong1;~Yizhong_Liu1;~Tingyu_Fan2;~Dawei_Li6;~Zhenyu_Guan1;~Jianwei_Liu2;~Jianying_Zhou1",
        "gender": "F;M;M;M;M;;M;Not Specified",
        "homepage": "https://scholar.google.com/citations?hl=zh-CN&user=QIYTlVwAAAAJ;https://ye-d.github.io/;;;http://cst.buaa.edu.cn/info/1208/3027.htm;;http://cst.buaa.edu.cn/info/1206/2649.htm;http://jianying.space/",
        "dblp": ";73/4099;;;;121/1665;;",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;ZO7id5IAAAAJ;8PXwE_MAAAAJ;;;https://scholar.google.com/citations?hl=zh-TW;;",
        "orcid": "0000-0003-3417-5653;;;0000-0002-1530-1928;;;;",
        "linkedin": "ruonan-chen-838a52317/;;;;;;;",
        "or_profile": "~Ruonan_Chen1;~Ye_Dong1;~Yizhong_Liu1;~Tingyu_Fan2;~Dawei_Li6;~Zhenyu_Guan1;~Jianwei_Liu2;~Jianying_Zhou1",
        "aff": "Beihang University;National University of Singapore+Singapore University of Technology and Design;Beihang University;Institute of Information Engineering, Chinese Academy of Sciences;Beihang University;Beihang University;School of Cyber Science and Technology, Beihang University;",
        "aff_domain": "buaa.edu.cn;nus.edu.sg+sutd.edu.sg;buaa.edu.cn;iie.ac.cn;buaa.edu.cn;buaa.edu.cn;cst.buaa.edu.cn;",
        "position": "PhD student;Postdoc+Postdoc;Assistant Professor;PhD student;Assistant Professor;Full Professor;Full Professor;",
        "bibtex": "@inproceedings{\nchen2025flock,\ntitle={{FL}ock: Robust and Privacy-Preserving Federated Learning based on Practical Blockchain State Channels},\nauthor={Ruonan Chen and Ye Dong and Yizhong Liu and Tingyu Fan and Dawei Li and Zhenyu Guan and Jianwei Liu and Jianying Zhou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=q5T7whUuGa}\n}",
        "github": "",
        "project": "",
        "reviewers": "eoRp;UMZm;26Cx;UTN1",
        "site": "https://openreview.net/forum?id=q5T7whUuGa",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "5;5;5;7",
        "scope": "4;4;4;4",
        "confidence": "2;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.5,
            0.8660254037844386
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.8528028654224418
    },
    {
        "id": "qIareorXas",
        "title": "Conformal Graph-level Out-of-distribution Detection with Adaptive Data Augmentation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Graph-level out-of-distribution (OOD) detection, which attempts to identify OOD graphs originated from an unknown distribution, is a vital building block for safety-critical applications in Web and society. Current approaches concentrate on how to learn better graph representations, but fail to provide any statistically guarantee on detection results, therefore impeding their deployments in the scenario where detection errors would result in serious consequences. To overcome this critical issue, we propose the Conformal Graph-level Out-of-distribution Detection (CGOD), extending the theory of conformal prediction to graph-level OOD detection with a rigorous control over the false positive rate. In CGOD, we develop a new aggregated non-conformity score function based on the proposed adaptive data augmentation. Through the guidance from two designed metrics, i.e., score consistency and representation diversity, our augmentation strategy can generate multiple non-conformity scores, and aggregating these generated non-conformity scores together is robust to the misleading information. Meanwhile, our score function can perceive the subsequent process of conformal inference, enabling the aggregated non-conformity score to be adaptive to different input graphs and deriving a more accurate score estimation. We conduct experiments on multiple real-world datasets with different empirical settings. Extensive results and model analyses demonstrate the superior performance of our approach over several competitive baselines.",
        "keywords": "Graph-level out-of-distribution detection;conformal prediction;graph neural networks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xixun Lin;Yanan Cao;Nan Sun;Lixin Zou;Chuan Zhou;Peng Zhang;Shuai Zhang;Ge Zhang;Jia Wu",
        "authorids": "~Xixun_Lin3;~Yanan_Cao1;~Nan_Sun2;~Lixin_Zou1;~Chuan_Zhou3;~Peng_Zhang55;~Shuai_Zhang23;~Ge_Zhang2;~Jia_Wu3",
        "gender": "M;F;M;M;M;M;M;;M",
        "homepage": "https://linxixun.github.io/;;https://sunnan191.github.io/;https://www.zoulixin.site/;http://www.chuanzhou.online/;;https://zh-shuai.github.io/;;http://web.science.mq.edu.au/~jiawu/",
        "dblp": "190/7231;97/5152-1;;193/4216;https://dblp.uni-trier.de/pid/52/564-1;21/1048-1;;;25/5536-1",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;https://scholar.google.com/citations?hl=zh-CN;J8tHYjIAAAAJ;4oBUWVEAAAAJ;https://scholar.google.com.au/citations?user=89C_mxcAAAAJ;https://scholar.google.com.hk/citations?user=PUDxORcAAAAJ;;kbnFw94AAAAJ",
        "orcid": "0009-0004-6645-0597;0000-0003-3534-1094;0009-0006-3844-0206;0000-0001-6755-871X;0000-0001-9958-8673;0000-0001-7973-2746;;;0000-0002-1371-5801",
        "linkedin": ";;https://linkedin.com/in/nan-sun-11781030b;;;;;;",
        "or_profile": "~Xixun_Lin3;~Yanan_Cao1;~Nan_Sun2;~Lixin_Zou1;~Chuan_Zhou3;~Peng_Zhang55;~Shuai_Zhang23;~Ge_Zhang2;~Jia_Wu3",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Wuhan University;Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Chinese Academy of Sciences;Guangzhou University;Academy of Mathematics and Systems Science, Chinese Academy of Sciences;;Macquarie University",
        "aff_domain": "iie.ac.cn;iie.ac.cn;iie.ac.cn;whu.edu.cn;amss.ac.cn;gzhu.edu.cn;amss.ac.cn;;mq.edu.au",
        "position": "Assistant Professor;Full Professor;MS student;Associate Professor;Associate Professor;Full Professor;PhD student;;Associate Professor",
        "bibtex": "@inproceedings{\nlin2025conformal,\ntitle={Conformal Graph-level Out-of-distribution Detection with Adaptive Data Augmentation},\nauthor={Xixun Lin and Yanan Cao and Nan Sun and Lixin Zou and Chuan Zhou and Peng Zhang and Shuai Zhang and Ge Zhang and Jia Wu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qIareorXas}\n}",
        "github": "",
        "project": "",
        "reviewers": "GMrr;WoiR;gmvS;bjCb",
        "site": "https://openreview.net/forum?id=qIareorXas",
        "pdf_size": 0,
        "novelty": "4;4;5;6",
        "technical_quality": "6;4;4;4",
        "scope": "3;3;4;4",
        "confidence": "2;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.5,
            0.8660254037844386
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.30151134457776363
    },
    {
        "id": "qNvCoMKXed",
        "title": "Local Differentially Private Release of Infinite Streams With Temporal Relevance",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "The data stream generated by users on web applications is often collected using a local differential privacy (LDP) approach to ensure privacy. This approach offers rigorous theoretical guarantees and low computational overhead, albeit at the expense of data utility. Data utility encompasses both the value of individual data points and the temporal relevance that exists between them, but existing studies primarily focus on enhancing the former utility while neglecting the latter. Furthermore, the collected data often requires cleaning, and we have demonstrated through a case study that data stream lacking time relevance poses a significant risk to users' privacy during the cleaning process. In this paper, for the first time we present an online LDP publishing mechanism while preserving the inherent temporal relevance for the infinite stream, called the Sampling Period Perturbation Algorithm (SPPA). Specifically, we model the temporal relevance between data points as the Fourier interpolation function, resulting in a computational complexity reduction from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ when compared with the conventional Markov approach in the offline setting. To strike a better balance between privacy and utility, we add noise to the sampling period due to its minimal impact on sensitivity, which is analyzed by our novel concepts of $(\\epsilon,\\tau)$-temporal indistinguishability and $(\\epsilon,w,\\tau)$-event LDP. Through extensive experiments, SPPA exhibits superior performance in terms of both data utility and privacy preservation compared to the state-of-the-art baselines. In particular, when $\\epsilon=1$, compared with the state-of-the-art baseline, SPPA diminishes the MSE by up to 64.2\\%, and raises the event monitoring efficiency by up to 21.4\\%.",
        "keywords": "infinite streams;time series;temporal relevance;temporal privacy;local differential privacy",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Runze Wang;Jiahao Liu;Miao Hu;Yipeng Zhou;Di Wu",
        "authorids": "~Runze_Wang2;~Jiahao_Liu8;~Miao_Hu2;~Yipeng_Zhou1;~Di_Wu21",
        "gender": ";M;M;M;M",
        "homepage": ";;;https://sites.google.com/site/yipenghomepage/;http://netlabsysu.org/dwu/",
        "dblp": ";;74/8189-1;78/6594.html;52/328-1",
        "google_scholar": ";;5qp88KUAAAAJ;https://scholar.google.ca/citations?user=uv95RgUAAAAJ;https://scholar.google.com.hk/citations?hl=zh-CN",
        "orcid": "0009-0002-3462-6653;0000-0001-8608-381X;0000-0002-1518-002X;;0000-0002-9433-7725",
        "linkedin": ";;;;",
        "or_profile": "~Runze_Wang2;~Jiahao_Liu8;~Miao_Hu2;~Yipeng_Zhou1;~Di_Wu21",
        "aff": "SUN YAT-SEN UNIVERSITY;Sun Yat-Sen University;SUN YAT-SEN UNIVERSITY;Macquarie University;SUN YAT-SEN UNIVERSITY",
        "aff_domain": "sysu.edu.cn;mail2.sysu.edu.cn;sysu.edu.cn;mq.edu.au;sysu.edu.cn",
        "position": "PhD student;MS student;Associate Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nwang2025local,\ntitle={Local Differentially Private Release of Infinite Streams With Temporal Relevance},\nauthor={Runze Wang and Jiahao Liu and Miao Hu and Yipeng Zhou and Di Wu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qNvCoMKXed}\n}",
        "github": "",
        "project": "",
        "reviewers": "yts3;YLZ1;i9b8;d2Qx",
        "site": "https://openreview.net/forum?id=qNvCoMKXed",
        "pdf_size": 0,
        "novelty": "3;5;5;6",
        "technical_quality": "4;4;5;6",
        "scope": "3;4;3;4",
        "confidence": "3;4;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            1.0897247358851685
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "qSuWIHIr9w",
        "title": "TensorJSFuzz: Effective Testing of Web-Based Deep Learning Frameworks via Input-Constraint Extraction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As web applications grow in popularity, developers are increasingly integrating deep learning (DL) models into these environments. Web-based DL frameworks (e.g., TensorFlow.js) are essential for building and deploying such applications. Ensuring the quality of these frameworks is critical for the reliability of DL systems. While extensive testing efforts have been made for native DL frameworks such as TensorFlow and PyTorch, web-based DL frameworks have not yet undergone systematic testing. A key challenge in this context is generating high-quality inputs that are both syntactically and semantically valid, as well as designing effective test oracles tailored to the unique constraints of web-specific environments. To address this gap, we introduce TensorJSFuzz, a novel method for testing web-based DL frameworks. To ensure input quality, TensorJSFuzz extracts constraints directly from the source code of framework APIs. By leveraging Large Language Models (e.g., ChatGPT) to understand the code and extract input constraints, TensorJSFuzz performs type-aware random generation coupled with dependency-aware refinement to create high-quality test inputs. These inputs are then subjected to differential testing across various backends, including CPU, TensorFlow, Wasm, and WebGL. Our experimental results show that TensorJSFuzz outperforms baseline methods in generating valid inputs and identifying bugs. In particular, TensorJSFuzz successfully detected 92 bugs, with 30 already confirmed or fixed by developers, demonstrating its effectiveness in improving the robustness of web-based DL frameworks.",
        "keywords": "Web-based Deep Learning;Fuzzing;Large Language Model",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Lili Quan;Xiaofei Xie;Qianyu Guo;Lingxiao Jiang;Sen Chen;Junjie Wang;Xiaohong Li",
        "authorids": "~Lili_Quan1;~Xiaofei_Xie2;~Qianyu_Guo4;~Lingxiao_Jiang1;~Sen_Chen1;~Junjie_Wang15;~Xiaohong_Li2",
        "gender": "F;M;M;M;M;F;F",
        "homepage": ";http://xiaofeixie.bitbucket.io/;;http://www.mysmu.edu/faculty/lxjiang/;https://sen-chen.github.io/;;https://cic.tju.edu.cn/faculty/lxh/index.html",
        "dblp": "155/5397.html;127/0713;;82/3572;;;",
        "google_scholar": "BqZeUjkAAAAJ;FfcZfJgAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.com.sg/citations?user=0hssXLPZL2YC;;https://scholar.google.com/citations?hl=en;",
        "orcid": ";0000-0002-1288-6502;;0000-0002-4336-8548;;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Lili_Quan1;~Xiaofei_Xie2;~Qianyu_Guo4;~Lingxiao_Jiang1;~Sen_Chen1;~Junjie_Wang15;~Xiaohong_Li2",
        "aff": "Tianjin University;Singapore Management University;Beijing zhongguancun Laboratory;Singapore Management University;;;Tianjin University",
        "aff_domain": "tju.edu.cn;smu.edu.sg;zgclab.edu.cn;smu.edu.sg;;;tju.edu.cn",
        "position": "PhD student;Assistant Professor;Assistant Professor;Full Professor;;;Full Professor",
        "bibtex": "@inproceedings{\nquan2025tensorjsfuzz,\ntitle={Tensor{JSF}uzz: Effective Testing of Web-Based Deep Learning Frameworks via Input-Constraint Extraction},\nauthor={Lili Quan and Xiaofei Xie and Qianyu Guo and Lingxiao Jiang and Sen Chen and Junjie Wang and Xiaohong Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qSuWIHIr9w}\n}",
        "github": "",
        "project": "",
        "reviewers": "jLtU;Z7M7;5R7x;SxXm;7R1A",
        "site": "https://openreview.net/forum?id=qSuWIHIr9w",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "4;5;5;4;5",
        "scope": "3;4;4;4;4",
        "confidence": "3;1;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.2,
            0.9797958971132712
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.408248290463863
    },
    {
        "id": "qcnePVejeV",
        "title": "Do Not Trust What They Tell: Exposing Malicious Accomplices in Tor via Anomalous Circuit Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The Tor network, while offering anonymity through traffic routing across volunteer-operated nodes, remains vulnerable to attacks that aim to deanonymize users by correlating traffic patterns between colluded Entry and Exit nodes in circuits. This paper presents a novel approach for detecting anomalous circuits in the Tor network, and for the first time provides a more comprehensive identification of potential malicious accomplice nodes in Tor by taking roles of nodes in anomalous circuits into consideration. Our method strategically utilizes modified Middle nodes to capture traffic data, followed by a novel circuit classification based on traffic patterns to pinpoint concerned circuits. Two kinds of anomalies are identified: routing anomalies and usage anomalies, that respectively represent the anomalies with explicit or implicit violation of Tor's circuit construction guidelines. This leads to a successful revealing of totally 1,960 anomalous nodes in Tor. Furthermore, we apply clustering analysis with considering corresponding anomalous circuits and other key characteristics to the detected anomalous nodes, revealing potential hidden organizations behind these nodes that can threaten the network's security. Our findings highlight the necessity for the Tor project to adopt targeted mitigation strategies to enhance overall network security and privacy.",
        "keywords": "Tor network;Anonymity;Anomalous circuit;Traffic analysis",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yixuan Yao;Ming Yang;Zixia Liu;Kai Dong;Xiaodan-Gu;Chunmian Wang",
        "authorids": "~Yixuan_Yao1;~Ming_Yang15;~Zixia_Liu1;~Kai_Dong1;~Xiaodan-Gu1;~Chunmian_Wang1",
        "gender": "M;;;M;F;M",
        "homepage": ";;;https://cs.seu.edu.cn/dk/main.htm;;",
        "dblp": ";98/2604-1;;88/7785;;",
        "google_scholar": "https://scholar.google.com/citations?view_op=list_works;;;gp4YbVUAAAAJ;;enqkPMUAAAAJ",
        "orcid": ";0000-0002-8209-1000;;;0009-0001-0519-1358;",
        "linkedin": ";;;;;",
        "or_profile": "~Yixuan_Yao1;~Ming_Yang15;~Zixia_Liu1;~Kai_Dong1;~Xiaodan-Gu1;~Chunmian_Wang1",
        "aff": "Southeast University;Southeast University;;Southeast University;Southeast University;",
        "aff_domain": "seu.edu.cn;seu.edu.cn;;seu.edu.cn;seu.edu.cn;",
        "position": "PhD student;Full Professor;;Associate Professor;Associate Professor;",
        "bibtex": "@inproceedings{\nyao2025do,\ntitle={Do Not Trust What They Tell: Exposing Malicious Accomplices in Tor via Anomalous Circuit Detection},\nauthor={Yixuan Yao and Ming Yang and Zixia Liu and Kai Dong and Xiaodan-Gu and Chunmian Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qcnePVejeV}\n}",
        "github": "",
        "project": "",
        "reviewers": "cN9W;Nz9C;kPSC;hRVE;iU7f",
        "site": "https://openreview.net/forum?id=qcnePVejeV",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "4;3;4;3;5",
        "scope": "4;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            3.8,
            0.7483314773547882
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "qlkcnJrA1G",
        "title": "Pontus: A Memory-Efficient and High-Accuracy Approach for Persistence-Based Item Lookup in High-Velocity Data Streams",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In today's web-scale, data-driven environments, real-time detection of persistent items that consistently recur over time is essential for maintaining system integrity, reliability, and security. Persistent items often signal critical anomalies, such as stealthy DDoS and botnet attacks in web infrastructures. Although various methods exist for identifying such items as well as for determining their frequency, they require recording every item for processing, which is impractical at very high data rates achieved by modern data streams. In this paper, we introduce Pontus, a novel approach that uses an approximate data structure (sketch) specifically designed for the efficient and accurate detection of persistent items. Our method not only achieves fast and precise lookup but is also flexible, allowing for minor modifications to accommodate other types of persistence-based item detection tasks, such as detecting persistent items with low frequency. We rigorously validate our approach through formal methods, offering detailed proofs of time/space complexity and error bounds to demonstrate its theoretical soundness. Our extensive trace-driven evaluations across various persistence-based tasks further demonstrate Pontus's effectiveness in significantly improving detection accuracy and enhancing processing speed compared to existing approaches. We implement Pontus in an experimental platform with industry-grade Intel Tofino switches and demonstrate the practical feasibility of our approach in a real-world memory-constrained environment.",
        "keywords": "Data stream processing;persistent item lookup;probabilistic data structure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weihe Li;ZUKAI LI;Beyza B\u00fct\u00fcn;Alec F Diallo;Marco Fiore;Paul Patras",
        "authorids": "~Weihe_Li1;~ZUKAI_LI1;~Beyza_B\u00fct\u00fcn1;~Alec_F_Diallo1;~Marco_Fiore1;~Paul_Patras1",
        "gender": ";M;F;M;M;",
        "homepage": ";;;https://alec-diallo.github.io/;https://networks.imdea.org/p/marco-fiore/;http://homepages.inf.ed.ac.uk/ppatras/",
        "dblp": ";;;298/4347;;03/7603.html",
        "google_scholar": ";;;IyHaFk0AAAAJ;PI2-CnkAAAAJ;https://scholar.google.co.uk/citations?user=0kC3nVgAAAAJ",
        "orcid": ";;;0000-0002-0793-0492;0000-0002-0772-9967;0000-0002-1037-0158",
        "linkedin": ";zukai-li;beyza-butun/;https://uk.linkedin.com/in/alecfrenn;;paulpatras/",
        "or_profile": "~Weihe_Li1;~ZUKAI_LI1;~Beyza_B\u00fct\u00fcn1;~Alec_F_Diallo1;~Marco_Fiore1;~Paul_Patras1",
        "aff": ";;IMDEA Networks Institute+Universidad Carlos III de Madrid;University of Edinburgh;IMDEA Networks Institute;University of Edinburgh",
        "aff_domain": ";;networks.imdea.org+uc3m.es;ed.ac.uk;networks.imdea.org;ed.ac.uk",
        "position": ";;PhD student+PhD student;Postdoc;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nli2025pontus,\ntitle={Pontus: A Memory-Efficient and High-Accuracy Approach for Persistence-Based Item Lookup in High-Velocity Data Streams},\nauthor={Weihe Li and ZUKAI LI and Beyza B{\\\"u}t{\\\"u}n and Alec F Diallo and Marco Fiore and Paul Patras},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qlkcnJrA1G}\n}",
        "github": "",
        "project": "",
        "reviewers": "zRkM;i545;wEcF;kjSJ;KFqr",
        "site": "https://openreview.net/forum?id=qlkcnJrA1G",
        "pdf_size": 0,
        "novelty": "4;5;5;6;6",
        "technical_quality": "4;6;5;7;7",
        "scope": "3;3;3;3;4",
        "confidence": "1;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            5.8,
            1.16619037896906
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            1.0954451150103321
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.7319250547113999
    },
    {
        "id": "qma7XR59ZW",
        "title": "Parallel Online Similarity Join over Trajectory Streams",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Trajectory Similarity Join (TS-Join), as a fundamental operation in trajectory data analytics, has been extensively investigated by existing studies in data science community. However, existing solutions are almost designed for offline static trajectories, which cannot guarantee real-time feedback. In addition, the join results retrieved from existing solutions generally contains a large proportion of out-of-date similar pairs, making them inapplicable to evolving trajectories. \nIn this light, we study a novel problem of online time-aware trajectory similarity join: Given a stream of evolving trajectories, we aim to dynamically discover trajectory pairs whose spatio-temporal similarity is no less than a specified threshold in a real-time manner. We innovatively introduce a time-aware exponential-decaying similarity function to eliminate out-of-date results. To support real-time querying over large populations of trajectories, we develop a Parallel Online Trajectory Similarity Join (POTSJ) framework incorporating with well-designed workload balancing techniques. We further enhance join efficiency through effective pruning strategies and tailored approximation techniques. The POTSJ framework we propose, which incorporates these elements, is capable of processing online TS-Join while simultaneously satisfying three key objectives: real-time result updates, comprehensive trajectory evaluation, and scalability. \nExtensive experiments on real-world datasets validate the efficiency and scalability superiority of our POTSJ framework in processing online TS-Join.",
        "keywords": "Trajectory;Stream;Join;Similarity",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhongjun Ding;Ke Li;Lisi Chen;Shuo Shang",
        "authorids": "~Zhongjun_Ding1;~Ke_Li17;~Lisi_Chen1;~Shuo_Shang1",
        "gender": "M;M;;",
        "homepage": ";https://scholar.google.com.hk/citations?user=jzlq6h8AAAAJ&hl=zh-CN;;https://sites.google.com/site/jedishang",
        "dblp": ";75/6627-19;;29/8750",
        "google_scholar": ";https://scholar.google.com.hk/citations?user=jzlq6h8AAAAJ;;https://scholar.google.com/citations?hl=en",
        "orcid": "0009-0001-7501-1009;0000-0001-9206-0892;;0000-0002-1117-2890",
        "linkedin": ";;;",
        "or_profile": "~Zhongjun_Ding1;~Ke_Li17;~Lisi_Chen1;~Shuo_Shang1",
        "aff": "University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;uestc.edu.cn;;uestc.edu.cn",
        "position": "MS student;PhD student;;Full Professor",
        "bibtex": "@inproceedings{\nding2025parallel,\ntitle={Parallel Online Similarity Join over Trajectory Streams},\nauthor={Zhongjun Ding and Ke Li and Lisi Chen and Shuo Shang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qma7XR59ZW}\n}",
        "github": "",
        "project": "",
        "reviewers": "T2Mr;nGUk;eVtJ;BJqE;njmW",
        "site": "https://openreview.net/forum?id=qma7XR59ZW",
        "pdf_size": 0,
        "novelty": "2;3;5;6;6",
        "technical_quality": "2;3;4;5;6",
        "scope": "3;2;4;3;4",
        "confidence": "3;4;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.624807680927192
        ],
        "technical_quality_avg": [
            4.0,
            1.4142135623730951
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.06579516949597691
    },
    {
        "id": "qsj78d8y1j",
        "title": "No-Regret Algorithms in non-Truthful Auctions with Budget and ROI Constraints",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Advertisers are increasingly using automated bidding to optimize their ad campaigns on online advertising platforms.\nAutobidding allows an advertiser to optimize her objective subject to various constraints.\nIn this paper, we design online autobidding algorithms to optimize value subject to ROI and budget constraints.\n\nWe consider an item is being auctioned in each of $T$ rounds.\nWe focus on one buyer with budget and ROI constraints in the stochastic setting: her value and highest competing bid faced are drawn i.i.d. from some unknown (joint) distribution in each round.\nWe design low-regret bidding algorithms that bid on behalf of this buyer.\nOur main result is an algorithm with full information feedback (i.e., the highest competing bid is revealed after each round) that guarantees a near-optimal $\\tilde O(\\sqrt T)$ regret with respect to the best Lipschitz function that maps values to bids.\nThe class of Lipschitz bidding functions is rich enough to best respond to many correlation structures between value and highest competing bid, e.g., positive or negative correlation.\nOur result applies to a wide range of auctions, most notably any mixture of first- and second-price auctions.\nIn addition, our result holds for both value-maximizing buyers and quasi-linear utility-maximizing buyers.\n\nWe also study the bandit setting, where the algorithm only observes whether the bidder wins the auction or not.\nIn this setting, we show an $\\Omega(T^{2/3})$ regret lower bound for first-price auctions, showing a significant disparity between the full information and bandit settings.\nWe also design an algorithm with a regret bound of $\\tilde O(T^{3/4})$ when the value distribution is known and is independent of the highest competing bid.",
        "keywords": "repeated auctions;online learning;first-price;budget constraint;ROI constraint",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Gagan Aggarwal;Giannis Fikioris;Mingfei Zhao",
        "authorids": "~Gagan_Aggarwal1;~Giannis_Fikioris1;~Mingfei_Zhao1",
        "gender": "F;M;M",
        "homepage": ";https://giannisfikioris.org;https://www.cs.yale.edu/homes/zhao-mingfei/",
        "dblp": "75/3847;264/9493.html;175/1739",
        "google_scholar": ";I7CqjFsAAAAJ;OFxBCzIAAAAJ",
        "orcid": "0009-0003-3296-4891;0000-0002-4920-478X;",
        "linkedin": ";;",
        "or_profile": "~Gagan_Aggarwal1;~Giannis_Fikioris1;~Mingfei_Zhao1",
        "aff": "Google Research;Cornell University;",
        "aff_domain": "research.google.com;cornell.edu;",
        "position": "Researcher;PhD student;",
        "bibtex": "@inproceedings{\naggarwal2025noregret,\ntitle={No-Regret Algorithms in non-Truthful Auctions with Budget and {ROI} Constraints},\nauthor={Gagan Aggarwal and Giannis Fikioris and Mingfei Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qsj78d8y1j}\n}",
        "github": "",
        "project": "",
        "reviewers": "si63;MdWu;DJYh;ufD7;gsar",
        "site": "https://openreview.net/forum?id=qsj78d8y1j",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "5;5;6;6;6",
        "scope": "4;4;4;4;4",
        "confidence": "3;3;2;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.6,
            0.48989794855663565
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.1666666666666667
    },
    {
        "id": "qvq7g5S7Hf",
        "title": "MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Search result diversification (SRD), aimed at ensuring that selected documents in a ranking list cover a wide range of subtopics, is a significant and extensively studied problem in Web search and Information Retrieval. Existing methods primarily utilize a paradigm of \"greedy selection\", i.e., selecting one document with the highest diversity score at a time. These approaches tend to be inefficient and are easily trapped in a suboptimal state. In addition, some other methods optimize an approximation of the objective function, but the results still remain suboptimal. To address these challenges, we introduce \\textbf{M}ulti-\\textbf{A}gent reinforcement learning (MARL) for search result \\textbf{DIV}ersity, which called \\textbf{MA4DIV}. In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. By modeling the SRD ranking problem as a cooperative MARL problem, this approach allows for directly optimizing the diversity metrics, such as $\\alpha$-NDCG, while achieving high training efficiency. We conducted experiments on public TREC datasets and a large-scale dataset in the industrial setting. The results show that MA4DIV achieves substantial improvements in both effectiveness and efficiency than existing baselines, especially on the industrial scale dataset.",
        "keywords": "Learning to Rank;Search Result Diversification;Multi-Agent Cooperation;Reinforcement Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yiqun Chen;Jiaxin Mao;Yi Zhang;Dehong Ma;Long Xia;Jun Fan;Daiting Shi;Zhicong Cheng;Gu Simiu;Dawei Yin",
        "authorids": "~Yiqun_Chen3;~Jiaxin_Mao1;~Yi_Zhang56;~Dehong_Ma1;~Long_Xia1;~Jun_Fan4;~Daiting_Shi2;~Zhicong_Cheng1;~Gu_Simiu1;~Dawei_Yin1",
        "gender": "M;M;;M;;M;M;M;M;M",
        "homepage": "https://chenyiqun.github.io/;https://sites.google.com/site/maojiaxin/;https://zhangyics.github.io/;https://madehong.github.io/;;;https://www.researchgate.net/profile/Daiting-Shi;;https://baike.baidu.com/item/%E8%BE%9C%E6%96%AF%E7%BC%AA/60897047;https://www.yindawei.com/",
        "dblp": "59/1143-4;174/8367;64/6544-50;32/2706;160/7582;;293/8193;88/8024;;",
        "google_scholar": "PYvsVB8AAAAJ;DDXcKKcAAAAJ;https://scholar.google.com.hk/citations?user=BgnOEFsAAAAJ;mOlY7gUAAAAJ;https://scholar.google.ca/citations?hl=en;jIeMCjIAAAAJ;;;;GuQ9bpAAAAAJ",
        "orcid": "0009-0008-6135-2604;0000-0002-9257-5498;;;;0009-0000-2127-0702;;;;0000-0002-0684-6205",
        "linkedin": ";;;;;;;;;dwyin/",
        "or_profile": "~Yiqun_Chen3;~Jiaxin_Mao1;~Yi_Zhang56;~Dehong_Ma1;~Long_Xia1;~Jun_Fan4;~Daiting_Shi2;~Zhicong_Cheng1;~Gu_Simiu1;~Dawei_Yin1",
        "aff": "Renmin University of China;Renmin University of China, Tsinghua University;ByteDance Inc.;;Baidu Inc.;Xiaohongshu;Baidu;Baidu;;Baidu",
        "aff_domain": "ruc.edu.cn;ruc.edu.cn;bytedance.com;;baidu.com;xiaohongshu.com;baidu.com;baidu.com;;baidu.com",
        "position": "PhD student;Assistant Professor;Search Scientist;;Research & Develop Engineer;Researcher;Researcher;Principal Researcher;;Principal Researcher",
        "bibtex": "@inproceedings{\nchen2025madiv,\ntitle={{MA}4{DIV}: Multi-Agent Reinforcement Learning for Search Result Diversification},\nauthor={Yiqun Chen and Jiaxin Mao and Yi Zhang and Dehong Ma and Long Xia and Jun Fan and Daiting Shi and Zhicong Cheng and Gu Simiu and Dawei Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=qvq7g5S7Hf}\n}",
        "github": "",
        "project": "",
        "reviewers": "mAij;PNxU;Z6Hh",
        "site": "https://openreview.net/forum?id=qvq7g5S7Hf",
        "pdf_size": 0,
        "novelty": "3;6;6",
        "technical_quality": "3;6;4",
        "scope": "2;3;3",
        "confidence": "3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.4142135623730951
        ],
        "technical_quality_avg": [
            4.333333333333333,
            1.247219128924647
        ],
        "scope_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5000000000000001
    },
    {
        "id": "rAvsdsxDLr",
        "title": "Graph with Sequence: Broad-Range Semantic Modeling for Fake News Detection",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The rapid proliferation of fake news on social media threatens social stability, creating an urgent demand for more effective detection methods. While many promising approaches have emerged, most rely on content analysis with limited semantic depth, leading to suboptimal comprehension of news content. To address this limitation, capturing broader-range semantics is essential yet challenging, as it introduces two primary types of noise: fully connecting sentences in news graphs often adds unnecessary structural noise, while highly similar but authenticity-irrelevant sentences introduce feature noise, complicating the detection process. To tackle these issues, we propose BREAK, a broad-range semantics model for fake news detection that leverages a fully connected graph to capture comprehensive semantics while employing dual denoising modules to minimize both structural and feature noise. The semantic structure denoising module balances the graph\u2019s connectivity by iteratively refining it between two bounds: a sequence-based structure as a lower bound and a fully connected graph as the upper bound. This refinement uncovers label-relevant semantic interrelations structures. Meanwhile, the semantic feature denoising module reduces noise from similar semantics by diversifying representations, aligning distinct outputs from the denoised graph and sequence encoders using KL-divergence to achieve feature diversification in high-dimensional space. The two modules are jointly optimized in a bi-level framework, enhancing the integration of denoised semantics into a comprehensive representation for detection. Extensive experiments across four datasets demonstrate that BREAK significantly outperforms existing methods in identifying fake news. Code is available at https://anonymous.4open.science/r/BREAK.",
        "keywords": "Fake news detection;broad-range semantics;bi-level optimization;graph neural network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "junwei Yin;Min Gao;Kai Shu;Wentao Li;Yinqiu Huang;Zongwei Wang",
        "authorids": "~junwei_Yin1;~Min_Gao2;~Kai_Shu1;~Wentao_Li1;~Yinqiu_Huang2;~Zongwei_Wang2",
        "gender": "M;F;;M;M;M",
        "homepage": ";http://www.cse.cqu.edu.cn/info/2095/7111.htm;https://www.cs.emory.edu/~kshu5/;https://wentaoli-92.github.io/;;https://coderwzw.github.io/",
        "dblp": ";45/1016-1.html;153/5265;60/8180-1.html;;125/8211-2",
        "google_scholar": ";K8oe7sMAAAAJ;-6bAV2cAAAAJ;https://scholar.google.com/citations?hl=en;24PemV8AAAAJ;https://scholar.google.com.hk/citations?user=pedoYGAAAAAJ",
        "orcid": "0009-0007-5737-3405;0000-0003-0127-7477;;0000-0003-4941-8814;;0000-0002-9774-4596",
        "linkedin": ";;;;;",
        "or_profile": "~junwei_Yin1;~Min_Gao2;~Kai_Shu1;~Wentao_Li1;~Yinqiu_Huang2;~Zongwei_Wang2",
        "aff": "Chongqing University;Chongqing University;Emory University;University of Leicester;Meituan;Chongqing University",
        "aff_domain": "cqu.edu.cn;cqu.edu.cn;emory.edu;leicester.ac.uk;meituan.com;cqu.edu.cn",
        "position": "MS student;Full Professor;Assistant Professor;Lecturer;Instructor;PhD student",
        "bibtex": "@inproceedings{\nyin2025graph,\ntitle={Graph with Sequence: Broad-Range Semantic Modeling for Fake News Detection},\nauthor={junwei Yin and Min Gao and Kai Shu and Wentao Li and Yinqiu Huang and Zongwei Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rAvsdsxDLr}\n}",
        "github": "",
        "project": "",
        "reviewers": "1Tsk;N26F;bhpE;2tQw",
        "site": "https://openreview.net/forum?id=rAvsdsxDLr",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "5;5;6;5",
        "scope": "3;4;4;3",
        "confidence": "4;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.30151134457776363
    },
    {
        "id": "rIkINybE6Y",
        "title": "Inferentially-Private Private Information",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Information disclosure can compromise privacy when revealed information is correlated with private information. We consider the notion of inferential privacy, which measures privacy leakage by bounding the inferential power a Bayesian adversary can gain by observing a released signal. Our goal is to devise an inferentially-private private information structure that maximizes the informativeness of the released signal, following the Blackwell ordering principle, while adhering to inferential privacy constraints. To achieve this, we devise an efficient release mechanism that achieves the inferentially-private Blackwell optimal private information structure for the setting where the private information is binary. Additionally, we propose a programming approach to compute the optimal structure for general cases given the utility function.\nThe design of our mechanisms builds on our geometric characterization of the Blackwell-optimal disclosure mechanisms under privacy constraints, which may be of independent interest.",
        "keywords": "privacy;information disclosure",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shuaiqi Wang;SHURAN ZHENG;Zinan Lin;Giulia Fanti;Steven Wu",
        "authorids": "~Shuaiqi_Wang1;~SHURAN_ZHENG2;~Zinan_Lin1;~Giulia_Fanti1;~Steven_Wu1",
        "gender": "M;;M;;",
        "homepage": "https://wsqwsq.github.io/;;https://zinanlin.me/;https://www.andrew.cmu.edu/user/gfanti/;",
        "dblp": "74/5587;;64/237-1;141/9910;",
        "google_scholar": "yy2OXxEAAAAJ;;67nE-wQ_g_cC;Rn_BmTYAAAAJ;",
        "orcid": "0000-0003-4962-7501;;;0000-0002-7671-2624;",
        "linkedin": ";;;;",
        "or_profile": "~Shuaiqi_Wang1;~SHURAN_ZHENG2;~Zinan_Lin1;~Giulia_Fanti1;~Steven_Wu1",
        "aff": "Carnegie Mellon University;;Microsoft;Carnegie Mellon University;",
        "aff_domain": "andrew.cmu.edu;;microsoft.com;andrew.cmu.edu;",
        "position": "PhD student;;Senior Researcher;Associate Professor;",
        "bibtex": "@inproceedings{\nwang2025inferentiallyprivate,\ntitle={Inferentially-Private Private Information},\nauthor={Shuaiqi Wang and SHURAN ZHENG and Zinan Lin and Giulia Fanti and Steven Wu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rIkINybE6Y}\n}",
        "github": "",
        "project": "",
        "reviewers": "MPBA;WBbW;63v4",
        "site": "https://openreview.net/forum?id=rIkINybE6Y",
        "pdf_size": 0,
        "novelty": "3;5;6",
        "technical_quality": "3;7;6",
        "scope": "3;3;3",
        "confidence": "2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            1.247219128924647
        ],
        "technical_quality_avg": [
            5.333333333333333,
            1.699673171197595
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9449111825230684
    },
    {
        "id": "rNvMJEgcu2",
        "title": "MixRec: Individual and Collective Mixing Empowers Data Augmentation for Recommender Systems",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The core of the modern recommender systems lies in learning high-quality embedding representations of users and items to investigate their positional relations in the feature space. Unfortunately, data sparsity caused by difficult-to-access interaction data severely limits the effectiveness of recommender systems. Faced with such a dilemma, various types of self-supervised learning methods have been introduced into recommender systems in an attempt to alleviate the data sparsity through distribution modeling or data augmentation. However, most data augmentation relies on elaborate manual design, which is not only not universal, but the bloated and redundant augmentation process may significantly slow down model training progress. To tackle these limitations, we propose a novel Dual Mixing-based Recommendation Framework (MixRec) to empower data augmentation as we wish. Specifically, we propose individual mixing and collective mixing, respectively. The former aims to provide a new positive sample that is unique to the target (user or item) and to make the pair-wise recommendation loss benefit from it, while the latter aims to portray a new sample that contains group properties in a batch. The two mentioned mixing mechanisms allow for data augmentation with only one parameter that does not need to be set multiple times and can be done in linear time complexity. Besides, we propose the dual-mixing contrastive learning to maximize the utilization of these new-constructed samples to enhance the consistency between pairs of positive samples. Experimental results on four real-world datasets demonstrate the effectiveness of MixRec in terms of recommendation performance, training efficiency, sparsity resistance, and usability.",
        "keywords": "recommender system;collaborative filtering;data augmentation;self-supervised learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yi Zhang;Yiwen Zhang",
        "authorids": "~Yi_Zhang70;~Yiwen_Zhang3",
        "gender": "M;M",
        "homepage": "https://blueghostyi.github.io/;http://bigdata.ahu.edu.cn/",
        "dblp": "64/6544-103;56/5142-1",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;",
        "orcid": "0000-0001-8196-0668;0000-0001-8709-1088",
        "linkedin": ";",
        "or_profile": "~Yi_Zhang70;~Yiwen_Zhang3",
        "aff": "Anhui University;Anhui University",
        "aff_domain": "ahu.edu.cn;ahu.edu.cn",
        "position": "PhD student;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025mixrec,\ntitle={MixRec: Individual and Collective Mixing Empowers Data Augmentation for Recommender Systems},\nauthor={Yi Zhang and Yiwen Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rNvMJEgcu2}\n}",
        "github": "",
        "project": "",
        "reviewers": "7wNA;75um;NRVG;dRqc",
        "site": "https://openreview.net/forum?id=rNvMJEgcu2",
        "pdf_size": 0,
        "novelty": "3;3;5;6",
        "technical_quality": "3;3;4;6",
        "scope": "3;3;3;3",
        "confidence": "4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            1.299038105676658
        ],
        "technical_quality_avg": [
            4.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5555555555555555
    },
    {
        "id": "rVc9zLcMsi",
        "title": "LIRA: A Learning-based Query-aware Partition Framework for Large-scale ANN Search",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Approximate nearest neighbor (ANN) search is fundamental in various applications such as information retrieval.\nTo enhance efficiency, partition-based methods are proposed to narrow the search space by probing partial partitions, yet they face two common issues.\nFirst, in the query phase, a widely adopted strategy in existing studies such as IVF is to probe partitions based on the distance ranks of a query to partition centroids.\nThis inevitably leads to irrelevant partition probing, since data distribution is not considered.\nSecond, in the partition construction phase, all the partition-based methods have the boundary problem that separates a query's $k$NN to multiple partitions and produces a long-tailed $k$NN distribution, degrading the optimal $nprobe$ (i.e., the number of probing partitions) and the search efficiency.\nTo address these problems, we propose LIRA, a LearnIng-based queRy-aware pArtition framework. Specifically, we propose a probing model to learn and directly probe the partitions containing the $k$NN of a query. Probing partitions with the model can reduce probing waste and allow for query-aware probing with query-specific $nprobe$. Moreover, we incorporate the probing model into a learning-based redundancy strategy to mitigate the adverse impact of the long-tailed $k$NN distribution on partition probing. \nExtensive experiments on real-world vector datasets demonstrate the superiority of LIRA in the trade-off among accuracy, latency, and query fan-out.\nThe results show that LIRA consistently reduces the latency and the query fan-out up to 30\\%.",
        "keywords": "Approximate nearest neighbor search;Learning-to-index",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ximu Zeng;Liwei Deng;Penghao Chen;Xu Chen;Han Su;Kai Zheng",
        "authorids": "~Ximu_Zeng1;~Liwei_Deng2;~Penghao_Chen1;~Xu_Chen24;~Han_Su1;~Kai_Zheng5",
        "gender": "F;M;M;;;M",
        "homepage": "https://github.com/SimoneZeng;https://liweideng0830.github.io/liweideng.github.io/;https://github.com/Ur-Eine;;https://ydri.uestc.edu.cn/info/1049/1041.htm;http://zheng-kai.com/#",
        "dblp": "325/3130;145/9154-1;;;23/3419-1.html;73/3928-1",
        "google_scholar": "https://scholar.google.com.hk/citations?hl=zh-CN;;;;;EM-l50cAAAAJ",
        "orcid": "0000-0002-5871-1871;0000-0002-9377-4309;0009-0006-1223-7787;;;0000-0002-0217-3998",
        "linkedin": "ximu-zeng-695099322/;;;;;",
        "or_profile": "~Ximu_Zeng1;~Liwei_Deng2;~Penghao_Chen1;~Xu_Chen24;~Han_Su1;~Kai_Zheng5",
        "aff": "University of Electronic Science and Technology of China;Aalborg University+University of Electronic Science and Technology of China;University of Electronic Science and Technology of China;;University of Electronic Science and Technology of China;University of Electronic Science and Technology of China",
        "aff_domain": "uestc.edu.cn;cs.aau.dk+uestc.edu.cn;uestc.edu.cn;;uestc.edu.cn;uestc.edu.cn",
        "position": "PhD student;Postdoc+PhD student;MS student;;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nzeng2025lira,\ntitle={{LIRA}: A Learning-based Query-aware Partition Framework for Large-scale {ANN} Search},\nauthor={Ximu Zeng and Liwei Deng and Penghao Chen and Xu Chen and Han Su and Kai Zheng},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rVc9zLcMsi}\n}",
        "github": "",
        "project": "",
        "reviewers": "F4pS;7Zh9;yMoB;RCju",
        "site": "https://openreview.net/forum?id=rVc9zLcMsi",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "5;6;4;6",
        "scope": "4;4;4;4",
        "confidence": "4;4;4;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            5.25,
            0.82915619758885
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.816496580927726
    },
    {
        "id": "rb3wgt85in",
        "title": "ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. The code, complete prompt templates, case studies are publicly available at the anonymous link: https://colacare.netlify.app.",
        "keywords": "electronic health record;large language model;large language model agents",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zixiang Wang;Yinghao Zhu;Huiya Zhao;Xiaochen Zheng;Dehao Sui;Tianlong Wang;Wen Tang;Yasha Wang;Ewen M Harrison;Chengwei Pan;Junyi Gao;Liantao Ma",
        "authorids": "~Zixiang_Wang1;~Yinghao_Zhu1;~Huiya_Zhao1;~Xiaochen_Zheng1;~Dehao_Sui1;~Tianlong_Wang1;~Wen_Tang3;~Yasha_Wang3;~Ewen_M_Harrison1;~Chengwei_Pan1;~Junyi_Gao1;~Liantao_Ma1",
        "gender": "M;M;;Non-Binary;M;M;F;M;M;M;M;Not Specified",
        "homepage": "https://fieldry.github.io;https://yhzhu99.github.io;http://none.com;https://xcvil.github.io;;;;;https://www.ed.ac.uk/profile/ewen-harrison;https://iai.buaa.edu.cn/info/1013/1123.htm;http://aboutme.vixerunt.org;https://scholar.google.com/citations?view_op=list_works&hl=en&user=necbkJkAAAAJ",
        "dblp": ";98/10801;;224/5088.html;;258/5623;;70/2725.html;;190/5330.html;236/0032;193/6198",
        "google_scholar": "U73PSFAAAAAJ;LYrsSoEAAAAJ;;KUeQNfwAAAAJ;;;;;https://scholar.google.co.uk/citations?user=XkChtuoAAAAJ;;5-1DeBsAAAAJ;https://scholar.google.com/citations?view_op=list_works",
        "orcid": "0009-0000-1257-9580;0000-0002-2640-6477;;;0009-0000-9081-059X;0009-0002-7292-6868;0000-0002-2263-2979;;0000-0002-5018-3066;0000-0003-0497-7903;0000-0002-4951-8682;0000-0001-5233-0624",
        "linkedin": ";yinghao-zhu;;;;;;;;;;",
        "or_profile": "~Zixiang_Wang1;~Yinghao_Zhu1;~Huiya_Zhao1;~Xiaochen_Zheng1;~Dehao_Sui1;~Tianlong_Wang1;~Wen_Tang3;~Yasha_Wang3;~Ewen_M_Harrison1;~Chengwei_Pan1;~Junyi_Gao1;~Liantao_Ma1",
        "aff": "Peking University;The University of Hong Kong+Beihang University;Peking University;University of Zurich;Beihang University;Peking University;Beijing Medical University;Peking University;University of Edinburgh;Beihang Uinveristy;University of Edinburgh;Peking University",
        "aff_domain": "stu.pku.edu.cn;hku.hk+buaa.edu.cn;stu.pku.edu.cn;uzh.ch;buaa.edu.cn;stu.pku.edu.cn;bjmu.edu.cn;pku.edu.cn;ed.ac.uk;buaa.edu.cn;ed.ac.uk;pku.edu.cn",
        "position": "MS student;PhD student+MS student;MS student;PhD student;Undergrad student;MS student;Associate Professor;Full Professor;Full Professor;Associate Professor;PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025colacare,\ntitle={ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration},\nauthor={Zixiang Wang and Yinghao Zhu and Huiya Zhao and Xiaochen Zheng and Dehao Sui and Tianlong Wang and Wen Tang and Yasha Wang and Ewen M Harrison and Chengwei Pan and Junyi Gao and Liantao Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rb3wgt85in}\n}",
        "github": "",
        "project": "",
        "reviewers": "vxpv;GWg2;KcGx;mvV9;JUfE",
        "site": "https://openreview.net/forum?id=rb3wgt85in",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "5;4;5;5;6",
        "scope": "3;4;3;3;3",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            12,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "rdnzTocXBr",
        "title": "Rankformer: A Graph Transformer for Recommendation based on Ranking Objective",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recommender Systems (RS) aim to generate personalized ranked lists for each user and are also evaluated using ranking metrics. Although personalized ranking is a fundamental aspect of RS, this critical property is often overlooked in the design of model architectures. To address this issue, we propose Rankformer, a ranking-inspired recommendation model. The architecture of Rankformer is inspired by the gradient of the ranking objective, embodying a unique (graph) transformer architecture --- it leverages global information from all users and items to produce more informative representations, and employs specific attention weights to guide the evolution of embeddings towards improved ranking performance. We further develop an acceleration algorithm for Rankformer, reducing its complexity to a linear level with respect to the number of positive instances. Extensive experimental results demonstrate that Rankformer outperforms state-of-the-art methods.",
        "keywords": "Recommendation;Graph Transformer",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sirui Chen;Shen Han;Jiawei Chen;Binbin Hu;Sheng Zhou;Gang Wang;Yan Feng;Chun Chen;Can Wang",
        "authorids": "~Sirui_Chen5;~Shen_Han2;~Jiawei_Chen6;~Binbin_Hu1;~Sheng_Zhou1;~Gang_Wang32;~Yan_Feng1;~Chun_Chen1;~Can_Wang5",
        "gender": "F;M;;M;M;M;;M;M",
        "homepage": ";;;https://librahu.github.io/;https://zhoushengisnoob.github.io/;;https://person.zju.edu.cn/0085162;https://person.zju.edu.cn/en/0082004;https://person.zju.edu.cn/en/wangcan",
        "dblp": ";;;;34/4858-4.html;;62/3960-5.html;07/4182-0001.html;71/4716-1",
        "google_scholar": ";;;a70Jt9oAAAAJ;https://scholar.google.co.jp/citations?user=Ss76nMwAAAAJ;;;;https://scholar.google.fr/citations?user=C63q3HoAAAAJ",
        "orcid": "0009-0006-5652-7970;0000-0001-6714-5237;;0000-0002-2505-1619;0000-0003-3645-1041;0000-0001-6248-1426;0000-0002-3605-5404;0000-0002-6198-7481;0000-0002-5890-4307",
        "linkedin": ";;;;;;;;",
        "or_profile": "~Sirui_Chen5;~Shen_Han2;~Jiawei_Chen6;~Binbin_Hu1;~Sheng_Zhou1;~Gang_Wang32;~Yan_Feng1;~Chun_Chen1;~Can_Wang5",
        "aff": "Zhejiang University;College of Computer Science and Technology, Zhejiang University;;Ant Group;Zhejiang University;;Zhejiang University;Zhejiang University;Zhejiang University",
        "aff_domain": "zju.edu.cn;cs.zju.edu.cn;;antfin.com;zju.edu.cn;;zju.edu.cn;zju.edu.cn;zju.edu.cn",
        "position": "PhD student;MS student;;Researcher;Associate Professor;;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nchen2025rankformer,\ntitle={Rankformer: A Graph Transformer for Recommendation based on Ranking Objective},\nauthor={Sirui Chen and Shen Han and Jiawei Chen and Binbin Hu and Sheng Zhou and Gang Wang and Yan Feng and Chun Chen and Can Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rdnzTocXBr}\n}",
        "github": "",
        "project": "",
        "reviewers": "p6re;HU1v;feRr;ZUfg;rvb3",
        "site": "https://openreview.net/forum?id=rdnzTocXBr",
        "pdf_size": 0,
        "novelty": "3;5;5;5;6",
        "technical_quality": "3;5;4;4;5",
        "scope": "4;3;3;4;4",
        "confidence": "4;3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.9797958971132712
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            9,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.16666666666666663
    },
    {
        "id": "rgWFuHLXtK",
        "title": "Least Privilege Access for Persistent Storage Mechanisms in Web Browsers",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Web applications often include third-party content and scripts to personalize a user's online experience. These scripts have unrestricted access to a user's private data stored in the browser's persistent storage like cookies, localstorage and IndexedDB, associated with the host page. Various mechanisms have been implemented to restrict access to these storage objects, e.g., content security policy, the HttpOnly attribute with cookies, etc. However, the existing mechanisms provide an all-or-none access and do not work in scenarios where web applications need to allow controlled access to cookies and localstorage objects by third-party scripts. If some of these scripts behave maliciously, they can easily access and modify private user information that are stored in the browser objects.\n\nThe goal of our work is to design a mechanism to enforce fine-grained control of persistent storage objects. We perform an empirical study of persistent storage access by third-party scripts on Tranco's top 10,000 websites and find that 89.84% of all cookie accesses, 90.98% of all localstorage accesses and 72.49% of IndexedDB accesses are done by third-party scripts. Our approach enforces least privilege access for third-party scripts on these objects to ensure their security by attaching labels to the storage objects that specify which domains are allowed to read from and write to these objects. We implement our approach on the Firefox browser and show that it effectively blocks scripts from other domains, which are not allowed access, based on these labels, from accessing the storage objects. We show that our enforcement results in some functionality breakage in websites with the default settings, which can be fixed by correctly labeling the storage objects used by the third-party scripts.",
        "keywords": "Cookies;localstorage;browser security;least privilege access",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Gayatri Priyadarsini Kancherla;Dishank Goel;ABHISHEK BICHHAWAT",
        "authorids": "~Gayatri_Priyadarsini_Kancherla1;~Dishank_Goel1;~ABHISHEK_BICHHAWAT1",
        "gender": "F;M;M",
        "homepage": "https://sites.google.com/view/gayatri-priyadarsini/home;;http://people.iitgn.ac.in/~abhishek/",
        "dblp": ";;61/10308",
        "google_scholar": "frriD8UAAAAJ;;qJavKW4AAAAJ",
        "orcid": ";;0000-0002-3075-2743",
        "linkedin": "https://linkedin.com/in/gayatri-priyadarsini/;dishankgoel;",
        "or_profile": "~Gayatri_Priyadarsini_Kancherla1;~Dishank_Goel1;~ABHISHEK_BICHHAWAT1",
        "aff": "Indian Institute of Technology, Gandhinagar;;Indian Institute of Technology, Gandhinagar",
        "aff_domain": "iitgn.ac.in;;iitgn.ac.in",
        "position": "PhD student;;Assistant Professor",
        "bibtex": "@inproceedings{\nkancherla2025least,\ntitle={Least Privilege Access for Persistent Storage Mechanisms in Web Browsers},\nauthor={Gayatri Priyadarsini Kancherla and Dishank Goel and ABHISHEK BICHHAWAT},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rgWFuHLXtK}\n}",
        "github": "",
        "project": "",
        "reviewers": "HB2V;FNvU;haz4;3DHE;P5jB",
        "site": "https://openreview.net/forum?id=rgWFuHLXtK",
        "pdf_size": 0,
        "novelty": "3;3;4;4;7",
        "technical_quality": "3;4;2;2;4",
        "scope": "3;4;4;4;4",
        "confidence": "3;4;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.469693845669907
        ],
        "technical_quality_avg": [
            3.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.38888888888888884
    },
    {
        "id": "rm07DoACiF",
        "title": "LLM-BS: Enhancing Large Language Models for Recommendation through Exogenous Behavior-Semantics Integration",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning.\n  Existing LLM-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. Typically, these systems apply pre-trained linguistic semantics while learning collaborative semantics from scratch using the LLM-Backbone. However, as LLM architectures are not inherently tailored for recommendation tasks, this approach results in inefficient learning of collaborative information, poor understanding of result correlations, and a failure to leverage traditional RSs features effectively.\n  To address these challenges, we propose LLM-BS, a decoder-only LLM-based generative recommendation framework that integrates endogenous and exogenous Behavioral and Semantic information in a non-intrusive manner.\n  Specifically, we propose 1) a dual-source, knowledge-rich item indexing scheme that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2) a multi-scale reconfiguration alignment that non-intrusively guides the model toward a deeper understanding of both collaborative and semantic signals; 3) an Annealing Adapter designed to finely balance the model\u2019s recommendation performance with its comprehension capabilities.\n  We demonstrate LLM-BS\u2019s effectiveness through rigorous testing on three public benchmarks.",
        "keywords": "Recommender systems;large language models (LLM);Behavior-Semantic Collaboration",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Minjie Hong;Yan Xia;Zehan Wang;Jieming Zhu;Ye Wang;Sihang Cai;Xiaoda Yang;Quanyu Dai;Zhenhua Dong;Zhimeng Zhang;Zhou Zhao",
        "authorids": "~Minjie_Hong1;~Yan_Xia4;~Zehan_Wang2;~Jieming_Zhu2;~Ye_Wang6;~Sihang_Cai1;~Xiaoda_Yang1;~Quanyu_Dai1;~Zhenhua_Dong1;~Zhimeng_Zhang3;~Zhou_Zhao3",
        "gender": "M;M;M;M;M;M;M;M;;M;",
        "homepage": ";https://github.com/marmot-xy;https://github.com/12zehan17;https://jiemingzhu.github.io/;;https://github.com/nohi191212;https://yangxiaoda1.github.io/;;;https://person.zju.edu.cn/NB19004;",
        "dblp": "357/6170;17/6518-6;126/7826-1;10/2717;44/6292;389/2548;381/0751.html;210/1089;;;",
        "google_scholar": "xNaUrS4AAAAJ;6kEbV3IAAAAJ;euXK0lkAAAAJ;oNKerP8AAAAJ;https://scholar.google.com/citations?view_op=list_works;;;https://scholar.google.com/citations?hl=en;;;",
        "orcid": "0009-0000-0368-2527;0000-0003-4631-741X;0009-0007-7509-7563;0000-0002-5666-8320;;0009-0007-8693-7142;0009-0002-7297-4536;0000-0001-7578-2738;;0000-0001-9492-4252;",
        "linkedin": ";;;;;;;;;;",
        "or_profile": "~Minjie_Hong1;~Yan_Xia4;~Zehan_Wang2;~Jieming_Zhu2;~Ye_Wang6;~Sihang_Cai1;~Xiaoda_Yang1;~Quanyu_Dai1;~Zhenhua_Dong1;~Zhimeng_Zhang3;~Zhou_Zhao3",
        "aff": "Zhejiang University;Zhejiang University;Zhejiang University;Huawei Noah's Ark Lab;;College of Computer Science and Technology, Zhejiang University;Zhejiang University;Huawei Technologies Ltd.;;Zhejiang University+Zhejiang University;",
        "aff_domain": "zju.edu.cn;zju.edu.cn;zju.edu.cn;huawei.com;;cs.zju.edu.cn;zju.edu.cn;huawei.com;;zju.edu.cn+zju.edu.cn;",
        "position": "MS student;PhD student;PhD student;Researcher;;MS student;MS student;Researcher;;Associate Professor+Instructor;",
        "bibtex": "@inproceedings{\nhong2025llmbs,\ntitle={{LLM}-{BS}: Enhancing Large Language Models for Recommendation through Exogenous Behavior-Semantics Integration},\nauthor={Minjie Hong and Yan Xia and Zehan Wang and Jieming Zhu and Ye Wang and Sihang Cai and Xiaoda Yang and Quanyu Dai and Zhenhua Dong and Zhimeng Zhang and Zhou Zhao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=rm07DoACiF}\n}",
        "github": "",
        "project": "",
        "reviewers": "kxxk;xahL;xmPF;bxFj;XMJM",
        "site": "https://openreview.net/forum?id=rm07DoACiF",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "5;5;6;4;3",
        "scope": "4;4;4;4;3",
        "confidence": "4;3;4;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            11,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7905694150420948
    },
    {
        "id": "s3KIzcRdll",
        "title": "node2binary: Compact Graph Node Embeddings Using Binary Vectors",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "With the adoption of deep learning models to low-power, small-memory edge devices, energy consumption and storage usage of such models has become a key concern. The problem acerbates even further with ever-growing data and equally-matched bulkier models. This concern is particularly pronounced for graph data due to its quadratic storage, irregular (non-grid) geometry, and very large size. Typical graph data, such as road networks, infrastructure networks, social networks easily exceeds millions of nodes, and several gigabytes of storage is needed just to store the node embedding vectors, let alone the model parameters. In recent years, the memory issue has been addressed by moving away from memory-intensive double precision floating-point arithmetic towards single-precision or even half-precision, often by trading-off marginally small performance. Along this effort, we propose Node2binary, which embeds graph nodes in as low as 128 binary bits, which drastically reduces the memory footprint of vertex embedding vectors by several order of magnitude. Node2binary leverages a fast community detection algorithm to covert the given graph into a hierarchical partition tree and then find embedding of graph vertices in binary space by solving a combinatorial optimization (CO) task over the tree edges. CO is NP-hard, but Node2binary uses an innovative combination of discrete gradient descent and randomization to solve this effectively and efficiently. Our extensive experiments over four real-world graphs show that Node2binary achieves competitive performances compared to the state-of-the art graph embedding methods in both node classification and link prediction tasks.",
        "keywords": "Binary Space Embedding;Graph Embedding;Discrete Gradient Descent;Randomized Algorithm",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Niloy Talukder;Croix Gyurek;Mohammad Hasan",
        "authorids": "~Niloy_Talukder1;~Croix_Gyurek1;~Mohammad_Hasan1",
        "gender": "M;M;M",
        "homepage": ";;http://cs.iupui.edu/~alhasan/",
        "dblp": ";;87/5931.html",
        "google_scholar": "-YDyG6MAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.com.tw/citations?user=fsCnri8AAAAJ",
        "orcid": ";;",
        "linkedin": "niloytalukder/;;",
        "or_profile": "~Niloy_Talukder1;~Croix_Gyurek1;~Mohammad_Hasan1",
        "aff": "Indiana University;University of Waterloo;Indiana University Indianapolis",
        "aff_domain": "iu.edu;uwaterloo.ca;iu.edu",
        "position": "PhD student;MS student;Full Professor",
        "bibtex": "@inproceedings{\ntalukder2025nodebinary,\ntitle={node2binary: Compact Graph Node Embeddings Using Binary Vectors},\nauthor={Niloy Talukder and Croix Gyurek and Mohammad Hasan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=s3KIzcRdll}\n}",
        "github": "",
        "project": "",
        "reviewers": "u9NE;iQpv;MMsf;ei7U;5XC6",
        "site": "https://openreview.net/forum?id=s3KIzcRdll",
        "pdf_size": 0,
        "novelty": "2;4;5;6;6",
        "technical_quality": "3;4;4;5;5",
        "scope": "3;4;3;4;3",
        "confidence": "3;3;2;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.4966629547095764
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.13363062095621214
    },
    {
        "id": "sKs91EOWae",
        "title": "Boosting Asynchronous Decentralized Learning with Model Fragmentation",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Decentralized learning (DL) is an emerging technique that allows nodes on the web to collaboratively train machine learning models without sharing raw data.\nDealing with stragglers, i.e., nodes with slower compute or communication than others, is a key challenge in DL.\nWe present DivShare, a novel asynchronous DL algorithm that achieves fast model convergence in the presence of communication stragglers.\nDivShare achieves this by having nodes fragment their models into parameter subsets and send, in parallel to computation, each subset to a random sample of other nodes instead of sequentially exchanging full models.\nThe transfer of smaller fragments allows more efficient usage of the collective bandwidth and enables nodes with slow network links to contribute with at least some of their model parameters quickly.\nBy theoretically proving the convergence of DivShare, we provide, to the best of our knowledge, the first formal proof of convergence for a DL algorithm that accounts for the effects of asynchronous communication with delays.\nWe experimentally evaluate DivShare against two state-of-the-art DL baselines, AD-PSGD and Swift, and with two standard datasets, CIFAR-10 and Movielens.\nWe find that DivShare with communication stragglers lowers time-to-accuracy by up to 3.9x compared to AD-PSGD on the CIFAR-10 dataset.\nCompared to baselines, DivShare also achieves up to 19.4% better accuracy and 9.5% lower test loss on the CIFAR-10 and Movielens datasets, respectively.",
        "keywords": "Decentralized Learning;Collaborative Machine Learning;Asynchronous Decentralized Learning;Communication Stragglers",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sayan Biswas;Anne-Marie Kermarrec;Alexis Marouani;Rafael Pires;Rishi Sharma;Martijn De Vos",
        "authorids": "~Sayan_Biswas1;~Anne-Marie_Kermarrec3;~Alexis_Marouani1;~Rafael_Pires1;~Rishi_Sharma2;~Martijn_De_Vos1",
        "gender": "M;;M;M;M;",
        "homepage": "https://blitzwas.github.io/;;;https://pires.tech/;https://rishisharma.netlify.app/;https://devos50.github.io",
        "dblp": "198/0633;;;189/6914;158/4544-1;137/4243",
        "google_scholar": "PqfgluAAAAAJ;;;https://scholar.google.ch/citations?user=EegvylkAAAAJ;jUfDXOsAAAAJ;",
        "orcid": ";;;0000-0002-7826-1599;0000-0002-1928-1549;",
        "linkedin": "sayanbiswas5/;;alexis-marouani-900148154?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app;rafaelppires/?locale=en_US;rishi-s8/;",
        "or_profile": "~Sayan_Biswas1;~Anne-Marie_Kermarrec3;~Alexis_Marouani1;~Rafael_Pires1;~Rishi_Sharma2;~Martijn_De_Vos1",
        "aff": "EPFL - EPF Lausanne;;Ecole Normale Superieure+\u00c9cole Polytechnique;EPFL - EPF Lausanne+EPFL - EPF Lausanne;EPFL - EPF Lausanne+Microsoft+Massachusetts Institute of Technology;EPFL - EPF Lausanne",
        "aff_domain": "epfl.ch;;ens-paris-saclay.fr+polytechnique.edu;epfl.ch+epfl.ch;epfl.ch+microsoft.com+mit.edu;epfl.ch",
        "position": "Postdoc;;MS student+MS student;Lecturer+Postdoc;PhD student+Intern+Intern;Postdoc",
        "bibtex": "@inproceedings{\nbiswas2025boosting,\ntitle={Boosting Asynchronous Decentralized Learning with Model Fragmentation},\nauthor={Sayan Biswas and Anne-Marie Kermarrec and Alexis Marouani and Rafael Pires and Rishi Sharma and Martijn De Vos},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=sKs91EOWae}\n}",
        "github": "",
        "project": "",
        "reviewers": "e3GD;4Mru;d9KT;RJ7W",
        "site": "https://openreview.net/forum?id=sKs91EOWae",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "6;4;5;7",
        "scope": "4;4;2;3",
        "confidence": "4;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.5,
            1.118033988749895
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            2.75,
            0.82915619758885
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8703882797784891
    },
    {
        "id": "sY0qgZeA8U",
        "title": "Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Data summarization tasks are often modeled as $k$-clustering problems, where the goal is to choose $k$ data points, called cluster centers, that best represent the dataset by minimizing a clustering objective. A popular objective is to minimize the maximum distance between any data point and its nearest center, which is formalized as the $k$-center problem. While in some applications all data points can be chosen as centers, in the general setting, centers must be chosen from a predefined subset of points, referred as facilities or suppliers; this is known as the $k$-supplier problem. In this work, we focus on fair data summarization modeled as the fair $k$-supplier problem, where data consists of several groups, and a minimum number of centers must be selected from each group while minimizing the $k$-supplier  objective. The groups can be disjoint or overlapping, leading to two distinct problem variants each with different computational complexity. \n\nWe present $3$-approximation algorithms for both variants, improving the previously known factor of $5$. For disjoint groups, our algorithm runs in polynomial time, while for overlapping groups, we present a fixed-parameter tractable algorithm, where the exponential runtime depends only on the number of groups and centers. We show that these approximation factors match the theoretical lower bounds, assuming standard complexity theory conjectures. Finally, using an (anonymous) open-source implementation, we demonstrate the scalability of our algorithms on large synthetic datasets and assess the price of fairness on real-world data, comparing solution quality with and without fairness constraints.",
        "keywords": "Algorithmic Fairness;Fair Clustering;Responsible Computing;Approximation Algorithms;Fair $k$-supplier",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ameet Gadekar;Aristides Gionis;Suhas Thejaswi",
        "authorids": "~Ameet_Gadekar1;~Aristides_Gionis1;~Suhas_Thejaswi1",
        "gender": ";Not Specified;",
        "homepage": "https://amitgadekar.in/;https://www.kth.se/profile/argioni;",
        "dblp": "159/1768;g/AristidesGionis;",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.tw/citations?user=11JgipcAAAAJ;",
        "orcid": "0009-0004-8040-9881;;",
        "linkedin": ";;",
        "or_profile": "~Ameet_Gadekar1;~Aristides_Gionis1;~Suhas_Thejaswi1",
        "aff": "CISPA Helmholtz Center for Information Security;KTH Royal Institute of Technology, Stockholm, Sweden;",
        "aff_domain": "cispa.de;kth.se;",
        "position": "Postdoc;Professor;",
        "bibtex": "@inproceedings{\ngadekar2025fair,\ntitle={Fair Clustering for Data Summarization: Improved Approximation Algorithms and Complexity Insights},\nauthor={Ameet Gadekar and Aristides Gionis and Suhas Thejaswi},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=sY0qgZeA8U}\n}",
        "github": "",
        "project": "",
        "reviewers": "HBDG;dQSb;XbeV;dYbB;XzQz",
        "site": "https://openreview.net/forum?id=sY0qgZeA8U",
        "pdf_size": 0,
        "novelty": "2;3;5;5;6",
        "technical_quality": "2;5;5;5;6",
        "scope": "3;3;2;2;4",
        "confidence": "4;2;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.469693845669907
        ],
        "technical_quality_avg": [
            4.6,
            1.3564659966250536
        ],
        "scope_avg": [
            2.8,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5091750772173155
    },
    {
        "id": "sYZvdIh9ro",
        "title": "AdvTG: An Adversarial Traffic Generation Framework to Deceive DL-Based Malicious Traffic Detection Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Deep learning-based (DL-based) malicious traffic detection methods are effective but vulnerable to adversarial attacks. Existing adversarial attack methods have shown promising results when targeting traffic detection models based on statistics and sequence features.  However, these methods are less effective against models that rely on payload analysis.  \nThe main reason is the difficulty in generating semantic, compliant, and functional payloads, which limits their practical application.\n\nIn this paper, we propose AdvTG, an adversarial traffic generation framework based on the large language model (LLM) and reinforcement learning (RL). Specifically, AdvTG is designed to attack various DL-based detection models across diverse features and architectures, thereby enhancing the generalization capabilities of the generated adversarial traffic. Moreover, we design a specialized prompt for payload generation tasks, where functional fields and target types are supplied as input, while non-functional fields are generated to produce the mutated traffic. This fine-tuning endows the LLM with task comprehension and traffic pattern reasoning abilities, allowing it to generate traffic that remains compliant and functional.    Furthermore, leveraging RL, AdvTG automatically selects traffic fields that exhibit more robust adversarial properties. \nExperimental results show that AdvTG achieves over 40\\% attack success rate (ASR) across six detection models on four base datasets and two extended datasets, significantly outperforming other adversarial attack methods.",
        "keywords": "Malicious Traffic Detection;Adversarial Attacks;Large Language Model;Reinforcement Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "peishuai sun;Yun Xiaochun;Shuhao Li;Tao Yin;Si Cx;Jiang Xie",
        "authorids": "~peishuai_sun1;~Yun_Xiaochun1;~Shuhao_Li4;~Tao_Yin3;~Si_Cx1;~Jiang_Xie2",
        "gender": "M;M;M;;F;M",
        "homepage": ";https://people.ucas.ac.cn/~yxc;;;https://dblp2.uni-trier.de/pid/62/5048.html;https://orcid.org/0000-0003-3219-3102",
        "dblp": ";;https://dblp2.uni-trier.de/pid/25/5081.html;;https://dblp2.uni-trier.de/pid/62/5048.html;https://dblp2.uni-trier.de/pid/x/JXie-4.html",
        "google_scholar": ";;;;;",
        "orcid": "0000-0003-1135-8297;;;0009-0007-1708-7949;;0000-0003-3219-3102",
        "linkedin": ";;;;;",
        "or_profile": "~peishuai_sun1;~Yun_Xiaochun1;~Shuhao_Li4;~Tao_Yin3;~Si_Cx1;~Jiang_Xie2",
        "aff": "University of Chinese Academy of Sciences;;;;;",
        "aff_domain": "ucas.edu;;;;;",
        "position": "Undergrad student;;;;;",
        "bibtex": "@inproceedings{\nsun2025advtg,\ntitle={Adv{TG}: An Adversarial Traffic Generation Framework to Deceive {DL}-Based Malicious Traffic Detection Models},\nauthor={peishuai sun and Yun Xiaochun and Shuhao Li and Tao Yin and Si Cx and Jiang Xie},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=sYZvdIh9ro}\n}",
        "github": "",
        "project": "",
        "reviewers": "tQx9;NKXf;F6GP;7RQF",
        "site": "https://openreview.net/forum?id=sYZvdIh9ro",
        "pdf_size": 0,
        "novelty": "4;4;4;6",
        "technical_quality": "4;4;5;6",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            4.75,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "sdFk3g79gL",
        "title": "BoxCD: Leveraging Contrastive Probabilistic Box Embedding for Effective and Efficient Learner Modeling",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In digital education, Cognitive Diagnosis (CD) is essential for modeling learners' cognitive states, such as problem-solving ability and knowledge proficiency, by analyzing their response data, like answer correctness. However, traditional CD methods struggle with \\textit{effectiveness} and \\textit{efficiency}. They fail to capture the diversity and uncertainty of learners' cognitive states. Additionally, response prediction can be time-consuming.\nTo address these issues, we propose BoxCD, a contrastive probabilistic box embedding model for cognitive diagnosis. BoxCD utilizes high-dimensional axis-aligned hyper-rectangles (boxes) to represent learners and exercises, with the volume of intersecting boxes used to predict learners' responses. This approach effectively captures semantic diversity and uncertainty while enhancing diagnostic effectiveness. To stabilize box embeddings, we integrate contrastive learning objectives with response prediction goals, optimizing the distance between positive and negative samples of learner and exercise boxes to improve uniformity. Additionally, we develop a rank-based response prediction method that leverages the geometric properties of box embeddings to efficiently assess learners' response correctness.\nComprehensive experiments on two real-world datasets demonstrate that BoxCD outperforms traditional CD models in both effectiveness and efficiency, showcasing its potential to enhance personalized learning in digital education platforms.",
        "keywords": "User Modeling",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Weibo Gao;Qi Liu;Linan Yue;Fangzhou Yao;Zhenya Huang;Zheng Zhang;Rui Lv",
        "authorids": "~Weibo_Gao1;~Qi_Liu3;~Linan_Yue1;~Fangzhou_Yao1;~Zhenya_Huang2;~Zheng_Zhang20;~Rui_Lv1",
        "gender": ";M;M;;M;;F",
        "homepage": ";http://staff.ustc.edu.cn/~qiliuql/;https://yuelinan.github.io/;;http://staff.ustc.edu.cn/~huangzhy/;;https://karin0018.github.io/",
        "dblp": ";95/2446-3;297/1080;;178/8690;;33/2510",
        "google_scholar": ";5EoHAFwAAAAJ;https://scholar.google.com.hk/citations?user=XDaNgG4AAAAJ;;dVZuU90AAAAJ;;",
        "orcid": ";0000-0001-6956-5550;0000-0002-5980-6098;;0000-0003-1661-0420;;",
        "linkedin": ";;;;;;",
        "or_profile": "~Weibo_Gao1;~Qi_Liu3;~Linan_Yue1;~Fangzhou_Yao1;~Zhenya_Huang2;~Zheng_Zhang20;~Rui_Lv1",
        "aff": ";University of Science and Technology of China;Southeast University;;University of Science and Technology of China;;University of Science and Technology of China",
        "aff_domain": ";ustc.edu.cn;seu.edu.cn;;ustc.edu.cn;;ustc.edu.cn",
        "position": ";Full Professor;Associate Professor;;Associate Professor;;PhD student",
        "bibtex": "@inproceedings{\ngao2025boxcd,\ntitle={Box{CD}: Leveraging Contrastive Probabilistic Box Embedding for Effective and Efficient Learner Modeling},\nauthor={Weibo Gao and Qi Liu and Linan Yue and Fangzhou Yao and Zhenya Huang and Zheng Zhang and Rui Lv},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=sdFk3g79gL}\n}",
        "github": "",
        "project": "",
        "reviewers": "USh2;6w8F;A6Sa;xFng;8Uuf",
        "site": "https://openreview.net/forum?id=sdFk3g79gL",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "4;4;4;5;4",
        "scope": "3;4;4;3;3",
        "confidence": "3;2;4;1;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.2,
            0.39999999999999997
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            1.019803902718557
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.4803844614152614
    },
    {
        "id": "smJ1GcDfIs",
        "title": "Graph Wave Networks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Dynamics modeling has been introduced as a novel paradigm in message passing (MP) of graph neural networks (GNNs). Existing methods consider MP between nodes as a heat diffusion process, and leverage \\textit{heat equation} to model the temporal evolution of nodes in the embedding space. However, heat equation can hardly depict the wave nature of graph signals in graph signal processing. Besides, heat equation is essentially a partial differential equation (PDE) involving a first partial derivative of time, whose numerical solution usually has low stability, and leads to inefficient model training. In this paper, we would like to depict more wave details in MP, since graph signals are essentially wave signals that can be seen as a superposition of a series of waves in the form of eigenvector. This motivates us to consider MP as a wave propagation process to capture the temporal evolution of wave signals in the space. Based on wave equation in physics, we innovatively develop a graph wave equation to leverage the wave propagation on graphs. In details, we demonstrate that the graph wave equation can be connected to traditional spectral GNNs, facilitating the design of graph wave networks (GWNs) based on various Laplacians and enhancing the performance of the spectral GNNs. Besides, the graph wave equation is particularly a PDE involving a second partial derivative of time, which has stronger stability on graphs than the heat equation that involves a first partial derivative of time. Additionally, we theoretically prove that the numerical solution derived from the graph wave equation are constantly stable, enabling to significantly enhance model efficiency while ensuring its performance. Extensive experiments show that GWNs achieve state-of-the-art and efficient performance on benchmark datasets, and exhibit outstanding performance in addressing challenging graph problems, such as over-smoothing and heterophily. Our code is available at https://anonymous.4open.science/r/GWN/.",
        "keywords": "Graph Neural Networks;Partial Differential Equations;Wave Equation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Juwei Yue;Haikuo Li;Jiawei Sheng;Yihan Guo;Xinghua Zhang;Chuan Zhou;Tingwen Liu;Li Guo",
        "authorids": "~Juwei_Yue2;~Haikuo_Li1;~Jiawei_Sheng1;~Yihan_Guo2;~Xinghua_Zhang1;~Chuan_Zhou3;~Tingwen_Liu1;~Li_Guo2",
        "gender": ";M;M;;M;M;M;F",
        "homepage": ";https://lihaikuo.nlp.ac;https://jiaweisheng.github.io/;;https://xinghuazhang.top/;http://www.chuanzhou.online/;http://liutingwen.ac.cn;https://people.ucas.ac.cn/~guoli",
        "dblp": ";;276/7004;;188/3331-1;https://dblp.uni-trier.de/pid/52/564-1;56/7911;02/929-1",
        "google_scholar": ";;CcPWJCYAAAAJ;;_XlhNDsAAAAJ;4oBUWVEAAAAJ;JqOOSuIAAAAJ;",
        "orcid": ";;0000-0002-4865-982X;;0000-0001-6954-5605;0000-0001-9958-8673;0000-0002-0750-6923;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Juwei_Yue2;~Haikuo_Li1;~Jiawei_Sheng1;~Yihan_Guo2;~Xinghua_Zhang1;~Chuan_Zhou3;~Tingwen_Liu1;~Li_Guo2",
        "aff": ";Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;;Alibaba Group;Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences",
        "aff_domain": ";iie.ac.cn;iie.ac.cn;;alibaba-inc.com;amss.ac.cn;iie.ac.cn;iie.ac.cn",
        "position": ";PhD student;Associate Professor;;Researcher;Associate Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nyue2025graph,\ntitle={Graph Wave Networks},\nauthor={Juwei Yue and Haikuo Li and Jiawei Sheng and Yihan Guo and Xinghua Zhang and Chuan Zhou and Tingwen Liu and Li Guo},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=smJ1GcDfIs}\n}",
        "github": "",
        "project": "",
        "reviewers": "Y7Mw;pnBD;gDRu;BtFo",
        "site": "https://openreview.net/forum?id=smJ1GcDfIs",
        "pdf_size": 0,
        "novelty": "4;6;6;6",
        "technical_quality": "3;6;6;6",
        "scope": "3;4;4;4",
        "confidence": "3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            5.25,
            1.299038105676658
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "ss9UXxbSys",
        "title": "Bridging the Gap: Teacher-Assisted Wasserstein Knowledge Distillation for Efficient Multi-Modal Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multi-modal recommender systems (MMRecs) leverage diverse modalities to deliver personalized recommendations, yet they often struggle with efficiency due to the large size of modality encoders and the complexity of fusing high-dimensional features. To address the efficiency issue, a promising solution is to compress a cumbersome MMRec into a lightweight ID-based Multi-Layer Perceptron-based Recommender system (MLPRec) through Knowledge Distillation (KD). Despite effectiveness, this approach overlooks the significant gap between the complex teacher MMRec and the lightweight, ID-based student MLPRec, which differ significantly in size, architecture, and input modalities, leading to ineffective knowledge transfer and suboptimal student performance. To bridge this gap, we propose TARec, a novel teacher-assisted Wasserstein Knowledge Distillation framework for compressing MMRecs into an efficient MLPRec. TARec introduces: (i) a two-staged KD process using an intermediate Teacher Assistant (TA) model to bridge the gap between teacher and student, facilitating smoother knowledge transfer; (ii) logit-level KD using the Wasserstein Distance as metric, replacing the conventional KL divergence to ensure stable gradient flow even with significant teacher-student gaps; and (iii) embedding-level contrastive KD to further distill high-quality embedding-level knowledge from teacher. Extensive experiments on real-world datasets verify the effectiveness of TARec, demonstrating that TARec significantly outperforms the state-of-the-art MMRecs while reducing computational costs. Our anonymous code is available at: https://anonymous.4open.science/r/TARec-0980/.",
        "keywords": "Multi-modal Recommendation;Knowledge Distillation;Optimal Transport;Wasserstein Distance",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ziyi Zhuang;Hanwen Du;Hui Han;Youhua Li;Junchen Fu;Joemon M. Jose;Yongxin Ni",
        "authorids": "~Ziyi_Zhuang2;~Hanwen_Du1;~Hui_Han3;~Youhua_Li2;~Junchen_Fu1;~Joemon_M._Jose1;~Yongxin_Ni1",
        "gender": "M;;F;;M;M;",
        "homepage": "https://github.com/Suehn;;https://github.com/abigcatcat;;https://junchen-fu.github.io/;http://www.dcs.gla.ac.uk/~jj;https://github.com/yxni98",
        "dblp": ";;;;331/8068;84/5102;278/9930",
        "google_scholar": ";;;;V3r0t9sAAAAJ;7t8ha2sAAAAJ;",
        "orcid": ";;;;0000-0003-4759-2042;0000-0001-9228-1759;0009-0003-7606-1475",
        "linkedin": ";;;;;joemon-jose-1102285/?originalSubdomain=uk;",
        "or_profile": "~Ziyi_Zhuang2;~Hanwen_Du1;~Hui_Han3;~Youhua_Li2;~Junchen_Fu1;~Joemon_M._Jose1;~Yongxin_Ni1",
        "aff": "Shanghai Jiaotong University;;Shanghai Jiaotong University;;University of Glasgow;University of Glasgow;Westlake University",
        "aff_domain": "sjtu.edu.cn;;sjtu.edu.cn;;gla.ac.uk;glasgow.ac.uk;westlake.edu.cn",
        "position": "MS student;;MS student;;PhD student;Professor;Researcher",
        "bibtex": "@inproceedings{\nzhuang2025bridging,\ntitle={Bridging the Gap: Teacher-Assisted Wasserstein Knowledge Distillation for Efficient Multi-Modal Recommendation},\nauthor={Ziyi Zhuang and Hanwen Du and Hui Han and Youhua Li and Junchen Fu and Joemon M. Jose and Yongxin Ni},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ss9UXxbSys}\n}",
        "github": "",
        "project": "",
        "reviewers": "1Ng3;dGaR;4iFi",
        "site": "https://openreview.net/forum?id=ss9UXxbSys",
        "pdf_size": 0,
        "novelty": "3;4;4",
        "technical_quality": "5;5;5",
        "scope": "4;3;4",
        "confidence": "4;4;1",
        "wc_review": "",
        "novelty_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.0,
            0.0
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            1.4142135623730951
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5000000000000001
    },
    {
        "id": "stFVHso95H",
        "title": "Bridging the Gap: Aligning Language Model Generation with Structured Information Extraction via Controllable State Transition",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Large language models (LLM) achieve superior performance in generative tasks. However, due to the natural gap between language model generation and structured information extraction in three dimensions: task type, output format, and modeling granularity, they often fall short in structured information extraction, a crucial capability for effective data utilization on the web. In this paper, we define the generation process of the language model as the controllable state transition, aligning the generation and extraction processes to ensure the integrity of the output structure and adapt to the goals of the information extraction task. Furthermore, we propose the Structure2Text decider to help the language model understand the fine-grained extraction information, which converts the structured output into natural language and makes state decisions, thereby focusing on the task-specific information kernels, and alleviating language model hallucinations and incorrect content generation. We conduct extensive experiments and detailed analyses on myriad information extraction tasks. Our method not only achieves significant performance improvements but also ensures the integrity of the output structure, making it easy to parse the extracted content.",
        "keywords": "Information Extraction;Large Language Model;Few-shot Learning;Structure Generation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hao Li;Yubing Ren;Yanan Cao;Yingjie Li;Fang Fang;Zheng Lin;Shi Wang",
        "authorids": "~Hao_Li45;~Yubing_Ren1;~Yanan_Cao1;~Yingjie_Li3;~Fang_Fang6;~Zheng_Lin5;~Shi_Wang2",
        "gender": "M;;F;M;;;",
        "homepage": "https://github.com/hlee-top;https://lilice-r.github.io/;;https://github.com/lyj963;;;https://ictkc.github.io",
        "dblp": ";331/1171;97/5152-1;;;;",
        "google_scholar": "gFxTgcMAAAAJ;https://scholar.google.com/citations?hl=zh-CN;;;;;",
        "orcid": ";0000-0002-0815-3998;0000-0003-3534-1094;;;;0000-0002-1329-2415",
        "linkedin": ";;;;;;",
        "or_profile": "~Hao_Li45;~Yubing_Ren1;~Yanan_Cao1;~Yingjie_Li3;~Fang_Fang6;~Zheng_Lin5;~Shi_Wang2",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Sciences;;;Chinese Academy of Sciences",
        "aff_domain": "iie.ac.cn;iie.ac.cn;iie.ac.cn;iie.ac.cn;;;ict.ac.cn",
        "position": "PhD student;Associate Professor;Full Professor;PhD student;;;Full Professor",
        "bibtex": "@inproceedings{\nli2025bridging,\ntitle={Bridging the Gap: Aligning Language Model Generation with Structured Information Extraction via Controllable State Transition},\nauthor={Hao Li and Yubing Ren and Yanan Cao and Yingjie Li and Fang Fang and Zheng Lin and Shi Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=stFVHso95H}\n}",
        "github": "",
        "project": "",
        "reviewers": "Uc3T;MLU4;1qYB;y77i",
        "site": "https://openreview.net/forum?id=stFVHso95H",
        "pdf_size": 0,
        "novelty": "5;6;6;6",
        "technical_quality": "5;5;5;6",
        "scope": "4;4;4;4",
        "confidence": "3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "syOhXfIXv0",
        "title": "Semantics-Aware Cookie Purpose Compliance",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In response to stringent data protection regulations, websites typically display a cookie banner to inform users about the usage and purposes of cookies, seeking their explicit consent before installing any cookies into their browsers. However, a systematic approach for reliably assessing compliance between the website-declared purpose and the semantic-intended purpose of cookies (denoted as $potential$ $cookie$ $purpose$ $violation$) has been notably absent.  Websites may still, whether intentionally or unintentionally (e.g., due to third-party libraries imported), mis-declare cookies that may be abused for tracking purposes.  \n\nWe address this gap with COOVER ($\\underline{coo}kie$  $\\underline{v}alue$  $examin\\underline{er}$).  We advocate that the value of the cookie is a more reliable indicator of its semantic-intended purpose compared to other features, such as expires and meta-information, which can be easily obfuscated. COOVER decomposes the cookie value into primitive $segments$ representing minimal semantic units, and fine-tunes a GPT-3.5 model to automatically interpret their semantics. Based on the interpretation, it classifies cookies into four GDPR-defined purposes. We benchmark COOVER against two widely-used content management providers (CMPs) i.e., CookiePedia and Cookie Script, and the state-of-the-art cookie classifier named CookieBlock. It achieves an F1 score of 95%, significantly outperforming other methods. To understand the $status$ $quo$ of potential cookie purpose violations on the web, we employ COOVER to analyze Alexa Top 1k websites. Remarkably, out of 15,339 cookies across these websites, only 3.1% quality as $truly$ necessary cookies, while 44.1% of websites suffer from issues of potential purpose violation. Our work serves as a wake-up call to web service providers and encourages further regulatory interventions to rectify non-compliance issues within the web infrastructure.",
        "keywords": "website cookie",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Baiqi Chen;Jiawei Lyu;Tingmin Wu;Mohan Baruwal Chhetri;Guangdong Bai",
        "authorids": "~Baiqi_Chen1;~Jiawei_Lyu2;~Tingmin_Wu1;~Mohan_Baruwal_Chhetri1;~Guangdong_Bai1",
        "gender": "F;M;F;;",
        "homepage": ";;;;",
        "dblp": ";;192/6021;;",
        "google_scholar": "r9aeVpcAAAAJ;;QULCtjgAAAAJ;https://scholar.google.com.au/citations?hl=en;",
        "orcid": ";;;0000-0002-6138-7742;",
        "linkedin": ";jiawei-lyu;;;",
        "or_profile": "~Baiqi_Chen1;~Jiawei_Lyu2;~Tingmin_Wu1;~Mohan_Baruwal_Chhetri1;~Guangdong_Bai1",
        "aff": "The University of Queensland;;CSIRO's Data61;Data61, CSIRO;",
        "aff_domain": "uq.edu.au;;data61.csiro.au;data61.csiro.au;",
        "position": "PhD student;;Researcher;Researcher;",
        "bibtex": "@inproceedings{\nchen2025semanticsaware,\ntitle={Semantics-Aware Cookie Purpose Compliance},\nauthor={Baiqi Chen and Jiawei Lyu and Tingmin Wu and Mohan Baruwal Chhetri and Guangdong Bai},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=syOhXfIXv0}\n}",
        "github": "",
        "project": "",
        "reviewers": "McsE;FAKh;mKmP;UtbS",
        "site": "https://openreview.net/forum?id=syOhXfIXv0",
        "pdf_size": 0,
        "novelty": "5;5;5;7",
        "technical_quality": "5;5;5;6",
        "scope": "4;4;3;4",
        "confidence": "2;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            5.25,
            0.4330127018922193
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.0,
            0.7071067811865476
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.816496580927726
    },
    {
        "id": "t0q7KbmB7o",
        "title": "Hypergraph-based Temporal Modelling of Repeated Intent for Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In sequential recommendation scenarios, user intent is a key driver of consumption behavior. However, consumption intents are usually latent and hence, difficult to leverage for recommender systems. Additionally, intents can be of repeated nature (e.g. yearly shopping for christmas gifts or buying a new phone), which has not been exploited by previous approaches. To navigate these impediments we propose the HyperHawkes framework which models user sessions via hypergraphs and extracts user intents via contrastive clustering. We use Hawkes Processes to model the temporal dynamics of intents, namely repeated consumption patterns and long-term interests of users. For short-term interest adaption, which is more fine-grained than intent-level modeling, we use a multi-level attention mixture network and fuse long-term and short-term signals. We use the generalized expectation-maximization (EM) framework for training the model by alternating between intent representation learning and optimizing parameters of the long- and short-term modules. Extensive experiments on four real-world datasets from different domains show that HyperHawkes significantly outperforms existing state-of-the-art methods.",
        "keywords": "sequential recommendation;hypergraph;user intent;temporal modeling",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Andreas Peintner;Amir Reza Mohammadi;Michael M. M\u00fcller;Eva Zangerle",
        "authorids": "~Andreas_Peintner1;~Amir_Reza_Mohammadi1;~Michael_M._M\u00fcller1;~Eva_Zangerle1",
        "gender": "M;M;;",
        "homepage": "https://pintonos.github.io/;https://amirreza-m95.github.io/;;",
        "dblp": "326/6695;356/7964;;",
        "google_scholar": "https://scholar.google.de/citations?user=HCKACzoAAAAJ;8PCPMncAAAAJ;;",
        "orcid": "0000-0001-7337-524X;0000-0003-3934-6941;;",
        "linkedin": ";amirreza-mohammadi-75936039/;;",
        "or_profile": "~Andreas_Peintner1;~Amir_Reza_Mohammadi1;~Michael_M._M\u00fcller1;~Eva_Zangerle1",
        "aff": "University of Innsbruck;Universit\u00e4t Innsbruck;;",
        "aff_domain": "uibk.ac.at;uibk.ac.at;;",
        "position": "PhD student;PhD student;;",
        "bibtex": "@inproceedings{\npeintner2025hypergraphbased,\ntitle={Hypergraph-based Temporal Modelling of Repeated Intent for Sequential Recommendation},\nauthor={Andreas Peintner and Amir Reza Mohammadi and Michael M. M{\\\"u}ller and Eva Zangerle},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=t0q7KbmB7o}\n}",
        "github": "",
        "project": "",
        "reviewers": "i8UJ;wEjM;TNAD;r6K2;JpBi",
        "site": "https://openreview.net/forum?id=t0q7KbmB7o",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;5;5;6;6",
        "scope": "4;4;3;4;4",
        "confidence": "3;4;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "t44I1uUjAg",
        "title": "Mer\\underline{K}ury: Adaptive Resource Allocation to Enhance the \\underline{K}ubernetes Performance for Large-Scale Clusters",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As a prevalent paradigm of modern web applications, cloud computing has experienced a surge in adoption. The deployment of vast and various workloads encapsulated within containers has become ubiquitous across cloud platforms, imposing substantial demands on the supporting infrastructure. However, Kubernetes (k8s), the de-facto standard for container orchestration, struggles with low scheduling throughput and high latency in large-scale clusters. The primary challenges are identified as excessive loads of read requests and resource contention among co-located components. \n    \nIn response to these challenges, in this paper, we present MerKury, a lightweight framework to enhance the Kubernetes performance for large-scale clusters. It employs a dual strategy: first, it preprocesses specific requests to alleviate unnecessary load, and second, it introduces an adaptive resource allocation algorithm to mitigate resource contention. Evaluations under different scenarios of varying cluster scale have demonstrated that MerKury notably augments cluster scheduling throughput up to 16.4$\\times$ and reduces request latency by up to 39.3\\%, outperforming vanilla Kubernetes and baseline resource allocation methods.",
        "keywords": "resource allocation;Kubernetes;large-scale",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiayin Luo;Xinkui Zhao;\u9a6c\u5b87\u946b;Shengye Pang;Jianwei Yin",
        "authorids": "~Jiayin_Luo1;~Xinkui_Zhao1;~\u9a6c\u5b87\u946b1;~Shengye_Pang1;~Jianwei_Yin1",
        "gender": "M;M;M;;M",
        "homepage": ";https://person.zju.edu.cn/en/NB22088;https://github.com/Ma-YuXin/Ma-YuXin;https://orcid.org/my-orcid?orcid=0009-0002-5510-2867;https://person.zju.edu.cn/0001038",
        "dblp": ";135/5118;;;74/3786",
        "google_scholar": ";;;;0s1A5fwAAAAJ",
        "orcid": "0009-0005-9706-0839;0000-0002-1115-5652;;;0000-0003-4703-7348",
        "linkedin": ";;;;",
        "or_profile": "~Jiayin_Luo1;~Xinkui_Zhao1;~\u9a6c\u5b87\u946b1;~Shengye_Pang1;~Jianwei_Yin1",
        "aff": "Zhejiang University;Zhejiang University;Zhejiang University;Shanghai University;Zhejiang University",
        "aff_domain": "zju.edu.cn;zju.edu.cn;zju.edu.cn;shu.edu.cn;zju.edu.cn",
        "position": "PhD student;Full Professor;MS student;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nluo2025merunderlinekury,\ntitle={Mer{\\textbackslash}underline\\{K\\}ury: Adaptive Resource Allocation to Enhance the {\\textbackslash}underline\\{K\\}ubernetes Performance for Large-Scale Clusters},\nauthor={Jiayin Luo and Xinkui Zhao and \u9a6c\u5b87\u946b and Shengye Pang and Jianwei Yin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=t44I1uUjAg}\n}",
        "github": "",
        "project": "",
        "reviewers": "q24H;CcRS;nZwz;Hs9J;wATt",
        "site": "https://openreview.net/forum?id=t44I1uUjAg",
        "pdf_size": 0,
        "novelty": "3;4;4;4;5",
        "technical_quality": "5;3;4;5;6",
        "scope": "3;3;3;3;3",
        "confidence": "3;3;2;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.4,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.7905694150420948
    },
    {
        "id": "tYnnq11rKd",
        "title": "Dealing with Noisy Data in Federated Learning: An Incentive Mechanism with Flexible Pricing",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Federated Learning (FL) has emerged as a promising training framework that enables a server to effectively train a global model by coordinating multiple devices, i.e., clients, without sharing their raw data. Keeping data locally can ensure data privacy, but also makes the server difficult to assess data quality, leading to the noisy data issue. Specifically, for any given taring task, only a portion of each client's data is relevant and beneficial, while the rest may be redundant or noisy. Training with excessive noisy data can degrade performance. Motivated by this, we investigate the limitations of existing studies and develop an incentive mechanism with flexible pricing tailored for noisy data settings. The insight lies in mitigating the impact of noisy data by selecting appropriate clients and incentivizing them to clean their data spontaneously. Further, both rigorous theoretical analysis and extensive simulations compared with state-of-the-art methods have been well-conducted to validate the effectiveness of the proposed mechanism.",
        "keywords": "Federated learning;noisy data;incentive mechanism;flexible pricing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hengzhi Wang;Haoran Chen;Minghe Ma;Laizhong Cui",
        "authorids": "~Hengzhi_Wang1;~Haoran_Chen11;~Minghe_Ma1;~Laizhong_Cui1",
        "gender": "M;;M;M",
        "homepage": ";;https://github.com/CraVioleamMO;https://csse.szu.edu.cn/staff/cuilz/",
        "dblp": ";;;86/10615",
        "google_scholar": "VypaEDUAAAAJ;;;",
        "orcid": "0000-0002-3334-8308;;;0000-0003-1991-290X",
        "linkedin": ";;;",
        "or_profile": "~Hengzhi_Wang1;~Haoran_Chen11;~Minghe_Ma1;~Laizhong_Cui1",
        "aff": "Shenzhen University;;Shenzhen University;Shenzhen University",
        "aff_domain": "szu.edu.cn;;szu.edu.cn;szu.edu.cn",
        "position": "Assistant Professor;;MS student;Full Professor",
        "bibtex": "@inproceedings{\nwang2025dealing,\ntitle={Dealing with Noisy Data in Federated Learning: An Incentive Mechanism with Flexible Pricing},\nauthor={Hengzhi Wang and Haoran Chen and Minghe Ma and Laizhong Cui},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=tYnnq11rKd}\n}",
        "github": "",
        "project": "",
        "reviewers": "u9vt;g12J;CHmM",
        "site": "https://openreview.net/forum?id=tYnnq11rKd",
        "pdf_size": 0,
        "novelty": "4;5;5",
        "technical_quality": "4;5;5",
        "scope": "3;3;4",
        "confidence": "3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "tmQDHqzupm",
        "title": "Hypergraph-based Zero-shot Multi-modal Product Attribute Value Extraction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "It is essential for e-commerce platforms to provide accurate, complete, and timely product attribute values, in order to improve the search and recommendation experience for both customers and sellers. In the real-world scenario, it is difficult for these platforms to identify attribute values for the newly introduced products given no similar product history records for training or retrieval. Besides, how to jointly learn the product representation given various product information in multiple modalities, such as textual modality (e.g., product titles and descriptions) and visual modality (e.g., product images), is also a challenging task. To address these limitations, we propose a novel method for extracting multi-label product attribute-value pairs from multiple modalities in the zero-shot scenario, where labeled data is absent during training. Specifically, our method constructs heterogeneous hypergraphs, where product information from different modalities is represented by different types of nodes, and the text and image nodes are embedded and learned through CLIP encoders to effectively capture and integrate multimodal product information. Then, the complex interrelations among these nodes are modeled through the hyperedges. By learning informative node representations, our method can accurately predict links between unseen product nodes and attribute-value nodes, enabling zero-shot attribute value extraction. We conduct extensive experiments and ablation studies on several categories of the public MAVE dataset and the results demonstrate that our proposed method significantly outperforms several state-of-the-art generative model baselines in multi-label, multi-modal product attribute value extraction in the zero-shot setting.",
        "keywords": "attribute value extraction;multi-modal learning;zero-shot learning;heterogeneous hypergraph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jiazhen Hu;Jiaying Gong;Hongda Shen;Hoda Eldardiry",
        "authorids": "~Jiazhen_Hu1;~Jiaying_Gong1;~Hongda_Shen1;~Hoda_Eldardiry2",
        "gender": "F;;M;F",
        "homepage": ";;https://hongdashen.github.io/;https://people.cs.vt.edu/hdardiry/",
        "dblp": ";;;51/9923",
        "google_scholar": ";;J6AFOEEAAAAJ;RQq30hYAAAAJ",
        "orcid": ";;;0000-0002-9712-6667",
        "linkedin": "jiazhen-hu-433681224;;;eldardiry/",
        "or_profile": "~Jiazhen_Hu1;~Jiaying_Gong1;~Hongda_Shen1;~Hoda_Eldardiry2",
        "aff": "Virginia Polytechnic Institute and State University;;eBay Inc.;, Virginia Polytechnic Institute and State University",
        "aff_domain": "vt.edu;;ebay.com;cs.vt.edu",
        "position": "PhD student;;Researcher;Associate Professor",
        "bibtex": "@inproceedings{\nhu2025hypergraphbased,\ntitle={Hypergraph-based Zero-shot Multi-modal Product Attribute Value Extraction},\nauthor={Jiazhen Hu and Jiaying Gong and Hongda Shen and Hoda Eldardiry},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=tmQDHqzupm}\n}",
        "github": "",
        "project": "",
        "reviewers": "wrtW;igqs;NNkP;DTBG;FpUc",
        "site": "https://openreview.net/forum?id=tmQDHqzupm",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;5;4;5;5",
        "scope": "2;3;3;4;4",
        "confidence": "2;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.790569415042095
    },
    {
        "id": "trPIg0ECvv",
        "title": "Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multi-modal time series data is common in web technologies like the Internet of Things (IoT).  Existing methods for multi-modal time series representation learning aim to disentangle the modality-shared and modality-specific latent variables. Although achieving notable performances on downstream tasks, they usually assume an orthogonal latent space. However, the modality-specific and modality-shared latent variables might be dependent on real-world scenarios. Therefore, we propose a general generation process, where the modality-shared and modality-specific latent variables are dependent, and further develop a \\textbf{M}ulti-mod\\textbf{A}l \\textbf{TE}mporal Disentanglement (\\textbf{MATE}) model. Specifically, our \\textbf{MATE} model is built on a temporally variational inference architecture with the modality-shared and modality-specific prior networks for the disentanglement of latent variables. Furthermore, we establish identifiability results to show that the extracted representation is disentangled. More specifically, we first achieve the subspace identifiability for modality-shared and modality-specific latent variables by leveraging the pairing of multi-modal data. Then we establish the component-wise identifiability of modality-specific latent variables by employing sufficient changes of historical latent variables. Extensive experimental studies on 12 datasets show a general improvement in different downstream tasks,  highlighting the effectiveness of our method in real-world scenarios.",
        "keywords": "Multimodal Time Series;Time Series Representation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ruichu Cai;Zhifan Jiang;Kaitao Zheng;Zijian Li;Weilin Chen;Xuexin Chen;Yifan Shen;Guangyi Chen;Zhifeng Hao;Kun Zhang",
        "authorids": "~Ruichu_Cai1;~Zhifan_Jiang2;~Kaitao_Zheng1;~Zijian_Li1;~Weilin_Chen1;~Xuexin_Chen1;~Yifan_Shen4;~Guangyi_Chen1;~Zhifeng_Hao2;~Kun_Zhang1",
        "gender": "M;M;M;M;M;M;M;M;;M",
        "homepage": "https://ruichucai.github.io/;https://github.com/sseij;https://github.com/Jerome142857;;;;https://sanshuiii.github.io/about/;https://chengy12.github.io/;;http://www.andrew.cmu.edu/user/kunz1/",
        "dblp": "09/6889;;;27/10487;234/4796-1;226/9631.html;59/7950-4;c/GuangyiChen-2;;96/3115-1",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;;j3ilESoAAAAJ;KVvl1vgAAAAJ;;PMKkElwAAAAJ;https://scholar.google.com/citations?hl=zh-CN;;RGoypN4AAAAJ",
        "orcid": ";;;;;;0000-0003-2358-1146;;;",
        "linkedin": ";;;;;;;;;",
        "or_profile": "~Ruichu_Cai1;~Zhifan_Jiang2;~Kaitao_Zheng1;~Zijian_Li1;~Weilin_Chen1;~Xuexin_Chen1;~Yifan_Shen4;~Guangyi_Chen1;~Zhifeng_Hao2;~Kun_Zhang1",
        "aff": "Guangdong University of Technology;Guangdong University of Technology;Guangdong University of Technology;Mohamed bin Zayed University of Artificial Intelligence;Guangdong University of Technology;Guangdong Polytechnic Normal University;Mohamed bin Zayed University of Artificial Intelligence;Mohamed bin Zayed University of Artificial Intelligence+Carnegie Mellon University;;Mohamed bin Zayed University of Artificial Intelligence+Carnegie Mellon University",
        "aff_domain": "gdut.edu.cn;gdut.edu.cn;gdut.edu.cn;mbzuai.ac.ae;gdut.edu.cn;gpnu.edu;mbzuai.ac.ae;mbzuai.ac.ae+cmu.edu;;mbzuai.ac.ae+cmu.edu",
        "position": "Full Professor;MS student;MS student;Postdoc;Ph.D.;Lecturer;PhD student;Postdoc+Postdoc;;Professor+Associate Professor",
        "bibtex": "@inproceedings{\ncai2025learning,\ntitle={Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals},\nauthor={Ruichu Cai and Zhifan Jiang and Kaitao Zheng and Zijian Li and Weilin Chen and Xuexin Chen and Yifan Shen and Guangyi Chen and Zhifeng Hao and Kun Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=trPIg0ECvv}\n}",
        "github": "",
        "project": "",
        "reviewers": "BfoY;jEgo;VqEp;mvyF;WW2u",
        "site": "https://openreview.net/forum?id=trPIg0ECvv",
        "pdf_size": 0,
        "novelty": "2;4;4;5;5",
        "technical_quality": "3;6;4;5;5",
        "scope": "3;3;3;4;3",
        "confidence": "3;2;3;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.6,
            1.0198039027185568
        ],
        "scope_avg": [
            3.2,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "twj53tItvH",
        "title": "Multimodal Graph-based Variational Mixture of Experts Network for Zero-shot Multimodal Information Extraction",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multimodal information extraction on social media is a series of fundamental tasks to construct the multimodal knowledge graph. The tasks are defined to extract the structural information in free texts with the incorporate images, such as: multimodal named entity typing and multimodal relation extraction. However, the growing number of multimodal data implies a growing category set and the newly emerged entity types or relations should be recognized without additional training. To address the aforementioned disadvantages, we focus on the zero-shot multimodal information extraction task which requires to utilize textual and visual modalities for identifying previously unseen categories in a zero-shot manner. Compared with the text-based zero-shot information extraction models, the existing multimodal ones make the textual and visual modalities aligned directly and exploit various fusion strategies to improve their generalization ability. But the existing methods only align the global representations of multimodal data and ignore the fine-grained semantic correlation of the text-image pairs and samples. Therefore, we propose the multimodal graph-based variational mixture of experts network (MG-VMoE) which takes the MoE network as the backbone and exploits the sparse expert weights for aligning the multimodal representations in a fine-grained way. Considering to learn the informative and aligned representations of multimodal data, we design each expert network as a variational information bottleneck to process the two modalities in a uni-backbone. Moreover, we do not only model the correlation of the text-image pair inner a sample, but also propose the multimodal graph-based virtual adversarial training to learn the semantic correlation between the samples. The experimental results on the two benchmark datasets demonstrate the superiority of MG-VMoE over the baselines.",
        "keywords": "multimodal information extraction;zero-shot learning;multimodal representation learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Baohang Zhou;Ying Zhang;Yu Zhao;Xuhui Sui;Xiaojie Yuan",
        "authorids": "~Baohang_Zhou1;~Ying_Zhang7;~Yu_Zhao14;~Xuhui_Sui1;~Xiaojie_Yuan1",
        "gender": "M;F;F;;",
        "homepage": "https://scholar.google.com/citations?user=U_-raXAAAAAJ;https://dbis.nankai.edu.cn/2023/0322/c12139a506904/page.htm;https://scholar.google.com/citations?user=47fMA2QAAAAJ&hl=en;https://www.linkedin.com/in/%E6%97%AD%E8%BE%89-%E9%9A%8B-0305b334b/;https://dbis.nankai.edu.cn/2023/0322/c12139a506919/page.htm",
        "dblp": "284/1471.html;13/6769-15;57/2056-43;321/6900.html;79/2280",
        "google_scholar": "U_-raXAAAAAJ;;47fMA2QAAAAJ;;",
        "orcid": "0000-0002-7577-6204;0000-0003-4906-5828;0000-0002-0326-7152;0000-0001-5386-9912;0000-0002-5876-6856",
        "linkedin": ";;;;",
        "or_profile": "~Baohang_Zhou1;~Ying_Zhang7;~Yu_Zhao14;~Xuhui_Sui1;~Xiaojie_Yuan1",
        "aff": "Tiangong University+Nankai University;Nankai University;Nankai University;Nankai University;Nankai University",
        "aff_domain": "tiangong.edu.cn+nankai.edu.cn;nankai.edu.cn;nankai.edu.cn;nankai.edu.cn;nankai.edu.cn",
        "position": "Lecturer+PhD student;Full Professor;PhD student;PhD student;Full Professor",
        "bibtex": "@inproceedings{\nzhou2025multimodal,\ntitle={Multimodal Graph-based Variational Mixture of Experts Network for Zero-shot Multimodal Information Extraction},\nauthor={Baohang Zhou and Ying Zhang and Yu Zhao and Xuhui Sui and Xiaojie Yuan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=twj53tItvH}\n}",
        "github": "",
        "project": "",
        "reviewers": "3JCZ;4G7C;62gL;MpjG;29m8",
        "site": "https://openreview.net/forum?id=twj53tItvH",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "4;3;4;6;6",
        "scope": "3;3;4;3;4",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.6,
            1.2
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.9302605094190635
    },
    {
        "id": "ty7Qk12Pd8",
        "title": "Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multi-modal sequential recommendation (SR) leverages multi-modal data to learn more comprehensive item features and user preferences than traditional SR methods, which has become a critical topic in both academia and industry. Existing methods typically focus on enhancing multi-modal information utility through adaptive modality fusion to capture the evolving of user preference from user-item interaction sequences. However, most of them overlook the interference caused by redundant interest-irrelevant information contained in rich multi-modal data. Additionally, they primarily rely on implicit temporal information based solely on chronological ordering, neglecting explicit temporal signals that could more effectively represent dynamic user interest over time. To address these limitations, we propose a Hierarchical time-aware Mixture of experts for multi-modal Sequential Recommendation (HM4SR) with a two-level Mixture of Experts (MoE) and a multi-task learning strategy. Specifically, the first MoE, named Interactive MoE, extracts essential user interest-related information from the multi-modal data of each item. Then, the second MoE, termed Temporal MoE, captures user dynamic interests by introducing explicit temporal embeddings from timestamps in modality encoding. To further address data sparsity, we propose three auxiliary supervision tasks: sequence-level category prediction (CP) for item feature understanding, contrastive learning on ID (IDCL) to align sequence context with user interests, and placeholder contrastive learning (PCL) to integrate temporal information with modalities for dynamic interest modeling. Extensive experiments on four public datasets verify the effectiveness of HM4SR compared to several state-of-the-art approaches.",
        "keywords": "Sequential Recommendation;Multi-modal Recommendation;Mixture of Experts;Temporal Information",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shengzhe Zhang;Liyi Chen;Dazhong Shen;Chao Wang;Hui Xiong",
        "authorids": "~Shengzhe_Zhang3;~Liyi_Chen3;~Dazhong_Shen1;~Chao_Wang14;~Hui_Xiong1",
        "gender": "M;F;M;M;M",
        "homepage": ";http://home.ustc.edu.cn/~liyichen/;http://www.shendazhong.com/;https://chaowang-ustc.github.io/;https://www.hkust-gz.edu.cn/people/hui-xiong/",
        "dblp": "350/8080.html;;222/7906;188/7759-86;262/1686-1.html",
        "google_scholar": ";J7JWDwkAAAAJ;5vSh09YAAAAJ;j08V64UAAAAJ;cVDF1tkAAAAJ",
        "orcid": ";0000-0003-2166-4386;0000-0002-3947-4153;0000-0001-7717-447X;0000-0001-6016-6465",
        "linkedin": ";;;;",
        "or_profile": "~Shengzhe_Zhang3;~Liyi_Chen3;~Dazhong_Shen1;~Chao_Wang14;~Hui_Xiong1",
        "aff": "University of Science and Technology of China;University of Science and Technology of China;Nanjing University of Aeronautics and Astronautics;University of Science and Technology of China;Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "ustc.edu.cn;ustc.edu.cn;nuaa.edu;ustc.edu.cn;hkust.edu",
        "position": "Undergrad student;PhD student;Associate Professor;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nzhang2025hierarchical,\ntitle={Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation},\nauthor={Shengzhe Zhang and Liyi Chen and Dazhong Shen and Chao Wang and Hui Xiong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=ty7Qk12Pd8}\n}",
        "github": "",
        "project": "",
        "reviewers": "bbcu;ThLb;J5La;qx7V",
        "site": "https://openreview.net/forum?id=ty7Qk12Pd8",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "4;5;5;4",
        "scope": "3;4;4;3",
        "confidence": "3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.5,
            0.5
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.9045340337332909
    },
    {
        "id": "uAOFSQEE4G",
        "title": "Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "X\u2019s Community Notes, a crowd-sourced fact-checking system, allows users to annotate potentially misleading posts. Notes rated as helpful by a diverse set of users are prominently displayed below the original post. While demonstrably effective at reducing misinformation's impact when notes are displayed, there is an opportunity for notes to appear on many more posts: for 91% of posts where at least one note is proposed, no notes ultimately achieve sufficient support from diverse users to be shown on the platform. This motivates the development of Supernotes: AI-generated notes that synthesize information from several existing community notes and are written to foster consensus among a diverse set of users. Our framework uses an LLM to generate many diverse Supernote candidates from existing proposed notes. These candidates are then evaluated by a novel scoring model, trained on millions of historical Community Notes ratings, selecting candidates that are most likely to be rated helpful by a diverse set of users. To test our framework, we ran a human subjects experiment in which we asked participants to compare the Supernotes generated by our framework to the best existing community notes for 100 sample posts. We found that participants rated the Supernotes as significantly more helpful, and when asked to choose between the two, preferred the Supernotes 75.2% of the time. Participants also rated the Supernotes more favorably than the best existing notes on quality, clarity, coverage, context, and argumentativeness. Finally, in a follow-up experiment, we asked participants to compare the Supernotes against LLM-generated summaries and found that the participants rated the Supernotes significantly more helpful, demonstrating that both the LLM-based candidate generation and the consensus-driven scoring play crucial roles in creating notes that effectively build consensus among diverse users.",
        "keywords": "Community Notes;Misinformation;Crowd-Sourced Fact-Checking;Automated Fact-checking;LLMs",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Soham De;Michiel A. Bakker;Jay Baxter;Martin Saveski",
        "authorids": "~Soham_De4;~Michiel_A._Bakker1;~Jay_Baxter1;~Martin_Saveski1",
        "gender": "M;;M;M",
        "homepage": "https://www.sohamde.in;;http://jaybaxter.net;http://martinsaveski.com/",
        "dblp": ";;;138/9642",
        "google_scholar": "i1ad6GmN4uoC;;mcBOmJYAAAAJ;M3D870YAAAAJ",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Soham_De4;~Michiel_A._Bakker1;~Jay_Baxter1;~Martin_Saveski1",
        "aff": "University of Washington;;Twitter;University of Washington",
        "aff_domain": "uw.edu;;twitter.com;uw.edu",
        "position": "PhD student;;Researcher;Assistant Professor",
        "bibtex": "@inproceedings{\nde2025supernotes,\ntitle={Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking},\nauthor={Soham De and Michiel A. Bakker and Jay Baxter and Martin Saveski},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uAOFSQEE4G}\n}",
        "github": "",
        "project": "",
        "reviewers": "x5k4;k34w;SN7o;hi2W",
        "site": "https://openreview.net/forum?id=uAOFSQEE4G",
        "pdf_size": 0,
        "novelty": "4;4;6;6",
        "technical_quality": "4;6;6;4",
        "scope": "3;3;4;4",
        "confidence": "4;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0
        ],
        "technical_quality_avg": [
            5.0,
            1.0
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5773502691896257
    },
    {
        "id": "uEladLyKgE",
        "title": "Hyperbolic Variational Graph Auto-Encoder for Next POI Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Next Point-of-Interest (POI) recommendation has become a crucial task in Location-Based Social Networks (LBSNs), which provide personalized recommendations by predicting the user's next check-in locations. Commonly used models including Recurrent Neural Networks (RNNs) and Graph Convolutional Networks (GCNs) have been widely explored. However, these models face significant challenges, including the difficulty of capturing the hierarchical and tree-like structure of POIs in Euclidean space and the sparsity problem inherent in POI recommendations. To address these challenges, we propose a Hyperbolic Variational Graph Auto-Encoder (HVGAE) for next POI recommendation. Specifically, we utilize a Hyperbolic Graph Convolutional Network (Hyperbolic GCN) to model hierarchical structures and tree-like relationships by converting node embeddings from euclidean space to hyperbolic space. Then we use Variational Graph Auto-Encoder (VGAE) to convert node embeddings to probabilistic distributions, enhancing the capture of deeper latent features and providing a more robust model structure. Furthermore, we combine the Mamba4Rec recommender and Rotary Position Embedding (RoPE) and propose Rotary Position Mamba (RPMamba) to effectively utilize POI embeddings rich in sequential information, which improves the accuracy of the next POI recommendation. Extensive experiments on three public datasets demonstrate the superior performance of the HVGAE model.",
        "keywords": "Point-of-interest recommendation;hyperbolic space;variational graph auto-encoder;graph convolutional network;mamba",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuwen Liu;Lianyong Qi;Xingyuan Mao;Weiming Liu;Fan Wang;Xiaolong Xu;Xuyun Zhang;Wanchun Dou;Xiaokang Zhou;Amin Beheshti",
        "authorids": "~Yuwen_Liu1;~Lianyong_Qi1;~Xingyuan_Mao1;~Weiming_Liu2;~Fan_Wang14;~Xiaolong_Xu3;~Xuyun_Zhang1;~Wanchun_Dou1;~Xiaokang_Zhou1;~Amin_Beheshti2",
        "gender": ";M;;;;;M;M;M;M",
        "homepage": ";https://sites.google.com/view/lianyongqi/home;;;;https://faculty.nuist.edu.cn/xuxiaolong/en/index.htm;https://researchers.mq.edu.au/en/persons/xuyun-zhang;https://cs.nju.edu.cn/douwanchun/;;https://data-science-group.github.io/people/aminbeheshti/",
        "dblp": ";01/8326.html;389/2627;;;10/137-1;54/8558;57/5595;;90/10041.htmlx",
        "google_scholar": "IBhXvD8AAAAJ;pxNRRsAAAAAJ;dHtLwS4AAAAJ;;;https://scholar.google.com/citations?hl=zh-CN;https://scholar.google.com.au/citations?user=wbF6HL8AAAAJ;;https://scholar.google.co.jp/citations?hl=ja;https://scholar.google.com.au/citations?user=Uw1OLAgAAAAJ",
        "orcid": "0000-0002-4911-5744;0000-0001-9875-9856;0009-0005-6897-2935;;;0000-0003-4879-9803;0000-0001-7353-4159;0000-0003-4833-2023;0000-0003-3488-4679;0000-0002-5988-5494",
        "linkedin": ";;;;;;;;;prof-amin-beheshti/",
        "or_profile": "~Yuwen_Liu1;~Lianyong_Qi1;~Xingyuan_Mao1;~Weiming_Liu2;~Fan_Wang14;~Xiaolong_Xu3;~Xuyun_Zhang1;~Wanchun_Dou1;~Xiaokang_Zhou1;~Amin_Beheshti2",
        "aff": "China University of Petroleum;China University of Petroleum;China University of Petroleum;;;Nanjing University of Information Science and Technology;Macquarie University;Nanjing University;Kansai University;Macquarie University",
        "aff_domain": "upc.edu.cn;upc.edu.cn;upc.edu.cn;;;nuist.edu.cn;mq.edu.au;nju.edu.cn;kansai-u.ac.jp;mq.edu.au",
        "position": "PhD student;Full Professor;Undergrad student;;;Full Professor;Associate Professor;Full Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025hyperbolic,\ntitle={Hyperbolic Variational Graph Auto-Encoder for Next {POI} Recommendation},\nauthor={Yuwen Liu and Lianyong Qi and Xingyuan Mao and Weiming Liu and Fan Wang and Xiaolong Xu and Xuyun Zhang and Wanchun Dou and Xiaokang Zhou and Amin Beheshti},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uEladLyKgE}\n}",
        "github": "",
        "project": "",
        "reviewers": "cP14;Pc35;7QQq;VE33",
        "site": "https://openreview.net/forum?id=uEladLyKgE",
        "pdf_size": 0,
        "novelty": "4;4;5;5",
        "technical_quality": "4;5;4;3",
        "scope": "4;4;4;3",
        "confidence": "4;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.5
        ],
        "technical_quality_avg": [
            4.0,
            0.7071067811865476
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            10,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "uMPEhA2LZI",
        "title": "Unified and Generalizable Reinforcement Learning for Facility Location Problems on Graphs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Facility location problems on graphs are ubiquitous in the real world and hold significant importance, yet their resolution is often impeded by NP-hardness. MIP solvers can find the optimal solutions but fail to handle large instances, while algorithm efficiency has a higher priority in cases of emergency.\nRecently, machine learning methods have been proposed to tackle such classical problems with fast inference, but they are limited to the myopic constructive pattern and only consider simple cases in Euclidean space. \nThis paper introduces a unified and generalizable approach to tackle facility location problems on weighted graphs with deep reinforcement learning, demonstrating a keen awareness of complex graph structures. \nStriking a harmonious balance between solution quality and running time, our method stands out with superior efficiency and steady performance. \nOur model trained on small graphs is highly scalable and consistently generates high-quality solutions, achieving a speedup of more than 2000 times to Gurobi on instances with 1000 nodes.\nThe experiments on Shanghai road networks further demonstrate its practical value in solving real-world problems.",
        "keywords": "facility location problems;graphs and networks;combinatorial optimization;deep reinforcement learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wenxuan Guo;Runzhong Wang;Yanyan Xu;Yaohui Jin",
        "authorids": "~Wenxuan_Guo1;~Runzhong_Wang1;~Yanyan_Xu2;~Yaohui_Jin2",
        "gender": "F;M;M;M",
        "homepage": "http://aryaguo.github.io;http://runzhong.wang;https://www.researchgate.net/profile/Yanyan-Xu-4;http://front.sjtu.edu.cn/~jinyh/",
        "dblp": ";239/4351;39/706-2;27/7040",
        "google_scholar": ";uoM0g3cAAAAJ;4A8N4PMAAAAJ;H_7_oVcAAAAJ",
        "orcid": "0000-0001-6336-3819;0000-0002-9566-738X;0000-0001-5429-3177;0000-0001-6158-6277",
        "linkedin": ";;;yaohui-jin-bab58511/",
        "or_profile": "~Wenxuan_Guo1;~Runzhong_Wang1;~Yanyan_Xu2;~Yaohui_Jin2",
        "aff": "Shanghai Jiaotong University;Massachusetts Institute of Technology;Shanghai Jiaotong University;Shanghai Jiaotong University",
        "aff_domain": "sjtu.edu.cn;mit.edu;sjtu.edu.cn;sjtu.edu.cn",
        "position": "PhD student;Postdoc;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nguo2025unified,\ntitle={Unified and Generalizable Reinforcement Learning for Facility Location Problems on Graphs},\nauthor={Wenxuan Guo and Runzhong Wang and Yanyan Xu and Yaohui Jin},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uMPEhA2LZI}\n}",
        "github": "",
        "project": "",
        "reviewers": "qrMx;16fL;kmyi;5sgY;rwV9",
        "site": "https://openreview.net/forum?id=uMPEhA2LZI",
        "pdf_size": 0,
        "novelty": "3;4;5;5;6",
        "technical_quality": "3;5;5;5;6",
        "scope": "3;3;3;3;3",
        "confidence": "3;3;2;3;4",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            1.0198039027185568
        ],
        "technical_quality_avg": [
            4.8,
            0.9797958971132712
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.31008683647302115
    },
    {
        "id": "uNXr6f0ARA",
        "title": "Balancing Graph Embedding Smoothness in Self-supervised Learning via Information-Theoretic Decomposition",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In the graph domain, SSL has garnered significant attention, particularly in employing Graph Neural Networks (GNNs) with pretext tasks originally designed for other domains, such as contrastive learning and feature reconstruction. \n  However, it remains uncertain whether these methods effectively reflect essential graph properties, such as representation similarity with its neighbors. \n  We observe that existing methods position opposite ends of a spectrum driven by the graph embedding smoothness, with each end corresponding to outperformance on specific downstream tasks. \n  Further insights suggest that balancing between the extremes can lead to improved performance across a wider range of downstream tasks. \nTo find the balance respective to the graph embedding smoothness, we decompose the SSL objective into three terms, which are derived by incorporating the neighbor representation variable through the lens of information theory.\n  A framework, \\textbf{\\mname{}} (\\textbf{B}alancing \\textbf{S}moothness in \\textbf{G}raph SSL), introduces novel loss functions designed to supplement the representation quality in graph-based SSL by optimizing the derived three terms: neighbor loss, minimal loss, and divergence loss.\nWe present a rigorous theoretical analysis of the effects of these loss functions, highlighting their significance from both the SSL and graph smoothness perspectives. Extensive experiments on multiple real-world datasets across node classification and link prediction consistently demonstrate that \\mname{} achieves state-of-the-art performance, outperforming existing methods.\n  Our implementation code is available at \\url{https://anonymous.4open.science/r/BSG-2025/}.",
        "keywords": "Self-supervised Learning;Graph Neural Network;Oversmoothing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Heesoo Jung;Hogun Park",
        "authorids": "~Heesoo_Jung1;~Hogun_Park2",
        "gender": "M;",
        "homepage": "https://github.com/steve30572;https://hogunpark.com",
        "dblp": "340/7862;05/3540",
        "google_scholar": "NH_YMugAAAAJ;0YEYuGIAAAAJ",
        "orcid": "0000-0002-6554-2391;0000-0003-0576-5806",
        "linkedin": ";hogunpark/en",
        "or_profile": "~Heesoo_Jung1;~Hogun_Park2",
        "aff": "Sungkyunkwan University;Sungkyunkwan University",
        "aff_domain": "skku.edu;skku.edu",
        "position": "PhD student;Associate Professor",
        "bibtex": "@inproceedings{\njung2025balancing,\ntitle={Balancing Graph Embedding Smoothness in Self-supervised Learning via Information-Theoretic Decomposition},\nauthor={Heesoo Jung and Hogun Park},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uNXr6f0ARA}\n}",
        "github": "",
        "project": "",
        "reviewers": "MaFn;1G3M;efun;ZQuQ;p3rq",
        "site": "https://openreview.net/forum?id=uNXr6f0ARA",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "4;5;3;5;5",
        "scope": "4;4;4;3;3",
        "confidence": "4;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8451542547285165
    },
    {
        "id": "uddtlRWcNW",
        "title": "Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "With the widespread use of social media, organizations, and individuals use these platforms to raise funds and support causes. Unfortunately, this has led to the rise of scammers in soliciting fraudulent donations. In this study, we conduct a large-scale analysis of donation-based scams on social media platforms. More specifically, we studied profile creation and scam operation fraudulent donation solicitation on X, Instagram, Facebook, YouTube, and Telegram. By collecting data from 151,966 accounts and their 3,053,333 posts related to donations between March 2024 and May 2024, we identified 832 scammers using various techniques to deceive users into making fraudulent donations. Analyzing the fraud communication channels such as phone number, email, and external URL linked, we show that these scamming accounts perform various fraudulent donation schemes, including classic abuse such as fake fundraising website setup, crowdsourcing fundraising, and asking users to communicate via email, phone, and pay via various payment methods. Through collaboration with industry partners PayPal and cryptocurrency abuse database Chainabuse, we further validated the scams and measured the financial losses on these platforms. Our study highlights significant weaknesses in social media platforms' ability to protect users from fraudulent donations. Additionally, we recommended social media platforms, and financial services for taking proactive steps to block these fraudulent activities. Our study provides a foundation for the security community and researchers to automate detecting and mitigating fraudulent donation solicitation on social media platforms.",
        "keywords": "Donation abuse;fraudsters;social media;web security",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Bhupendra Acharya;Dario Lazzaro;Antonio Emanuele Cin\u00e0;Thorsten Holz",
        "authorids": "~Bhupendra_Acharya1;~Dario_Lazzaro1;~Antonio_Emanuele_Cin\u00e01;~Thorsten_Holz1",
        "gender": "M;M;M;M",
        "homepage": "https://www.bhupendraacharya.com;;https://github.com/Cinofix;https://cispa.de",
        "dblp": "301/5830.html;;274/2233;h/ThorstenHolz",
        "google_scholar": "PWEiSVMAAAAJ;;https://scholar.google.it/citations?user=Qtj8Lb8AAAAJ;tv2HR38AAAAJ",
        "orcid": "0009-0005-3663-152X;0009-0007-5125-2290;0000-0003-3807-6417;0000-0002-2783-1264",
        "linkedin": "bhupendra-acharya-5516402b/;;antonio-cina/;",
        "or_profile": "~Bhupendra_Acharya1;~Dario_Lazzaro1;~Antonio_Emanuele_Cin\u00e01;~Thorsten_Holz1",
        "aff": "CISPA Helmholtz Center for Information Security;University of Roma \"La Sapienza\"+University of Genoa;University of Genoa;CISPA Helmholtz Center for Information Security",
        "aff_domain": "cispa.de;uniroma1.it+unige.it;unige.it;cispa.saarland",
        "position": "Postdoc;PhD student+PhD student;Assistant Professor;Principal Researcher",
        "bibtex": "@inproceedings{\nacharya2025pirates,\ntitle={Pirates of Charity: Exploring Donation-based Abuses in Social Media Platforms},\nauthor={Bhupendra Acharya and Dario Lazzaro and Antonio Emanuele Cin{\\`a} and Thorsten Holz},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uddtlRWcNW}\n}",
        "github": "",
        "project": "",
        "reviewers": "5HSW;SH1C;aJEb;u6hQ;ibQp",
        "site": "https://openreview.net/forum?id=uddtlRWcNW",
        "pdf_size": 0,
        "novelty": "3;5;5;6;6",
        "technical_quality": "3;3;4;5;5",
        "scope": "3;4;4;4;4",
        "confidence": "2;4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.0,
            0.8944271909999159
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.24397501823713333
    },
    {
        "id": "upN9jbO79N",
        "title": "ABO: Abandon Bayer Filter for Adaptive Edge Offloading in Responsive Augmented Reality",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Bayer-patterned color filter array (CFA) has been the go-to solution for color image sensors. In augmented reality (AR), although color interpolation (i.e. demosaicing) of pre-demosaic RAW images facilitates user-friendly rendering, it creates no benefits in offloaded neural network analytics but only increases the image channels by $3\\times$ with higher transmission overheads. Thus, we propose ABO, an adaptive RAW frame offloading framework that parallelizes demosaicing with DNN offloading. The contributions are three-fold: First, we design a configurable tile-wise RAW image neural codec to compress frame sizes while sustaining the downstream DNN accuracy under various bandwidth restraints. Second, based on content-aware tiles-in-frame selection and runtime bandwidth estimation, a dynamic transmission controller adaptively calibrates codec configurations to maximize the DNN accuracy under real-time constraints. Third, we further optimize the system pipelining to reduce the end-to-end frame processing latency. Through extensive evaluations on a prototype platform, ABO consistently provides a 40\\% more frame processing throughput and a 30\\% less end-to-end latency while improving the offloaded DNN accuracy by up to 15\\% compared to SOTA baselines. It also presents improved robustness against dim light and motion blur situations.",
        "keywords": "Mobile Computing; DNN Offloading; Augmented Reality",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yongxuan Han;Shengzhong Liu;Fan Wu;Guihai Chen",
        "authorids": "~Yongxuan_Han1;~Shengzhong_Liu1;~Fan_Wu10;~Guihai_Chen3",
        "gender": "M;M;M;M",
        "homepage": ";https://liushengzhong1023.github.io/;https://www.cs.sjtu.edu.cn/~fwu/;https://cs.nju.edu.cn/gchen/index.htm",
        "dblp": ";166/5424;07/6378-15.html;51/1742.html",
        "google_scholar": ";REzrIucAAAAJ;NwoNqygAAAAJ;",
        "orcid": ";;0000-0003-0965-9058;",
        "linkedin": "yongxuan-han-7665a5330/;;;",
        "or_profile": "~Yongxuan_Han1;~Shengzhong_Liu1;~Fan_Wu10;~Guihai_Chen3",
        "aff": "Shanghai Jiaotong University;Shanghai Jiaotong University;Shanghai Jiaotong University;Shanghai Jiaotong University",
        "aff_domain": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "position": "PhD student;Associate Professor;Professor;Full Professor",
        "bibtex": "@inproceedings{\nhan2025abo,\ntitle={{ABO}: Abandon Bayer Filter for Adaptive Edge Offloading in Responsive Augmented Reality},\nauthor={Yongxuan Han and Shengzhong Liu and Fan Wu and Guihai Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=upN9jbO79N}\n}",
        "github": "",
        "project": "",
        "reviewers": "hAF4;SoDp;FfaF;tjav",
        "site": "https://openreview.net/forum?id=upN9jbO79N",
        "pdf_size": 0,
        "novelty": "4;5;5;5",
        "technical_quality": "5;6;6;6",
        "scope": "2;3;4;4",
        "confidence": "3;3;4;4",
        "wc_review": "",
        "novelty_avg": [
            4.75,
            0.4330127018922193
        ],
        "technical_quality_avg": [
            5.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.25,
            0.82915619758885
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5773502691896257
    },
    {
        "id": "uzQyer3n7G",
        "title": "SPEAR: A Structure-Preserving Manipulation Method for Graph Backdoor Attacks",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph Neural Networks (GNNs) are vulnerable to backdoor attacks, where adversaries implant malicious triggers to manipulate model predictions. Existing graph backdoor attacks are susceptible to defense mechanisms or robust classifiers because they rely on subgraph injection or structural perturbations, e.g., creating additional edges to attach backdoor triggers to the original graph. To enhance the stealthiness of graph backdoors, we propose SPEAR, a novel structure-preserving graph backdoor attack that avoids modifying the graph\u2019s topology. SPEAR operates within a limited attack budget by selectively perturbing node attributes while ensuring the triggers exert significant influence through a global importance-driven feature selection strategy. Additionally, a neighborhood-aware trigger generator is employed to underpin a high attack success rate by utilizing semantic information from the neighborhood. SPEAR amplifies effectiveness and stealthiness by combining subtle yet impactful attribute manipulation with a refined trigger generation mechanism. Extensive experiments demonstrate that SPEAR achieves state-of-the-art effectiveness in bypassing defenses on real-world datasets, establishing it as a potent and stealthy backdoor attack for graph-based tasks.",
        "keywords": "Adversarial Attack;Backdoor Attack;Graph Neural Network",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuanhao Ding;Yang Liu;Yugang Ji;Weigao Wen;Qing He;Xiang Ao",
        "authorids": "~Yuanhao_Ding1;~Yang_Liu73;~Yugang_Ji3;~Weigao_Wen1;~Qing_He2;~Xiang_Ao2",
        "gender": "M;M;;M;M;M",
        "homepage": "https://yhding.github.io/;https://ponderly.github.io/;;;http://www.ict.cas.cn/sourcedb_2018_ict_cas/cn/jssrck/200909/t20090917_2496626.html;https://aoxaustin.github.io/",
        "dblp": ";51/3710-200;;;14/3700-3;71/1982-1",
        "google_scholar": ";kVoIIXkAAAAJ;;;tkbgSDYAAAAJ;W8wrWfMAAAAJ",
        "orcid": ";0000-0002-1525-0788;;;0000-0001-8833-5398;0000-0001-9633-8361",
        "linkedin": ";;;https://www.linkedin.cn/incareer/in/ACoAABlg3QUBY92_T2u0E9MmBcmBoAJzIoMYnjE;;",
        "or_profile": "~Yuanhao_Ding1;~Yang_Liu73;~Yugang_Ji3;~Weigao_Wen1;~Qing_He2;~Xiang_Ao2",
        "aff": "University of Chinese Academy of Sciences;Institute of Computing Technology, Chinese Academy of Sciences;;;Institute of Computing Technology, Chinese Academy of Sciences;University of Chinese Academy of Sciences+Institute of Computing Technology, Chinese Academy of Sciences",
        "aff_domain": "ict.ac;ict.ac.cn;;;ict.ac.cn;ucas.ac.cn+ict.ac.cn",
        "position": "MS student;Assistant Professor;;;Full Professor;Associate Professor+Associate Professor",
        "bibtex": "@inproceedings{\nding2025spear,\ntitle={{SPEAR}: A Structure-Preserving Manipulation Method for Graph Backdoor Attacks},\nauthor={Yuanhao Ding and Yang Liu and Yugang Ji and Weigao Wen and Qing He and Xiang Ao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=uzQyer3n7G}\n}",
        "github": "",
        "project": "",
        "reviewers": "viVu;uA4z;m9bM",
        "site": "https://openreview.net/forum?id=uzQyer3n7G",
        "pdf_size": 0,
        "novelty": "4;5;5",
        "technical_quality": "4;6;5",
        "scope": "3;4;3",
        "confidence": "3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "technical_quality_avg": [
            5.0,
            0.816496580927726
        ],
        "scope_avg": [
            3.3333333333333335,
            0.4714045207910317
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "v1iPOY9UCN",
        "title": "MGF-ESE: An Enhanced Semantic Extractor with Multi-Granularity Feature Fusion for Code Summarization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Code summarization aims to generate concise natural language descriptions of source code, helping developers to acquaint with software systems and reduce maintenance costs. Existing code summarization approaches widely employ attention mechanisms to assess the relevance between nodes in the Abstract Syntax Tree (AST), which generates context vectors that reflect the semantics of the source code. However, these approaches with AST fail to extract other granular features, such as token sequences and Control Flow Graphs (CFG), which suffer from severe semantic gaps when capturing data and control dependencies. To address this issue, we design an enhanced semantic extractor with multi-granularity feature fusion (MGF-ESE) to improve the model capability in comprehending and processing the overall semantics of the code. Specifically, to process the AST more effectively, we present a novel AST generation method with compresses the scale of nodes to enhance the semantic information of each node. Then, we present a disentangled attention mechanism based on relative positional embeddings for further encoding. Moreover, we extract the token sequences and CFG of source code to supplement the syntactic and structural information, and further fuse them with the AST separately through cross-attention modules. Finally, extensive experiments on two public datasets show that MGF-ESE outperforms the state-of-the-arts with higher-quality code summaries on key metrics, including BLEU, METEOR, and ROUGE.",
        "keywords": "source code summarization;semantic extraction;abstract syntax tree;control flow graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xiaolong Xu;Yuxin Cao;Hongsheng Hu;Haolong Xiang;Lianyong Qi;Junqun Xiong;Wanchun Dou",
        "authorids": "~Xiaolong_Xu3;~Yuxin_Cao2;~Hongsheng_Hu2;~Haolong_Xiang1;~Lianyong_Qi1;~Junqun_Xiong1;~Wanchun_Dou1",
        "gender": ";M;;M;M;M;M",
        "homepage": "https://faculty.nuist.edu.cn/xuxiaolong/en/index.htm;https://github.com/shenxuanwannnian;;https://scholar.google.com/citations?user=94DjoRoAAAAJ&hl=en;https://sites.google.com/view/lianyongqi/home;;https://cs.nju.edu.cn/douwanchun/",
        "dblp": "10/137-1;;;194/6883.html;01/8326.html;;57/5595",
        "google_scholar": "https://scholar.google.com/citations?hl=zh-CN;;;94DjoRoAAAAJ;pxNRRsAAAAAJ;;",
        "orcid": "0000-0003-4879-9803;;;;0000-0001-9875-9856;;0000-0003-4833-2023",
        "linkedin": ";;;;;junqun-xiong/;",
        "or_profile": "~Xiaolong_Xu3;~Yuxin_Cao2;~Hongsheng_Hu2;~Haolong_Xiang1;~Lianyong_Qi1;~Junqun_Xiong1;~Wanchun_Dou1",
        "aff": "Nanjing University of Information Science and Technology;Nanjing University of Information Science and Technology;;Nanjing University of Information Science and Technology;China University of Petroleum;;Nanjing University",
        "aff_domain": "nuist.edu.cn;nuist.edu.cn;;nuist.edu.cn;upc.edu.cn;;nju.edu.cn",
        "position": "Full Professor;MS student;;Lecturer;Full Professor;;Full Professor",
        "bibtex": "@inproceedings{\nxu2025mgfese,\ntitle={{MGF}-{ESE}: An Enhanced Semantic Extractor with Multi-Granularity Feature Fusion for Code Summarization},\nauthor={Xiaolong Xu and Yuxin Cao and Hongsheng Hu and Haolong Xiang and Lianyong Qi and Junqun Xiong and Wanchun Dou},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=v1iPOY9UCN}\n}",
        "github": "",
        "project": "",
        "reviewers": "2d5z;5o99;gByV;L11h;eD7i",
        "site": "https://openreview.net/forum?id=v1iPOY9UCN",
        "pdf_size": 0,
        "novelty": "4;5;5;5;6",
        "technical_quality": "4;4;5;5;6",
        "scope": "3;3;3;2;4",
        "confidence": "4;2;3;1;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.6324555320336759
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.8,
            1.16619037896906
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "vYaDOpmUN9",
        "title": "Fast Estimation and Optimization of Resistance Diameter on Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The resistance diameter of a graph is the maximum resistance distance among all pairs of nodes in the graph, which has found various applications in many scenarios. However, direct computation of resistance diameter involves the pseudoinverse of graph Laplacian, which takes cubic time and is thus infeasible for huge networks with millions of nodes. In this paper, we consider the computation and optimization problems for resistance diameter of a graph. First, we develop a nearly linear time algorithm to approximate the resistance diameter, which has a theoretically guaranteed error. Then, we propose and study an optimization problem of adding a fixed number of  edges to a graph, such that the resistance diameter of the resulting graph is  minimized. We show that this optimization problem is NP-hard, and that the objective function is non-supermodular but monotone. Moreover, we propose two fast heuristic  algorithms to approximately solve this problem. Finally, we conduct extensive experiments on different networks with sizes up to one million nodes, demonstrating the superiority of our algorithms in terms of efficiency and effectiveness.",
        "keywords": "Resistance distance;Resistance diameter;Combinatorial optimization;Graph mining;Linear algorithm;Convex hull;Laplacian solver",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zenan Lu;Xiaotian Zhou;Zhongzhi Zhang",
        "authorids": "~Zenan_Lu1;~Xiaotian_Zhou1;~Zhongzhi_Zhang1",
        "gender": "M;M;M",
        "homepage": ";https://scholar.google.com.hk/citations?user=ZIf9Gs0AAAAJ&hl=zh-CN;https://scholar.google.com/citations?user=DrcEuSkAAAAJ&hl=zh-CN",
        "dblp": ";;47/7618",
        "google_scholar": ";https://scholar.google.com.hk/citations?user=ZIf9Gs0AAAAJ;DrcEuSkAAAAJ",
        "orcid": "0000-0002-1716-5800;0000-0002-2150-6284;0000-0003-1260-2079",
        "linkedin": ";;",
        "or_profile": "~Zenan_Lu1;~Xiaotian_Zhou1;~Zhongzhi_Zhang1",
        "aff": ";Fudan University;Fudan University",
        "aff_domain": ";fudan.edu.cn;fudan.edu.cn",
        "position": ";PhD student;Full Professor",
        "bibtex": "@inproceedings{\nlu2025fast,\ntitle={Fast Estimation and Optimization of Resistance Diameter on Graphs},\nauthor={Zenan Lu and Xiaotian Zhou and Zhongzhi Zhang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=vYaDOpmUN9}\n}",
        "github": "",
        "project": "",
        "reviewers": "oiUg;Yezb;gKm7;Xu16;z4hU",
        "site": "https://openreview.net/forum?id=vYaDOpmUN9",
        "pdf_size": 0,
        "novelty": "5;5;5;6;6",
        "technical_quality": "5;4;6;6;6",
        "scope": "3;4;4;3;4",
        "confidence": "2;3;3;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            5.4,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.2182178902359924
    },
    {
        "id": "vo7EHT3iBs",
        "title": "Hunting in the Dark Forest: A Pre-trained Model for On-chain Attack Transaction Detection in Web3",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In recent years, a large number of on-chain attacks have emerged in the blockchain empowered Web3 ecosystem. In the year of 2023 alone, on-chain attacks have caused losses of over \\$585 million. Attackers use blockchain transactions to carry out on-chain attacks, for example, exploiting vulnerabilities or business logic flaws in Web3 applications. A wealth of efforts have been devoted to detecting on-chain attack transactions through expert patterns and machine learning techniques. However, in this ever-evolving ecosystem, the performance of current methods is limited in detecting new on-chain attacks, due to the obsoleting of attack recognition patterns or the reliance on on-chain attack samples. In this paper, we propose a universal approach for detecting on-chain attacks even when there are few or even no new on-chain attack samples. Specifically, an in-depth analysis of the transaction characteristics is conducted, and we propose a new insight to train a generic attack transaction detecting model, i.e., transaction reconstruction. Particularly, to overcome the over-fitting in the transaction reconstruction task, we use the web-scale function comments related to transactions as supervision information, rather than expert-confirmed labels. Experimental results demonstrate that the proposed approach surpasses the supervised state-of-the-art by 13\\% in AUC, with just 30 known on-chain attack samples. Moreover, without any known attack samples, our method can still detect new on-chain attacks in the wild (with a precision of 61.83\\%). Among attacks detected in the wild, we confirm 1,692 address poisoning attacks, a new type of on-chain attack targeting token holders. Our code is available at: https://anonymous.4open.science/r/6F40.",
        "keywords": "Attack detection;Blockchain transaction analysis;Web3",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhiying Wu;Jiajing Wu;Hui Zhang;Zibin Zheng;Weiqiang Wang",
        "authorids": "~Zhiying_Wu1;~Jiajing_Wu1;~Hui_Zhang32;~Zibin_Zheng1;~Weiqiang_Wang4",
        "gender": "M;F;F;M;M",
        "homepage": ";http://xplanet.site/;https://github.com/SodalimeZero;https://www.zibinzheng.com/;https://www.linkedin.com/in/weiqiang-wang-489b925/",
        "dblp": ";;;z/ZibinZheng;",
        "google_scholar": ";EaqeskUAAAAJ;;WPC6ED4AAAAJ;",
        "orcid": "0000-0003-4633-0008;0000-0001-5155-8547;0009-0008-8717-9184;0000-0002-7878-4330;0000-0002-6159-619X",
        "linkedin": ";;;;weiqiang-wang-489b925/",
        "or_profile": "~Zhiying_Wu1;~Jiajing_Wu1;~Hui_Zhang32;~Zibin_Zheng1;~Weiqiang_Wang4",
        "aff": "SUN YAT-SEN UNIVERSITY;;SUN YAT-SEN UNIVERSITY;Sun Yat-sen University;Ant Group",
        "aff_domain": "sysu.edu.cn;;sysu.edu.cn;sysu.edu.cn;antgroup.com",
        "position": "PhD student;;MS student;Full Professor;Researcher",
        "bibtex": "@inproceedings{\nwu2025hunting,\ntitle={Hunting in the Dark Forest: A Pre-trained Model for On-chain Attack Transaction Detection in Web3},\nauthor={Zhiying Wu and Jiajing Wu and Hui Zhang and Zibin Zheng and Weiqiang Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=vo7EHT3iBs}\n}",
        "github": "",
        "project": "",
        "reviewers": "8zsH;fBs1;N825;F4es;czrY",
        "site": "https://openreview.net/forum?id=vo7EHT3iBs",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "5;4;3;4;5",
        "scope": "4;3;4;4;3",
        "confidence": "2;4;2;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.8944271909999159
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "vrqvcVZL3Y",
        "title": "Compress and Mix: Advancing Efficient Taxonomy Completion with Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Taxonomy completion aims to integrate new concepts into existing taxonomies by determining their appropriate hypernym and hyponym. While semantic and structural information are crucial for this task, existing approaches often struggle to balance these aspects effectively. In this paper, we propose **COMI**, an efficient taxonomy completion framework that leverages large language models (LLMs) to capture both semantic and structural information in a unified manner. COMI **co**mpresses node semantics into token representations, enabling LLMs to efficiently process the input structure composed of these tokens. To enhance the model's understanding of the structure, a further fine-tuning process using contrastive learning with **mi**xup data augmentation is applied, where mixup generates diverse and challenging negative samples. Through these innovations, COMI improves the integration of semantic and structural information, leading to more accurate taxonomy completion. The experimental results on three real-world datasets demonstrate that COMI achieves state-of-the-art performance while showing up to 284$\\times$  faster inference compared to the previous best method. Our code and compressed tokens will be available for further study upon publication.",
        "keywords": "Taxonomy Completion;LLM;Context Compression;Mixup",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hongyuan Xu;Yuhang Niu;Yanlong Wen;Xiaojie Yuan",
        "authorids": "~Hongyuan_Xu1;~Yuhang_Niu1;~Yanlong_Wen1;~Xiaojie_Yuan1",
        "gender": "M;M;;",
        "homepage": ";https://github.com/nyh-a;;https://dbis.nankai.edu.cn/2023/0322/c12139a506919/page.htm",
        "dblp": "220/2889;;;79/2280",
        "google_scholar": "https://scholar.google.com/citations?view_op=list_works;;;",
        "orcid": ";;;0000-0002-5876-6856",
        "linkedin": ";;;",
        "or_profile": "~Hongyuan_Xu1;~Yuhang_Niu1;~Yanlong_Wen1;~Xiaojie_Yuan1",
        "aff": "Nankai University;Nankai University;;Nankai University",
        "aff_domain": "nku.nankai.edu.cn;nankai.edu.cn;;nankai.edu.cn",
        "position": "PhD student;MS student;;Full Professor",
        "bibtex": "@inproceedings{\nxu2025compress,\ntitle={Compress and Mix: Advancing Efficient Taxonomy Completion with Large Language Models},\nauthor={Hongyuan Xu and Yuhang Niu and Yanlong Wen and Xiaojie Yuan},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=vrqvcVZL3Y}\n}",
        "github": "",
        "project": "",
        "reviewers": "HWyB;AL8E;9K1p;z66k;aBEX",
        "site": "https://openreview.net/forum?id=vrqvcVZL3Y",
        "pdf_size": 0,
        "novelty": "4;4;4;5;6",
        "technical_quality": "5;5;4;5;6",
        "scope": "4;3;2;2;4",
        "confidence": "3;2;2;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.8
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.0,
            0.8944271909999159
        ],
        "confidence_avg": [
            2.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.37500000000000006
    },
    {
        "id": "vyIZHrURMu",
        "title": "Community Detection in Large-Scale Complex Networks via Structural Entropy Game",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Community detection is a critical task in graph theory, social network analysis, and bioinformatics, where communities are defined as clusters of densely interconnected nodes. However, detecting communities in large-scale networks with millions of nodes and billions of edges remains challenging due to the inefficiency and unreliability of existing methods. Moreover, many current approaches are limited to specific graph types, such as unweighted or undirected graphs, reducing their broader applicability. To address these limitations, we propose a novel heuristic community detection algorithm inspired by game theory, termed \\framework, which identifies communities by minimizing the network's 2-dimensional (2D) structural entropy. In this potential game model, nodes decide whether to stay or transfer to another community based on a strategy that maximizes a 2D structural entropy utility function. Additionally, we introduce a structural entropy-based node overlapping heuristic to detect overlapping communities. The algorithm operates with near-linear time complexity, enabling efficient community detection in large-scale networks. Experimental results on real-world networks demonstrate that CoDeSEG is the fastest method available and achieves state-of-the-art performance in overlapping normalized mutual information (ONMI) and F1 scores.",
        "keywords": "Community Detection;Large- scale Networks;Structural Entropy;Potential Games",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yantuan Xian;Pu Li;Hao Peng;Zhengtao Yu;Yan Xiang;Philip S. Yu",
        "authorids": "~Yantuan_Xian1;~Pu_Li7;~Hao_Peng7;~Zhengtao_Yu2;~Yan_Xiang2;~Philip_S._Yu1",
        "gender": "M;M;M;M;F;M",
        "homepage": "https://liip.kust.edu.cn;;https://penghao-bdsc.github.io/;http://rsc.kmust.edu.cn/info/1181/1081.htm;https://xzy.kmust.edu.cn/info/1129/1310.htm;https://cs.uic.edu/profiles/philip-yu/",
        "dblp": ";;69/7742-1;03/6757;;y/PhilipSYu",
        "google_scholar": ";;R25rbyQAAAAJ;;;D0lL1r0AAAAJ",
        "orcid": ";0009-0007-1410-4096;0000-0003-0458-5977;0000-0001-8952-8984;;0000-0002-3491-5968",
        "linkedin": ";;;;;",
        "or_profile": "~Yantuan_Xian1;~Pu_Li7;~Hao_Peng7;~Zhengtao_Yu2;~Yan_Xiang2;~Philip_S._Yu1",
        "aff": "Kunming University of Science and Technology;Kunmimg University of Science and Technology;Beihang University;Kunming University of Science and Technology;Kunmimg University of Science and Technology;University of Illinois Chicago",
        "aff_domain": "kust.edu.cn;kmust.edu.cn;buaa.edu.cn;kmust.edu.cn;kmust.edu.cn;uic.edu",
        "position": "Full Professor;MS student;Full Professor;Full Professor;Associate Professor;Full Professor",
        "bibtex": "@inproceedings{\nxian2025community,\ntitle={Community Detection in Large-Scale Complex Networks via Structural Entropy Game},\nauthor={Yantuan Xian and Pu Li and Hao Peng and Zhengtao Yu and Yan Xiang and Philip S. Yu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=vyIZHrURMu}\n}",
        "github": "",
        "project": "",
        "reviewers": "L8AS;teHj;27Ru;ccuq;L1Mq",
        "site": "https://openreview.net/forum?id=vyIZHrURMu",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;5;5;5;6",
        "scope": "4;4;4;4;4",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.40824829046386296
    },
    {
        "id": "w5aYTHtq4F",
        "title": "Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Terms and conditions for online shopping websites often contain terms that can have significant financial consequences for customers. Despite their impact, there is currently no comprehensive understanding of the types and potential risks associated with unfavorable financial terms. Furthermore, there are no publicly available detection systems or datasets to systematically identify or mitigate these terms. In this paper, we take the first steps toward solving this problem with three key contributions.\n\nFirst, we introduce TermMiner, an automated data collection and topic modeling pipeline to understand the landscape of unfavorable financial terms. Second, we create ShopTC-100K, a dataset of terms and conditions from shopping websites in the Tranco top 100K list, comprising 1.8 million terms from 8,251 websites. Consequently, we develop a taxonomy of 22 types from 4 categories of unfavorable financial terms\u2014spanning purchase, post-purchase, account termination, and legal aspects. Third, we build TermLens, an automated detector that uses Large Language Models (LLMs) to identify unfavorable financial terms. \n\nFine-tuned on an annotated dataset, TermLens achieves an F1 score of 94.6% and a false positive rate of 2.3% using GPT-4o. When applied to shopping websites from the Tranco top 100K, we find that 47.21% of these sites contain at least one unfavorable financial term, with such terms being more prevalent on less popular websites. Case studies further highlight the financial risks and customer dissatisfaction associated with unfavorable financial terms, as well as the limitations of existing ecosystem defenses.",
        "keywords": "Topic modeling;unfavorable terms;consumer protection;terms and conditions dataset;deceptive content",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Elisa Tsai;Neal Mangaokar;Boyuan Zheng;Haizhong Zheng;Atul Prakash",
        "authorids": "~Elisa_Tsai1;~Neal_Mangaokar1;~Boyuan_Zheng4;~Haizhong_Zheng1;~Atul_Prakash1",
        "gender": "Not Specified;;M;M;",
        "homepage": "https://eltsai.github.io/;https://nealmangaokar.com;;http://zhenghaizhong.com/;https://www.eecs.umich.edu/~aprakash",
        "dblp": "301/5874.html;278/0806.html;;158/4817;p/AtulPrakash",
        "google_scholar": "3NA-OTQAAAAJ;k7GbiDIAAAAJ;;Zx6pKsQAAAAJ;kIkHa2IAAAAJ",
        "orcid": ";0000-0002-0684-4971;;0000-0003-3723-8701;0000-0002-4907-3687",
        "linkedin": ";;byron-zheng-8a851a268?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=ios_app;haizhong-zheng-1093a0a7/;atul-prakash-8729a44/",
        "or_profile": "~Elisa_Tsai1;~Neal_Mangaokar1;~Boyuan_Zheng4;~Haizhong_Zheng1;~Atul_Prakash1",
        "aff": "University of Michigan - Ann Arbor;University of Michigan - Ann Arbor;University of Michigan - Ann Arbor+University of Michigan - Ann Arbor;Carnegie Mellon University;University of Michigan",
        "aff_domain": "umich.edu;umich.edu;umich.edu+umich.edu;andrew.cmu.edu;umich.edu",
        "position": "PhD student;PhD student;PhD student+Undergrad student;Postdoc;Professor",
        "bibtex": "@inproceedings{\ntsai2025harmful,\ntitle={Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale},\nauthor={Elisa Tsai and Neal Mangaokar and Boyuan Zheng and Haizhong Zheng and Atul Prakash},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=w5aYTHtq4F}\n}",
        "github": "",
        "project": "",
        "reviewers": "VRWJ;QBTk;PHAx;uv2X",
        "site": "https://openreview.net/forum?id=w5aYTHtq4F",
        "pdf_size": 0,
        "novelty": "4;5;5;6",
        "technical_quality": "3;5;5;5",
        "scope": "4;3;4;4",
        "confidence": "3;3;3;4",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            0.7071067811865476
        ],
        "technical_quality_avg": [
            4.5,
            0.8660254037844386
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.816496580927726
    },
    {
        "id": "wCesxsnIcj",
        "title": "TransBox: $\\mathcal{EL}^{++}$-closed Ontology Embedding",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "OWL (Web Ontology Language) ontologies, which are able to represent both relational and type facts as standard knowledge graphs and complex domain knowledge in Description Logic (DL) axioms, are widely adopted in domains such as healthcare and bioinformatics. Inspired by the success of knowledge graph embeddings, embedding OWL ontologies has gained significant attention in recent years. Current methods primarily focus on learning embeddings for atomic concepts and roles, enabling the evaluation based on normalized axioms through specially designed score functions. However, they often neglect the embedding of complex concepts, making it difficult to infer with more intricate axioms. This limitation reduces their effectiveness in advanced reasoning tasks, such as Ontology Learning and ontology-mediated Query Answering. In this paper, we propose $\\mathcal{EL}^{++}$-closed ontology embeddings which are able to represent any logical expressions in DL $\\mathcal{EL}^{++}$ via composition. Furthermore, we develop TransBox, an effective $\\mathcal{EL}^{++}$-closed ontology embedding method that can handle many-to-one, one-to-many and many-to-many relations. Our extensive experiments demonstrate that TransBox often achieves state-of-the-art performance across various real-world datasets for predicting complex axioms. Code and data are available at the https://anonymous.4open.science/r/TransBox-F4B7.",
        "keywords": "Ontology Embedding;Ontology Completion;Description Logic;Web Ontology Language;Ontology Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hui Yang;Jiaoyan Chen;Uli Sattler",
        "authorids": "~Hui_Yang5;~Jiaoyan_Chen1;~Uli_Sattler1",
        "gender": "M;M;F",
        "homepage": ";https://chenjiaoyan.github.io/;http://www.cs.man.ac.uk/~sattler/",
        "dblp": "04/;56/8110-1;s/UlrikeSattler",
        "google_scholar": ";https://scholar.google.ch/citations?user=5Cy4z8wAAAAJ;uMI-tgsAAAAJ",
        "orcid": "0000-0002-4262-4001;0000-0003-4643-6750;0000-0003-4103-3389",
        "linkedin": ";;",
        "or_profile": "~Hui_Yang5;~Jiaoyan_Chen1;~Uli_Sattler1",
        "aff": "University of Manchester;The University of Manchester+The University of Manchester+University of Oxford;University of Manchester",
        "aff_domain": "manchester.ac.uk;manchester.ac.uk+manchester.ac.uk+cs.ox.ac.uk;cs.man.ac.uk",
        "position": "Postdoc;Associate Professor+Assistant Professor+Senior Researcher;Full Professor",
        "bibtex": "@inproceedings{\nyang2025transbox,\ntitle={TransBox:  \\${\\textbackslash}mathcal\\{{EL}\\}{\\textasciicircum}\\{++\\}\\$-closed Ontology Embedding},\nauthor={Hui Yang and Jiaoyan Chen and Uli Sattler},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=wCesxsnIcj}\n}",
        "github": "",
        "project": "",
        "reviewers": "GAG8;Rdtx;6tuH",
        "site": "https://openreview.net/forum?id=wCesxsnIcj",
        "pdf_size": 0,
        "novelty": "3;6;7",
        "technical_quality": "6;6;7",
        "scope": "4;3;4",
        "confidence": "3;2;2",
        "wc_review": "",
        "novelty_avg": [
            5.333333333333333,
            1.699673171197595
        ],
        "technical_quality_avg": [
            6.333333333333333,
            0.4714045207910317
        ],
        "scope_avg": [
            3.6666666666666665,
            0.4714045207910317
        ],
        "confidence_avg": [
            2.3333333333333335,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.970725343394151
    },
    {
        "id": "whZcGAvXHo",
        "title": "Networked Digital Public Goods Games with Heterogeneous Players and Convex Costs",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "In the digital age, resources such as open-source software and publicly accessible databases form a crucial category of digital public goods, providing extensive benefits across the Internet. However, the inherent non-exclusivity and non-competitiveness of these public goods frequently result in under-provision, a dilemma exacerbated by individuals' tendency to free-ride. This scenario fosters both cooperation and competition among users, leading to the emergence of public goods games.\n\nThis paper investigates networked public goods games involving heterogeneous players and convex costs to explore solutions of Nash Equilibrium (NE) for this problem. In these games, each player can choose her own effort level, representing the contributions to public goods.\nWe employ network structures to depict the interactions among participants.\nEach player's utility is composed of a \\emph{concave} value component, influenced by collective efforts, and a \\emph{convex} cost component, determined solely by individual effort.\nTo the best of our knowledge, this study is the first to explore a networked public goods game with convex costs.\n\nOur research begins by examining welfare solutions aimed at maximizing social welfare and ensuring the convergence of pseudo-gradient ascent dynamics. We establish the presence of NE in this model and provide an in-depth analysis of the conditions under which NE is unique. Additionally, we introduce the concept of game equivalence, which expands the range of public goods games that can support a unique NE.\nWe also delve into \\emph{comparative statics}, an essential tool in economics, to evaluate how slight modifications in the model\u2014interpreted as monetary redistribution\u2014impact player utilities. In addition, we analyze a particular scenario with a predefined game structure, illustrating the practical relevance of our theoretical insights.\nConsequently, our research enhances the broader understanding of strategic interactions and structural dynamics in networked public goods games, with significant implications for policy design in internet economic and social networks.",
        "keywords": "Public Good Games; Networks; Nash Equilibrium; Social Welfare; Pseudo-Gradient Dynamics; Comparative Statics.",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yukun Cheng;Xiaotie Deng;Yunxuan Ma",
        "authorids": "~Yukun_Cheng2;~Xiaotie_Deng1;~Yunxuan_Ma1",
        "gender": "F;M;M",
        "homepage": ";https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm;http://dagame.pku.edu.cn",
        "dblp": "https://dblp.uni-trier.de/pid/55/7264.html;d/XiaotieDeng;338/9043",
        "google_scholar": ";https://scholar.google.com.tw/citations?user=OBUwP_oAAAAJ;mplXCJAAAAAJ",
        "orcid": "0000-0002-3638-3440;0000-0002-5282-6467;",
        "linkedin": ";;",
        "or_profile": "~Yukun_Cheng2;~Xiaotie_Deng1;~Yunxuan_Ma1",
        "aff": "Jiangnan University;Peking University;Peking University",
        "aff_domain": "jiangnan.edu.cn;pku.edu.cn;pku.edu.cn",
        "position": "Full Professor;Full Professor;PhD student",
        "bibtex": "@inproceedings{\ncheng2025networked,\ntitle={Networked Digital Public Goods Games with Heterogeneous Players and Convex Costs},\nauthor={Yukun Cheng and Xiaotie Deng and Yunxuan Ma},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=whZcGAvXHo}\n}",
        "github": "",
        "project": "",
        "reviewers": "R6UW;oCXC;p63g;aWH4;Coy4",
        "site": "https://openreview.net/forum?id=whZcGAvXHo",
        "pdf_size": 0,
        "novelty": "5;5;5;5;6",
        "technical_quality": "7;5;5;5;6",
        "scope": "4;4;4;3;3",
        "confidence": "3;3;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            5.6,
            0.7999999999999999
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.25
    },
    {
        "id": "wz46GyAptn",
        "title": "CTR-Driven Advertising Image Generation with Multimodal Large Language Models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In web data, advertising images are crucial for capturing user attention and improving advertising effectiveness. Most existing methods generate background for products primarily focus on the aesthetic quality, which may fail to achieve satisfactory online performance. To address this limitation, we explore the use of Multimodal Large Language Models (MLLMs) for generating advertising images by optimizing for Click-Through Rate (CTR) as the primary objective. Firstly, we build targeted pre-training tasks, and leverage a large-scale e-commerce multimodal dataset to equip MLLMs with initial capabilities for advertising image generation tasks. To further improve the CTR of generated images, we propose a novel reward model to fine-tune pre-trained MLLMs through Reinforcement Learning (RL), which can jointly utilize multimodal features and accurately reflect user click preferences. Meanwhile, a product-centric preference optimization strategy is developed to ensure that the generated background content aligns with the product characteristics after fine-tuning, enhancing the overall relevance and effectiveness of the advertising images. Extensive experiments have demonstrated that our method achieves state-of-the-art performance in both online and offline metrics. We will release our code and weights upon acceptance of the paper.",
        "keywords": "CTR-Driven;Advertising Image Generation;Online Advertising;Multimodal Large Language Models",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Xingye Chen;Wei Feng;Zhenbang Du;Weizhen Wang;yanyin chen;Haohan Wang;Linkai Liu;Yaoyu Li;jinyuan zhao;Yu Li;Zheng Zhang;Jingjing Lv;Junjie Shen;Zhangang Lin;Jingping Shao;Yuanjie Shao;Xinge You;Changxin Gao;Nong Sang",
        "authorids": "~Xingye_Chen1;~Wei_Feng8;~Zhenbang_Du1;~Weizhen_Wang2;~yanyin_chen1;~Haohan_Wang3;~Linkai_Liu1;~Yaoyu_Li2;~jinyuan_zhao2;~Yu_Li7;~Zheng_Zhang26;~Jingjing_Lv1;~Junjie_Shen2;~Zhangang_Lin1;~Jingping_Shao1;~Yuanjie_Shao1;~Xinge_You1;~Changxin_Gao1;~Nong_Sang1",
        "gender": ";M;M;M;F;M;;M;F;F;M;M;M;M;M;M;M;M;M",
        "homepage": ";;;;https://github.com/chenyanyin;;;;;;https://www.zhihu.com/people/linolzhang;https://mail.163.com;;;https://www.jd.com/;https://hust.teacher.360eol.com/teacherBasic/preview?teacherType=&teacherId=15992;http://bmal.hust.edu.cn/info/1005/1091.htm;https://sites.google.com/site/changxingao/home;http://faculty.hust.edu.cn/sangnong/en/index.htm",
        "dblp": ";;359/9964;;;;;;;;;;;;;168/2177.html;16/1184;99/7463;10/1545",
        "google_scholar": ";https://scholar.google.com.hk/citations?user=FvIAct4AAAAJ;;;;https://scholar.google.com/citations?hl=zh-CN;;;https://scholar.google.com/citations?hl=zh-CN;4-1R-bMAAAAJ;;;;;;GqA1wSgAAAAJ;v7bRZX8AAAAJ;4tku-lwAAAAJ;ky_ZowEAAAAJ",
        "orcid": ";0009-0005-8890-4956;0000-0002-1386-8381;0009-0001-4006-774X;0009-0004-5508-3605;0000-0003-3451-6884;;0000-0002-7362-7897;;;0009-0002-6391-4814;0009-0000-5518-7077;0009-0008-6983-5213;;;;;0000-0003-2736-3920;0000-0002-9167-1496",
        "linkedin": ";;;;;;;;;;;;;jack-zhangang-lin-020b2237/;;;;;",
        "or_profile": "~Xingye_Chen1;~Wei_Feng8;~Zhenbang_Du1;~Weizhen_Wang2;~yanyin_chen1;~Haohan_Wang3;~Linkai_Liu1;~Yaoyu_Li2;~jinyuan_zhao2;~Yu_Li7;~Zheng_Zhang26;~Jingjing_Lv1;~Junjie_Shen2;~Zhangang_Lin1;~Jingping_Shao1;~Yuanjie_Shao1;~Xinge_You1;~Changxin_Gao1;~Nong_Sang1",
        "aff": ";JD;Georgia Institute of Technology+Huazhong University of Science and Technology;;JD;JD.com;;JD;;, Chinese Academy of Sciences+JD.com;JD;JD;JD;JD;JD;Huazhong University of Science and Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology;Huazhong University of Science and Technology",
        "aff_domain": ";jd.com;gatech.edu+hust.edu.cn;;jd.com;jd.com;;jd.com;;ict.ac.cn+jd.com;jd.com;jd.com;jd.com;jd.com;jd.com;hust.edu.cn;hust.edu.cn;hust.edu.cn;hust.edu.cn",
        "position": ";Researcher;PhD student+MS student;;Researcher;Researcher;;Researcher;;Associate Professor+Researcher;Full Professor;Researcher;Researcher;Researcher;Researcher;Associate Professor;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nchen2025ctrdriven,\ntitle={{CTR}-Driven Advertising Image Generation with Multimodal Large Language Models},\nauthor={Xingye Chen and Wei Feng and Zhenbang Du and Weizhen Wang and yanyin chen and Haohan Wang and Linkai Liu and Yaoyu Li and jinyuan zhao and Yu Li and Zheng Zhang and Jingjing Lv and Junjie Shen and Zhangang Lin and Jingping Shao and Yuanjie Shao and Xinge You and Changxin Gao and Nong Sang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=wz46GyAptn}\n}",
        "github": "",
        "project": "",
        "reviewers": "ooZy;PZGu;QSPJ;TGgc;FJrV",
        "site": "https://openreview.net/forum?id=wz46GyAptn",
        "pdf_size": 0,
        "novelty": "4;4;4;5;5",
        "technical_quality": "4;4;4;6;5",
        "scope": "3;4;3;3;4",
        "confidence": "3;4;3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.48989794855663565
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.6324555320336759
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            19,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.6454972243679028
    },
    {
        "id": "wzeZ2kp7jS",
        "title": "IPdb: A High-precision IP Level Industry Categorization of Web Services",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "IP addresses with web services are crucial in the Internet ecosystem. Classifying these addresses by industry and organization offers valuable insights into the entities utilizing them, enabling more efficient network management and enhanced security. Previous work in website classification and Internet management struggles to offer an IP-level perspective of the industries of web services due to their limited industry categories or potential industry inconsistencies between IP address owners and AS owners. To this end, we present IPdb, an IP-level industry categorization dataset. To construct the dataset, we developed LLMIC, a Large Language Model-based Industry Categorization framework with a precision of nearly 96\\%. IPdb serves as a labeled database for future endeavors in developing IP-level industry classifiers, encompassing over 200 million IP addresses. Furthermore, our study indicates that 30\\% $\\sim$ 50\\% of organizations within critical infrastructure industries deploy web servers across multiple ASes. Our study \nalso validates the problem of mismatched granularity in industry categorization at the AS level with 87.83\\% ASes in IPv4 and 72.96\\% ASes in IPv6 containing IP addresses from different industries.",
        "keywords": "Internet management;Web mearsurement",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Hongxu Chen;Guanglei Song;Zhiliang Wang;Jiahai Yang;Songyun Wu;Jinlei Lin;Lin He;Chenglong Li",
        "authorids": "~Hongxu_Chen9;~Guanglei_Song2;~Zhiliang_Wang3;~Jiahai_Yang1;~Songyun_Wu2;~Jinlei_Lin1;~Lin_He4;~Chenglong_Li5",
        "gender": "M;M;M;M;;M;M;M",
        "homepage": "https://ch3n-hx.github.io/;https://scholar.google.com/citations?user=dpcpsXQAAAAJ&hl=zh-CN&oi=ao;https://www.insc.tsinghua.edu.cn/info/1157/2853.htm;http://nmgroup.tsinghua.edu.cn/yang/index_en.htm;;https://github.com/linjinlei/;https://helinhl.github.io/;https://www.insc.tsinghua.edu.cn/info/1157/2450.htm",
        "dblp": ";;;;;;;83/7820-1",
        "google_scholar": ";dpcpsXQAAAAJ;;;;;;https://scholar.google.com/citations?hl=zh-CN",
        "orcid": "0009-0004-6729-459X;;;;0000-0003-4382-6550;;;0000-0003-4300-678X",
        "linkedin": ";;;;;;;",
        "or_profile": "~Hongxu_Chen9;~Guanglei_Song2;~Zhiliang_Wang3;~Jiahai_Yang1;~Songyun_Wu2;~Jinlei_Lin1;~Lin_He4;~Chenglong_Li5",
        "aff": "Tsinghua University;;Tsinghua University;;Tsinghua University;Tsinghua University;Tsinghua University;Tsinghua University+Zhongguancun Laboratory",
        "aff_domain": "mails.tsinghua.edu.cn;;tsinghua.edu.cn;;mails.tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn;tsinghua.edu.cn+zgclab.edu.cn",
        "position": "MS student;;Associate Professor;;PhD student;PhD student;Assistant Professor;Associate Professor+Associate Professor",
        "bibtex": "@inproceedings{\nchen2025ipdb,\ntitle={{IP}db: A High-precision {IP} Level Industry Categorization of Web Services},\nauthor={Hongxu Chen and Guanglei Song and Zhiliang Wang and Jiahai Yang and Songyun Wu and Jinlei Lin and Lin He and Chenglong Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=wzeZ2kp7jS}\n}",
        "github": "",
        "project": "",
        "reviewers": "8RvU;gTbv;mVfp;x2XX;Aw7y",
        "site": "https://openreview.net/forum?id=wzeZ2kp7jS",
        "pdf_size": 0,
        "novelty": "3;4;4;5;5",
        "technical_quality": "4;4;4;5;6",
        "scope": "4;3;3;4;4",
        "confidence": "3;2;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            0.8
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.13363062095621217
    },
    {
        "id": "x1nXBzUknn",
        "title": "DAGE: DAG Query Answering via Relational Combinator with Logical Constraints",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Predicting answers to queries over knowledge graphs is called a complex reasoning task because answering a query requires subdividing it into subqueries. Existing query embedding methods use this decomposition to compute the embedding of a query as the combination of the embedding of the subqueries. This requirement limits the answerable queries to queries having a single free variable and being decomposable, which are called tree-form queries and correspond to the $SROI^-$ description logic. In this paper, we define a more general set of queries, called DAG queries, formulate a description logic corresponding to them, called DAG-DL, propose a query embedding method for them, called DAGE, and a new benchmark to evaluate query embeddings on them. Given the computational graph of a DAG query, DAGE combines the possibly multiple paths between two nodes into a single path with a trainable operator that represents the intersection of relations and learns DAG-DL tautologies. We show that it is possible to implement DAGE on top of existing query embedding methods, and we empirically measure the outstanding improvement of our method over the results of vanilla methods evaluated in tree-form queries that result in relaxing the DAG queries of our proposed benchmark.",
        "keywords": "Description Logics;Knowledge Graph",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yunjie He;Bo Xiong;Daniel Hern\u00e1ndez;Yuqicheng Zhu;Evgeny Kharlamov;Steffen Staab",
        "authorids": "~Yunjie_He1;~Bo_Xiong3;~Daniel_Hern\u00e1ndez1;~Yuqicheng_Zhu1;~Evgeny_Kharlamov1;~Steffen_Staab2",
        "gender": "F;M;M;M;M;M",
        "homepage": ";;https://daniel.degu.cl;https://zhuyuqicheng.github.io/;https://www.mn.uio.no/ifi/english/people/aca/evgenykh/;https://www.ki.uni-stuttgart.de/de/institut/team/Staab-00004/",
        "dblp": "288/0438;;18/4942-2;330/2167;20/4833;s/SteffenStaab",
        "google_scholar": "https://scholar.google.com/citations?hl=en;lmBXicIAAAAJ;4K2-3iQAAAAJ;TE5jy5cAAAAJ;https://scholar.google.de/citations?user=-slpMF8AAAAJ;https://scholar.google.com/citations?hl=de",
        "orcid": ";;0000-0002-7896-0875;;0000-0003-3247-4166;0000-0002-0780-4154",
        "linkedin": "yunjie-he-20618216b/;;;yuqicheng-zhu-531658161/;;",
        "or_profile": "~Yunjie_He1;~Bo_Xiong3;~Daniel_Hern\u00e1ndez1;~Yuqicheng_Zhu1;~Evgeny_Kharlamov1;~Steffen_Staab2",
        "aff": "Universit\u00e4t Stuttgart; Bosch Center for Artificial Intelligence;Stanford University;Universit\u00e4t Stuttgart;Universit\u00e4t Stuttgart;University of Oslo+Robert Bosch GmbH, Bosch;University of Stuttgart+University of Southampton",
        "aff_domain": "uni-stuttgart.de;stanford.edu;uni-stuttgart.de;uni-stuttgart.de;uio.no+de.bosch.com;ki.uni-stuttgart.de+soton.ac.uk",
        "position": "PhD student;Postdoc;Postdoc;PhD student;Associate Professor+Bosch Center for Artificial Intelligence;Full Professor+Full Professor",
        "bibtex": "@inproceedings{\nhe2025dage,\ntitle={{DAGE}: {DAG} Query Answering via Relational Combinator with Logical Constraints},\nauthor={Yunjie He and Bo Xiong and Daniel Hern{\\'a}ndez and Yuqicheng Zhu and Evgeny Kharlamov and Steffen Staab},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=x1nXBzUknn}\n}",
        "github": "",
        "project": "",
        "reviewers": "J3aj;R6bD;oSU5;vbk9;xZ8k",
        "site": "https://openreview.net/forum?id=x1nXBzUknn",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;4;6;5;7",
        "scope": "4;3;3;3;4",
        "confidence": "3;2;2;4;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.2,
            1.16619037896906
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.06250000000000001
    },
    {
        "id": "xALBXUXnet",
        "title": "WasmGuard: Enhancing Web Security through Robust Raw-Binary Detection of WebAssembly Malware",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "WebAssembly (Wasm), a binary instruction format designed for efficient cross-platform execution, has rapidly become a foundational web standard, widely adopted in browsers, client-side, and server-side applications. However, its growing popularity has led to an increase in Wasm-targeted malware, including cryptojackers and obfuscated malicious scripts, which pose significant threats to web security. In spite of progress in deep learning based detection methods for Wasm malware, such as MINOS, these approaches face substantial performance degradation in adversarial environments. In our experiments, MINOS\u2019s detection accuracy dropped to 49.90\\% under adversarial attacks, revealing critical vulnerabilities. To address this, we introduce \\textbf{WasmGuard}, a robust malware detection framework tailored for Wasm. WasmGuard employs FGSM-based adversarial training with prior-based initialization for perturbation bytes in customized sections, coupled with a novel adversarial contrastive learning objective. Using our large-scale dataset, \\textbf{WasmMal-15K} (publicly available), WasmGuard outperforms six competing methods, achieving up to 99.20\\% Robust Accuracy and 99.93\\% Standard Accuracy under PGD-50 adversarial attacks, while maintaining low training overhead. Additionally, we have released \\textbf{WebChecker}, a WasmGuard-powered browser plugin, providing real-time protection against malicious Wasm files.",
        "keywords": "Wasm malware detection;Adversarial robustness;Contrastive learning;Perturbation bytes;Web security",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yuxia Sun;HuiHong Chen;Zhixiao Fu;Wenjian Lv;Zitao Liu;Haolin Liu",
        "authorids": "~Yuxia_Sun2;~HuiHong_Chen1;~Zhixiao_Fu2;~Wenjian_Lv1;~Zitao_Liu1;~Haolin_Liu9",
        "gender": ";;;M;M;M",
        "homepage": ";;;https://github.com/Dara-to-win;http://www.zitaoliu.com/;https://jwxy.xtu.edu.cn/info/1148/2543.htm#:~:text=\u5218\u660a\u9716\uff0c\u535a\u58eb\uff0c\u526f\u6559\u6388",
        "dblp": ";;;;210/0898;",
        "google_scholar": ";;;;rRTzNm0AAAAJ;",
        "orcid": "0000-0002-5959-0629;0009-0008-6836-697X;;;0000-0003-0491-307X;",
        "linkedin": ";;;;;",
        "or_profile": "~Yuxia_Sun2;~HuiHong_Chen1;~Zhixiao_Fu2;~Wenjian_Lv1;~Zitao_Liu1;~Haolin_Liu9",
        "aff": "Jinan University;Jinan University;;;Jinan University;Xiangtan University",
        "aff_domain": "jnu.edu.cn;jnu.edu.cn;;;jnu.edu.cn;xtu.edu.cn",
        "position": "Associate Professor;MS student;;;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nsun2025wasmguard,\ntitle={WasmGuard: Enhancing Web Security through Robust Raw-Binary Detection of WebAssembly Malware},\nauthor={Yuxia Sun and HuiHong Chen and Zhixiao Fu and Wenjian Lv and Zitao Liu and Haolin Liu},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=xALBXUXnet}\n}",
        "github": "",
        "project": "",
        "reviewers": "GRfx;PHep;mW2d;1JFZ",
        "site": "https://openreview.net/forum?id=xALBXUXnet",
        "pdf_size": 0,
        "novelty": "3;5;5;5",
        "technical_quality": "3;6;6;5",
        "scope": "3;4;4;3",
        "confidence": "3;3;3;1",
        "wc_review": "",
        "novelty_avg": [
            4.5,
            0.8660254037844386
        ],
        "technical_quality_avg": [
            5.0,
            1.224744871391589
        ],
        "scope_avg": [
            3.5,
            0.5
        ],
        "confidence_avg": [
            2.5,
            0.8660254037844386
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3333333333333333
    },
    {
        "id": "xT9Jy2d6Sd",
        "title": "Towards Efficient Conversational Recommendations: Expected Value of Information Meets Bandit Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In conversational recommender systems, interactively presenting queries and leveraging user feedback are crucial for efficiently estimating user preferences and improving recommendation quality. Selecting optimal queries in these systems is a significant challenge that has been extensively studied as a sequential decision problem. The expected value of information (EVOI), which computes the expected reward improvement, provides a principled criterion for query selection. However, it is computationally expensive and lacks theoretical performance guarantees. Conversely, conversational bandits offer provable regret upper bounds, but their query selection strategies yield only marginal regret improvements over non-conversational approaches. To address these limitations, we integrate EVOI within the conversational bandit framework by proposing a new conversational mechanism featuring two key techniques: (1) gradient-based EVOI, which replaces the complex Bayesian updates in conventional EVOI with efficient stochastic gradient descent, significantly reducing computational complexity and facilitating theoretical analysis; and (2) smoothed key term contexts, which enhance exploration by adding random perturbations to uncover more specific user preferences. Our approach applies to both Bayesian (Thompson Sampling) and frequentist (UCB) variants of conversational bandits. We introduce two new algorithms, ConTS-EVOI and ConUCB-EVOI, and rigorously prove that they achieve substantially tighter regret bounds, with both algorithms offering a $\\sqrt{d}$ improvement in their dependence on the time horizon $T$, where $d$ is the dimension of the feature space. Extensive evaluations on synthetic and real-world datasets validate the effectiveness of our methods.",
        "keywords": "Conversational Recommendation;Preference Elicitation;Multi-Armed Bandit;Online Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhuohua Li;Maoli Liu;Xiangxiang Dai;John C.S. Lui",
        "authorids": "~Zhuohua_Li2;~Maoli_Liu1;~Xiangxiang_Dai2;~John_C.S._Lui2",
        "gender": ";F;;M",
        "homepage": ";https://liumaoli.me/;;http://www.cse.cuhk.edu.hk/~cslui/Index.html",
        "dblp": ";334/8266;;l/JohnCSLui",
        "google_scholar": ";DFDtmBAAAAAJ;;https://scholar.google.com.tw/citations?user=7LVjQ7MAAAAJ",
        "orcid": ";0000-0002-6321-6576;;0000-0001-7466-0384",
        "linkedin": ";maoli-liu/;;",
        "or_profile": "~Zhuohua_Li2;~Maoli_Liu1;~Xiangxiang_Dai2;~John_C.S._Lui2",
        "aff": ";The Chinese University of Hong Kong;;The Chinese University of Hong Kong",
        "aff_domain": ";cse.cuhk.edu.hk;;cse.cuhk.edu.hk",
        "position": ";PhD student;;Full Professor",
        "bibtex": "@inproceedings{\nli2025towards,\ntitle={Towards Efficient Conversational Recommendations: Expected Value of Information Meets Bandit Learning},\nauthor={Zhuohua Li and Maoli Liu and Xiangxiang Dai and John C.S. Lui},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=xT9Jy2d6Sd}\n}",
        "github": "",
        "project": "",
        "reviewers": "xxrL;o7fJ;eaqG;ARYp;En3j",
        "site": "https://openreview.net/forum?id=xT9Jy2d6Sd",
        "pdf_size": 0,
        "novelty": "3;3;5;5;6",
        "technical_quality": "4;4;5;5;5",
        "scope": "4;4;4;4;3",
        "confidence": "3;3;4;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            1.2
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.3563483225498992
    },
    {
        "id": "xVatnSFsh4",
        "title": "What\u2019s in Phishers: A Longitudinal Study of Security Configurations in Phishing Websites and Kits",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Phishing attacks pose a significant threat to Internet users. Understanding the security posture of phishing infrastructure is crucial for developing effective defense strategies, as it helps identify potential weaknesses that attackers might exploit. Despite extensive research, there may still be a gap in fully understanding these security weaknesses. To address this important issue, this paper presents a longitudinal study of security configurations and vulnerabilities in phishing websites and associated kits. We focus on two main areas: (1) analyzing the security configurations of phishing websites and servers, particularly HTTP headers and application-level security, and (2) examining the prevalence and types of vulnerabilities in phishing kits. We analyze data from 906,731 distinct phishing websites collected over 2.5 years, covering HTML headers, client-side resources, and phishing kits. Our findings suggest that phishing websites often employ weak security configurations, with 88.8% of the 13,344 collected phishing kits containing at least one potential vulnerability, and 12.5% containing backdoor vulnerabilities. These vulnerabilities present an opportunity for defenders to shift from passive defense to active disruption of phishing operations. Our research proposes a new approach to leverage weaknesses in phishing infrastructure, allowing defenders to take proactive actions to disable phishing sites earlier and reduce their effectiveness.",
        "keywords": "Phishing;HTTP headers;Phishing kit",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Kyungchan Lim;Kiho Lee;Fujiao Ji;Yonghwi Kwon;Hyoungshick Kim;Doowon Kim",
        "authorids": "~Kyungchan_Lim1;~Kiho_Lee1;~Fujiao_Ji1;~Yonghwi_Kwon3;~Hyoungshick_Kim1;~Doowon_Kim1",
        "gender": "M;M;F;M;M;",
        "homepage": ";https://github.com/0xk1h0;;http://yongkwon.info;https://seclab.skku.edu/people/hyoungshick-kim/;",
        "dblp": ";;;139/7034.html;64/5383;",
        "google_scholar": "3h9ziwEAAAAJ;https://scholar.google.co.kr/citations?user=MOTHTpcAAAAJ;ofl_bg8AAAAJ;YK3KT3kAAAAJ;;",
        "orcid": ";0000-0002-8713-3863;;;;",
        "linkedin": ";kiho-lee-a253b5249/;;;;",
        "or_profile": "~Kyungchan_Lim1;~Kiho_Lee1;~Fujiao_Ji1;~Yonghwi_Kwon3;~Hyoungshick_Kim1;~Doowon_Kim1",
        "aff": ", University of Tennessee, Knoxville;University of Tennessee, Knoxville;University of Tennessee, Knoxville;University of Maryland, College Park;Sungkyunkwan University;",
        "aff_domain": "eecs.utk.edu;utk.edu;utk.edu;umd.edu;skku.edu;",
        "position": "PhD student;Researcher;PhD student;Assistant Professor;Full Professor;",
        "bibtex": "@inproceedings{\nlim2025whats,\ntitle={What{\\textquoteright}s in Phishers: A Longitudinal Study of Security Configurations in Phishing Websites and Kits},\nauthor={Kyungchan Lim and Kiho Lee and Fujiao Ji and Yonghwi Kwon and Hyoungshick Kim and Doowon Kim},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=xVatnSFsh4}\n}",
        "github": "",
        "project": "",
        "reviewers": "aFh1;qZjb;qxci;QpZu;y4zd",
        "site": "https://openreview.net/forum?id=xVatnSFsh4",
        "pdf_size": 0,
        "novelty": "4;4;5;5;7",
        "technical_quality": "3;5;5;6;6",
        "scope": "4;3;4;3;4",
        "confidence": "3;3;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            5.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            5.0,
            1.0954451150103321
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.6,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.74535599249993
    },
    {
        "id": "xqjnhRqdK9",
        "title": "Federated Graph Anomaly Detection via Disentangled Representation Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph anomaly detection plays a crucial role in identifying nodes that deviate significantly from normal patterns within a graph, with applications spanning various domains such as fraud detection, authorship fraud, and rumor propagation. Traditional methods primarily focus on aggregating information from neighboring nodes and reconstructing the central node based on these aggregated features. The anomaly degree is then calculated by comparing the reconstructed features with the original ones. Despite their effectiveness, these methods face limitations due to the constraints of device performance and the need to protect user privacy. In reality, graph data is often partitioned and distributed across different local clients, which leads to isolated client subgraphs. This partitioning results in incomplete feature aggregation, as the connections between subgraphs are missing, ultimately reducing the performance of anomaly detection models. To overcome these challenges, a federated graph anomaly detection approach based on disentangled representation learning is proposed. This method separates node features into two distinct components: intrinsic features and subgraph style features. By identifying outliers within the subgraph style features, a set of pseudo-nodes is generated and shared across the entire graph. These pseudo-nodes simulate connections between otherwise isolated subgraphs, which enables more comprehensive aggregation of intrinsic features from neighboring nodes. In addition, conditional variational autoencoders (CVAE) are employed alongside contrastive learning strategies to alleviate class imbalance and achieve effective feature disentanglement. These techniques help ensure that anomalous nodes are detected more accurately despite the inherent challenges of federated graph systems.\nExtensive experiments conducted on six diverse datasets provide compelling evidence of the proposed method's superior performance in federated graph anomaly detection, highlighting its ability to effectively handle incomplete graph structures while maintaining data privacy.",
        "keywords": "Graph Anomaly Detection;Graph Neural Networks;Federated Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zhengyang Liu;Hang Yu;Xiangfeng Luo",
        "authorids": "~Zhengyang_Liu3;~Hang_Yu9;~Xiangfeng_Luo1",
        "gender": ";M;M",
        "homepage": ";;https://cs.shu.edu.cn/szdw/jsxx.htm",
        "dblp": "96/8612-7;74/2568-6;63/4996",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.au/citations?user=3BLeGSoAAAAJ;LdrdX7kAAAAJ",
        "orcid": "0009-0009-0526-3612;0000-0003-3444-9992;",
        "linkedin": ";;",
        "or_profile": "~Zhengyang_Liu3;~Hang_Yu9;~Xiangfeng_Luo1",
        "aff": "Shanghai University;Shanghai University;Shanghai University",
        "aff_domain": "shu.edu.cn;shu.edu.cn;shu.edu.cn",
        "position": "PhD student;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nliu2025federated,\ntitle={Federated Graph Anomaly Detection via Disentangled Representation Learning},\nauthor={Zhengyang Liu and Hang Yu and Xiangfeng Luo},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=xqjnhRqdK9}\n}",
        "github": "",
        "project": "",
        "reviewers": "G9Hm;6ZTT;JtWd;59nv",
        "site": "https://openreview.net/forum?id=xqjnhRqdK9",
        "pdf_size": 0,
        "novelty": "5;5;6;6",
        "technical_quality": "5;4;6;6",
        "scope": "3;4;4;4",
        "confidence": "4;4;4;4",
        "wc_review": "",
        "novelty_avg": [
            5.5,
            0.5
        ],
        "technical_quality_avg": [
            5.25,
            0.82915619758885
        ],
        "scope_avg": [
            3.75,
            0.4330127018922193
        ],
        "confidence_avg": [
            4.0,
            0.0
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "xzzQndeqMu",
        "title": "EVA-MVC: Equitable View-weight Allocation for Generic Multi-View Clustering",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Contemporary datasets sourced from the web often adopt a multi-view format, collecting data from diverse sources, domains, or modules. \nExisting methodologies employed to analyze such datasets frequently overlook or inaccurately allocate the view-weights, pivotal metrics reflecting each view's significance.\nThis work introduces EVA-MVC, a simple yet effective algorithm designed for Equitable View-weight Allocation (EVA) seamlessly integrated with arbitrary Multi-view Clustering (MVC) methods.\nWithin the EVA phase, we establish theoretical connections between view supplementarity and Multi-view Subspace Learning (MSL), leading to the partiton of views into View Communities (VCs) based on these foundational principles. \nThese VCs exhibit internal supplementarity similarities, facilitating Equitable View-weights Allocation through VC-specific MSL.\nThe proposed EVA process precedes and operates independently of traditional or SOTA MVC approaches, requiring no additional processing or specialized design, making it an ideal preprocessing step for MVC applications. \nThrough comprehensive evaluations across diverse multi-view datasets, our findings reveal that our EVA significantly enhances the effectiveness of mainstream MVC frameworks, resulting in a notable performance improvement.",
        "keywords": "Multi-view Subspace Clustering;Large-scale;Information Fusion;Equitable View-weight Allocation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "yuan fang;Xiaofeng Feng;Geping Yang;Ruichu Cai;Yiyang Yang;Zhiguo Gong;Zhifeng Hao",
        "authorids": "~yuan_fang3;~Xiaofeng_Feng1;~Geping_Yang1;~Ruichu_Cai1;~Yiyang_Yang1;~Zhiguo_Gong1;~Zhifeng_Hao5",
        "gender": "M;F;M;M;M;M;M",
        "homepage": "https://github.com/FY0109?tab=repositories;;;https://ruichucai.github.io/;;https://www.fst.um.edu.mo/people/fstzgg/;https://www.scholat.com/zfhao",
        "dblp": ";;319/3574;09/6889;67/9902;95/6295;",
        "google_scholar": ";;uDtpkgMAAAAJ;https://scholar.google.com/citations?hl=en;P7fcA8IAAAAJ;i75MaGYAAAAJ;",
        "orcid": ";0009-0005-9463-5924;;;0000-0002-9306-4489;;",
        "linkedin": ";;;;;;",
        "or_profile": "~yuan_fang3;~Xiaofeng_Feng1;~Geping_Yang1;~Ruichu_Cai1;~Yiyang_Yang1;~Zhiguo_Gong1;~Zhifeng_Hao5",
        "aff": "Guangdong University of Technology;Guangdong University of Technology;University of Macau;Guangdong University of Technology;Guangdong University of Technology;University of Macau;",
        "aff_domain": "gdut.edu.cn;gdut.edu.cn;um.edu.mo;gdut.edu.cn;gdut.edu.cn;um.edu.mo;",
        "position": "MS student;MS student;PhD student;Full Professor;Lecturer;Full Professor;",
        "bibtex": "@inproceedings{\nfang2025evamvc,\ntitle={{EVA}-{MVC}: Equitable View-weight Allocation for Generic Multi-View Clustering},\nauthor={yuan fang and Xiaofeng Feng and Geping Yang and Ruichu Cai and Yiyang Yang and Zhiguo Gong and Zhifeng Hao},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=xzzQndeqMu}\n}",
        "github": "",
        "project": "",
        "reviewers": "35ZZ;xGaW;ZxU7;vtB6",
        "site": "https://openreview.net/forum?id=xzzQndeqMu",
        "pdf_size": 0,
        "novelty": "3;4;5;5",
        "technical_quality": "4;5;5;5",
        "scope": "3;3;3;4",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.25,
            0.82915619758885
        ],
        "technical_quality_avg": [
            4.75,
            0.4330127018922193
        ],
        "scope_avg": [
            3.25,
            0.4330127018922193
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "replies_avg": [
            4,
            0
        ],
        "authors#_avg": [
            7,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.17407765595569782
    },
    {
        "id": "y5tQ9BX5NW",
        "title": "DecETT: Accurate App Fingerprinting Under Encrypted Tunnels via Dual Decouple-based Semantic Enhancement",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Due to the growing demand for privacy protection, encrypted tunnels have become increasingly popular among mobile app users, which brings new challenges for app fingerprinting (AF)-based network management. Existing methods primarily transfer traditional AF methods to encrypted tunnels directly, ignoring the core obfuscation and re-encapsulation mechanism of encrypted tunnels, thus resulting in unsatisfactory performance. \nIn this paper, we propose DecETT, a dual decouple-based semantic enhancement method for accurate AF under encrypted tunnels. \nSpecifically, DecETT improves AF under encrypted tunnels from two perspectives: app-specific feature enhancement and irrelevant tunnel feature decoupling.\nConsidering the obfuscated app-specific information in encrypted tunnel traffic, DecETT introduces TLS traffic with stronger app-specific information as a semantic anchor to guide and enhance the fingerprint generation for tunnel traffic. \nFurthermore, to address the app-irrelevant tunnel feature introduced by the re-encapsulation mechanism, DecETT is designed with a dual decouple-based fingerprint enhancement module, which decouples the tunnel feature and app semantic feature from tunnel traffic separately, thereby minimizing the impact of tunnel features on accurate app fingerprint extraction.\nEvaluation under five prevalent encrypted tunnels indicates that DecETT outperforms state-of-the-art methods in accurate AF under encrypted tunnels, and further demonstrates its superiority under tunnels with more complicated obfuscation. Project page: https://github.com/DecETT/DecETT",
        "keywords": "App Fingerprinting;Encrypted Tunnel;Encrypted Traffic Analysis;Decouple-based Representation Learning",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zheyuan Gu;Chang Liu;Xiyuan Zhang;Chen Yang;Gaopeng Gou;Gang Xiong;Zhen Li;Sijia Li",
        "authorids": "~Zheyuan_Gu1;~Chang_Liu66;~Xiyuan_Zhang3;~Chen_Yang34;~Gaopeng_Gou2;~Gang_Xiong1;~Zhen_Li27;~Sijia_Li7",
        "gender": "F;;M;;M;M;M;F",
        "homepage": ";;;;https://people.ucas.ac.cn/~gougaopeng;https://people.ucas.edu.cn/~xionggang;https://www.ucas.edu.cn/;",
        "dblp": ";;;;13/10808;;;",
        "google_scholar": ";;;;;;;https://scholar.google.com.hk/citations?hl=zh-CN",
        "orcid": "0009-0003-3344-9058;;0009-0004-5465-0663;;;0000-0002-3190-6521;;",
        "linkedin": ";;;;;;;",
        "or_profile": "~Zheyuan_Gu1;~Chang_Liu66;~Xiyuan_Zhang3;~Chen_Yang34;~Gaopeng_Gou2;~Gang_Xiong1;~Zhen_Li27;~Sijia_Li7",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences;;Institute of Information Engineering, Chinese Academy of Sciences;;University of Chinese Academy of Sciences;Institute of Information Engineering, Chinese Academy of Science;;",
        "aff_domain": "iie.ac.cn;;iie.ac.cn;;ucas.ac.cn;iie.ac.cn;;",
        "position": "PhD student;;PhD student;;Full Professor;Full Professor;;",
        "bibtex": "@inproceedings{\ngu2025decett,\ntitle={Dec{ETT}: Accurate App Fingerprinting Under Encrypted Tunnels via Dual Decouple-based Semantic Enhancement},\nauthor={Zheyuan Gu and Chang Liu and Xiyuan Zhang and Chen Yang and Gaopeng Gou and Gang Xiong and Zhen Li and Sijia Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=y5tQ9BX5NW}\n}",
        "github": "",
        "project": "",
        "reviewers": "zuo7;PAPx;atiG",
        "site": "https://openreview.net/forum?id=y5tQ9BX5NW",
        "pdf_size": 0,
        "novelty": "3;4;5",
        "technical_quality": "5;4;5",
        "scope": "3;3;3",
        "confidence": "3;2;3",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            0.816496580927726
        ],
        "technical_quality_avg": [
            4.666666666666667,
            0.4714045207910317
        ],
        "scope_avg": [
            3.0,
            0.0
        ],
        "confidence_avg": [
            2.6666666666666665,
            0.4714045207910317
        ],
        "replies_avg": [
            3,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "yDePDK82F0",
        "title": "50 Shades of Deceptive Patterns: A Unified Taxonomy, Multimodal Detection, and Security Implications",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Deceptive patterns (DPs) are user interface designs deliberately crafted to manipulate users into unintended decisions, often by exploiting cognitive biases for the benefit of companies or services. While numerous studies have explored ways to identify these deceptive patterns, many existing solutions require significant human intervention and struggle to keep pace with the evolving nature of deceptive designs. \nTo address these challenges, we expanded the deceptive pattern taxonomy from security and privacy perspectives, refining its categories and scope. We created a comprehensive dataset of deceptive patterns by integrating existing small-scale datasets with new samples, resulting in 6,725 images and 10,421 DP instances from mobile apps and websites. We then developed DPGuard, a novel automatic tool leveraging commercial multimodal large language models (MLLMs) for deceptive pattern detection. Experimental results show that DPGuard outperforms state-of-the-art methods. Finally, we conducted an extensive empirical evaluation on 2,000 popular mobile apps and websites, revealing that 23.61% of mobile screenshots and 47.27% of website screenshots feature at least one deceptive pattern instance. Through four unexplored case studies that inform security implications, we highlight the critical importance of the unified taxonomy in addressing the growing challenges of Internet deception.",
        "keywords": "Deceptive Pattern;Multimodal Detection;Security;Privacy",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zewei Shi;Ruoxi Sun;Jieshan Chen;Jiamou Sun;Jason Xue;Yansong Gao;Feng Liu;Xingliang YUAN",
        "authorids": "~Zewei_Shi1;~Ruoxi_Sun3;~Jieshan_Chen1;~Jiamou_Sun2;~Jason_Xue1;~Yansong_Gao2;~Feng_Liu2;~Xingliang_YUAN2",
        "gender": "M;M;Not Specified;M;;;M;",
        "homepage": ";;https://chenjshnn.github.io/;https://research.csiro.au/ss/people/staff/;;;https://fengliu90.github.io/index.html;http://xyuancs.github.io",
        "dblp": ";72/7683;;229/9223;;;77/1318-3;21/8884",
        "google_scholar": "https://scholar.google.com.au/citations?user=GZQNGnkAAAAJ;https://scholar.google.com.au/citations?user=Ei4jdwQAAAAJ;slrzj8kAAAAJ;l2UCgDYAAAAJ;;;https://scholar.google.com/citations?hl=en;https://scholar.google.com.hk/citations?user=81yWaCoAAAAJ",
        "orcid": "0009-0002-5290-7678;0000-0001-5404-8550;;0000-0002-5212-7068;;;0000-0002-5005-9129;0000-0002-3701-4946",
        "linkedin": "zeweishi/;;;;;;alexfengliu;",
        "or_profile": "~Zewei_Shi1;~Ruoxi_Sun3;~Jieshan_Chen1;~Jiamou_Sun2;~Jason_Xue1;~Yansong_Gao2;~Feng_Liu2;~Xingliang_YUAN2",
        "aff": "University of Melbourne;CSIRO's Data61;Commonwealth Scientific and Industrial Research Organisation, CSIRO;, CSIRO;;;University of Melbourne;University of Melbourne",
        "aff_domain": "unimelb.edu.au;data61.csiro.au;data61.csiro.au;data61.csiro.au;;;unimelb.edu.au;unimelb.edu.au",
        "position": "PhD student;Postdoc;Researcher;Researcher;;;Assistant Professor;Associate Professor",
        "bibtex": "@inproceedings{\nshi2025,\ntitle={50 Shades of Deceptive Patterns: A Unified Taxonomy, Multimodal Detection, and Security Implications},\nauthor={Zewei Shi and Ruoxi Sun and Jieshan Chen and Jiamou Sun and Jason Xue and Yansong Gao and Feng Liu and Xingliang YUAN},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=yDePDK82F0}\n}",
        "github": "",
        "project": "",
        "reviewers": "EPz4;54rq;BPDY;wxUA;YyoV",
        "site": "https://openreview.net/forum?id=yDePDK82F0",
        "pdf_size": 0,
        "novelty": "4;4;5;5;6",
        "technical_quality": "5;4;5;3;6",
        "scope": "4;3;4;3;4",
        "confidence": "3;3;3;3;2",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.7483314773547882
        ],
        "technical_quality_avg": [
            4.6,
            1.019803902718557
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            8,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8017837257372731
    },
    {
        "id": "yXtGrd4Ib7",
        "title": "Linking Souls to Humans: Blockchain Accounts with Credible Anonymity for Web 3.0 Decentralized Identity",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "A decentralized identity system that can provide users with self-sovereign digital identities to facilitate complete control over their own data is paramount to Web 3.0. The account system on blockchain is an ideal archetype for realizing Web 3.0 decentralized identity. However, a disadvantage of such completely anonymous identity system is that users can create multiple accounts without authentication to obfuscate their activities on the blockchain. In particular, the current anonymous blockchain account system cannot accurately register the social relationships and interactions between real human users, given the amorphous mappings between users and blockchain identities. This work proposes zkBID, a zero-knowledge blockchain-account-based Web 3.0 decentralized identity scheme, to overcome endemic mistrust in blockchain account systems. zkBID links souls (blockchain accounts) to humans (users\u2019 personhood credentials) in a one-to-one manner to truly reflect the social relationships and interactions between humans on the blockchain. zkBID conceals the one-to-one relationships between blockchain accounts and users\u2019 personhood credentials for privacy protection using linkable ring signature. Thus, with zkBID, the users\u2019 blockchain  accounts are credible anonymously. Importantly, zkBID is fully decentralized: all user-related data are generated by users and verified by smart contracts on the blockchain. We implemented zkBID and built a blockchain test network for evaluation purposes. Our tests demonstrate the effectiveness of zkBID and suggest proper ways to configure zkBID system parameters.",
        "keywords": "Web 3.0;Blockchain;Identity;Zero-knowledge Proofs;Linkable Ring Signatures",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Taotao Wang;Zibin Lin;Shengli Zhang;Long Shi;Qing Yang;Boris D\u00fcdder",
        "authorids": "~Taotao_Wang2;~Zibin_Lin2;~Shengli_Zhang3;~Long_Shi3;~Qing_Yang15;~Boris_D\u00fcdder1",
        "gender": "M;M;M;M;M;",
        "homepage": "https://postman511.github.io/cn_index.html;;;https://sites.google.com/site/longshiunsw/;https://q-yang.github.io/;https://forskning.ku.dk/soeg/result/?pure=da%2Fpersons%2F575423",
        "dblp": ";;;;;118/3885.html",
        "google_scholar": "https://scholar.google.com.hk/citations?user=nG7Y7rMAAAAJ;https://scholar.google.com.hk/citations?hl=zh-CN;https://scholar.google.com/citations?hl=zh-CN;6geBWS8AAAAJ;;https://scholar.google.de/citations?user=0ic62YwAAAAJ",
        "orcid": ";0009-0005-9423-3917;;;;0000-0002-0241-7729",
        "linkedin": ";;;;;boris-duedder/",
        "or_profile": "~Taotao_Wang2;~Zibin_Lin2;~Shengli_Zhang3;~Long_Shi3;~Qing_Yang15;~Boris_D\u00fcdder1",
        "aff": "Shenzhen University;Shenzhen University;;Nanjing University of Science and Technology;Shenzhen University;University of Copenhagen",
        "aff_domain": "szu.edu.cn;szu.edu.cn;;njust.edu.cn;szu.edu.cn;diku.dk",
        "position": "Associate Professor;PhD student;;Full Professor;Associate Professor;Associate Professor",
        "bibtex": "@inproceedings{\nwang2025linking,\ntitle={Linking Souls to Humans: Blockchain Accounts with Credible Anonymity for Web 3.0 Decentralized Identity},\nauthor={Taotao Wang and Zibin Lin and Shengli Zhang and Long Shi and Qing Yang and Boris D{\\\"u}dder},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=yXtGrd4Ib7}\n}",
        "github": "",
        "project": "",
        "reviewers": "qKKR;42dx;gCiR;PnpP;9tbR",
        "site": "https://openreview.net/forum?id=yXtGrd4Ib7",
        "pdf_size": 0,
        "novelty": "3;3;3;6;6",
        "technical_quality": "5;4;5;5;6",
        "scope": "4;3;3;4;4",
        "confidence": "3;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.2,
            1.469693845669907
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.39999999999999997
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.6123724356957945
    },
    {
        "id": "yexIJEru0l",
        "title": "NI-GDBA: Non-Intrusive Distributed Backdoor Attack Based on Adaptive Perturbation on Federated Graph Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Federated Graph Learning (FedGL) is an emerging Federated Learning (FL) framework that learns the graph data from various clients to train better Graph Neural Networks(GNNs) model. Owing to concerns regarding the security of such framework, numerous studies have attempted to execute backdoor attacks on FedGL, with a particular focus on distributed backdoor attacks. However, all existing methods posting distributed backdoor attack on FedGL only focus on injecting distributed backdoor triggers into the training data of each malicious client, which will cause model performance degradation on original task and is not always effective when confronted with robust federated learning defense algorithms, leading to low success rate of attack. What's more, the backdoor signals introduced by the malicious clients may be smoothed out by other clean signals from the honest clients, which potentially undermining the performance of the attack.\n\nTo address the above significant shortcomings, we propose a non-intrusive graph distributed backdoor attack(NI-GDBA) that does not require backdoor triggers to be injected in the training data. Our attack trains an adaptive perturbation trigger generator model for each malicious client to learn the natural backdoor from the GNN model downloading from the server with the malicious client's local data. In contrast to traditional distributed backdoor attacks on FedGL via trigger injection in training data, our attack on different datasets such as Molecules and Bioinformatics have higher attack success rate, stronger persistence and stealth, and has no negative impact on the performance of the global GNN model. We also explore the robustness of NI-GDBA under different defense strategies, and based on our extensive experimental studies, we show that our attack method is robust to current federated learning defense methods, thus it is necessary to consider non-intrusive distributed backdoor attacks on FedGL as a novel threat that requires custom defenses. Code is available at an anonymous github repository: https://anonymous.4open.science/r/NI-GDBA-64E5/",
        "keywords": "Federated Graph Learning;Backdoor Attacks",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ken Li;Bin Shi;Jiazhe Wei;Bo Dong",
        "authorids": "~Ken_Li2;~Bin_Shi2;~Jiazhe_Wei1;~Bo_Dong11",
        "gender": "M;M;M;M",
        "homepage": "https://kiyotakali.github.io/;https://gr.xjtu.edu.cn/web/shibin/english-version;https://github.com/xjtu-wjz?tab=repositories;https://bodong-xjtu.github.io/",
        "dblp": ";63/4724.html;;45/5631-1.html",
        "google_scholar": ";https://scholar.google.com/citations?hl=zh-CN;;YGNmpzIAAAAJ",
        "orcid": "0009-0001-3793-2405;0000-0001-8272-9361;;0000-0001-7695-9072",
        "linkedin": ";;;",
        "or_profile": "~Ken_Li2;~Bin_Shi2;~Jiazhe_Wei1;~Bo_Dong11",
        "aff": "Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University;Xi'an Jiaotong University",
        "aff_domain": "xjtu.edu.cn;xjtu.edu.cn;xjtu.edu.cn;xjtu.edu.cn",
        "position": "Undergrad student;Associate Professor;Undergrad student;Researcher",
        "bibtex": "@inproceedings{\nli2025nigdba,\ntitle={{NI}-{GDBA}: Non-Intrusive Distributed Backdoor Attack Based on Adaptive Perturbation on Federated Graph Learning},\nauthor={Ken Li and Bin Shi and Jiazhe Wei and Bo Dong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=yexIJEru0l}\n}",
        "github": "",
        "project": "",
        "reviewers": "ivux;KJkh;rsYM;qYas;eJvd",
        "site": "https://openreview.net/forum?id=yexIJEru0l",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;5;5;4;5",
        "scope": "4;4;3;3;3",
        "confidence": "4;3;3;2;2",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.6,
            0.48989794855663565
        ],
        "scope_avg": [
            3.4,
            0.4898979485566356
        ],
        "confidence_avg": [
            2.8,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.8685990362153791
    },
    {
        "id": "yuzbzzekdB",
        "title": "Privacy-Friendly Cross-Domain Recommendation via Distilling User-irrelevant Information",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Privacy-preserving Cross-Domain Recommendation (CDR) has been extensively studied to address the cold-start problem using auxiliary source domains while simultaneously protecting sensitive information. However, existing privacy-preserving CDR methods rely heavily on transferring sensitive user embeddings or behaviour logs, which leads to adopt privacy methods to distort the data patterns before transferring it to the target domain. The distorted information can compromise overall performance during the knowledge transfer process. To overcome these challenges, our approach differs from existing privacy-preserving methods that focus on safeguarding user-sensitive information. Instead, we concentrate on distilling transferable knowledge from insensitive item embeddings, which we refer to as \\textbf{prototypes}. Specifically, we propose a conditional model inversion mechanism to accurately distill prototypes for individual users. We have designed a new data format and corresponding learning paradigm for distilling transferable prototypes from traditional recommendation models using model inversion. These prototypes facilitate bridging the domain shift between distinct source and target domains in a privacy-friendly manner. Additionally, they enable the identification of top-k users in the target domain to substitute for cold-start users prediction. We conduct extensive experiments across large real-world datasets, and the results substantiate the effectiveness of PFCDR.",
        "keywords": "Cross-Domain Recommendation; Cold-start Problem; Source-free knowledge distillation",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Cheng Wang;Wenchao Xu;Haozhao Wang;Wei Liu;Ruixuan Li",
        "authorids": "~Cheng_Wang13;~Wenchao_Xu1;~Haozhao_Wang1;~Wei_Liu30;~Ruixuan_Li1",
        "gender": ";;M;;M",
        "homepage": "https://scholar.google.com/citations?hl=en&user=9mzD-q0AAAAJ;;https://wanghaozhao.mysxl.cn/;;http://idc.hust.edu.cn/rxli/index.html",
        "dblp": ";;224/4500.html;;60/4429.html",
        "google_scholar": "https://scholar.google.com/citations?hl=en;;https://scholar.google.com.hk/citations?user=yFrOuMEAAAAJ;;https://scholar.google.com/scholar?q=ruixuan+li",
        "orcid": "0000-0002-7181-4939;;0000-0002-7591-5315;;0000-0002-7791-5511",
        "linkedin": ";;;;https://www.linkedin.cn/incareer/in/ruixuan-li-b367319",
        "or_profile": "~Cheng_Wang13;~Wenchao_Xu1;~Haozhao_Wang1;~Wei_Liu30;~Ruixuan_Li1",
        "aff": "Huawei Technologies Ltd.;;Huazhong University of Science and Technology;;Huazhong University of Science and Technology",
        "aff_domain": "huawei.com;;hust.edu.cn;;hust.edu.cn",
        "position": "Researcher;;Assistant Professor;;Full Professor",
        "bibtex": "@inproceedings{\nwang2025privacyfriendly,\ntitle={Privacy-Friendly Cross-Domain Recommendation via Distilling User-irrelevant Information},\nauthor={Cheng Wang and Wenchao Xu and Haozhao Wang and Wei Liu and Ruixuan Li},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=yuzbzzekdB}\n}",
        "github": "",
        "project": "",
        "reviewers": "fVdo;qHT3;MLK8;ezTX;Q2qD",
        "site": "https://openreview.net/forum?id=yuzbzzekdB",
        "pdf_size": 0,
        "novelty": "4;5;5;5;5",
        "technical_quality": "4;5;6;5;5",
        "scope": "3;3;4;4;4",
        "confidence": "3;2;4;4;3",
        "wc_review": "",
        "novelty_avg": [
            4.8,
            0.39999999999999997
        ],
        "technical_quality_avg": [
            5.0,
            0.6324555320336759
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.2,
            0.7483314773547882
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.13363062095621223
    },
    {
        "id": "yvN3PilD1S",
        "title": "Automatic Instruction Data Selection for Large Language Models via Uncertainty-Aware Influence Maximization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent years have witnessed the prevalent integration of Large Language Models (LLMs) in various Web applications, such as search engines and recommender systems. As an emerging technique, instruction tuning aims to align pre-trained LLMs as capable chatbots that excel at following human instructions. Previous research indicates that selecting an appropriate subset of a large instruction dataset can enhance the capabilities of LLMs and reduce training costs. However, existing works tend to overlook external correlations between instruction examples during data selection process, which can introduce potential bias and lead to sub-optimal performance. To bridge this gap, we formalize this problem from graph influence maximization perspective and propose Uncertainty-aware influence Maximization (UniMax), a data selection framework that explicitly incorporates the complex inter-dependencies within instruction data. Specifically, we first define a latent instruction graph, treating each instruction example as a graph node and representing their implicit relations as graph edges. Instead of solely relying on heuristic metrics for graph construction, we develop a self-supervised graph learner to uncover the latent structure beyond surface-level feature correlations. After that, we propose an uncertainty-aware influence function to score each example on the instruction graph, allowing a simple greedy algorithm to select a valuable subset that embodies both high influence and uncertainty with an approximation guarantee. Extensive experiments on public datasets show that the proposed approach can significantly enhance model capabilities, underscoring the importance of exploiting data dependencies in instruction data selection.",
        "keywords": "Large Language Models;Instruction Tuning;Data Selection",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jindong Han;Hao Liu;Jun Fang;Naiqiang Tan;Hui Xiong",
        "authorids": "~Jindong_Han1;~Hao_Liu17;~Jun_Fang5;~Naiqiang_Tan1;~Hui_Xiong1",
        "gender": ";;M;M;M",
        "homepage": "https://hanjindong.github.io/;https://raymondhliu.github.io/;;;https://www.hkust-gz.edu.cn/people/hui-xiong/",
        "dblp": "228/8325;09/3214-26;;271/6535.html;262/1686-1.html",
        "google_scholar": "e9lFam0AAAAJ;;;;cVDF1tkAAAAJ",
        "orcid": "0000-0002-1542-6149;0000-0003-4271-1567;0000-0001-6083-1234;;0000-0001-6016-6465",
        "linkedin": ";;;;",
        "or_profile": "~Jindong_Han1;~Hao_Liu17;~Jun_Fang5;~Naiqiang_Tan1;~Hui_Xiong1",
        "aff": "Shandong University+Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology (Guangzhou);Didi International Business Group;;Hong Kong University of Science and Technology (Guangzhou)",
        "aff_domain": "sdu.edu.cn+ust.hk;hkust-gz.edu.cn;didiglobal.com;;hkust.edu",
        "position": "Associate Professor+PhD student;Assistant Professor;Researcher;;Full Professor",
        "bibtex": "@inproceedings{\nhan2025automatic,\ntitle={Automatic Instruction Data Selection for Large Language Models via Uncertainty-Aware Influence Maximization},\nauthor={Jindong Han and Hao Liu and Jun Fang and Naiqiang Tan and Hui Xiong},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=yvN3PilD1S}\n}",
        "github": "",
        "project": "",
        "reviewers": "NCmK;h6No;CkQH;hBQX;PA7H",
        "site": "https://openreview.net/forum?id=yvN3PilD1S",
        "pdf_size": 0,
        "novelty": "3;4;5;5;5",
        "technical_quality": "4;4;5;6;5",
        "scope": "4;3;3;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.4,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            4.8,
            0.7483314773547882
        ],
        "scope_avg": [
            3.6,
            0.4898979485566356
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    },
    {
        "id": "z13UqeDT39",
        "title": "Disentangled Knowledge Tracing for Alleviating Cognitive Bias",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In the realm of Intelligent Tutoring System (ITS), the accurate assessment of students' knowledge states through Knowledge Tracing (KT) is crucial for personalized learning. However, due to data bias, $i.e.$, the unbalanced distribution of question groups ($e.g.$, concepts), conventional KT models are plagued by cognitive bias, which tends to result in cognitive underload for overperformers and cognitive overload for underperformers. More seriously, this bias is amplified with the exercise recommendations by ITS. After delving into the causal relations in the KT models, we identify the main cause as the confounder effect of students' historical correct rate distribution over question groups on the student representation and prediction score. Towards this end, we propose a Disentangled Knowledge Tracing (DisKT) model, which separately models students' familiar and unfamiliar abilities based on causal effects and eliminates the impact of the confounder in student representation within the model. Additionally, to shield the contradictory psychology ($e.g.$, guessing and mistaking) in the students\u2019 biased data, DisKT introduces a contradiction attention mechanism. Furthermore, DisKT enhances the interpretability of the model predictions by integrating a variant of Item Response Theory. Experimental results on 11 benchmarks and 3 synthesized datasets with different bias strengths demonstrate that DisKT significantly alleviates cognitive bias and outperforms 14 baselines in evaluation accuracy. Our code and datasets are available at https://anonymous.4open.science/r/DisKT.",
        "keywords": "Knowledge Tracing",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yiyun Zhou;Zheqi Lv;Shengyu Zhang;Jingyuan Chen",
        "authorids": "~Yiyun_Zhou1;~Zheqi_Lv1;~Shengyu_Zhang2;~Jingyuan_Chen3",
        "gender": ";;M;F",
        "homepage": ";;https://shengyuzhang.github.io/;https://scholar.google.com/citations?user=o_G2qa0AAAAJ&hl=en",
        "dblp": ";;47/3459-1;",
        "google_scholar": ";;l4Dyt7EAAAAJ;o_G2qa0AAAAJ",
        "orcid": ";;0000-0002-0030-8289;0000-0003-0415-6937",
        "linkedin": ";;;",
        "or_profile": "~Yiyun_Zhou1;~Zheqi_Lv1;~Shengyu_Zhang2;~Jingyuan_Chen3",
        "aff": ";;Zhejiang University;Zhejiang University",
        "aff_domain": ";;zju.edu.cn;zju.edu.cn",
        "position": ";;ZJU100 Young Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nzhou2025disentangled,\ntitle={Disentangled Knowledge Tracing for Alleviating Cognitive Bias},\nauthor={Yiyun Zhou and Zheqi Lv and Shengyu Zhang and Jingyuan Chen},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=z13UqeDT39}\n}",
        "github": "",
        "project": "",
        "reviewers": "8CdA;YrSs;hUFL;Zn3H;wgxe",
        "site": "https://openreview.net/forum?id=z13UqeDT39",
        "pdf_size": 0,
        "novelty": "4;4;5;6;7",
        "technical_quality": "4;4;4;6;7",
        "scope": "3;3;3;2;4",
        "confidence": "3;2;2;2;4",
        "wc_review": "",
        "novelty_avg": [
            5.2,
            1.16619037896906
        ],
        "technical_quality_avg": [
            5.0,
            1.2649110640673518
        ],
        "scope_avg": [
            3.0,
            0.6324555320336759
        ],
        "confidence_avg": [
            2.6,
            0.8
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.5144957554275266
    },
    {
        "id": "zYTBj1KPpA",
        "title": "SAHSD: Enhancing Hate Speech Detection in LLM-Powered Web Applications via Sentiment Analysis and Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "As large language models (LLMs) increasingly power web applications, including social networks, the challenge of moderating hate speech has become a critical concern for the Web. These LLM-powered applications, while offering near-human interaction capabilities, are vulnerable to harmful or biased content due to imperfect training data scraped from the Web. Current hate speech detection methods often struggle with limited annotated data, especially for real-time moderation on these platforms. This paper introduces Sentiment-Aided Hate Speech Detection (SAHSD), a novel approach designed to enhance hate speech detection specifically in LLM-powered web applications. By treating hate speech detection as a few-shot learning task, SAHSD utilizes sentiment analysis to refine pre-trained language models (LM) for improved accuracy in recognizing harmful content. SAHSD first employs publicly available sentiment datasets to train a sentiment analysis model, which is then fine-tuned by merging sentiment prompts with hate speech prompts, enabling efficient and accurate detection even with limited training samples. The effectiveness of SAHSD is demonstrated through experiments on widely used web-sourced datasets like SBIC and HateXplain. SAHSD achieves an exceptional F1-score of 0.99 with only 64 training samples and outperforms advanced techniques such as ToKen, MRP, and HARE, with significant improvements of 33% on SBIC and 95% on HateXplain. SAHSD surpasses GPT-4 in generalization performance across multiple datasets, showing an 8% improvement when trained on equal-sized samples. These results underscore SAHSD's potential to enhance content moderation in LLM-driven web platforms, contributing to a safer, more inclusive and accountable Web ecosystem.",
        "keywords": "Security; Machine Learning; Large Language Model; Hate Speech",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yulong Wang;Hong Li;Ni Wei",
        "authorids": "~Yulong_Wang9;~Hong_Li10;~Ni_Wei1",
        "gender": "M;;",
        "homepage": "https://teacher.bupt.edu.cn/wangyulong1/zh_CN/index.htm;;",
        "dblp": "97/5856-1;;",
        "google_scholar": "vkk1vJ4AAAAJ;;",
        "orcid": "0000-0003-0759-2208;0009-0008-7316-5590;",
        "linkedin": ";;",
        "or_profile": "~Yulong_Wang9;~Hong_Li10;~Ni_Wei1",
        "aff": "Beijing University of Posts and Telecommunications;Guizhou University;",
        "aff_domain": "bupt.edu.cn;gzu.edu.cn;",
        "position": "Associate Professor;Lecturer;",
        "bibtex": "@inproceedings{\nwang2025sahsd,\ntitle={{SAHSD}: Enhancing Hate Speech Detection in {LLM}-Powered Web Applications via Sentiment Analysis and Few-Shot Learning},\nauthor={Yulong Wang and Hong Li and Ni Wei},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=zYTBj1KPpA}\n}",
        "github": "",
        "project": "",
        "reviewers": "ZmtG;PZh2;LbKX;URwZ;jDFK",
        "site": "https://openreview.net/forum?id=zYTBj1KPpA",
        "pdf_size": 0,
        "novelty": "2;4;4;5;5",
        "technical_quality": "4;5;3;5;6",
        "scope": "2;3;4;3;4",
        "confidence": "3;4;4;1;1",
        "wc_review": "",
        "novelty_avg": [
            4.0,
            1.0954451150103321
        ],
        "technical_quality_avg": [
            4.6,
            1.019803902718557
        ],
        "scope_avg": [
            3.2,
            0.7483314773547882
        ],
        "confidence_avg": [
            2.6,
            1.3564659966250536
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.5383819020581656
    },
    {
        "id": "zc1XEMHbeO",
        "title": "Reembedding and Reweighting are Needed for Tail Item Sequential Recommendation",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Large vision models (LVMs) and large language models (LLMs) are becoming cutting-edge for sequential recommendation, given their success in broad applications. Despite their advantages over traditional approaches, these models suffer more significant performance degradation on tail items against conventional ID-based solutions, which are largely overlooked by recent research. In this paper, we substantiate the above challenges as (1) all-in ground-truth, i.e., the standard cross-entropy (CE) loss focuses solely on the target items while treating all non-ground-truth equally, causing insufficient optimization for tail items, and (2) knowledge transfer tax, i.e., the knowledge encapsulated in LLMs and LVMs dominates the optimization process due to insufficient training for tail items. We propose reweighting and reembedding, a simple yet efficient method to address the above challenges. Specifically, we reinitialize tail item embedding via a Gaussian distribution to alleviate knowledge transfer tax; besides, a reweighting function is incorporated in the CE loss, which adaptively adjusts item weights during training to encourage the model to pay more attention to tail items rather than exclusively optimizing for ground-truth. Overall, our method enables a more nuanced optimization and is mathematically comparable to the direct preference optimization (DPO) in LLMs. Our extensive experiments on three public datasets show our method outperforms fourteen baselines in overall performance and improves the performance on tail items by a large margin. Our code is available at https://anonymous.4open.science/r/R2Rec-0AE0.",
        "keywords": "sequential recommendation;tail item;language models and vision models;reweighting and reembedding",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Zihao Li;Yakun Chen;Tong Zhang;Xianzhi Wang",
        "authorids": "~Zihao_Li16;~Yakun_Chen1;~Tong_Zhang29;~Xianzhi_Wang1",
        "gender": ";;F;M",
        "homepage": ";;;https://profiles.uts.edu.au/XIANZHI.WANG",
        "dblp": ";;;51/8330",
        "google_scholar": ";aC_XhAwAAAAJ;https://scholar.google.com/citations?hl=en;https://scholar.google.com.au/citations?user=Xej6piMAAAAJ",
        "orcid": ";;0000-0001-8043-237X;0000-0001-9582-3445",
        "linkedin": ";;;xianzhiwang5386/",
        "or_profile": "~Zihao_Li16;~Yakun_Chen1;~Tong_Zhang29;~Xianzhi_Wang1",
        "aff": ";The Education University of Hong Kong+University of Technology Sydney;University of Technology Sydney (UTS);University of Technology Sydney",
        "aff_domain": ";eduhk.hk+uts.edu.au;uts.eud.au;uts.edu.au",
        "position": ";Postdoc+PhD student;PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nli2025reembedding,\ntitle={Reembedding and Reweighting are Needed for Tail Item Sequential Recommendation},\nauthor={Zihao Li and Yakun Chen and Tong Zhang and Xianzhi Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=zc1XEMHbeO}\n}",
        "github": "",
        "project": "",
        "reviewers": "4Dcs;WLLT;pgQT;fJub;zmyV",
        "site": "https://openreview.net/forum?id=zc1XEMHbeO",
        "pdf_size": 0,
        "novelty": "2;3;4;4;5",
        "technical_quality": "2;3;4;3;4",
        "scope": "3;4;4;4;4",
        "confidence": "4;3;3;4;3",
        "wc_review": "",
        "novelty_avg": [
            3.6,
            1.019803902718557
        ],
        "technical_quality_avg": [
            3.2,
            0.7483314773547882
        ],
        "scope_avg": [
            3.8,
            0.39999999999999997
        ],
        "confidence_avg": [
            3.4,
            0.4898979485566356
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": -0.48038446141526137
    },
    {
        "id": "zefCoSncYR",
        "title": "Str-GCL: Structural Commonsense Driven Graph Contrastive Learning",
        "track": "main",
        "status": "Oral",
        "tldr": "",
        "abstract": "Graph Contrastive Learning (GCL) is a widely adopted approach in unsupervised representation learning, utilizing representational constraints to derive effective embeddings. However, current GCL methods primarily focus on capturing implicit semantic relationships, often overlooking the structural commonsense embedded within the graph\u2019s structure and attributes. This structural commonsense is crucial for effective representation learning. Identifying and integrating such structural commonsense in GCL poses a significant challenge. To address this gap, we propose a novel framework called Structural Commonsense Unveiling in Graph Contrastive Learning (Str-GCL). Str-GCL leverages first-order symbolic logic rules to represent structural commonsense and explicitly integrates these rules into the GCL framework. Specifically, we introduce structural commonsense from both topological and attribute rule perspectives, processing these rules independently without modifying the original graph. Additionally, we design a representation alignment mechanism that guides the encoder to effectively capture this structural commonsense. To the best of our knowledge, this is the first attempt to directly incorporate structural commonsense into GCL in a rule-based manner. Extensive experiments demonstrate that Str-GCL significantly outperforms existing GCL methods, providing a new perspective on leveraging structural commonsense in graph representation learning.",
        "keywords": "Graph Neural Networks;Self-Supervised Learning on Graphs;Graph Contrastive Learning;Structural Commonsense",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Dongxiao He;Yongqi Huang;Jitao Zhao;Xiaobao Wang;Zhen Wang",
        "authorids": "~Dongxiao_He1;~Yongqi_Huang2;~Jitao_Zhao2;~Xiaobao_Wang1;~Zhen_Wang11",
        "gender": "F;M;;M;M",
        "homepage": "http://cic.tju.edu.cn/faculty/hedongxiao/index.htm;;;https://wangxbtju.github.io;http://iopen.nwpu.edu.cn/info/1015/1351.htm?ivk_sa=1024320u",
        "dblp": "48/8875;44/7839;;122/4465;",
        "google_scholar": "JyqwTr4AAAAJ;sNt-BUYAAAAJ;;fMAvbmYAAAAJ;https://scholar.google.co.uk/citations?hl=zh-CN",
        "orcid": ";0009-0005-0466-3404;;;",
        "linkedin": ";;;;",
        "or_profile": "~Dongxiao_He1;~Yongqi_Huang2;~Jitao_Zhao2;~Xiaobao_Wang1;~Zhen_Wang11",
        "aff": "Tianjin University;Tianjin University;;Tianjin University;",
        "aff_domain": "tju.edu.cn;tju.edu.cn;;tju.edu.cn;",
        "position": "Full Professor;MS student;;Associate Professor;",
        "bibtex": "@inproceedings{\nhe2025strgcl,\ntitle={Str-{GCL}: Structural Commonsense Driven Graph Contrastive Learning},\nauthor={Dongxiao He and Yongqi Huang and Jitao Zhao and Xiaobao Wang and Zhen Wang},\nbooktitle={THE WEB CONFERENCE 2025},\nyear={2025},\nurl={https://openreview.net/forum?id=zefCoSncYR}\n}",
        "github": "",
        "project": "",
        "reviewers": "T8ak;Qb1w;TcbM;rGk2;JmKM",
        "site": "https://openreview.net/forum?id=zefCoSncYR",
        "pdf_size": 0,
        "novelty": "3;5;5;5;5",
        "technical_quality": "4;6;6;5;5",
        "scope": "4;4;4;4;4",
        "confidence": "3;3;3;3;3",
        "wc_review": "",
        "novelty_avg": [
            4.6,
            0.7999999999999999
        ],
        "technical_quality_avg": [
            5.2,
            0.7483314773547882
        ],
        "scope_avg": [
            4.0,
            0.0
        ],
        "confidence_avg": [
            3.0,
            0.0
        ],
        "replies_avg": [
            5,
            0
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "corr_novelty_confidence": 0.0
    }
]