[
    {
        "id": "2XAAdvSlP2",
        "title": "Is Transductive Learning Equivalent to PAC Learning?",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Much of learning theory is concerned with the design and analysis of probably approximately correct (PAC) learners. The closely related transductive model of learning has recently seen more scrutiny, with its learners often used as precursors to PAC learners. Our goal in this work is to understand and quantify the exact relationship between these two models. \n\nFirst, we observe that modest extensions of existing results show the models to be essentially equivalent for realizable learning for most natural loss functions, up to low order terms in the error and sample complexity. The situation for agnostic learning appears less straightforward, with sample complexities potentially separated by a $\\frac{1}{\\epsilon}$ factor. This is therefore where our main contributions lie. Our results are two-fold: \n\n1. For agnostic learning with bounded losses (including, for example, multiclass classification), we show that PAC learning reduces to transductive learning at the cost of low-order terms in the error and sample complexity. This is via an adaptation of the reduction of Aden-Ali et al. (2023a) to the agnostic setting. \n\n2. For agnostic binary classification, we show the converse: transductive learning is essentially no more difficult than PAC learning. Together with our first result this implies that the PAC and transductive models are essentially equivalent for agnostic binary classification. This is our most technical result, and involves two key steps: (a) A symmetrization argument on the agnostic one-inclusion graph (OIG) of Asilis et al. (2024) to derive the worst-case agnostic transductive instance, and (b) expressing the error of the agnostic OIG algorithm for this instance in terms of the empirical Rademacher complexity of the class. \n\nWe leave as an intriguing open question whether our second result can be extended beyond binary classification to show the transductive and PAC models equivalent more broadly.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shaddin Dughmi;Yusuf Hakan Kalayci;Grayson York",
        "authorids": "~Shaddin_Dughmi1;~Yusuf_Hakan_Kalayci1;~Grayson_York1",
        "gender": ";M;",
        "homepage": ";https://yhkalayci.github.io/;https://agraysonyork.com/",
        "dblp": ";;",
        "google_scholar": ";ae5Sh9EAAAAJ;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Shaddin_Dughmi1;~Yusuf_Hakan_Kalayci1;~Grayson_York1",
        "aff": ";University of Southern California;University of Southern California",
        "aff_domain": ";usc.edu;usc.edu",
        "position": ";PhD student;PhD student",
        "bibtex": "@inproceedings{\ndughmi2025is,\ntitle={Is Transductive Learning Equivalent to {PAC} Learning?},\nauthor={Shaddin Dughmi and Yusuf Hakan Kalayci and Grayson York},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=2XAAdvSlP2}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_NsUM;KgJr;FtZN;EXSR",
        "site": "https://openreview.net/forum?id=2XAAdvSlP2",
        "pdf_size": 0,
        "rating": "0;0;7;7;7",
        "confidence": "0;4;5;3;5",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.429285639896449
        ],
        "confidence_avg": [
            3.4,
            1.8547236990991407
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            5,
            0
        ],
        "corr_rating_confidence": 0.6163156344279368
    },
    {
        "id": "7Nal6i5lje",
        "title": "Information-Theoretic Guarantees for Recovering Low-Rank Tensors from Symmetric Rank-One Measurements",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We investigate the sample complexity of recovering tensors with low symmetric rank from symmetric rank-one measurements, a setting particularly motivated by the study of higher-order interactions in statistics and the analysis of two-layer polynomial neural networks. Using a covering number argument, we analyze the performance of the symmetric rank minimization program and establish near-optimal sample complexity bounds when the underlying distribution is log-concave. Our measurement model involves random symmetric rank-one tensors, leading to involved probability calculations. To address these challenges, we employ the Carbery-Wright inequality, a powerful tool for studying anti-concentration properties of random polynomials, and leverage orthogonal polynomial expansions. Additionally, we provide a sample complexity lower bound via Fano\u2019s inequality, and discuss broader implications of our results for two-layer polynomial networks.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eren C. Kizildag",
        "authorids": "~Eren_C._Kizildag2",
        "gender": "M",
        "homepage": "https://www.eren-kizildag.com/",
        "dblp": "",
        "google_scholar": "https://scholar.google.com/citations?hl=en",
        "orcid": "",
        "linkedin": "",
        "or_profile": "~Eren_C._Kizildag2",
        "aff": "University of Illinois, Urbana Champaign",
        "aff_domain": "uiuc.edu",
        "position": "Assistant Professor",
        "bibtex": "@inproceedings{\nkizildag2025sample,\ntitle={Sample Complexity of Recovering Low Rank Tensors from Symmetric Rank-One Measurements},\nauthor={Eren C. Kizildag},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=7Nal6i5lje}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_oKcm;Hw9h;KoE3;QKj5",
        "site": "https://openreview.net/forum?id=7Nal6i5lje",
        "pdf_size": 0,
        "rating": "0;0;5;6;7",
        "confidence": "0;4;3;3;4",
        "wc_review": "",
        "rating_avg": [
            3.6,
            3.006659275674582
        ],
        "confidence_avg": [
            2.8,
            1.469693845669907
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            11,
            0
        ],
        "corr_rating_confidence": 0.47976081115765207
    },
    {
        "id": "86jwIpf9FZ",
        "title": "Effective Littlestone dimension",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Delle Rose et al.~(COLT'23)  introduced an effective version of the Vapnik-Chervonenkis dimension, and showed that it characterizes improper PAC learning with total computable learners. In this paper, we introduce and study a similar effectivization of the notion of Littlestone dimension.  Finite effective Littlestone dimension is a necessary condition for computable online learning but is not a sufficient one---which we already establish for classes of the effective Littlestone dimension 2. However, the effective Littlestone dimension equals the optimal mistake bound for computable learners in two special cases: a) for classes of Littlestone dimension 1 and b) when the learner receives as additional information an upper bound on the numbers to be guessed. Interestingly, a finite effective Littlestone dimension also guarantees that the class consists only of computable functions.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Valentino Delle Rose;Alexander Kozachinskiy;Tomasz Steifer",
        "authorids": "~Valentino_Delle_Rose1;~Alexander_Kozachinskiy1;~Tomasz_Steifer1",
        "gender": "M;M;M",
        "homepage": ";https://kozlachinskiy.github.io/;http://bluebox.ippt.pan.pl/~tsteifer/",
        "dblp": "276/1878;164/0711;240/3151.html",
        "google_scholar": "qXGXKRwAAAAJ;gAKBJ7kAAAAJ;https://scholar.google.pl/citations?user=Sjw4GpgAAAAJ",
        "orcid": "0000-0002-7701-0026;0000-0002-9956-9023;0000-0003-0753-1042",
        "linkedin": ";;",
        "or_profile": "~Valentino_Delle_Rose1;~Alexander_Kozachinskiy1;~Tomasz_Steifer1",
        "aff": "University of Roma \"La Sapienza\";Pontificia Universidad Catolica de Chile;Pontificia Universidad Catolica de Chile",
        "aff_domain": "uniroma1.it;puc.cl;uc.cl",
        "position": "Postdoc;Postdoc;Postdoc",
        "bibtex": "@inproceedings{\nrose2025effective,\ntitle={Effective Littlestone dimension},\nauthor={Valentino Delle Rose and Alexander Kozachinskiy and Tomasz Steifer},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=86jwIpf9FZ}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_jFai;foY3;q79b;be9W",
        "site": "https://openreview.net/forum?id=86jwIpf9FZ",
        "pdf_size": 0,
        "rating": "0;0;7;7;7",
        "confidence": "0;4;4;5;3",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.429285639896449
        ],
        "confidence_avg": [
            3.2,
            1.7204650534085255
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": 0.5694947974514993
    },
    {
        "id": "8dclfIuMJ1",
        "title": "Full Swap Regret and Discretized Calibration",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the problem of minimizing swap regret in structured normal-form games. Players have a very large (potentially infinite) number of pure actions, but each action has an embedding into $d$-dimensional space and payoffs are given by bilinear functions of these embeddings. We provide an efficient learning algorithm for this setting that incurs at most $\\tilde{O}(T^{(d+1)/(d+3)})$ swap regret after $T$ rounds.\n\nTo achieve this, we introduce a new online learning problem we call \\emph{full swap regret minimization}. In this problem, a learner repeatedly takes a (randomized) action in a bounded convex $d$-dimensional action set $\\mathcal{K}$ and then receives a loss from the adversary, with the goal of minimizing their regret with respect to the \\emph{worst-case} swap function mapping $\\mathcal{K}$ to $\\mathcal{K}$. For varied assumptions about the convexity and smoothness of the loss functions, we design algorithms with full swap regret bounds ranging from $O(T^{d/(d+2)})$ to $O(T^{(d+1)/(d+2)})$.\n\nFinally, we apply these tools to the problem of online forecasting to minimize calibration error, showing that several notions of calibration can be viewed as specific instances of full swap regret. In particular, we design efficient algorithms for online forecasting that guarantee at most $O(T^{1/3})$ $\\ell_2$-calibration error and $O(\\max(\\sqrt{\\epsilon T}, T^{1/3}))$ \\emph{discretized-calibration} error (when the forecaster is restricted to predicting multiples of $\\epsilon$).",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Maxwell Fishelson;Robert Kleinberg;Princewill Okoroafor;Renato Paes Leme;Jon Schneider;Yifeng Teng",
        "authorids": "~Maxwell_Fishelson1;~Robert_Kleinberg1;~Princewill_Okoroafor1;~Renato_Paes_Leme1;~Jon_Schneider1;~Yifeng_Teng1",
        "gender": "M;M;;;M;M",
        "homepage": "http://maxkfish.com;http://www.cs.cornell.edu/~rdk/;https://pokoroafor.github.io/;;https://jschnei.github.io;http://pages.cs.wisc.edu/~yifengt/",
        "dblp": ";k/RDKleinberg;;https://dblp.org/pers/hd/l/Leme:Renato_Paes;146/0503;154/6415",
        "google_scholar": ";https://scholar.google.com.tw/citations?user=zkvW8FQAAAAJ;;;Jc97EyAAAAAJ;CO1j3SMAAAAJ",
        "orcid": ";0000-0002-8306-3407;;;;",
        "linkedin": ";;;;;",
        "or_profile": "~Maxwell_Fishelson1;~Robert_Kleinberg1;~Princewill_Okoroafor1;~Renato_Paes_Leme1;~Jon_Schneider1;~Yifeng_Teng1",
        "aff": "Massachusetts Institute of Technology;Google+Cornell University;Department of Computer Science, Cornell University;Google;Google;Google Research",
        "aff_domain": "mit.edu;google.com+cornell.edu;cs.cornell.edu;google.com;google.com;google.com",
        "position": "PhD student;Researcher+Full Professor;PhD student;Researcher;Researcher;Research Scientist",
        "bibtex": "@inproceedings{\nfishelson2025full,\ntitle={Full Swap Regret and Discretized Calibration},\nauthor={Maxwell Fishelson and Robert Kleinberg and Princewill Okoroafor and Renato Paes Leme and Jon Schneider and Yifeng Teng},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=8dclfIuMJ1}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Area_Chair_MV4D;yEjC;66RW;ejhz",
        "site": "https://openreview.net/forum?id=8dclfIuMJ1",
        "pdf_size": 0,
        "rating": "0;0;0;6;7;8",
        "confidence": "0;0;5;3;3;4",
        "wc_review": "",
        "rating_avg": [
            3.5,
            3.547299442298794
        ],
        "confidence_avg": [
            2.5,
            1.8929694486000912
        ],
        "authors#_avg": [
            6,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            6,
            0
        ],
        "corr_rating_confidence": 0.4591758331083698
    },
    {
        "id": "8hTHFXxMMd",
        "title": "Understanding Aggregations of Proper Learners in Multiclass Classification",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Multiclass learnability is known to exhibit a properness barrier: there are learnable classes which cannot be learned by any proper learner. Binary classification faces no such barrier for learnability, but a similar one for $\\textit{optimal}$ learning, which can in general only be achieved by improper learners. Fortunately, recent advances in binary classification have demonstrated that this requirement can be satisfied using aggregations of proper learners, some of which are strikingly simple. This raises a natural question: to what extent can simple aggregations of proper learners overcome the properness barrier in multiclass classification? \n\nWe give a positive answer to this question for classes which have finite Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners of Hanneke, Larsen, and Aden-Ali et al.\\ (appropriately generalized to the multiclass setting) achieve sample complexity $O\\left( \\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$. This forms a strict improvement upon the sample complexity of ERM. We complement this with a lower bound demonstrating that for certain classes of Graph dimension $d_G$, majorities of ERM learners require $\\Omega \\left( \\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples. Furthermore, we show that a single ERM requires $\\Omega \\left(\\frac{d_G \\ln(1 / \\epsilon) + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples on such classes, improving upon the lower bound of Daniely et al. (2012) by a factor of $\\ln(1 / \\epsilon)$. For multiclass learning in full generality i.e., for classes of finite DS dimension but possibly infinite Graph dimension we give a strong refutation to these learning strategies, by exhibiting a learnable class which cannot be learned to constant error by any aggregation of a finite number of proper learners.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Julian Asilis;Mikael M\u00f8ller H\u00f8gsgaard;Grigoris Velegkas",
        "authorids": "~Julian_Asilis1;~Mikael_M\u00f8ller_H\u00f8gsgaard1;~Grigoris_Velegkas1",
        "gender": "M;M;M",
        "homepage": "https://jasilis.com/;https://pure.au.dk/portal/da/persons/mikael-moeller-hoegsgaard(3b07133a-329d-4585-a864-d37c7cb9056b).html;",
        "dblp": "307/5139;295/8599;254/1885",
        "google_scholar": "Cu3RV2UAAAAJ;;Ty1kgP0AAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Julian_Asilis1;~Mikael_M\u00f8ller_H\u00f8gsgaard1;~Grigoris_Velegkas1",
        "aff": "University of Southern California;Aarhus University;Yale University",
        "aff_domain": "usc.edu;cs.au.dk;yale.edu",
        "position": "PhD student;PhD student;PhD student",
        "bibtex": "@inproceedings{\nasilis2025understanding,\ntitle={Understanding Aggregations of Proper Learners in Multiclass Classification},\nauthor={Julian Asilis and Mikael M{\\o}ller H{\\o}gsgaard and Grigoris Velegkas},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=8hTHFXxMMd}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_kaM5;W4YY;bM9f;VuFr",
        "site": "https://openreview.net/forum?id=8hTHFXxMMd",
        "pdf_size": 0,
        "rating": "0;7;7;8",
        "confidence": "5;4;3;3",
        "wc_review": "",
        "rating_avg": [
            5.5,
            3.2015621187164243
        ],
        "confidence_avg": [
            3.75,
            0.82915619758885
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": -0.8946750577612211
    },
    {
        "id": "AsPOqBoQNC",
        "title": "Computationally efficient reductions between some statistical models",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the problem of approximately transforming a sample from a source statistical model to a sample from a target statistical model without knowing the parameters of the source model, and construct several computationally efficient such reductions between canonical statistical experiments. In particular, we provide computationally efficient procedures that approximately reduce uniform, Erlang, and Laplace location models to general target families. We illustrate our methodology by establishing nonasymptotic reductions between some canonical high-dimensional problems, spanning mixtures of experts, phase retrieval, and signal denoising. Notably, the reductions are structure-preserving and can accommodate missing data. We also point to a possible application in transforming one differentially private mechanism to another.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "MENGQI LOU;Guy Bresler;Ashwin Pananjady",
        "authorids": "~MENGQI_LOU1;~Guy_Bresler1;~Ashwin_Pananjady1",
        "gender": "M;M;M",
        "homepage": ";http://www.mit.edu/~gbresler/;https://sites.gatech.edu/ashwin-pananjady/",
        "dblp": ";71/3436;132/9037",
        "google_scholar": "uOEl6ToAAAAJ;;kAOvHSoAAAAJ",
        "orcid": ";;0000-0003-0824-9815",
        "linkedin": ";;",
        "or_profile": "~MENGQI_LOU1;~Guy_Bresler1;~Ashwin_Pananjady1",
        "aff": "Georgia Institute of Technology;Massachusetts Institute of Technology;Georgia Institute of Technology",
        "aff_domain": "gatech.edu;mit.edu;gatech.edu",
        "position": "PhD student;Associate Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nlou2025computationally,\ntitle={Computationally efficient reductions between some statistical models},\nauthor={MENGQI LOU and Guy Bresler and Ashwin Pananjady},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=AsPOqBoQNC}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Authors;Area_Chair_NydD;e8Br;DQo7;DPEr",
        "site": "https://openreview.net/forum?id=AsPOqBoQNC",
        "pdf_size": 0,
        "rating": "0;0;0;0;6;7;9",
        "confidence": "0;0;0;5;2;4;4",
        "wc_review": "",
        "rating_avg": [
            3.142857142857143,
            3.719776161797582
        ],
        "confidence_avg": [
            2.142857142857143,
            2.030381486221699
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            15,
            0
        ],
        "corr_rating_confidence": 0.54583431849311
    },
    {
        "id": "CL5faSlqaN",
        "title": "Efficient PAC Learning of Halfspaces with Constant Malicious Noise Rate",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Understanding noise tolerance of machine learning algorithms is a central quest in learning theory. In this work, we study the problem of computationally efficient PAC learning of halfspaces in the presence of malicious noise, where an adversary can corrupt both instances and labels of training samples. The best-known noise tolerance either depends on a target error rate under distributional assumptions or on a margin parameter under large-margin conditions. In this work, we show that when both types of conditions are satisfied, it is possible to achieve constant noise tolerance by minimizing a reweighted hinge loss. Our key ingredients include: 1) an efficient algorithm that finds weights to control the gradient deterioration from corrupted samples, and 2) a new analysis on the robustness of the hinge loss equipped with such weights.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jie Shen",
        "authorids": "~Jie_Shen6",
        "gender": "",
        "homepage": "",
        "dblp": "32/1203-5",
        "google_scholar": "Em5N8u0AAAAJ",
        "orcid": "",
        "linkedin": "",
        "or_profile": "~Jie_Shen6",
        "aff": "Stevens Institute of Technology",
        "aff_domain": "stevens.edu",
        "position": "Assistant Professor",
        "bibtex": "@inproceedings{\nshen2025efficient,\ntitle={Efficient {PAC} Learning of Halfspaces with Constant Malicious Noise Rate},\nauthor={Jie Shen},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=CL5faSlqaN}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Authors;Area_Chair_eazf;thhX;dBzf;8Gww",
        "site": "https://openreview.net/forum?id=CL5faSlqaN",
        "pdf_size": 0,
        "rating": "0;0;0;0;6;6;8",
        "confidence": "0;0;0;5;4;3;4",
        "wc_review": "",
        "rating_avg": [
            2.857142857142857,
            3.356382892705923
        ],
        "confidence_avg": [
            2.2857142857142856,
            2.050385727772475
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.5871675433248582
    },
    {
        "id": "EHMcSd60XP",
        "title": "Clustering with bandit feedback: breaking down the computation/information gap",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We investigate the Clustering with Bandit feedback Problem (CBP). A learner interacts with an $N$-armed stochastic bandit with $d$-dimensional subGaussian feedback. There exists a hidden partition of the arms into $K$ groups, such that arms within the same group, share the same mean vector. The learner's task is to uncover this hidden partition with the smallest budget - i.e. the least number of observation - and with a probability of error smaller than a prescribed constant $\\delta$. In this paper, (i) we derive a non asymptotic lower bound for the budget, and (ii) we introduce the computationally efficient ACB algorithm, whose budget  matches the lower bound in most regimes. \nWe improve on the performance of a uniform sampling strategy. Importantly, contrary to the batch setting, we establish that there is no computation-information gap in the bandit setting.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Victor Thuot;Alexandra Carpentier;Christophe Giraud;Nicolas Verzelen",
        "authorids": "~Victor_Thuot1;~Alexandra_Carpentier2;~Christophe_Giraud1;~Nicolas_Verzelen1",
        "gender": ";F;;",
        "homepage": ";https://sites.google.com/site/alexandracarpentierresearch/?pli=1;https://www.imo.universite-paris-saclay.fr/~giraud/;https://verzelen.montpellier.inrae.fr/",
        "dblp": ";;15/3175-2;40/1671.html",
        "google_scholar": ";;gF-ziCAAAAAJ;",
        "orcid": ";;0009-0004-1836-5742;",
        "linkedin": ";;;",
        "or_profile": "~Victor_Thuot1;~Alexandra_Carpentier2;~Christophe_Giraud1;~Nicolas_Verzelen1",
        "aff": ";Universit\u00e4t Potsdam;Universit\u00e9 Paris Saclay;INRAE",
        "aff_domain": ";uni-potsdam.de;universite-paris-saclay.fr;inrae.fr",
        "position": ";Full Professor;Full Professor;Associate Professor",
        "bibtex": "@inproceedings{\nvictor2025clustering,\ntitle={Clustering with bandit feedback: breaking down the computation/information gap},\nauthor={Thuot Victor and Alexandra Carpentier and Christophe Giraud and Nicolas Verzelen},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=EHMcSd60XP}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Area_Chair_mE56;q6yb;gC9r;quSZ",
        "site": "https://openreview.net/forum?id=EHMcSd60XP",
        "pdf_size": 0,
        "rating": "0;0;0;6;6;7",
        "confidence": "0;0;5;3;2;3",
        "wc_review": "",
        "rating_avg": [
            3.1666666666666665,
            3.1841621957571333
        ],
        "confidence_avg": [
            2.1666666666666665,
            1.771690968789108
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.29051352612517073
    },
    {
        "id": "Fc3j44T06e",
        "title": "A Unified Theory of Supervised Online Learnability",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the online learnability of hypothesis classes with respect to arbitrary, but bounded loss functions. No characterization of online learnability is known at this level of generality. In this paper, we close this gap by showing that existing techniques can be used to characterize any online learning problem with a bounded loss function. Along the way, we give a new scale-sensitive combinatorial dimension, named the Sequential Minimax dimension, that generalizes all existing dimensions in online learning theory and provides upper and lower bounds on the minimax value.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Vinod Raman;Unique Subedi;Ambuj Tewari",
        "authorids": "~Vinod_Raman1;~Unique_Subedi2;~Ambuj_Tewari1",
        "gender": "M;;M",
        "homepage": "https://vinodkraman.github.io;;https://www.ambujtewari.com",
        "dblp": "126/5382;;24/567",
        "google_scholar": "Wn5QzOgAAAAJ;;ttbl4FsAAAAJ",
        "orcid": ";;0000-0001-6969-7844",
        "linkedin": ";;",
        "or_profile": "~Vinod_Raman1;~Unique_Subedi2;~Ambuj_Tewari1",
        "aff": "University of Michigan - Ann Arbor;;University of Michigan - Ann Arbor",
        "aff_domain": "umich.edu;;umich.edu",
        "position": "PhD student;;Full Professor",
        "bibtex": "@inproceedings{\nraman2025a,\ntitle={A Unified Theory of Supervised Online Learnability},\nauthor={Vinod Raman and Unique Subedi and Ambuj Tewari},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=Fc3j44T06e}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_cS2c;Area_Chair_cS2c;3Stt;UcuN;MnWQ",
        "site": "https://openreview.net/forum?id=Fc3j44T06e",
        "pdf_size": 0,
        "rating": "0;0;6;7;9",
        "confidence": "0;4;4;3;4",
        "wc_review": "",
        "rating_avg": [
            4.4,
            3.7202150475476548
        ],
        "confidence_avg": [
            3.0,
            1.5491933384829668
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            11,
            0
        ],
        "corr_rating_confidence": 0.5205321865412682
    },
    {
        "id": "FsI3wb6lG0",
        "title": "Generalization bounds for mixing processes via delayed online-to-PAC conversions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the generalization error of statistical learning algorithms in a non i.i.d. setting, where the training data is sampled from a stationary mixing process. We develop an analytic framework for this scenario based on a reduction to online learning with delayed feedback. In particular, we show that the existence of an online learning algorithm with bounded regret (against a fixed statistical learning algorithm in a specially constructed game of online learning with delayed feedback) implies low generalization error of said statistical learning method even if the data sequence is sampled from a mixing time series. The rates demonstrate a trade-off between the amount of delay in the online learning game and the degree of dependence between consecutive data points, with near-optimal rates recovered in a number of well-studied settings when the delay is tuned appropriately as a function of the mixing time of the process.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Baptiste Ab\u00e9l\u00e8s;Eugenio Clerico;Gergely Neu",
        "authorids": "~Baptiste_Ab\u00e9l\u00e8s1;~Eugenio_Clerico1;~Gergely_Neu1",
        "gender": "M;M;M",
        "homepage": ";https://github.com/eclerico;http://cs.bme.hu/~gergo",
        "dblp": ";;83/7606",
        "google_scholar": "PRca6iwAAAAJ;;https://scholar.google.ch/citations?user=uz27G84AAAAJ",
        "orcid": ";;",
        "linkedin": "https://www.linkedin.com/feed/;;",
        "or_profile": "~Baptiste_Ab\u00e9l\u00e8s1;~Eugenio_Clerico1;~Gergely_Neu1",
        "aff": "Universitat Pompeu Fabra;Universitat Pompeu Fabra;Universitat Pompeu Fabra",
        "aff_domain": "upf.edu;upf.edu;upf.edu",
        "position": "PhD student;Postdoc;Assistant Professor",
        "bibtex": "@inproceedings{\nabeles2025generalization,\ntitle={Generalization bounds for mixing processes via delayed online-to-{PAC} conversions},\nauthor={Baptiste Ab{\\'e}l{\\`e}s and Eugenio Clerico and Gergely Neu},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=FsI3wb6lG0}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_dr3u;ocxV;cL1W;rtYW",
        "site": "https://openreview.net/forum?id=FsI3wb6lG0",
        "pdf_size": 0,
        "rating": "0;0;7;7;7",
        "confidence": "0;4;3;4;4",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.429285639896449
        ],
        "confidence_avg": [
            3.0,
            1.5491933384829668
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            12,
            0
        ],
        "corr_rating_confidence": 0.5270462766947301
    },
    {
        "id": "GSgcnyQzpz",
        "title": "How rotation invariant algorithms are fooled by noise on sparse targets",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "It is well known that rotation invariant algorithms are sub-optimal for learning sparse linear problems,\nwhen the number of examples is below the input dimension. This includes any gradient descent\ntrained neural net with a fully-connected input layer initialized with a rotationally symmetric\ndistribution. The simplest sparse problem is learning a single feature out of d features. In that case\nthe classification error or regression loss of rotation invariant algorithms grows with 1\u2212n/d, where n\nis the number of examples seen. These lower bounds become vacuous when the number of examples\nn reaches the dimension d. After d examples, the gradient space has full rank and any weight vector\ncan be expressed, including the unit vector that determines the target feature.\nIn this work, we show that when noise is added to this sparse linear problem, rotation invariant\nalgorithms are still sub-optimal after seeing d or more examples. We prove this via a lower bound\nfor the Bayes optimal algorithm on a rotationally symmetrized problem. We then prove much\nlower upper bounds on the same problem for a large variety of algorithms that are non-invariant by\nrotations.\nFinally, we analyze the gradient flow trajectories of many standard optimization algorithms\n(such as AdaGrad) on the same noisy feature learning problem, and show how they veer away from\nthe noisy sparse targets. We then contrast them with a group of non-rotation invariant algorithms\nthat veer towards the sparse targets.\nWe believe that the lower bounds method and trajectory categorization will be crucial for\nanalyzing other families of algorithms with different classes of invariances.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Manfred K Warmuth;Wojciech Kotlowski;Matt Jones;Ehsan Amid",
        "authorids": "~Manfred_K_Warmuth1;~Wojciech_Kotlowski1;~Matt_Jones1;~Ehsan_Amid1",
        "gender": "M;M;M;M",
        "homepage": "https://mwarmuth.bitbucket.io/;https://www.cs.put.poznan.pl/wkotlowski/;http://Matt.Colorado.edu;https://sites.google.com/corp/view/eamid/",
        "dblp": "w/ManfredKWarmuth.html;63/4977;;142/5754",
        "google_scholar": "LR6kjO4AAAAJ;-75xQzMAAAAJ;Q7FDrMIAAAAJ;https://scholar.google.fi/citations?user=F6omR3gAAAAJ",
        "orcid": ";;;",
        "linkedin": ";;;ehsan-amid-63aba754",
        "or_profile": "~Manfred_K_Warmuth1;~Wojciech_Kotlowski1;~Matt_Jones1;~Ehsan_Amid1",
        "aff": "Google Research;Poznan University of Technology;University of Colorado Boulder;Google DeepMind",
        "aff_domain": "google.com;put.poznan.pl;colorado.edu;google.com",
        "position": "Principal Researcher;Associate Professor;Full Professor;Research Scientist",
        "bibtex": "@inproceedings{\nwarmuth2025how,\ntitle={How rotation invariant algorithms are fooled by noise on sparse targets},\nauthor={Manfred K Warmuth and Wojciech Kotlowski and Matt Jones and Ehsan Amid},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=GSgcnyQzpz}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_PL1C;U8cN;1Wvk;S25Y",
        "site": "https://openreview.net/forum?id=GSgcnyQzpz",
        "pdf_size": 0,
        "rating": "0;0;5;6;7",
        "confidence": "0;5;3;3;3",
        "wc_review": "",
        "rating_avg": [
            3.6,
            3.006659275674582
        ],
        "confidence_avg": [
            2.8,
            1.6
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.14966777367849135
    },
    {
        "id": "JABal85PJe",
        "title": "For Universal Multiclass Online Learning, Bandit Feedback and Full Supervision are Equivalent",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the problem of multiclass online learning under $\\textit{bandit feedback}$ within the framework of $\\textit{universal learning}$  [Bousquet, Hanneke, Moran, van Handel, and Yehudayoff; STOC '21].\n    \nIn multiclass online learning under bandit feedback, it is well known that no concept class $\\mathcal{C}$ is $\\textit{uniformly}$ learnable when the effective label space is unbounded, or in other words, no online learner guarantees a finite bound on the expected number of mistakes holding uniformly over all realizable data sequences. In contrast, surprisingly, we show that in the case of $\\textit{universal}$ learnability of concept classes $\\mathcal{C}$, there is an exact equivalence between multiclass online learnability under bandit feedback and full supervision, in both the realizable and agnostic settings.\n    \nMore specifically, our first main contribution is a theory that establishes an inherent dichotomy in multiclass online learning under bandit feedback within the realizable setting. In particular, for any concept class $\\mathcal{C}$ even when the effective label space is unbounded, we have: (1) If $\\mathcal{C}$ does not have an infinite multiclass Littlestone tree, then there is a deterministic online learner that makes only finitely many mistakes against any realizable adversary, crucially without placing a uniform bound on the number of mistakes. (2) If $\\mathcal{C}$ has an infinite multiclass Littlestone tree, then there is a strategy for the realizable adversary that forces any learner, including randomized, to make linear expected number of mistakes. Furthermore, our second main contribution reveals a similar trend in the agnostic setting.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Steve Hanneke;Amirreza Shaeiri;Hongao Wang",
        "authorids": "~Steve_Hanneke1;~Amirreza_Shaeiri1;~Hongao_Wang1",
        "gender": "M;M;M",
        "homepage": "http://www.stevehanneke.com;;https://phijack.github.io/",
        "dblp": "40/154;;",
        "google_scholar": "fEhNO7YAAAAJ;nRTM5b8AAAAJ;",
        "orcid": ";0000-0002-2715-7652;",
        "linkedin": ";;",
        "or_profile": "~Steve_Hanneke1;~Amirreza_Shaeiri1;~Hongao_Wang1",
        "aff": "Purdue University;Purdue University;Purdue University",
        "aff_domain": "purdue.edu;purdue.edu;purdue.edu",
        "position": "Assistant Professor;PhD student;PhD student",
        "bibtex": "@inproceedings{\nhanneke2025for,\ntitle={For Universal Multiclass Online Learning, Bandit Feedback and Full Supervision are Equivalent},\nauthor={Steve Hanneke and Amirreza Shaeiri and Hongao Wang},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=JABal85PJe}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_NbrK;1b6p;xq6u;TobW",
        "site": "https://openreview.net/forum?id=JABal85PJe",
        "pdf_size": 0,
        "rating": "0;0;4;7;9",
        "confidence": "0;2;4;3;4",
        "wc_review": "",
        "rating_avg": [
            4.0,
            3.63318042491699
        ],
        "confidence_avg": [
            2.6,
            1.4966629547095764
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            12,
            0
        ],
        "corr_rating_confidence": 0.7723929758166558
    },
    {
        "id": "JKVYCLDdgp",
        "title": "Do PAC-Learners Learn the Marginal Distribution?",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The Fundamental Theorem of PAC Learning asserts that learnability of a concept class $H$ is equivalent to the *uniform convergence* of empirical error in $H$ to its mean, or equivalently, to the problem of *density estimation*, learnability of the underlying marginal distribution with respect to events in $H$. This seminal equivalence relies strongly on PAC learning's `distribution-free' assumption, that the adversary may choose any marginal distribution over data. Unfortunately, the distribution-free model is known to be overly adversarial in practice, failing to predict the success of modern machine learning algorithms, but without the Fundamental Theorem our theoretical understanding of learning under distributional constraints remains highly limited.\n\nIn this work, we revisit the connection between PAC learning, uniform convergence, and density estimation beyond the distribution-free setting when the adversary is restricted to choosing a marginal distribution from a known family $\\mathscr{P}$. We prove that while the traditional Fundamental Theorem fails, a finer-grained connection between the three fundamental notions continues to hold:\n\n1. PAC-Learning is strictly sandwiched between two relaxed models of density estimation, differing only in whether the learner knows the set of well-estimated events in $\\mathcal{H}$.\n\n2. Under reasonable assumptions on $\\mathcal{H}$ and $\\mathscr{P}$, density estimation is equivalent to *uniform estimation*, a weakening of uniform convergence allowing non-empirical estimators.\n\nTogether, our results give a clearer picture of how the Fundamental Theorem extends beyond the distribution-free setting and shed new light on the classically challenging problem of learning under arbitrary distributional assumptions.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Max Hopkins;Daniel Kane;Shachar Lovett;Gaurav Mahajan",
        "authorids": "~Max_Hopkins1;~Daniel_Kane1;~Shachar_Lovett1;~Gaurav_Mahajan1",
        "gender": "M;M;;",
        "homepage": "http://cseweb.ucsd.edu/~nmhopkin/;http://cseweb.ucsd.edu/~dakane/;;",
        "dblp": "206/6755;52/6817;;",
        "google_scholar": "https://scholar.google.com/citations?hl=en;https://scholar.google.com.tw/citations?user=DulpV-cAAAAJ;;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Max_Hopkins1;~Daniel_Kane1;~Shachar_Lovett1;~Gaurav_Mahajan1",
        "aff": "Institue for Advanced Study, Princeton+Princeton University;University of California, San Diego;University of California-San Diego;",
        "aff_domain": "ias.edu+princeton.edu;ucsd.edu;;",
        "position": "Postdoc+Postdoc;Full Professor;;",
        "bibtex": "@inproceedings{\nhopkins2025do,\ntitle={Do {PAC}-Learners Learn the Marginal Distribution?},\nauthor={Max Hopkins and Daniel Kane and Shachar Lovett and Gaurav Mahajan},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=JKVYCLDdgp}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_Cp3V;k7bZ;vK1Y;FpMi",
        "site": "https://openreview.net/forum?id=JKVYCLDdgp",
        "pdf_size": 0,
        "rating": "0;7;7;7",
        "confidence": "4;3;4;3",
        "wc_review": "",
        "rating_avg": [
            5.25,
            3.031088913245535
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            10,
            0
        ],
        "corr_rating_confidence": -0.5773502691896257
    },
    {
        "id": "JTRjD4JeSq",
        "title": "Data Dependent Regret Bounds for Online Portfolio Selection with Predicted Returns",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study data-dependent regret bounds for the Online Portfolio Selection (OPS) problem. As opposed to worst-case bounds that hold uniformly over all sequence of returns, data-dependent bounds adapt to the specific sequence of returns seen by the investor. Consider a market of $n$ assets and $T$ time periods, consisting of the returns $r_1,\\dots,r_T \\in \\mathbb{R}^n_+$. The regret of our proposed algorithm, Log-Barrier Adaptive-Curvature Online Newton Step (LB-AdaCurv ONS) is bounded by $O(\\min(nR\\log T, \\sqrt{nT\\log T}))$, where  $R = \\max_{t,i,j} \\frac{r_t(i)}{r_t(j)}$ is a data dependent quantity that is not known to the algorithm. Thus, LB-AdaCurv ONS has a worst case regret of $O(\\sqrt{nT \\log T})$ while simultaneously having a data-dependent regret of $O(nR\\log T)$. \n\nNext, we consider the more practical setting of OPS with predicted returns, where the investor has access to predictions that can be incorporated into the portfolio selection process. We propose the Optimistic Expected Utility LB-FTRL (OUE-LB-FTRL) algorithm that incorporates the predictions using a utility function. If the predictions are accurate, OUE-LB-FTRL's regret is $O(n \\log T)$ and even if the predictions are arbitrary, regret is always bounded by $O(\\sqrt{nT\\log T})$. We provide a meta-algorithm called Best-of-Both Worlds for OPS (BoB-OPS), that combines the portfolios of an expected utility investor and a regret minimizing investor. By properly instantiating BoB-OPS, we show that the regret with respect to the expected utility investor is $O(\\log T)$ and the static regret is $O(n \\log T)$.\n\nFinally, we also show new First-Order, Second-Order and Gradual-Variation regret bounds for OPS. In our analysis, we developed new regret inequalities for optimistic FTRL with convex hint functions. This extends prior work on optimistic FTRL that used only linear hints, and so could be of independent interest.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sudeep Raja Putta;Shipra Agrawal",
        "authorids": "~Sudeep_Raja_Putta1;~Shipra_Agrawal1",
        "gender": "M;F",
        "homepage": "https://sudeepraja.github.io/;https://www.columbia.edu/~sa3305",
        "dblp": "199/6583;a/ShipraAgrawal",
        "google_scholar": "0MxBCEIAAAAJ;https://scholar.google.co.in/citations?user=qzIHHMEAAAAJ",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Sudeep_Raja_Putta1;~Shipra_Agrawal1",
        "aff": "Columbia University;Columbia University",
        "aff_domain": "columbia.edu;columbia.edu",
        "position": "PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nputta2025data,\ntitle={Data Dependent Regret Bounds for Online Portfolio Selection with Predicted Returns},\nauthor={Sudeep Raja Putta and Shipra Agrawal},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=JTRjD4JeSq}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_ZTwT;Q336;GdQ4;k6ge",
        "site": "https://openreview.net/forum?id=JTRjD4JeSq",
        "pdf_size": 0,
        "rating": "0;6;7;7",
        "confidence": "5;3;4;3",
        "wc_review": "",
        "rating_avg": [
            5.0,
            2.9154759474226504
        ],
        "confidence_avg": [
            3.75,
            0.82915619758885
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": -0.8273403039920306
    },
    {
        "id": "JlgUg6SKAJ",
        "title": "Reliable Active Apprenticeship Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We propose a learning problem, which we call reliable active apprenticeship learning, for which we define a learning algorithm providing optimal performance guarantees, which we further show are sharply characterized by the eluder dimension of a policy class.  In this setting, a learning algorithm is tasked with behaving optimally in an unknown environment given by a Markov decision process.  The correct actions are specified by an unknown optimal policy in a given policy class.  The learner initially does not know the optimal policy, but it has the ability to query an expert, which returns the optimal action for the current state.  A learner is said to be reliable if, whenever it takes an action without querying the expert, its action is guaranteed to be optimal.  We are then interested in designing a reliable learner which does not query the expert too often.  We propose a reliable learning algorithm which provably makes the minimal possible number of queries, which we show is precisely characterized by the eluder dimension of the policy class.  We further extend this to allow for imperfect experts, modeled as an oracle with noisy responses.  We study two variants of this, inspired by noise conditions from classification: namely, Massart noise and Tsybakov noise.  In both cases, we propose a reliable learning strategy which achieves a nearly-minimal number of queries, and prove upper and lower bounds on the optimal number of queries in terms of the noise conditions and the eluder dimension of the policy class.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Steve Hanneke;Liu Yang;Gongju Wang;Yulun Song",
        "authorids": "~Steve_Hanneke1;~Liu_Yang2;wanggj129@chinaunicom.cn;songyl100@chinaunicom.cn",
        "gender": "M;;;",
        "homepage": "http://www.stevehanneke.com;;;",
        "dblp": "40/154;27/3367-1;;",
        "google_scholar": "fEhNO7YAAAAJ;;;",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "~Steve_Hanneke1;~Liu_Yang2;wanggj129@chinaunicom.cn;songyl100@chinaunicom.cn",
        "aff": "Purdue University;Data Intelligence Division, China Unicom Digital Technology Co., Ltd.;;",
        "aff_domain": "purdue.edu;chinaunicom.cn;;",
        "position": "Assistant Professor;Researcher;;",
        "bibtex": "@inproceedings{\nhanneke2025reliable,\ntitle={Reliable Active Apprenticeship Learning},\nauthor={Steve Hanneke and Liu Yang and Gongju Wang and Yulun Song},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=JlgUg6SKAJ}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_ZGAJ;GEdn;P1mS;Szof",
        "site": "https://openreview.net/forum?id=JlgUg6SKAJ",
        "pdf_size": 0,
        "rating": "0;0;6;7;7",
        "confidence": "0;5;3;3;4",
        "wc_review": "",
        "rating_avg": [
            4.0,
            3.286335345030997
        ],
        "confidence_avg": [
            3.0,
            1.6733200530681511
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.2545875386086578
    },
    {
        "id": "KPVneVjxMO",
        "title": "Refining the Sample Complexity of Comparative Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Comparative learning, a recently introduced variation of the PAC (Probably Approximately Correct) framework, interpolates between the two standard extreme settings of realizable and agnostic PAC learning. In comparative learning the labeling is assumed to be from one hypothesis class (the source class) while the learner's performance is to be measured against another hypothesis class (the benchmark class). This setup allows for incorporating more specific prior knowledge into PAC type learning bounds, which are known to be otherwise overly pessimistic. It also naturally represents model distillation tasks, where a predictor with specific requirements (such as being bounded in size or being interpretable) is trained on the labels from another model. A first sample complexity analysis of comparative learning established upper and lower bounds for general comparative learning. In this work, we propose a more fine grained view on this setting, distinguishing between proper learning and general (improper) learning. We derive novel upper and lower sample complexity bounds for both settings. In particular, we identify conditions for each of the regimes, and thereby exhibit how the rate depends on the relatedness of the two classes in perhaps unexpected ways.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sajad Rahmanian Ashkezari;Ruth Urner",
        "authorids": "~Sajad_Rahmanian_Ashkezari1;~Ruth_Urner3",
        "gender": ";F",
        "homepage": ";https://www.eecs.yorku.ca/~ruth/",
        "dblp": ";68/8050",
        "google_scholar": ";https://scholar.google.ca/citations?user=O7p7lRAAAAAJ",
        "orcid": ";",
        "linkedin": "sajad-rahmanian-51b76216a/;",
        "or_profile": "~Sajad_Rahmanian_Ashkezari1;~Ruth_Urner3",
        "aff": "York University;York University",
        "aff_domain": "yorku.ca;yorku.ca",
        "position": "MS student;Associate Professor",
        "bibtex": "@inproceedings{\nashkezari2025refining,\ntitle={Refining the Sample Complexity of  Comparative Learning},\nauthor={Sajad Rahmanian Ashkezari and Ruth Urner},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=KPVneVjxMO}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_SQQt;LcZ6;y9ZF;1CHX;Eicz",
        "site": "https://openreview.net/forum?id=KPVneVjxMO",
        "pdf_size": 0,
        "rating": "0;0;6;7;7;7",
        "confidence": "0;4;4;4;2;3",
        "wc_review": "",
        "rating_avg": [
            4.5,
            3.2015621187164243
        ],
        "confidence_avg": [
            2.8333333333333335,
            1.4624940645653537
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            14,
            0
        ],
        "corr_rating_confidence": 0.3737506905866113
    },
    {
        "id": "L57EeV3VKf",
        "title": "Generalisation under gradient descent via deterministic PAC-Bayes",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We establish disintegrated PAC-Bayesian generalisation bounds for models trained with gradient descent methods or continuous gradient flows. Contrary to standard practice in the PAC-Bayesian setting, our result applies to optimisation algorithms that are deterministic, without requiring any de-randomisation step. Our bounds are fully computable, depending on the density of the initial distribution and the Hessian of the training objective over the trajectory. We show that our framework can be applied to a variety of iterative optimisation algorithms, including stochastic gradient descent (SGD), momentum-based schemes, and damped Hamiltonian dynamics.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eugenio Clerico;Tyler Farghly;George Deligiannidis;Benjamin Guedj;Arnaud Doucet",
        "authorids": "~Eugenio_Clerico1;~Tyler_Farghly1;~George_Deligiannidis2;~Benjamin_Guedj1;~Arnaud_Doucet2",
        "gender": "M;M;M;M;",
        "homepage": "https://github.com/eclerico;https://tylerkf.github.io/;https://www.stats.ox.ac.uk/~deligian;https://bguedj.github.io;",
        "dblp": ";;;177/7258;",
        "google_scholar": ";suXJdCIAAAAJ;https://scholar.google.co.uk/citations?user=EF1FwN4AAAAJ;https://scholar.google.fr/citations?user=q-JTC2sAAAAJ;",
        "orcid": ";;;0000-0003-1237-7430;",
        "linkedin": ";https://uk.linkedin.com/in/tylerkf;;benjaminguedj/;",
        "or_profile": "~Eugenio_Clerico1;~Tyler_Farghly1;~George_Deligiannidis2;~Benjamin_Guedj1;~Arnaud_Doucet2",
        "aff": "Universitat Pompeu Fabra;University of Oxford;Oxford, University of Oxford;University College London, University of London+Inria;",
        "aff_domain": "upf.edu;ox.ac.uk;stats.ox.ac.uk;ucl.ac.uk+inria.fr;",
        "position": "Postdoc;PhD student;Full Professor;Full Professor+Research Scientist;",
        "bibtex": "@inproceedings{\nclerico2025generalisation,\ntitle={Generalisation under gradient descent via deterministic {PAC}-Bayes},\nauthor={Eugenio Clerico and Tyler Farghly and George Deligiannidis and Benjamin Guedj and Arnaud Doucet},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=L57EeV3VKf}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_gsR1;oEqj;K9iN;ffKT",
        "site": "https://openreview.net/forum?id=L57EeV3VKf",
        "pdf_size": 0,
        "rating": "0;0;6;6;7",
        "confidence": "0;4;4;3;4",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.124099870362662
        ],
        "confidence_avg": [
            3.0,
            1.5491933384829668
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.5372084289871701
    },
    {
        "id": "L68sXPqqjE",
        "title": "High-accuracy sampling from constrained spaces with the Metropolis-adjusted Preconditioned Langevin Algorithm",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We propose a first-order sampling method called the Metropolis-adjusted Preconditioned Langevin Algorithm for approximate sampling from a target distribution whose support is a proper convex subset of $\\mathbb{R}^{d}$. Our proposed method is the result of applying a Metropolis-Hastings filter to the Markov chain formed by a single step of the preconditioned Langevin algorithm with a metric $\\mathscr{G}$, and is motivated by the natural gradient descent algorithm for optimisation. We derive non-asymptotic upper bounds for the mixing time of this method for sampling from target distributions whose potentials are bounded relative to $\\mathscr{G}$, and for exponential distributions restricted to the support. Our analysis suggests that if $\\mathscr{G}$ satisfies stronger notions of self-concordance introduced in Kook and Vempala (2024), then these mixing time upper bounds have a strictly better dependence on the dimension than when $\\mathscr{G}$ is merely self-concordant. Our method is a high-accuracy sampler due to the polylogarithmic dependence on the error tolerance in our mixing time upper bounds.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Vishwak Srinivasan;Andre Wibisono;Ashia C. Wilson",
        "authorids": "~Vishwak_Srinivasan1;~Andre_Wibisono1;~Ashia_C._Wilson1",
        "gender": "M;M;F",
        "homepage": "https://www.mit.edu/~vishwaks;http://www.cs.yale.edu/homes/wibisono/;https://www.ashiawilson.com",
        "dblp": "211/7746;64/10962;",
        "google_scholar": "MW4-PPgAAAAJ;;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Vishwak_Srinivasan1;~Andre_Wibisono1;~Ashia_C._Wilson1",
        "aff": "Massachusetts Institute of Technology+Yale University;Yale University;Massachusetts Institute of Technology",
        "aff_domain": "mit.edu+yale.edu;yale.edu;mit.edu",
        "position": "PhD student+Researcher;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nsrinivasan2025highaccuracy,\ntitle={High-accuracy sampling from constrained spaces with the Metropolis-adjusted Preconditioned Langevin Algorithm},\nauthor={Vishwak Srinivasan and Andre Wibisono and Ashia C. Wilson},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=L68sXPqqjE}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_CwBG;iZr8;A1KC;8F7S;LALf",
        "site": "https://openreview.net/forum?id=L68sXPqqjE",
        "pdf_size": 0,
        "rating": "0;0;4;7;7;8",
        "confidence": "0;5;3;4;3;4",
        "wc_review": "",
        "rating_avg": [
            4.333333333333333,
            3.299831645537222
        ],
        "confidence_avg": [
            3.1666666666666665,
            1.5723301886761007
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            10,
            0
        ],
        "corr_rating_confidence": 0.34264305782667953
    },
    {
        "id": "MvGTH3S6rN",
        "title": "Non-stochastic Bandits With Evolving Observations",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We introduce a novel online learning framework that unifies and generalizes pre-established models, such as delayed and corrupted feedback, to encompass adversarial environments where action feedback evolves over time. In this setting, the observed loss is arbitrary and may not correlate with the true loss incurred, with each round updating previous observations adversarially. We propose regret minimization algorithms for both the full-information and bandit settings, with regret bounds quantified by the average feedback accuracy relative to the true loss. Our algorithms match the known regret bounds across many special cases, while also introducing previously unknown bounds.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Yogev Bar-On;Yishay Mansour",
        "authorids": "~Yogev_Bar-On1;~Yishay_Mansour2",
        "gender": "M;",
        "homepage": "https://yogev.io;",
        "dblp": "245/0139;",
        "google_scholar": "KiqkcNEAAAAJ;",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Yogev_Bar-On1;~Yishay_Mansour2",
        "aff": "Tel Aviv University;",
        "aff_domain": "tau.ac.il;",
        "position": "PhD student;",
        "bibtex": "@inproceedings{\nbar-on2025nonstochastic,\ntitle={Non-stochastic Bandits With Evolving Observations},\nauthor={Yogev Bar-On and Yishay Mansour},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=MvGTH3S6rN}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_Hebv;CVnL;N33v;DSiq",
        "site": "https://openreview.net/forum?id=MvGTH3S6rN",
        "pdf_size": 0,
        "rating": "0;0;6;7;8",
        "confidence": "0;4;3;3;3",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.4871191548325386
        ],
        "confidence_avg": [
            2.6,
            1.3564659966250538
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            6,
            0
        ],
        "corr_rating_confidence": 0.3551677980331627
    },
    {
        "id": "Nh4jz04lwf",
        "title": "A Characterization of List Regression",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "There has been a recent interest in understanding and characterizing the sample complexity of list learning tasks, where the learning algorithm is allowed to make a short list of $k$ predictions, and we simply require one of the predictions to be correct. This includes recent works characterizing the PAC sample complexity of standard list classification and online list classification.\n\nAdding to this theme, in this work, we provide a complete characterization of list PAC _regression_. We propose two combinatorial dimensions, namely the $k$-OIG dimension and the $k$-fat-shattering dimension, and show that they characterize realizable and agnostic $k$-list regression respectively. These quantities generalize known dimensions for standard regression. Our work thus extends existing list learning characterizations from classification to regression.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Chirag Pabbaraju;Sahasrajit Sarmasarkar",
        "authorids": "~Chirag_Pabbaraju1;~Sahasrajit_Sarmasarkar1",
        "gender": "M;",
        "homepage": "https://web.stanford.edu/~cpabbara/;https://sahasrajit123.github.io",
        "dblp": "231/7619;",
        "google_scholar": "IAGcpHkAAAAJ;",
        "orcid": "0000-0002-3424-691X;",
        "linkedin": "chirag-pabbaraju-277a4ba5/;",
        "or_profile": "~Chirag_Pabbaraju1;~Sahasrajit_Sarmasarkar1",
        "aff": "Stanford University;Stanford University",
        "aff_domain": "cs.stanford.edu;stanford.edu",
        "position": "PhD student;PhD student",
        "bibtex": "@inproceedings{\npabbaraju2025a,\ntitle={A Characterization of List Regression},\nauthor={Chirag Pabbaraju and Sahasrajit Sarmasarkar},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=Nh4jz04lwf}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_mJWo;hvHa;M6FU;G8M5",
        "site": "https://openreview.net/forum?id=Nh4jz04lwf",
        "pdf_size": 0,
        "rating": "0;0;5;7;7",
        "confidence": "0;5;1;3;4",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.1874754901018454
        ],
        "confidence_avg": [
            2.6,
            1.8547236990991407
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.15561868892048092
    },
    {
        "id": "P4OJds0sdD",
        "title": "A PAC-Bayesian Link Between Generalisation and Flat Minima",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Modern machine learning usually involves predictors in the overparameterised setting (number of trained parameters greater than dataset size), and their training yields not only good performance on training data, but also good generalisation capacity. This phenomenon challenges many theoretical results, and remains an open problem. To reach a better understanding, we provide novel generalisation bounds involving gradient terms. To do so, we combine the PAC-Bayes toolbox with Poincar\u00e9 and Log-Sobolev inequalities, avoiding an explicit dependency on the dimension of the predictor space. Our results highlight the positive influence of flat minima (being minima with a neighbourhood nearly minimising the learning problem as well) on generalisation performance, involving directly the benefits of the optimisation phase.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Maxime Haddouche;Paul Viallard;Umut Simsekli;Benjamin Guedj",
        "authorids": "~Maxime_Haddouche1;~Paul_Viallard1;~Umut_Simsekli1;~Benjamin_Guedj1",
        "gender": ";M;M;M",
        "homepage": "https://maximehaddouche.github.io/;https://paulviallard.github.io;https://www.di.ens.fr/~simsekli/;https://bguedj.github.io",
        "dblp": "267/5693.html;285/5954;https://dblp.org/pers/s/Simsekli:Umut.html;177/7258",
        "google_scholar": "0U7gG1sAAAAJ;k-5mpncAAAAJ;https://scholar.google.fr/citations?user=CuArAkgAAAAJ;https://scholar.google.fr/citations?user=q-JTC2sAAAAJ",
        "orcid": "0000-0001-9292-5112;;;0000-0003-1237-7430",
        "linkedin": ";;;benjaminguedj/",
        "or_profile": "~Maxime_Haddouche1;~Paul_Viallard1;~Umut_Simsekli1;~Benjamin_Guedj1",
        "aff": "INRIA;Inria;INRIA;University College London, University of London+Inria",
        "aff_domain": "inria.fr;inria.fr;inria.fr;ucl.ac.uk+inria.fr",
        "position": "Postdoc;Researcher;Research Faculty;Full Professor+Research Scientist",
        "bibtex": "@inproceedings{\nhaddouche2025a,\ntitle={A {PAC}-Bayesian Link Between Generalisation and Flat Minima},\nauthor={Maxime Haddouche and Paul Viallard and Umut Simsekli and Benjamin Guedj},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=P4OJds0sdD}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_naaY;tiMX;m8Pd;sSsB",
        "site": "https://openreview.net/forum?id=P4OJds0sdD",
        "pdf_size": 0,
        "rating": "0;0;6;6;7",
        "confidence": "0;4;4;4;3",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.124099870362662
        ],
        "confidence_avg": [
            3.0,
            1.5491933384829668
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            22,
            0
        ],
        "corr_rating_confidence": 0.4958847036804648
    },
    {
        "id": "PFKk0M8mrS",
        "title": "An Online Feasible Point Method for Benign Generalized Nash Equilibrium Problems.",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We consider a repeatedly played generalized Nash equilibrium game. This induces a multi-agent online learning problem with joint constraints. An important challenge in this setting is that the feasible set for each agent depends on the simultaneous moves of the other agents and, therefore, varies over time. As a consequence, the agents face time-varying constraints, which are not adversarial but rather endogenous to the system. Prior work in this setting focused on convergence to a feasible solution in the limit via integrating the constraints in the objective as a penalty function.  However, no existing work can guarantee that the constraints are satisfied for all iterations while simultaneously guaranteeing convergence to a generalized Nash equilibrium. This is a problem of fundamental theoretical interest and practical relevance.\nIn this work, we introduce a new online feasible point method. Under the assumption that limited communication between the agents is allowed, this method guarantees feasibility. We identify the class of benign generalized Nash equilibrium problems, for which the convergence of our method to the equilibrium is guaranteed. We set this class of benign generalized Nash equilibrium games in context with existing definitions and illustrate our method with examples.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Sarah Sachs;Hedi Hadiji;Tim van Erven;Mathias Staudigl",
        "authorids": "~Sarah_Sachs1;~Hedi_Hadiji1;~Tim_van_Erven1;~Mathias_Staudigl1",
        "gender": "F;M;M;M",
        "homepage": "https://www.uva.nl/en/profile/s/a/s.c.sachs/s.c.sachs.html?cb;https://hedi-hadiji.github.io/;http://www.timvanerven.nl;https://www.wim.uni-mannheim.de/staudigl/",
        "dblp": ";;82/1868;https://dblp.uni-trier.de/pers/hd/s/Staudigl:Mathias",
        "google_scholar": ";;https://scholar.google.nl/citations?user=kdxqEMQAAAAJ;",
        "orcid": ";;;0000-0003-2481-0019",
        "linkedin": ";;;",
        "or_profile": "~Sarah_Sachs1;~Hedi_Hadiji1;~Tim_van_Erven1;~Mathias_Staudigl1",
        "aff": "Bocconi University;CentraleSupelec;University of Amsterdam;Universit\u00e4t Mannheim+Maastricht University",
        "aff_domain": "unibocconi.it;centralesupelec.fr;uva.nl;uni-mannheim.de+maastrichtuniversity.nl",
        "position": "Postdoc;Assistant Professor;Associate Professor;Full Professor+Associate Professor",
        "bibtex": "@inproceedings{\nsachs2025an,\ntitle={An Online Feasible Point Method for Benign Generalized Nash Equilibrium Problems.},\nauthor={Sarah Sachs and Hedi Hadiji and Tim van Erven and Mathias Staudigl},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=PFKk0M8mrS}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_pekU;K8UB;hVaj;tiKx",
        "site": "https://openreview.net/forum?id=PFKk0M8mrS",
        "pdf_size": 0,
        "rating": "0;0;6;6;6",
        "confidence": "0;4;4;3;3",
        "wc_review": "",
        "rating_avg": [
            3.6,
            2.9393876913398134
        ],
        "confidence_avg": [
            2.8,
            1.469693845669907
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.4444444444444445
    },
    {
        "id": "PQtGREBPIP",
        "title": "Sharp bounds on aggregate expert error",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We revisit the classic problem of aggregating binary advice from conditionally independent experts, also known as the Naive Bayes setting. Our quantity of interest is the error probability of the optimal decision rule. In the case of symmetric errors (sensitivity = specificity), reasonably tight bounds on the optimal error probability are known. In the general asymmetric case, we are not aware of any nontrivial estimates on this quantity. Our contribution consists of sharp upper and lower bounds on the optimal error probability in the general case, which recover and sharpen the best known results in the symmetric special case. Since this turns out to be closely connected to bounding the total variation distance between two product distributions, our results also have bearing on this important and challenging problem.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Aryeh Kontorovich;Ariel Avital",
        "authorids": "~Aryeh_Kontorovich1;~Ariel_Avital1",
        "gender": ";M",
        "homepage": "http://www.cs.bgu.ac.il/~karyeh/;https://www.cs.bgu.ac.il/~karyeh/",
        "dblp": "20/10289;",
        "google_scholar": "https://scholar.google.co.il/citations?user=UNVQ5DsAAAAJ;",
        "orcid": ";",
        "linkedin": "prof-aryeh-kontorovich-7b236055/;",
        "or_profile": "~Aryeh_Kontorovich1;~Ariel_Avital1",
        "aff": "Ben Gurion University of the Negev;Ben Gurion University of the Negev, Technion",
        "aff_domain": "bgu.ac.il;bgu.ac.il",
        "position": "Professor;PhD student",
        "bibtex": "@inproceedings{\navital2025sharp,\ntitle={Sharp bounds on aggregate expert error},\nauthor={Ariel Avital and Aryeh Kontorovich},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=PQtGREBPIP}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_erh6;7DKp;p623;wMyh",
        "site": "https://openreview.net/forum?id=PQtGREBPIP",
        "pdf_size": 0,
        "rating": "0;0;6;6;7",
        "confidence": "0;4;4;3;1",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.124099870362662
        ],
        "confidence_avg": [
            2.4,
            1.624807680927192
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.13396212883589678
    },
    {
        "id": "Q1KuxL4laL",
        "title": "Fast Convergence of $\\Phi$-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the mixing time of two popular discrete-time Markov chains in continuous space, the Unadjusted Langevin Algorithm and the Proximal Sampler, which are discretizations of the Langevin dynamics. We extend mixing time analyses for these Markov chains to hold in $\\Phi$-divergence. We show that any $\\Phi$-divergence arising from a twice-differentiable strictly convex function $\\Phi$ converges to $0$ exponentially fast along these Markov chains, under the assumption that their stationary distributions satisfy the corresponding $\\Phi$-Sobolev inequality, which holds for example when the target distribution of the Langevin dynamics is strongly log-concave. Our setting includes as special cases popular mixing time regimes, namely the mixing in chi-squared divergence under a Poincar\u00e9 inequality, and the mixing in relative entropy under a log-Sobolev inequality. Our results follow by viewing the sampling algorithms as noisy channels and bounding the contraction coefficients arising in the appropriate strong data processing inequalities.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Siddharth Mitra;Andre Wibisono",
        "authorids": "~Siddharth_Mitra2;~Andre_Wibisono1",
        "gender": ";M",
        "homepage": "https://mitrodov.github.io/;http://www.cs.yale.edu/homes/wibisono/",
        "dblp": ";64/10962",
        "google_scholar": ";",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Siddharth_Mitra2;~Andre_Wibisono1",
        "aff": "Yale University;Yale University",
        "aff_domain": "yale.edu;yale.edu",
        "position": "PhD student;Assistant Professor",
        "bibtex": "@inproceedings{\nmitra2025fast,\ntitle={Fast Convergence of \\${\\textbackslash}Phi\\$-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler},\nauthor={Siddharth Mitra and Andre Wibisono},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=Q1KuxL4laL}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_zc4i;m261;7k7y;W2UN",
        "site": "https://openreview.net/forum?id=Q1KuxL4laL",
        "pdf_size": 0,
        "rating": "0;0;5;6;7",
        "confidence": "0;4;4;5;4",
        "wc_review": "",
        "rating_avg": [
            3.6,
            3.006659275674582
        ],
        "confidence_avg": [
            3.4,
            1.7435595774162693
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            11,
            0
        ],
        "corr_rating_confidence": 0.6409413198575192
    },
    {
        "id": "QfbnsooeZB",
        "title": "Self-Directed Node Classification on Graphs",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the problem of classifying the nodes of a given graph in the self-directed learning setup. This learning setting is a variant of online learning, where rather than an adversary determining the sequence in which nodes are presented, the learner autonomously and adaptively selects them. While self-directed learning of Euclidean halfspaces, linear functions, and general multiclass hypothesis classes was recently considered, no results previously existed specifically for self-directed node classification on graphs. In this paper, we address this problem developing efficient algorithms for it. More specifically, we focus on the case of (geodesically) convex clusters, i.e., for every two nodes sharing the same label, all nodes on every shortest path between them also share the same label. In particular, we devise an algorithm with runtime polynomial in $n$ that makes only $3(h(G)+1)^4 \\ln n$ mistakes on graphs with two convex clusters, where $n$ is the total number of nodes and $h(G)$ is the Hadwiger number, i.e., the size of the largest clique minor of the graph $G$. We also show that our algorithm is robust to the case that clusters are slightly non-convex, still achieving a mistake bound logarithmic in $n$. Finally, we devise a simple and efficient algorithm for homophilic clusters, where strongly connected nodes tend to belong to the same class.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Georgy Sokolov;Maximilian Thiessen;Margarita Akhmejanova;Fabio Vitale;Francesco Orabona",
        "authorids": "~Georgy_Sokolov1;~Maximilian_Thiessen1;~Margarita_Akhmejanova1;~Fabio_Vitale1;~Francesco_Orabona1",
        "gender": "M;;F;;M",
        "homepage": ";https://maxthiessen.github.io;;;https://francesco.orabona.com/",
        "dblp": ";https://dblp.uni-trier.de/pid/274/6633;;;80/3790.html",
        "google_scholar": "https://scholar.google.com/citations?view_op=new_profile;https://scholar.google.de/citations?user=XO5rGcwAAAAJ;bp5xVjwAAAAJ;;g1ha-iYAAAAJ",
        "orcid": ";0000-0001-9333-2685;;;",
        "linkedin": ";maximilian-thiessen/;;;",
        "or_profile": "~Georgy_Sokolov1;~Maximilian_Thiessen1;~Margarita_Akhmejanova1;~Fabio_Vitale1;~Francesco_Orabona1",
        "aff": "Moscow Institute of Physics and Technology+Moscow Institute of Physics and Technology;;King Abdullah University of Science and Technology;;King Abdullah University of Science and Technology",
        "aff_domain": "phystech.edu+phystech.edu;;kaust.edu.sa;;kaust.edu.sa",
        "position": "MS student+Researcher;;Postdoc;;Associate Professor",
        "bibtex": "@inproceedings{\nsokolov2025selfdirected,\ntitle={Self-Directed Node Classification on Graphs},\nauthor={Georgy Sokolov and Maximilian Thiessen and Margarita Akhmejanova and Fabio Vitale and Francesco Orabona},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=QfbnsooeZB}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_zpP5;jviV;tTj4;DbUU",
        "site": "https://openreview.net/forum?id=QfbnsooeZB",
        "pdf_size": 0,
        "rating": "0;0;7;7;7",
        "confidence": "0;4;3;4;3",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.429285639896449
        ],
        "confidence_avg": [
            2.8,
            1.4696938456699071
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.44444444444444453
    },
    {
        "id": "Rpy7ViuSNC",
        "title": "Noisy Computing of the Threshold Function",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Let $\\mathsf{TH}\\_{k}$ denote the $k$-out-of-$n$ threshold function: given $n$ input Boolean variables, the output is $1$ if and only if at least $k$ of the inputs are $1$. We consider the problem of computing the $\\mathsf{TH}\\_k$ function using noisy readings of the Boolean variables, where each reading is incorrect with some fixed and known probability $p \\in (0,1/2)$. As our main result, we show that it is sufficient to use $(1+o(1)) \\frac{n\\log \\frac{m}{\\delta}}{D\\_{\\mathsf{KL}}(p \\| 1-p)}$ queries in expectation to compute the $\\mathsf{TH}\\_k$ function with a vanishing error probability $\\delta = o(1)$, where $m\\triangleq \\min(k,n-k+1)$ and $D\\_{\\mathsf{KL}}(p \\| 1-p)$ denotes the Kullback-Leibler divergence between $\\mathsf{Bern}(p)$ and $\\mathsf{Bern}(1-p)$ distributions. Conversely, we show that any algorithm achieving an error probability of $\\delta = o(1)$ necessitates at least $(1-o(1))\\frac{(n-m)\\log\\frac{m}{\\delta}}{D\\_{\\mathsf{KL}}(p \\| 1-p)}$ queries in expectation. The upper and lower bounds are tight when $m=o(n)$, and are within a multiplicative factor of $\\frac{n}{n-m}$ when $m=\\Theta(n)$. In particular, when $k=n/2$, the $\\mathsf{TH}\\_k$ function corresponds to the $\\mathsf{MAJORITY}$ function, in which case the upper and lower bounds are tight up to a multiplicative factor of two. Compared to previous work, our result tightens the dependence on $p$ in both the upper and lower bounds.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ziao Wang;Nadim Ghaddar;Banghua Zhu;Lele Wang",
        "authorids": "~Ziao_Wang3;~Nadim_Ghaddar1;~Banghua_Zhu1;~Lele_Wang1",
        "gender": "M;;M;F",
        "homepage": "https://ziaow027.github.io/;https://nadimgh.github.io/;https://people.eecs.berkeley.edu/~banghua/;https://sites.google.com/site/wanglele1986/",
        "dblp": ";;204/5394;11/7909-1",
        "google_scholar": "https://scholar.google.ca/citations?user=ESCWolcAAAAJ;lyadgWkAAAAJ;https://scholar.google.com/citations?hl=en;ySwF8ioAAAAJ",
        "orcid": "0000-0002-1879-6559;;;",
        "linkedin": ";;;",
        "or_profile": "~Ziao_Wang3;~Nadim_Ghaddar1;~Banghua_Zhu1;~Lele_Wang1",
        "aff": "University of Michigan - Ann Arbor;University of Toronto;University of Washington;University of British Columbia",
        "aff_domain": "umich.edu;utoronto.ca;uw.edu;ubc.ca",
        "position": "Postdoc;Postdoc;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nwang2025noisy,\ntitle={Noisy Computing of the Threshold Function},\nauthor={Ziao Wang and Nadim Ghaddar and Banghua Zhu and Lele Wang},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=Rpy7ViuSNC}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_yf4F;Zovh;BbYK;YbKM",
        "site": "https://openreview.net/forum?id=Rpy7ViuSNC",
        "pdf_size": 0,
        "rating": "0;7;8;8",
        "confidence": "4;4;4;5",
        "wc_review": "",
        "rating_avg": [
            5.75,
            3.344772040064913
        ],
        "confidence_avg": [
            4.25,
            0.4330127018922193
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.38837866680189276
    },
    {
        "id": "S4v8GmS5gQ",
        "title": "Center-Based Approximation of a Drifting Distribution",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We present a novel technique for computing a center-based approximation of a drifting distribution. Given $k \\geq 1$ and a sequence of data, whose distribution is changing over time, the goal is to compute, at each step, the best $k$ centers representation of the current distribution, despite possibly having only a single sample from the most recent distribution. In data mining, this is traditionally attempted through the sliding-window mechanism, where the analysis is performed on the most recent fixed-size segment of the data. The problems with this approach are twofold: (1) setting the correct window size is challenging; and (2) a fixed window size cannot effectively track changes in the distribution happening at variable speed. In this paper, we propose a new methodology that dynamically adjusts the window size based on the recent drift of the data. The challenge is that it is not possible to explicitly estimate the drift, as we may have only a single data point from each distribution. Our main contribution lies in providing a rigorous mathematical analysis, establishing both an upper bound via a dynamic window size algorithm, and a lower bound that shows the tightness of our approach.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Alessio Mazzetto;Matteo Ceccarello;Andrea Pietracaprina;Geppino Pucci;Eli Upfal",
        "authorids": "~Alessio_Mazzetto1;~Matteo_Ceccarello1;~Andrea_Pietracaprina1;~Geppino_Pucci1;~Eli_Upfal1",
        "gender": "M;;M;M;M",
        "homepage": "https://cs.brown.edu/~amazzett/;https://www.dei.unipd.it/~ceccarello;http://www.dei.unipd.it/~capri/;http://www.dei.unipd.it/~geppo;",
        "dblp": "239/8316.html;https://dblp.uni-trier.de/pid/124/0019;95/3178.html;p/GeppinoPucci;u/EliUpfal",
        "google_scholar": "FkZ0hSsAAAAJ;;https://scholar.google.it/citations?user=X4HU5HIAAAAJ;https://scholar.google.it/citations?user=2N158yoAAAAJ;",
        "orcid": "0009-0006-5893-0915;;;0000-0001-9189-6938;",
        "linkedin": ";;;;",
        "or_profile": "~Alessio_Mazzetto1;~Matteo_Ceccarello1;~Andrea_Pietracaprina1;~Geppino_Pucci1;~Eli_Upfal1",
        "aff": "Brown University;University of Padua;University of Padua;University of Padua;Brown University",
        "aff_domain": "brown.edu;unipd.it;unipd.it;unipd.it;brown.edu",
        "position": "PhD student;Assistant Professor;Full Professor;Full Professor;Full Professor",
        "bibtex": "@inproceedings{\nmazzetto2025centerbased,\ntitle={Center-Based Approximation of a Drifting Distribution},\nauthor={Alessio Mazzetto and Matteo Ceccarello and Andrea Pietracaprina and Geppino Pucci and Eli Upfal},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=S4v8GmS5gQ}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_fiPz;uspc;DX3Z;HijQ",
        "site": "https://openreview.net/forum?id=S4v8GmS5gQ",
        "pdf_size": 0,
        "rating": "0;0;3;7;7",
        "confidence": "0;4;3;4;3",
        "wc_review": "",
        "rating_avg": [
            3.4,
            3.1368774282716245
        ],
        "confidence_avg": [
            2.8,
            1.4696938456699071
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.45116864545597307
    },
    {
        "id": "TAvypH5yl5",
        "title": "On Generalization Bounds for Neural Networks with Low Rank Layers",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "While previous optimization results have suggested that deep neural networks tend to favor low-rank weight matrices, the implications of this inductive bias on generalization bounds remain underexplored. In this paper, we apply a chain rule for Gaussian complexity (Maurer, 2016) to analyze how low-rank layers in deep networks can prevent the accumulation of rank and dimensionality factors that typically multiply across layers. This approach yields generalization bounds for rank and spectral norm constrained networks. We compare our results to prior generalization bounds for deep networks, highlighting how deep networks with low-rank layers can achieve better generalization than those with full-rank layers. Additionally, we discuss how this framework provides new perspectives on the generalization capabilities of deep networks exhibiting neural collapse.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Andrea Pinto;Akshay Rangamani;Tomaso A Poggio",
        "authorids": "~Andrea_Pinto1;~Akshay_Rangamani1;~Tomaso_A_Poggio2",
        "gender": "M;M;",
        "homepage": "https://www.agpinto.com;https://akshay-r.github.io;",
        "dblp": ";https://dblp.uni-trier.de/pers/hd/r/Rangamani:Akshay;",
        "google_scholar": "bxfWHjQAAAAJ;xaldisgAAAAJ;",
        "orcid": "0009-0000-8617-6266;;",
        "linkedin": "pinto-andrea;akshay-rangamani-6a2142181/;",
        "or_profile": "~Andrea_Pinto1;~Akshay_Rangamani1;~Tomaso_A_Poggio2",
        "aff": ";New Jersey Institute of Technology;",
        "aff_domain": ";njit.edu;",
        "position": ";Assistant Professor;",
        "bibtex": "@inproceedings{\npinto2025on,\ntitle={On Generalization Bounds for Neural Networks with Low Rank Layers},\nauthor={Andrea Pinto and Akshay Rangamani and Tomaso A Poggio},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=TAvypH5yl5}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Authors;Authors;Authors;Area_Chair_xtiR;oJ2Z;XzyW;sd6A;gQPE",
        "site": "https://openreview.net/forum?id=TAvypH5yl5",
        "pdf_size": 0,
        "rating": "0;0;0;0;0;0;5;6;6;8",
        "confidence": "0;0;0;0;0;4;3;4;3;4",
        "wc_review": "",
        "rating_avg": [
            2.5,
            3.138470965295043
        ],
        "confidence_avg": [
            1.8,
            1.8330302779823362
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            14,
            0
        ],
        "corr_rating_confidence": 0.7648300140862568
    },
    {
        "id": "WXGDyFsooW",
        "title": "The Plug-in Approach for Average-Reward and Discounted MDPs: Optimal Sample Complexity Analysis",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the sample complexity of the plug-in approach for learning $\\varepsilon$-optimal policies in average-reward Markov decision processes (MDPs) with a generative model. The plug-in approach constructs a model estimate then computes an average-reward optimal policy in the estimated model.  Despite representing arguably the simplest algorithm for this problem, the plug-in approach has never been theoretically analyzed. Unlike the more well-studied discounted MDP reduction method, the plug-in approach requires no prior problem information or parameter tuning. Our results fill this gap and address the limitations of prior approaches, as we show that the plug-in approach is optimal in several well-studied settings without using prior knowledge. Specifically it achieves the optimal diameter- and mixing-based sample complexities of $\\widetilde{O}\\left(SA \\frac{D}{\\varepsilon^2}\\right)$ and $\\widetilde{O}\\left(SA \\frac{\\tau_{\\mathrm{unif}}}{\\varepsilon^2}\\right)$, respectively, without knowledge of the diameter $D$ or uniform mixing time $\\tau_{\\mathrm{unif}}$.\n  We also obtain span-based bounds for the plug-in approach, and complement them with algorithm-specific lower bounds suggesting that they are unimprovable. Our results require novel techniques for analyzing long-horizon problems which may be broadly useful and which also improve results for the discounted plug-in approach, removing effective-horizon-related sample size restrictions and obtaining the first optimal complexity bounds for the full range of sample sizes without reward perturbation.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Matthew Zurek;Yudong Chen",
        "authorids": "~Matthew_Zurek1;~Yudong_Chen1",
        "gender": ";M",
        "homepage": ";https://pages.cs.wisc.edu/~yudongchen/",
        "dblp": ";15/1975-1",
        "google_scholar": ";ze5rCdwAAAAJ",
        "orcid": ";0000-0002-6416-5635",
        "linkedin": ";",
        "or_profile": "~Matthew_Zurek1;~Yudong_Chen1",
        "aff": ";Department of Computer Sciences, University of Wisconsin - Madison",
        "aff_domain": ";cs.wisc.edu",
        "position": ";Associate Professor",
        "bibtex": "@inproceedings{\nzurek2025the,\ntitle={The Plugin Approach for Average-Reward and Discounted {MDP}s: Optimal Sample Complexity Analysis},\nauthor={Matthew Zurek and Yudong Chen},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=WXGDyFsooW}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_Git6;DpK8;UQ2c;HSEG",
        "site": "https://openreview.net/forum?id=WXGDyFsooW",
        "pdf_size": 0,
        "rating": "0;6;6;7",
        "confidence": "5;2;3;3",
        "wc_review": "",
        "rating_avg": [
            4.75,
            2.7726341266023544
        ],
        "confidence_avg": [
            3.25,
            1.0897247358851685
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": -0.8894859640679303
    },
    {
        "id": "WzfgnrS87A",
        "title": "Strategyproof Learning with Advice",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "An important challenge in robust machine learning is when training data is provided by strategic sources who may intentionally report erroneous data for their own benefit. A line of work at the intersection of machine learning and mechanism design aims to deter strategic agents from reporting erroneous training data by designing learning algorithms that are strategyproof. Strategyproofness is a strong and desirable property, but it comes at a cost in the approximation ratio of even simple risk minimization problems. \n    \nIn this paper, we study strategyproof regression and classification problems in a model with advice. This model is part of a recent line on mechanism design with advice where the goal is to achieve both an improved approximation ratio when the advice is correct (consistency) and a bounded approximation ratio when the advice is incorrect (robustness). We provide the first non-trivial consistency-robustness tradeoffs for strategyproof regression and classification, which hold for simple yet interesting classes of functions. For classes of constant functions, we give a deterministic and strategyproof  mechanism that is, for any $\\gamma \\in (0, 2]$, $1+\\gamma$ consistent and $1 + 4/\\gamma$ robust and provide a lower bound that shows that this tradeoff is optimal. We extend this mechanism and its guarantees to homogeneous linear regression over $\\mathbb{R}$. In the binary classification problem of selecting from three or more labelings, we present strong impossibility results for both deterministic and randomized mechanism. Finally, we provide deterministic and randomized mechanisms for selecting from two labelings.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eric Balkanski;Cherlin Zhu",
        "authorids": "~Eric_Balkanski2;~Cherlin_Zhu1",
        "gender": ";F",
        "homepage": "http://ericbalkanski.com;https://ieor.columbia.edu/content/cherlin-zhu",
        "dblp": ";",
        "google_scholar": ";",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Eric_Balkanski2;~Cherlin_Zhu1",
        "aff": "Columbia University;Columbia University",
        "aff_domain": "columbia.edu;columbia.edu",
        "position": "Assistant Professor;PhD student",
        "bibtex": "@inproceedings{\nbalkanski2025strategyproof,\ntitle={Strategyproof Learning with Advice},\nauthor={Eric Balkanski and Cherlin Zhu},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=WzfgnrS87A}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_rAEk;bvB7;mHbv;VQ4U;QqoV",
        "site": "https://openreview.net/forum?id=WzfgnrS87A",
        "pdf_size": 0,
        "rating": "0;0;6;7;7;8",
        "confidence": "0;5;3;3;3;3",
        "wc_review": "",
        "rating_avg": [
            4.666666666666667,
            3.3499585403736303
        ],
        "confidence_avg": [
            2.8333333333333335,
            1.462494064565354
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            12,
            0
        ],
        "corr_rating_confidence": 0.15875301651315227
    },
    {
        "id": "XCrvIGhVqO",
        "title": "Cost-Free Fairness in Online Correlation Clustering",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In the correlation clustering problem, the input is a signed graph where the sign indicates whether pairs of nodes should be placed in the same cluster or not. The goal is to create a clustering that minimizes the number of disagreements with these signs.\nCorrelation clustering is a key unsupervised learning problem with many practical applications, and it has been widely studied in various settings, including versions with fairness constraints and cases where nodes arrive online.\nIn this paper, we explore a problem that combines these two settings: nodes arrive online, reveal their membership in protected groups upon arrival and we are only allowed to output fair clusters, i.e., clusters where the representation of each protected group is upper bounded by a user specified constant in the beginning of the arrival sequence.\nOur aim is to maintain an approximately optimal fair clustering while minimizing the worst-case  recourse of a node, i.e., the number of times a node changes clusters.\nWe present an algorithm that achieves worst-case logarithmic recourse per node while maintaining a constant-factor fair approximate clustering. Additionally, our approach simplifies the algorithm and analysis used in prior work in the online setting with recourse.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Eric Balkanski;Jason Chatzitheodorou;Andreas Maggiori",
        "authorids": "~Eric_Balkanski2;~Jason_Chatzitheodorou1;~Andreas_Maggiori1",
        "gender": ";;M",
        "homepage": "http://ericbalkanski.com;https://ieor.columbia.edu/content/iason-chatzitheodorou;",
        "dblp": ";;239/5932",
        "google_scholar": ";;2QzQRW4AAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Eric_Balkanski2;~Jason_Chatzitheodorou1;~Andreas_Maggiori1",
        "aff": "Columbia University;Columbia University;Columbia University",
        "aff_domain": "columbia.edu;columbia.edu;columbia.edu",
        "position": "Assistant Professor;PhD student;Postdoc",
        "bibtex": "@inproceedings{\nbalkanski2025costfree,\ntitle={Cost-Free Fairness in Online Correlation Clustering},\nauthor={Eric Balkanski and Jason Chatzitheodorou and Andreas Maggiori},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=XCrvIGhVqO}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_jfFJ;eEcB;Ntqa;N26N",
        "site": "https://openreview.net/forum?id=XCrvIGhVqO",
        "pdf_size": 0,
        "rating": "0;7;7;7",
        "confidence": "4;2;3;4",
        "wc_review": "",
        "rating_avg": [
            5.25,
            3.031088913245535
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": -0.5222329678670935
    },
    {
        "id": "XkyyvBcvA9",
        "title": "Error dynamics of mini-batch gradient descent with random reshuffling for least squares regression",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the discrete dynamics of mini-batch gradient descent with random reshuffling for least squares regression. We show that the training and generalization errors depend on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\\widetilde{X}$ in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. However, mini-batch gradient descent with random reshuffling exhibits a subtle dependence on the step size that a gradient flow analysis cannot detect, such as converging to a limit that depends on the step size. By comparing $Z$, a non-commutative polynomial of random matrices, with the sample covariance matrix of $X$ asymptotically, we demonstrate that batching affects the dynamics by resulting in a form of shrinkage on the spectrum.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Jackie Lok;Rishi Sonthalia;Elizaveta Rebrova",
        "authorids": "~Jackie_Lok1;~Rishi_Sonthalia1;~Elizaveta_Rebrova2",
        "gender": ";M;F",
        "homepage": "https://jackielok.github.io/;https://sites.google.com/umich.edu/rsonthal/home;https://erebrova.github.io/",
        "dblp": ";223/5758;",
        "google_scholar": ";HYozgRsAAAAJ;nZ27XjIAAAAJ",
        "orcid": ";;",
        "linkedin": ";rishi-sonthalia-53b44795/;",
        "or_profile": "~Jackie_Lok1;~Rishi_Sonthalia1;~Elizaveta_Rebrova2",
        "aff": "Princeton University;Boston College;Princeton University",
        "aff_domain": "princeton.edu;bc.edu;princeton.edu",
        "position": "PhD student;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nlok2025error,\ntitle={Error dynamics of mini-batch gradient descent with random reshuffling for least squares regression},\nauthor={Jackie Lok and Rishi Sonthalia and Elizaveta Rebrova},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=XkyyvBcvA9}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_QgmX;TVp9;RZLR;nCo7",
        "site": "https://openreview.net/forum?id=XkyyvBcvA9",
        "pdf_size": 0,
        "rating": "0;4;6;7",
        "confidence": "3;4;3;3",
        "wc_review": "",
        "rating_avg": [
            4.25,
            2.680951323690902
        ],
        "confidence_avg": [
            3.25,
            0.4330127018922193
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            18,
            0
        ],
        "corr_rating_confidence": -0.05383819020581655
    },
    {
        "id": "Y08eqbmCDD",
        "title": "The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the generalization performance of gradient methods in the fundamental stochastic convex optimization setting, focusing on its dimension dependence. First, for full-batch gradient descent (GD) we give a construction of a learning problem in dimension $d=O(n^2)$, where the canonical version of GD (tuned for optimal performance on the empirical risk) trained with $n$ training examples converges, with constant probability, to an approximate empirical risk minimizer with $\\Omega(1)$ population excess risk.\nOur bound translates to a lower bound of $\\smash{\\Omega(\\sqrt{d})}$ on the number of training examples required for standard GD to reach a non-trivial test error, answering an open question raised by Feldman (2016) and Amir, Koren and Livni (2021) and showing that a non-trivial dimension dependence is unavoidable. Furthermore, for standard one-pass stochastic gradient descent (SGD), we show that an application of the same construction technique provides a similar $\\smash{\\Omega(\\sqrt{d})}$ lower bound for the sample complexity of SGD to reach a non-trivial empirical error, despite achieving optimal test performance. This again provides for an exponential improvement in the dimension dependence compared to previous work (Koren et al., 2022), resolving an open question left therein.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Matan Schliserman;Uri Sherman;Tomer Koren",
        "authorids": "~Matan_Schliserman1;~Uri_Sherman1;~Tomer_Koren1",
        "gender": "M;M;M",
        "homepage": ";https://urisherman.github.io/;https://tomerkoren.github.io",
        "dblp": "314/6601;284/9712;12/10044",
        "google_scholar": ";https://scholar.google.co.il/citations?hl=en;wGG1voYAAAAJ",
        "orcid": ";;",
        "linkedin": ";uri-sherman-a1b85924/;",
        "or_profile": "~Matan_Schliserman1;~Uri_Sherman1;~Tomer_Koren1",
        "aff": "Tel Aviv University;Tel Aviv University;Tel Aviv University",
        "aff_domain": "tau.ac.il;tau.ac.il;tau.ac.il",
        "position": "PhD student;PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nschliserman2025the,\ntitle={The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization},\nauthor={Matan Schliserman and Uri Sherman and Tomer Koren},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=Y08eqbmCDD}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_s9jv;NCzh;AE5G;s8ww",
        "site": "https://openreview.net/forum?id=Y08eqbmCDD",
        "pdf_size": 0,
        "rating": "0;0;7;7;7",
        "confidence": "0;4;4;3;3",
        "wc_review": "",
        "rating_avg": [
            4.2,
            3.429285639896449
        ],
        "confidence_avg": [
            2.8,
            1.469693845669907
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            5,
            0
        ],
        "corr_rating_confidence": 0.4444444444444445
    },
    {
        "id": "bNkKkQM9wx",
        "title": "Efficient Optimal PAC Learning",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent advances in the binary classification setting by Hanneke (2016) and Larsen (2023) have\nresulted in optimal PAC learners. These learners leverage, respectively, a clever deterministic subsam-\npling scheme and the classic heuristic of bagging Breiman (1996). Both optimal PAC learners use, as\na subroutine, the natural algorithm of empirical risk minimization. Consequently, the computational\ncost of these optimal PAC learners is tied to that of the empirical risk minimizer algorithm.\nIn this work, we seek to provide an alternative perspective on the computational cost imposed by the\nlink to the empirical risk minimizer algorithm. To this end, we show the existence of an optimal PAC\nlearner, which offers a different tradeoff in terms of the computational cost induced by the empirical\nrisk minimizer.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Mikael M\u00f8ller H\u00f8gsgaard",
        "authorids": "~Mikael_M\u00f8ller_H\u00f8gsgaard1",
        "gender": "M",
        "homepage": "https://pure.au.dk/portal/da/persons/mikael-moeller-hoegsgaard(3b07133a-329d-4585-a864-d37c7cb9056b).html",
        "dblp": "295/8599",
        "google_scholar": "",
        "orcid": "",
        "linkedin": "",
        "or_profile": "~Mikael_M\u00f8ller_H\u00f8gsgaard1",
        "aff": "Aarhus University",
        "aff_domain": "cs.au.dk",
        "position": "PhD student",
        "bibtex": "@inproceedings{\nhgsgaard2025efficient,\ntitle={Efficient Optimal {PAC} Learning},\nauthor={Mikael M{\\o}ller H{\\o}gsgaard},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=bNkKkQM9wx}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_2pon;Xr3A;51iT;hiHW",
        "site": "https://openreview.net/forum?id=bNkKkQM9wx",
        "pdf_size": 0,
        "rating": "0;6;7;8",
        "confidence": "5;2;2;4",
        "wc_review": "",
        "rating_avg": [
            5.25,
            3.112474899497183
        ],
        "confidence_avg": [
            3.25,
            1.299038105676658
        ],
        "authors#_avg": [
            1,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            11,
            0
        ],
        "corr_rating_confidence": -0.63377649087223
    },
    {
        "id": "bwuYQ89hke",
        "title": "Online Learning of Quantum States with Logarithmic Loss via VB-FTRL",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Online learning of quantum states with the logarithmic loss (LL-OLQS) is a quantum generalization of online portfolio selection (OPS), a classic open problem in online learning for over three decades. This problem also emerges in designing stochastic optimization algorithms for maximum-likelihood quantum state tomography. Recently, J\u00e9z\u00e9quel et al. (2022, arXiv:2209.13932) proposed the VB-FTRL algorithm, the first regret-optimal algorithm for OPS with moderate computational complexity. In this paper, we generalize VB-FTRL for LL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The generalized algorithm achieves a regret rate of $O ( d^2 \\log ( d + T ) )$ for LL-OLQS. Each iteration of the algorithm consists of solving a semidefinite program that can be implemented in polynomial time by, for example, cutting-plane methods. For comparison, the best-known regret rate for LL-OLQS is currently $O ( d^2 \\log T )$, achieved by an exponential weight method. However, no explicit implementation is available for the exponential weight method for LL-OLQS. To facilitate the generalization, we introduce the notion of VB-convexity. VB-convexity is a sufficient condition for the volumetric barrier associated with any function to be convex and is of independent interest.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Wei-Fu Tseng;Kai-Chun Chen;Zi-Hong Xiao;Yen-Huan Li",
        "authorids": "weifu.tseng03@gmail.com;casper901208@gmail.com;eric@xiao.tw;~Yen-Huan_Li1",
        "gender": ";;;",
        "homepage": ";;;https://sites.google.com/site/yenhuanli/",
        "dblp": ";;;70/1370",
        "google_scholar": ";;;Mqz_yhAAAAAJ",
        "orcid": ";;;",
        "linkedin": ";;;",
        "or_profile": "weifu.tseng03@gmail.com;casper901208@gmail.com;eric@xiao.tw;~Yen-Huan_Li1",
        "aff": ";;;National Taiwan University",
        "aff_domain": ";;;ntu.edu.tw",
        "position": ";;;Associate Professor",
        "bibtex": "@inproceedings{\ntseng2025online,\ntitle={Online Learning of Quantum States with Logarithmic Loss via {VB}-{FTRL}},\nauthor={Wei-Fu Tseng and Kai-Chun Chen and Zi-Hong Xiao and Yen-Huan Li},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=bwuYQ89hke}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_XciH;ubiv;b7RH;m5x2",
        "site": "https://openreview.net/forum?id=bwuYQ89hke",
        "pdf_size": 0,
        "rating": "0;7;7;8",
        "confidence": "5;3;2;4",
        "wc_review": "",
        "rating_avg": [
            5.5,
            3.2015621187164243
        ],
        "confidence_avg": [
            3.5,
            1.118033988749895
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": -0.6984302957695783
    },
    {
        "id": "cf874WmsJC",
        "title": "Logarithmic Regret for Unconstrained Submodular Maximization Stochastic Bandit",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We address the *online unconstrained submodular maximization problem* (Online USM), in a setting with *stochastic bandit feedback*. In this framework, a decision-maker receives noisy rewards from a non monotone submodular function taking values in a known bounded interval. This paper proposes *Double-Greedy - Explore-then-Commit* (DG-ETC), adapting the Double-Greedy approach from the offline and online full-information settings. DG-ETC satisfies a $O(d\\log(dT))$ problem-dependent upper bound for the $1/2$-approximate pseudo-regret, as well as a  $O(dT^{2/3}\\log(dT)^{1/3})$ problem-free one at the same time, outperforming existing approaches. In particular, we introduce a problem-dependent notion of hardness characterizing the transition between logarithmic and polynomial regime for the upper bounds.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Julien Zhou;Pierre Gaillard;Thibaud Rahier;Julyan Arbel",
        "authorids": "~Julien_Zhou1;~Pierre_Gaillard1;~Thibaud_Rahier1;~Julyan_Arbel1",
        "gender": "M;M;M;M",
        "homepage": "https://jlnzhou.github.io/;http://pierre.gaillard.me;;http://www.julyanarbel.com/",
        "dblp": "371/2724;25/2131;;172/8198",
        "google_scholar": ";https://scholar.google.fr/citations?user=-CPaGaEAAAAJ;;Q7P4K3wAAAAJ",
        "orcid": ";0000-0001-6777-6127;;0000-0002-2525-4416",
        "linkedin": ";;;julyanarbel/",
        "or_profile": "~Julien_Zhou1;~Pierre_Gaillard1;~Thibaud_Rahier1;~Julyan_Arbel1",
        "aff": "Universit\u00e9 Grenoble Alpes+Criteo;INRIA;;Inria",
        "aff_domain": "univ-grenoble-alpes.fr+criteo.com;inria.fr;;inria.fr",
        "position": "PhD student+PhD student;Researcher;;Researcher",
        "bibtex": "@inproceedings{\nzhou2025logarithmic,\ntitle={Logarithmic Regret for Unconstrained Submodular Maximization Stochastic Bandit},\nauthor={Julien Zhou and Pierre Gaillard and Thibaud Rahier and Julyan Arbel},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=cf874WmsJC}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_DeY9;F8Nf;JVqR;NEMd;UozH",
        "site": "https://openreview.net/forum?id=cf874WmsJC",
        "pdf_size": 0,
        "rating": "0;0;6;6;7;7",
        "confidence": "0;4;3;3;4;2",
        "wc_review": "",
        "rating_avg": [
            4.333333333333333,
            3.0912061651652345
        ],
        "confidence_avg": [
            2.6666666666666665,
            1.3743685418725535
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            10,
            0
        ],
        "corr_rating_confidence": 0.33999275762786196
    },
    {
        "id": "gFViGKoKDq",
        "title": "On the Hardness of Learning One Hidden Layer Neural Networks",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In this work, we consider the problem of learning one hidden layer ReLU neural networks with inputs from $\\mathbb{R}^d$. We show that this learning problem is hard under standard cryptographic assumptions even when: (1) the size of the neural network is polynomial in $d$, (2) its input distribution is a standard Gaussian, and (3) the noise is Gaussian and polynomially small in $d$. Our hardness result is based on the hardness of the Continuous Learning with Errors (CLWE) problem, and in particular, is based on the largely believed worst-case hardness of approximately solving the shortest vector problem up to a multiplicative polynomial factor.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Shuchen Li;Ilias Zadik;Manolis Zampetakis",
        "authorids": "~Shuchen_Li1;~Ilias_Zadik2;~Manolis_Zampetakis2",
        "gender": "M;M;M",
        "homepage": "https://li-shuchen.github.io;https://iliaszadik.github.io/;https://mzampet.com/",
        "dblp": ";https://dblp.org/pers/z/Zadik:Ilias.html;",
        "google_scholar": ";https://scholar.google.co.il/citations?user=okLwXk0AAAAJ;",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Shuchen_Li1;~Ilias_Zadik2;~Manolis_Zampetakis2",
        "aff": "Yale University;Yale University;Yale University",
        "aff_domain": "yale.edu;yale.edu;yale.edu",
        "position": "PhD student;Assistant Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nli2025on,\ntitle={On the Hardness of Learning One Hidden Layer Neural Networks},\nauthor={Shuchen Li and Ilias Zadik and Manolis Zampetakis},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=gFViGKoKDq}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_gq7K;BbSU;9Mcu;AUwi",
        "site": "https://openreview.net/forum?id=gFViGKoKDq",
        "pdf_size": 0,
        "rating": "0;0;6;6;7",
        "confidence": "0;5;3;4;4",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.124099870362662
        ],
        "confidence_avg": [
            3.2,
            1.7204650534085253
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": 0.34233165417947625
    },
    {
        "id": "lEhg21XO0R",
        "title": "Proper Learnability and the Role of Unlabeled Data",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Proper learning refers to the setting in which learners must emit predictors in the underlying hypothesis class $\\mathcal{H}$, and often leads to learners with simple algorithmic forms (e.g., empirical risk minimization (ERM), structural risk minimization (SRM)). The limitation of proper learning, however, is that there exist problems which can only be learned improperly, e.g. in multiclass classification. Thus, we ask: Under what assumptions on the hypothesis class or the information provided to the learner is a problem properly learnable? We first demonstrate that when the unlabeled data distribution is given, there always exists an optimal proper learner. We refer to this as the $\\textit{distribution-fixed}$ PAC model, and continue to evaluate the learner on its worst-case performance over all distributions. Our result holds for all metric loss functions and any finite learning problem (with no dependence on its size). Further, we demonstrate that sample complexities in the distribution-fixed PAC model can shrink by only a logarithmic factor from the classic PAC model, strongly refuting the role of unlabeled data in PAC learning (from a worst-case perspective). \n\nWe complement this with impossibility results which obstruct any characterization of proper learnability in the classic (realizable) PAC model. First, we observe that there are problems whose proper learnability is logically $\\textit{undecidable}$, i.e., independent of the ZFC axioms. We also show that proper learnability is not a monotone property of the underlying hypothesis class, and that it is not a $\\textit{local}$ property (in a formal sense). We also point out how the non-monotonicity of proper learning obstructs relaxations of the distribution-fixed model that preserve proper learnability, including natural notions of class-conditional learning of the unlabeled data distribution.  Our impossibility results all hold even for the fundamental setting of multiclass classification, and go through a reduction of EMX learning (Ben-David et al., 2019) to classification which may be of independent interest.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Julian Asilis;Siddartha Devic;Shaddin Dughmi;Vatsal Sharan;Shang-Hua Teng",
        "authorids": "~Julian_Asilis1;~Siddartha_Devic1;~Shaddin_Dughmi1;~Vatsal_Sharan1;~Shang-Hua_Teng1",
        "gender": "M;;;M;M",
        "homepage": "https://jasilis.com/;http://sid.devic.us/;;https://vatsalsharan.github.io/;https://viterbi-web.usc.edu/~shanghua/",
        "dblp": "307/5139;239/8389;;126/2543;t/ShangHuaTeng",
        "google_scholar": "Cu3RV2UAAAAJ;LVL-kmUAAAAJ;;Ize17HEAAAAJ;JknkZcQAAAAJ",
        "orcid": ";;;;0000-0001-5011-4514",
        "linkedin": ";;;;shanghua-teng-a295598",
        "or_profile": "~Julian_Asilis1;~Siddartha_Devic1;~Shaddin_Dughmi1;~Vatsal_Sharan1;~Shang-Hua_Teng1",
        "aff": "University of Southern California;University of Southern California+Apple;;University of Southern California;University of Southern California",
        "aff_domain": "usc.edu;usc.edu+apple.com;;usc.edu;usc.edu",
        "position": "PhD student;PhD student+Intern;;Assistant Professor;Full Professor",
        "bibtex": "@inproceedings{\nasilis2025proper,\ntitle={Proper Learnability and the Role of Unlabeled Data},\nauthor={Julian Asilis and Siddartha Devic and Shaddin Dughmi and Vatsal Sharan and Shang-Hua Teng},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=lEhg21XO0R}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_oBCt;1Y2D;xRN8;DaG9;2CNW",
        "site": "https://openreview.net/forum?id=lEhg21XO0R",
        "pdf_size": 0,
        "rating": "0;0;6;7;7;7",
        "confidence": "0;5;4;2;3;4",
        "wc_review": "",
        "rating_avg": [
            4.5,
            3.2015621187164243
        ],
        "confidence_avg": [
            3.0,
            1.632993161855452
        ],
        "authors#_avg": [
            5,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            11,
            0
        ],
        "corr_rating_confidence": 0.1912730139190015
    },
    {
        "id": "nIBYq3O2HG",
        "title": "Optimal Rates for O(1)-Smooth DP-SCO with a Single Epoch and Large Batches",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In this paper we revisit the DP stochastic convex optimization (SCO) problem. For convex smooth losses, it is well known that the canonical DP-SGD (stochastic gradient descent) achieves the optimal rate of $O\\left(\\frac{LR}{\\sqrt{n}} + \\frac{LR \\sqrt{p \\log(1/\\delta)}}{\\epsilon n}\\right)$ under $(\\epsilon, \\delta)$-DP, and also well-known that variants of DP-SGD it can achieve the optimal rate in a single epoch. However, the batch gradient complexity (i.e., number of adaptive optimization steps), which is important in applications like federated learning, is less well-understood. In particular, all prior work on DP-SCO requires $\\Omega(n)$ batch gradient steps, multiple epochs, or convexity for privacy.\n\nWe propose an algorithm, Accelerated-DP-SRGD (stochastic recursive gradient descent), which bypasses the limitations of past work: it achieves the optimal rate for DP-SCO (up to polylog factors), in a single epoch using  $\\sqrt{n}$ batch gradient steps with batch size $\\sqrt{n}$, and can be made private for arbitrary (non-convex) losses via clipping. If the global minimizer is in the constraint set, we can further improve this to $n^{1/4}$ batch gradient steps with batch size $n^{3/4}$. To achieve this, our algorithm combines three key ingredients, a variant of stochastic recursive gradients (SRG), accelerated gradient descent, and correlated noise generation from DP continual counting.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Christopher A. Choquette-Choo;Arun Ganesh;Abhradeep Guha Thakurta",
        "authorids": "~Christopher_A._Choquette-Choo1;~Arun_Ganesh1;~Abhradeep_Guha_Thakurta1",
        "gender": "M;M;M",
        "homepage": "https://www.christopherchoquette.com;https://people.eecs.berkeley.edu/~arunganesh/;https://athakurta.squarespace.com/",
        "dblp": "250/9674;201/4732;31/8315",
        "google_scholar": "oDE4I64AAAAJ;fmwchbsAAAAJ;1rV69hMAAAAJ",
        "orcid": ";;",
        "linkedin": "christopher-choquette-choo/;;",
        "or_profile": "~Christopher_A._Choquette-Choo1;~Arun_Ganesh1;~Abhradeep_Guha_Thakurta1",
        "aff": "Google DeepMind;Google;Google",
        "aff_domain": "google.com;google.com;google.com",
        "position": "Research Scientist;Researcher;Senior Research Scientist",
        "bibtex": "@inproceedings{\nchoquette-choo2025optimal,\ntitle={Optimal Rates for O(1)-Smooth {DP}-{SCO} with a Single Epoch and Large Batches},\nauthor={Christopher A. Choquette-Choo and Arun Ganesh and Abhradeep Guha Thakurta},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=nIBYq3O2HG}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_Eog3;Ggyu;ke9a;RdzJ",
        "site": "https://openreview.net/forum?id=nIBYq3O2HG",
        "pdf_size": 0,
        "rating": "0;6;6;7",
        "confidence": "4;3;4;4",
        "wc_review": "",
        "rating_avg": [
            4.75,
            2.7726341266023544
        ],
        "confidence_avg": [
            3.75,
            0.4330127018922193
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            9,
            0
        ],
        "corr_rating_confidence": -0.26028960314767674
    },
    {
        "id": "nZIFBtNuJi",
        "title": "A Model for Combinatorial Dictionary Learning and Inference",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We are often interested in decomposing complex, structured data into simple components that explain the data. The linear version of this problem is well-studied as dictionary learning and factor analysis. In this work, we propose a combinatorial model in which to study this question, motivated by the way objects occlude each other in a scene to form an image. \n  First, we identify a property we call ``well-structuredness'' of a set of low-dimensional components which ensures that no two components in the set are {\\em too} similar. \n  We show how well-structuredness is sufficient for learning the set of latent components comprising a set of sample instances. We then consider the problem: \n  given a set of components and an instance generated from some unknown subset of them, \n  identify which parts of the instance arise from which components. We consider two variants: (1) determine the minimal number of components required to explain the instance; (2) determine the {\\em correct} explanation for as many locations as possible. For the latter goal, we also devise a version that is robust to adversarial corruptions, with just a slightly stronger assumption on the components. Finally, we show that the learning problem is computationally infeasible in the absence of any assumptions.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Avrim Blum;Kavya Ravichandran",
        "authorids": "~Avrim_Blum1;~Kavya_Ravichandran2",
        "gender": "M;F",
        "homepage": "https://home.ttic.edu/~avrim/;https://kavyar314.github.io/",
        "dblp": "b/AvrimBlum;",
        "google_scholar": "https://scholar.google.com.tw/citations?user=Jlv4MR4AAAAJ;",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Avrim_Blum1;~Kavya_Ravichandran2",
        "aff": "Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago",
        "aff_domain": "ttic.edu;ttic.edu",
        "position": "Full Professor;PhD student",
        "bibtex": "@inproceedings{\nblum2025a,\ntitle={A Model for Combinatorial Dictionary Learning and Inference},\nauthor={Avrim Blum and Kavya Ravichandran},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=nZIFBtNuJi}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_oobc;ado3;cdrB;YwbN",
        "site": "https://openreview.net/forum?id=nZIFBtNuJi",
        "pdf_size": 0,
        "rating": "0;5;6;7",
        "confidence": "4;3;2;4",
        "wc_review": "",
        "rating_avg": [
            4.5,
            2.692582403567252
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": -0.391924757669098
    },
    {
        "id": "nv8POnFtNa",
        "title": "A Complete Characterization of Learnability for Stochastic Noisy Bandits",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study the stochastic noisy bandit problem with an unknown reward function $f^*$ in a known function class $\\mathcal{F}$. Formally, a model $M$ maps arms $\\pi$ to a probability distribution $M(\\pi)$ of reward. A model class $\\mathcal{M}$ is a collection of models. For each model $M$, define its mean reward function $f^M(\\pi)=\\mathbb{E}_{r \\sim M(\\pi)}[r]$.  In the bandit learning problem, we proceed in rounds, pulling one arm $\\pi$ each round and observing a reward sampled from $M(\\pi)$. With knowledge of $\\mathcal{M}$, supposing that the true model $M\\in \\mathcal{M}$, the objective is to identify an arm $\\hat{\\pi}$ of near-maximal mean reward $f^M(\\hat{\\pi})$ with high probability in a bounded number of rounds. If this is possible, then the model class is said to be learnable. \n\nImportantly, a result of Hanneke and Yang (2023)  shows there exist model classes for which learnability is undecidable. However, the model class they consider features deterministic rewards, and they raise the question of whether learnability is decidable for classes containing sufficiently noisy models. More formally, for any function class $\\mathcal{F}$ of mean reward functions, we denote by $\\mathcal{M}_{\\mathcal{F}}$ the set of all models $M$ such that $f^M \\in \\mathcal{F}$. In other words, $\\mathcal{M} _{\\mathcal{F}}$ admits arbitrary zero-mean noise. Hanneke and Yang (2023)  ask the question: Can one give a simple complete characterization of which function classes $\\mathcal{F}$ satisfy that $\\mathcal{M} _{\\mathcal{F}}$ is learnable?\n\nFor the first time, we answer this question in the positive by giving a complete characterization of learnability for model classes $\\mathcal{M}_{\\mathcal{F}}$. In addition to that, we also describe the full spectrum of possible optimal query complexities. Further, we prove adaptivity is sometimes necessary to achieve the optimal query complexity. Last, we revisit an important complexity measure for interactive decision making, the Decision-Estimation-Coefficient (Foster et al., 2021, 2023),  and propose a new variant of the DEC which also characterizes learnability in this setting.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Steve Hanneke;Kun Wang",
        "authorids": "~Steve_Hanneke1;~Kun_Wang9",
        "gender": "M;M",
        "homepage": "http://www.stevehanneke.com;https://a865143034.github.io",
        "dblp": "40/154;",
        "google_scholar": "fEhNO7YAAAAJ;3SGYEokAAAAJ",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Steve_Hanneke1;~Kun_Wang9",
        "aff": "Purdue University;Purdue University",
        "aff_domain": "purdue.edu;purdue.edu",
        "position": "Assistant Professor;PhD student",
        "bibtex": "@inproceedings{\nwang2025a,\ntitle={A Complete Characterization of Learnability for Stochastic Noisy Bandits},\nauthor={Kun Wang and Steve Hanneke},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=nv8POnFtNa}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_jVbV;VKQB;uSop;ZqVj",
        "site": "https://openreview.net/forum?id=nv8POnFtNa",
        "pdf_size": 0,
        "rating": "0;0;6;6;7",
        "confidence": "0;3;5;3;3",
        "wc_review": "",
        "rating_avg": [
            3.8,
            3.124099870362662
        ],
        "confidence_avg": [
            2.8,
            1.6
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            17,
            0
        ],
        "corr_rating_confidence": 0.6321820946686739
    },
    {
        "id": "oytwNAlEfY",
        "title": "Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We give nearly-tight upper and lower bounds for the {\\em improving multi-armed bandits} problem. An instance of this problem has $k$ arms, each of whose reward function is a concave and increasing function of the {\\em number of times that arm has been pulled so far}. We show that for any randomized online algorithm, there exists an instance on which it must suffer at least an $\\Omega(\\sqrt{k})$ approximation factor relative to the optimal reward. We then provide a randomized online algorithm that guarantees an $O(\\sqrt{k})$ approximation factor, if it is told the maximum reward achievable by the optimal arm in advance. We then show how to remove this assumption at the cost of an extra $O(\\log k)$ approximation factor, achieving an overall $O(\\sqrt{k} \\log k)$ approximation relative to optimal.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Avrim Blum;Kavya Ravichandran",
        "authorids": "~Avrim_Blum1;~Kavya_Ravichandran2",
        "gender": "M;F",
        "homepage": "https://home.ttic.edu/~avrim/;https://kavyar314.github.io/",
        "dblp": "b/AvrimBlum;",
        "google_scholar": "https://scholar.google.com.tw/citations?user=Jlv4MR4AAAAJ;",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Avrim_Blum1;~Kavya_Ravichandran2",
        "aff": "Toyota Technological Institute at Chicago;Toyota Technological Institute at Chicago",
        "aff_domain": "ttic.edu;ttic.edu",
        "position": "Full Professor;PhD student",
        "bibtex": "@inproceedings{\nblum2025nearlytight,\ntitle={Nearly-tight Approximation Guarantees for the Improving Multi-Armed Bandits Problem},\nauthor={Avrim Blum and Kavya Ravichandran},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=oytwNAlEfY}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_d54R;maSC;WTKj;S78y",
        "site": "https://openreview.net/forum?id=oytwNAlEfY",
        "pdf_size": 0,
        "rating": "0;5;6;8",
        "confidence": "4;4;4;2",
        "wc_review": "",
        "rating_avg": [
            4.75,
            2.947456530637899
        ],
        "confidence_avg": [
            3.5,
            0.8660254037844386
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": -0.6366127389367093
    },
    {
        "id": "pT05NE9KNs",
        "title": "When and why randomised exploration works (in linear bandits)",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We provide an approach for the analysis of randomised exploration algorithms like Thompson sampling that does not rely on forced optimism or posterior inflation. With this, we demonstrate that in the $d$-dimensional linear bandit setting, when the action space is smooth and strongly convex, randomised exploration algorithms enjoy an $n$-step regret bound of the order $O(d\\sqrt{n} \\log(n))$. \nNotably, this shows for the first time that there exist non-trivial linear bandit settings where Thompson sampling can achieve optimal dimension dependence in the regret.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Marc Abeille;David Janz;Ciara Pike-Burke",
        "authorids": "~Marc_Abeille1;~David_Janz1;~Ciara_Pike-Burke2",
        "gender": ";M;",
        "homepage": "https://scholar.google.com/citations?user=0WsQ0uUAAAAJ&hl=fr&oi=ao;http://www.djanz.org;https://www.ma.imperial.ac.uk/~cpikebur/",
        "dblp": "190/7290;190/7685;202/1263",
        "google_scholar": ";https://scholar.google.co.uk/citations?user=rI5XB7sAAAAJ;Hl1vu1MAAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Marc_Abeille1;~David_Janz1;~Ciara_Pike-Burke2",
        "aff": "Criteo;University of Alberta;Imperial College London",
        "aff_domain": "criteo.com;ualberta.ca;imperial.ac.uk",
        "position": "Researcher;Postdoc;Lecturer",
        "bibtex": "@inproceedings{\nabeille2025when,\ntitle={When and why randomised exploration works (in linear bandits)},\nauthor={Marc Abeille and David Janz and Ciara Pike-Burke},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=pT05NE9KNs}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_wXtj;aff2;Ue2r;xrrF",
        "site": "https://openreview.net/forum?id=pT05NE9KNs",
        "pdf_size": 0,
        "rating": "0;0;7;7;8",
        "confidence": "0;4;4;3;4",
        "wc_review": "",
        "rating_avg": [
            4.4,
            3.6110940170535577
        ],
        "confidence_avg": [
            3.0,
            1.5491933384829668
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            10,
            0
        ],
        "corr_rating_confidence": 0.5362617710750641
    },
    {
        "id": "qbktUD8REC",
        "title": "Differentially Private Multi-Sampling from Distributions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Many algorithms have been developed to estimate probability distributions subject to differential privacy\n(DP): such an algorithm takes as input independent samples from a distribution and estimates the density\nfunction in a way that is insensitive to any one sample. A recent line of work, initiated by Raskhodnikova\net al. (Neurips \u201921), explores a weaker objective: a differentially private algorithm that approximates\na single sample from the distribution. Raskhodnikova et al. studied the sample complexity of DP\nsingle-sampling i.e., the minimum number of samples needed to perform this task. They showed that the\nsample complexity of DP single-sampling is less than the sample complexity of DP learning for certain\ndistribution classes. We define two variants of multi-sampling, where the goal is to privately approximate\n$m > 1$ samples. This better models the realistic scenario where synthetic data is needed for exploratory\ndata analysis.\n\nA baseline solution to multi-sampling is to invoke a single-sampling algorithm $m$ times on independently drawn datasets of samples. When the data comes from a finite domain, we improve over the baseline by a factor of $m$ in the sample complexity. When the data comes from a Gaussian, Ghazi et al. (Neurips \u201923) show that single-sampling can be performed under approximate differential privacy; we\nshow it is possible to single- and multi-sample Gaussians with known covariance subject to pure DP. Our\nsolution uses a variant of the Laplace mechanism that is of independent interest.\n\nWe also give sample complexity lower bounds, one for strong multi-sampling of finite distributions\nand another for weak multi-sampling of bounded-covariance Gaussians.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Albert Cheu;Debanuj Nayak",
        "authorids": "~Albert_Cheu1;~Debanuj_Nayak1",
        "gender": "M;M",
        "homepage": "https://albertcheu.com;https://debanujnayak.github.io/",
        "dblp": "209/9888;262/6598",
        "google_scholar": ";V4T2eSMAAAAJ",
        "orcid": ";",
        "linkedin": ";",
        "or_profile": "~Albert_Cheu1;~Debanuj_Nayak1",
        "aff": "Google;Boston University",
        "aff_domain": "google.com;bu.edu",
        "position": "Researcher;PhD student",
        "bibtex": "@inproceedings{\ncheu2025differentially,\ntitle={Differentially Private Multi-Sampling from Distributions},\nauthor={Albert Cheu and Debanuj Nayak},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=qbktUD8REC}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Authors;Area_Chair_Dqg1;Z8Uc;gp62;dCNx",
        "site": "https://openreview.net/forum?id=qbktUD8REC",
        "pdf_size": 0,
        "rating": "0;0;0;6;7;7",
        "confidence": "0;0;5;3;4;3",
        "wc_review": "",
        "rating_avg": [
            3.3333333333333335,
            3.34995854037363
        ],
        "confidence_avg": [
            2.5,
            1.8929694486000912
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.4468015119335245
    },
    {
        "id": "qgnVGFJMJo",
        "title": "Enhanced $H$-Consistency Bounds",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "Recent research has introduced a key notion of $H$-consistency bounds for surrogate losses. These bounds offer finite-sample guarantees, quantifying the relationship between the zero-one estimation error (or other target loss) and the surrogate loss estimation error for a specific hypothesis set. However, previous bounds were derived under the condition that a lower bound of the surrogate loss conditional regret is given as a convex function of the target conditional regret, without non-constant factors depending on the predictor or input instance. Can we derive finer and more favorable $H$-consistency bounds? In this work, we relax this condition and present a general framework for establishing *enhanced $H$-consistency bounds* based on more general inequalities relating conditional regrets. Our theorems not only subsume existing results as special cases but also enable the derivation of more favorable bounds in various scenarios. These include standard multi-class classification, binary and multi-class classification under Tsybakov noise conditions, and bipartite ranking.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Anqi Mao;Mehryar Mohri;Yutao Zhong",
        "authorids": "~Anqi_Mao1;~Mehryar_Mohri2;~Yutao_Zhong1",
        "gender": "F;M;",
        "homepage": "https://anqi-mao.github.io;https://cs.nyu.edu/~mohri/;",
        "dblp": "241/6864;03/5448;51/3178-2",
        "google_scholar": "nkjIZ-oAAAAJ;ktwwLjsAAAAJ;",
        "orcid": ";;",
        "linkedin": ";mehryar-mohri-3737b981/;",
        "or_profile": "~Anqi_Mao1;~Mehryar_Mohri2;~Yutao_Zhong1",
        "aff": "Courant Institute of Mathematical Sciences, NYU;New York University+Google Research;Google Research",
        "aff_domain": "cims.nyu.edu;nyu.edu+google.com;google.com",
        "position": "PhD student;Full Professor+Principal Researcher;Researcher",
        "bibtex": "@inproceedings{\nmao2025enhanced,\ntitle={Enhanced \\$H\\$-Consistency Bounds},\nauthor={Anqi Mao and Mehryar Mohri and Yutao Zhong},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=qgnVGFJMJo}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_3xRq;Tvdo;dSac;pL3N",
        "site": "https://openreview.net/forum?id=qgnVGFJMJo",
        "pdf_size": 0,
        "rating": "0;6;6;7",
        "confidence": "3;3;2;2",
        "wc_review": "",
        "rating_avg": [
            4.75,
            2.7726341266023544
        ],
        "confidence_avg": [
            2.5,
            0.5
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": -0.6311687442672026
    },
    {
        "id": "tKx9a84i8A",
        "title": "Minimax-optimal and Locally-adaptive Online Nonparametric Regression",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We study adversarial online nonparametric regression with general convex losses and propose a parameter-free learning algorithm that achieves minimax optimal rates. Our approach leverages chaining trees to compete against H\u00f6lder functions and establishes optimal regret bounds. While competing with nonparametric function classes can be challenging, they often exhibit local patterns - such as local H\u00f6lder continuity - that online algorithms can exploit. Without prior knowledge, our method dynamically tracks and adapts to different H\u00f6lder profiles by pruning a core chaining tree structure, aligning itself with local smoothness variations. This leads to the first computationally efficient algorithm with locally adaptive optimal rates for online regression in an adversarial setting. Finally, we discuss how these notions could be extended to a boosting framework, offering promising directions for future research.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Paul Liautaud;Pierre Gaillard;Olivier Wintenberger",
        "authorids": "~Paul_Liautaud1;~Pierre_Gaillard1;~Olivier_Wintenberger1",
        "gender": "M;M;M",
        "homepage": "https://perso.lpsm.paris/~liautaud/;http://pierre.gaillard.me;http://wintenberger.fr",
        "dblp": ";25/2131;144/7523",
        "google_scholar": ";https://scholar.google.fr/citations?user=-CPaGaEAAAAJ;",
        "orcid": ";0000-0001-6777-6127;",
        "linkedin": ";;",
        "or_profile": "~Paul_Liautaud1;~Pierre_Gaillard1;~Olivier_Wintenberger1",
        "aff": "Sorbonne Universit\u00e9 - Facult\u00e9 des Sciences (Paris VI);INRIA;LPSM",
        "aff_domain": "sorbonne-universite.fr;inria.fr;sorbonne-universite.fr",
        "position": "PhD student;Researcher;Full Professor",
        "bibtex": "@inproceedings{\nliautaud2025minimax,\ntitle={Minimax Adaptive Boosting for Online Nonparametric Regression},\nauthor={Paul Liautaud and Pierre Gaillard and Olivier Wintenberger},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=tKx9a84i8A}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_bTvc;Nj92;BB1n;hZXz",
        "site": "https://openreview.net/forum?id=tKx9a84i8A",
        "pdf_size": 0,
        "rating": "0;7;7;7",
        "confidence": "4;2;4;3",
        "wc_review": "",
        "rating_avg": [
            5.25,
            3.031088913245535
        ],
        "confidence_avg": [
            3.25,
            0.82915619758885
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": -0.5222329678670935
    },
    {
        "id": "u5xNVJlAse",
        "title": "Quantile Multi-Armed Bandits with 1-bit Feedback",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In this paper, we study a variant of best-arm identification involving elements of risk sensitivity and communication constraints. Specifically, the goal of the learner is to identify the arm with the highest quantile reward, while the communication from an agent (who observes rewards) and the learner (who chooses actions) is restricted to only one bit of feedback per arm pull. We propose an algorithm that utilizes noisy binary search as a subroutine, allowing the learner to estimate quantile rewards through 1-bit feedback. We derive an instance-dependent upper bound on the sample complexity of our algorithm and provide an algorithm-independent lower bound for specific instances, with the two matching to within logarithmic factors under mild conditions, or even to within constant factors in certain low error probability scaling regimes. The lower bound is applicable even in the absence of communication constraints, and thus we conclude that restricting to 1-bit feedback has a minimal impact on the scaling of the sample complexity.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Ivan Lau;Jonathan Scarlett",
        "authorids": "~Ivan_Lau1;~Jonathan_Scarlett1",
        "gender": ";M",
        "homepage": "https://ivanphlau.github.io/;https://www.comp.nus.edu.sg/~scarlett/",
        "dblp": "00/7449;78/9667",
        "google_scholar": "jDu9ZzYAAAAJ;https://scholar.google.co.uk/citations?user=a4D08aQAAAAJ",
        "orcid": "0000-0002-9596-6726;",
        "linkedin": ";",
        "or_profile": "~Ivan_Lau1;~Jonathan_Scarlett1",
        "aff": "National University of Singapore;National University of Singapore",
        "aff_domain": "nus.edu;nus.edu.sg",
        "position": "PhD student;Associate Professor",
        "bibtex": "@inproceedings{\nlau2025quantile,\ntitle={Quantile Multi-Armed Bandits with 1-bit Feedback},\nauthor={Ivan Lau and Jonathan Scarlett},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=u5xNVJlAse}\n}",
        "github": "",
        "project": "",
        "reviewers": "Authors;Area_Chair_bAxP;exKE;FJeN;7zKk",
        "site": "https://openreview.net/forum?id=u5xNVJlAse",
        "pdf_size": 0,
        "rating": "0;0;5;5;7",
        "confidence": "0;4;5;4;4",
        "wc_review": "",
        "rating_avg": [
            3.4,
            2.870540018881465
        ],
        "confidence_avg": [
            3.4,
            1.7435595774162693
        ],
        "authors#_avg": [
            2,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            8,
            0
        ],
        "corr_rating_confidence": 0.6073977599851283
    },
    {
        "id": "uQsn9AZPwR",
        "title": "Sample Compression Scheme Reductions",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We present novel reductions from sample compression schemes in multiclass classification, regression, and adversarially robust learning settings to binary sample compression schemes. Assuming we have a compression scheme for binary classes of size $f(d_\\mathrm{VC})$, where $d_\\mathrm{VC}$ is the VC dimension, then we have the following results: (1) If the binary compression scheme is a majority vote or a stable compression scheme, then there exists a multiclass compression scheme of size $O(f(d_\\mathrm{G}))$, where $d_\\mathrm{G}$ is the graph dimension. Moreover, for general binary compression schemes, we obtain a compression of size $O(f(d_\\mathrm{G})\\log|\\mathcal{Y}|)$, where $\\mathcal{Y}$ is the label space. (2) If the binary compression scheme is a majority vote or a stable compression scheme, then there exists an $\\epsilon$-approximate compression scheme for regression over $[0,1]$-valued functions of size $O(f(d_\\mathrm{P}))$, where $d_\\mathrm{P}$ is the pseudo-dimension. For general binary compression schemes, we obtain a compression of size $O(f(d_\\mathrm{P})\\log(1/\\epsilon))$. These results would have significant implications if the sample compression conjecture, which posits that any binary concept class with a finite VC dimension admits a binary compression scheme of size $O(d_\\mathrm{VC})$, is resolved (Littlestone and Warmuth, 1986; Floyd and Warmuth, 1995; Warmuth, 2003). Our results would then extend the proof of the conjecture immediately to other settings. We establish similar results for adversarially robust learning and also provide an example of a concept class that is robustly learnable but has no bounded-size compression scheme, demonstrating that learnability is not equivalent to having a compression scheme independent of the sample size, unlike in binary classification, where compression of size $2^{O(d_\\mathrm{VC})}$ is attainable (Moran and Yehudayoff, 2016).",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Idan Attias;Steve Hanneke;Arvind Ramaswami",
        "authorids": "~Idan_Attias1;~Steve_Hanneke1;~Arvind_Ramaswami1",
        "gender": "M;M;M",
        "homepage": "https://www.idanattias.com;http://www.stevehanneke.com;https://arvindr9.github.io/",
        "dblp": "228/6803;40/154;323/8022",
        "google_scholar": "-L6uUy0AAAAJ;fEhNO7YAAAAJ;CnS_JZQAAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Idan_Attias1;~Steve_Hanneke1;~Arvind_Ramaswami1",
        "aff": "University of Illinois at Chicago+Toyota Technological Institute at Chicago;Purdue University;Purdue University",
        "aff_domain": "uic.edu+ttic.edu;purdue.edu;purdue.edu",
        "position": "Postdoc+Postdoc;Assistant Professor;PhD student",
        "bibtex": "@inproceedings{\nattias2025sample,\ntitle={Sample Compression Scheme Reductions},\nauthor={Idan Attias and Steve Hanneke and Arvind Ramaswami},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=uQsn9AZPwR}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_X2bi;wMsz;b5wq;ysvY",
        "site": "https://openreview.net/forum?id=uQsn9AZPwR",
        "pdf_size": 0,
        "rating": "0;7;8;8",
        "confidence": "4;4;1;4",
        "wc_review": "",
        "rating_avg": [
            5.75,
            3.344772040064913
        ],
        "confidence_avg": [
            3.25,
            1.299038105676658
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": -0.38837866680189276
    },
    {
        "id": "wBux6OKfjz",
        "title": "Agnostic Private Density Estimation for GMMs via List Global Stability",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "We consider the problem of private density estimation for mixtures of unrestricted high dimensional Gaussians in the agnostic setting. We prove the first upper bound on the sample complexity of this problem. Previously, private learnability of high dimensional GMMs was only known in the realizable setting (Afzali et al., 2024).\n\nTo prove our result, we exploit the notion of list global stability (Ghazi et al., 2021a,b) that was originally introduced in the context of private supervised learning. We define an agnostic variant of this definition, showing that its existence is sufficient for agnostic private density estimation. We then construct an agnostic list globally stable learner for GMMs.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Mohammad Afzali;Hassan Ashtiani;Christopher Liaw",
        "authorids": "~Mohammad_Afzali1;~Hassan_Ashtiani1;~Christopher_Liaw1",
        "gender": "M;M;M",
        "homepage": ";https://www.cas.mcmaster.ca/ashtiani/;",
        "dblp": ";164/5733;177/8862",
        "google_scholar": "https://scholar.google.ca/citations?user=N0czmGoAAAAJ;;05WRGRsAAAAJ",
        "orcid": ";;",
        "linkedin": ";;",
        "or_profile": "~Mohammad_Afzali1;~Hassan_Ashtiani1;~Christopher_Liaw1",
        "aff": ";McMaster University;Google",
        "aff_domain": ";mcmaster.ca;google.com",
        "position": ";Associate Professor;Researcher",
        "bibtex": "@inproceedings{\nafzali2025agnostic,\ntitle={Agnostic Private Density Estimation for {GMM}s via List Global Stability},\nauthor={Mohammad Afzali and Hassan Ashtiani and Christopher Liaw},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=wBux6OKfjz}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_Gs5m;okap;PAcj;kKgD",
        "site": "https://openreview.net/forum?id=wBux6OKfjz",
        "pdf_size": 0,
        "rating": "0;7;7;8",
        "confidence": "4;4;4;4",
        "wc_review": "",
        "rating_avg": [
            5.5,
            3.2015621187164243
        ],
        "confidence_avg": [
            4.0,
            0.0
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            7,
            0
        ],
        "corr_rating_confidence": 0.0
    },
    {
        "id": "xSEtk5AupG",
        "title": "Boosting, Voting Classifiers and Randomized Sample Compression Schemes",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "In *boosting*, we aim to leverage multiple *weak learners* to produce a *strong learner*.\nAt the center of this paradigm lies the concept of building the strong learner as a *voting classifier*, which outputs a weighted majority vote of the weak learners.\nWhile many successful boosting algorithms, such as the iconic AdaBoost, produce voting classifiers, their theoretical performance has long remained sub-optimal: The best known bounds on the number of training examples necessary for a voting classifier to obtain a given accuracy has so far always contained at least two logarithmic factors above what is known to be achievable by general *weak-to-strong* learners.\nIn this work, we break this barrier by proposing a randomized boosting algorithm that outputs voting classifiers whose generalization error contains a single logarithmic dependency on the sample size.\nWe obtain this result by building a general framework that extends sample compression methods to support randomized learning algorithms based on sub-sampling.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Arthur da Cunha;Kasper Green Larsen;Martin Ritzert",
        "authorids": "~Arthur_da_Cunha1;~Kasper_Green_Larsen1;~Martin_Ritzert1",
        "gender": ";;M",
        "homepage": ";;",
        "dblp": ";;194/2447",
        "google_scholar": ";;https://scholar.google.de/citations?user=ZNioUNgAAAAJ",
        "orcid": ";;0000-0002-5322-3684",
        "linkedin": ";;martin-ritzert/",
        "or_profile": "~Arthur_da_Cunha1;~Kasper_Green_Larsen1;~Martin_Ritzert1",
        "aff": ";;Georg-August Universit\u00e4t G\u00f6ttingen",
        "aff_domain": ";;uni-goettingen.de",
        "position": ";;Postdoc",
        "bibtex": "@inproceedings{\ncunha2025boosting,\ntitle={Boosting, Voting Classifiers and Randomized Sample Compression Schemes},\nauthor={Arthur da Cunha and Kasper Green Larsen and Martin Ritzert},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=xSEtk5AupG}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_zmVd;kcG4;2nc7;vEES",
        "site": "https://openreview.net/forum?id=xSEtk5AupG",
        "pdf_size": 0,
        "rating": "0;7;7;7",
        "confidence": "4;3;3;4",
        "wc_review": "",
        "rating_avg": [
            5.25,
            3.031088913245535
        ],
        "confidence_avg": [
            3.5,
            0.5
        ],
        "authors#_avg": [
            3,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            6,
            0
        ],
        "corr_rating_confidence": -0.5773502691896257
    },
    {
        "id": "zWpqMU5Vqc",
        "title": "Optimal and learned algorithms for the online list update problem with Zipfian accesses",
        "track": "main",
        "status": "Poster",
        "tldr": "",
        "abstract": "The online list update problem is defined as follows: we are given a list of items and the cost to access any particular item is its position from the start of the list. A sequence of item accesses come online, and our goal is to dynamically reorder the list so that the aggregate access cost is small. We study the stochastic version of the problem where the items are accessed i.i.d. from an unknown distribution $p$. The study of the stochastic version goes back at least 60 years to McCabe. \n\nIn this paper, we first consider the simple online algorithm which swaps an accessed item with the item right before it, unless it is at the very front. This algorithm is known as the Transposition rule. We theoretically analyze the stationary behavior of Transposition and prove that its performance is within $1+o(1)$ factor of the optimal offline algorithm for access sequences sampled from heavy-tailed distributions, proving a conjecture of Rivest from 1976. \n\nWhile the stationary behavior of the Transposition rule is theoretically optimal in the aforementioned i.i.d setting, it can catastrophically fail under adversarial access sequences where only the last and second to last items are repeatedly accessed. A desirable outcome would be a policy that performs well under both circumstances. To achieve this, we use reinforcement learning to design an adaptive policy that performs well for both the i.i.d. setting and the above-mentioned adversarial access. Unsurprisingly, the learned policy appears to be an interpolation between Move-to-Front and Transposition with its behavior closer to Move-to-Front for adversarial access sequences and closer to Transposition for sequences sampled from heavy tailed distributions suggesting that the policy is adaptive and capable of responding to patterns in the access sequence.",
        "keywords": "",
        "primary_area": "",
        "supplementary_material": "",
        "author": "Piotr Indyk;Isabelle Quaye;Ronitt Rubinfeld;Sandeep Silwal",
        "authorids": "~Piotr_Indyk1;~Isabelle_Quaye1;~Ronitt_Rubinfeld1;~Sandeep_Silwal1",
        "gender": ";F;F;M",
        "homepage": "https://people.csail.mit.edu/indyk/;;http://people.csail.mit.edu/ronitt/;https://sandeepsilwal.com",
        "dblp": "i/PiotrIndyk;;;225/4637",
        "google_scholar": "oOwNKsAAAAAJ;;https://scholar.google.com.tw/citations?user=pZhZndYAAAAJ;MnDnUvcAAAAJ",
        "orcid": ";;;",
        "linkedin": ";isabellequaye/;;",
        "or_profile": "~Piotr_Indyk1;~Isabelle_Quaye1;~Ronitt_Rubinfeld1;~Sandeep_Silwal1",
        "aff": "Massachusetts Institute of Technology;Apple;Massachusetts Institute of Technology;Department of Computer Science, University of Wisconsin - Madison",
        "aff_domain": "mit.edu;apple.com;mit.edu;cs.wisc.edu",
        "position": "Full Professor;Intern;Full Professor;Assistant Professor",
        "bibtex": "@inproceedings{\nindyk2025optimal,\ntitle={Optimal and learned algorithms for the online list update problem with Zipfian accesses},\nauthor={Piotr Indyk and Isabelle Quaye and Ronitt Rubinfeld and Sandeep Silwal},\nbooktitle={36th International Conference on Algorithmic Learning Theory},\nyear={2025},\nurl={https://openreview.net/forum?id=zWpqMU5Vqc}\n}",
        "github": "",
        "project": "",
        "reviewers": "Area_Chair_Pddm;Z5ct;19Go;DSqn",
        "site": "https://openreview.net/forum?id=zWpqMU5Vqc",
        "pdf_size": 0,
        "rating": "0;5;6;7",
        "confidence": "4;3;4;4",
        "wc_review": "",
        "rating_avg": [
            4.5,
            2.692582403567252
        ],
        "confidence_avg": [
            3.75,
            0.4330127018922193
        ],
        "authors#_avg": [
            4,
            0
        ],
        "wc_review_avg": [
            0,
            0
        ],
        "replies_avg": [
            13,
            0
        ],
        "corr_rating_confidence": -0.10721125348377948
    }
]